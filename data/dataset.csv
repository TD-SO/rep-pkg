PostId,Title,Body,TDR,TDTYPE,Subcategory,Urgency,Lenght,NegativeS,NeutralS,PositiveS,CompoundS
316285,Shared Purpose tables in database design ( how would *you* implement a question/answer facility ),"I have long considered the design of a database that involves shared table purposes to be somewhat a trait of smelly code, and progressively increasing proliferation of smelly-code related problems.By this I mean, people over-normalizing, using 1 table where 2 tables could be more logical, people who've just discovered what normalizing is and overuse it to the point where they virtually layer a database on a database, or trying to use hierarchical data naively to solve all their problems. The question is, when you have 2 sets of data, which appear to be the same, but they have a different purpose, do you use the same table to represent it? When do you know when it is a good idea and a bad idea to use this? I've always been of the mind that needless self-referencing tables or structures that involved any table being used twice in the same query was a very dangerous predicament, both in design, and in long term performance and ease of future improvement.That was of course, until I saw a thing or two in the RSS feeds for SO here. Now I'm not going onto a meta discussion about how SO works, but there appears to be an implicit design consideration here that challenged my thinking and want to glean a more cohesive answer on that style of logic. You'll notice the generic question has the format:   /question/1234/stuff-here-that-s-safe-to-leave-outreAnd I generally assumed that this implied that questions were numerically ordered somewhere. But here is what stumped me:I'll take for example a href=https://stackoverflow.com/questions/316210question 316210/a. If you look at the a href=https://stackoverflow.com/feeds/question/316210rss feed/a for this question, you will note there is a entry for the question, and a series of answer entries, which are functionally identical for the question entry except for a few minor differences. Now note in the answer entries also have link references, ... to questions, not the same question however, but to different questions, such as a href=https://stackoverflow.com/questions/316218/question 316218/a, which , when visited, redirects you back to the original question. Now I'm not interested in emhow/em they implement that in the code, the problem is that you have here, questions and answers appear to be sharing the same table ( hence the sequential question ID's ) , and when users refer to an answer ID, you have to first query the database, and then go hey!, oops!, that's not a question! and then proceed to do a emsecond/em query to find out the parent of that question ( in the same table ) and then redirect you to the actual question page, not to mention all the hullabaloo required with self joining queries ( which I've always considered filthy ) and conditionals all over the place to tune behavior. Less Digressing, the real problem/The problem is, here you have 2 sets of data sharing the same table, and sure, this data is superficially similar, for now at least, but there looks like there is just so much technical debt involved. The long term considerations involved with implementing new features that can apply to questions and not answers and vice versa, not to mention avoiding one being interpreted as another in some obscure corner. You can't add a new column for use in one application set without having to consider the resulting effects in another. Sure, there is a minor benefit from using the singular table and that's when you emare/em making a feature that is shared between facets you only have to code it once, but this could be just as easily represented by using an ancestor class of common methods, and child classes that bind to the specific tables for the difference cases. So at least that way, adding a new feature has no follow-on implications for the other scenario. Now I've encountered this sort of problem in many places before, sure, but SO is the most easy example to point out. When you implement your databases like this, do you share the table, or do you fork?When, and why?",TD-related,architecture,database,4,667,0.047,0.867,0.085,0.9757
401541,Serialize ASP.NET Control collection,"I've been tasked with converting an existing ASP.NET site from using InProc session management to using the ASP.NET State Server.Of course what this means is that anything stored in the Session must be serializable.One of the most complicated pages in the app is currently storing an ASP.NET control collection to the Session. This is failing miserably because the controls cannot be serialized automatically.Short of totally rewriting how the page works to prevent the need for storing the control collection in the Session, does anyone have a trick/solution for making the collection serializable?",TD-related,architecture,legacy,3,92,0.067,0.921,0.012,-0.743
431107,Spring context files organization and best practices,"We have started using Spring framework in my project. After becoming acquainted with the basic features (IoC) we have started using spring aop and spring security as well.The problem is that we now have more than 8 different context files and I feel we didn't give enough thought for the organization of those files and their roles. New files were introduced as the project evolved. We have different context files for: metadata, aop, authorization, services, web resources (it's a RESTful application). So when a developer wants to add a new bean it's not always clear in which file he should add it. We need methodology.The question:Is there a best practice for spring files organization?Should the context files encapsulate layers (DAL , Business Logic, Web) or use cases ? or Flows?",TD-related,architecture,"duplication, suboptimal_design, management, framework",2,130,0.037,0.89,0.073,0.6962
577083,Is there a point where cost of refactoring outweighs the cost of re-writing?,"We have some really shocking code touted as a next generation framework at my current place of employment.Thing is, there is only one person of this opinion and that is the guy who wrote most of it. The rest of the department are of the impression it is badly coded, a pita to debug and just a bit naff in general.The guy that wrote it has a pretty influential position with management so they are on that side of the camp.We have highlighted (genuine) concerns to management but obviously they're not willing to put more time in to a project that doesn't directly contribute to the bottom line.There are several applications deployed on this framework so any refactoring will need to encompass those applications.The whole thing is so intertwined that we cant just rip out an implementation of a particular class and rewrite it that way so even simple changes to core api mean a large project.It does however have 3 years in live deployment and many bug fixes, corner cases and boundary conditions catered for.Do we rewrite in parts and try to refactor that in given that it would be several large projects, refactor over time which is likely to take another 3 years to get it in to shape or do we just rewrite our specific requirements on top of an existing framework?",TD-related,architecture,"management, dependency",5,225,0.034,0.932,0.035,0.0571
607683,n-Tier Architecture Feedback Needed,"I started my website, like stackoverflow, with a little technical debt that I'm trying to pay off. Being a contract developer, I've been in many places and see many different methods of achieving this result, but the way I'm going is..Presentation (web)Business Layer (old fashioned entity classes and BL layer)Data Layer (DA classes to SQL Server via Stored Proc)My question primarily concerns the Business Layer. Right now I have an Entity namespace and a BusinessLogic namespace. The BL has a reference to the DA and the Entity.The Entity has a reference to the DA(The DA is unaware of the BL or Entity)I really want all my churning of turning Data into Entities to occur within the BL -- thus the Business Logic. However, I want the Entity to be able to access the BL if need be -- and thus remove the Entity's reference to the DL.So...Is is wrong to have the BL and Entity objects within the same namespace so they can work together?Essentially, I'm trying have an entity object like Employee (classic example, eh?) and have the Employee have a public Hashtable[] SubordinateEmployeesreproperty that returns a Hashtable of other Employee objects that report to this employee. But I don't want to load it until it's needed. So for most employees the property would never get accessed, but when it does, it self-loads with a call to the BL, which calls the DA.Does the question make sense?If so, does my solution? Thanks so much in advance!",TD-related,architecture,"suboptimal_design, td_resolution, churn",2,247,0.032,0.764,0.204,0.9951
836274,Coverting from Datasets to stored procs and modern ORM,"How much effort would it take to migrate a large existing codebase from a ly Typed Dataset driven data access layer to a DAL driven by stored procs and/or a more modern ORM package? Is there any shiny tool that automates a portion of this process?The current code base has well over 100+ datasets mirroring the sql database (but haven't always been 100% in sync with changes in the DB structure). The current stance is that it would be too much time/effort to change now, but I question how much technical debt this is leaving us to pay down every week. This is to say nothing of the performance on the backend of datasets' SQL vs. an optimized sproc.So, is that justified? Would something like that be too much of a monster to tackle in a reasonable time and get a worthwhile payoff? I know I could change the DAO-like classes they use to interfaces (should be already) and develop this on the side while still using the datasets in production until a feasibility test of some sort could be done on a small subset of the whole.",TD-related,architecture,"suboptimal_design, td_resolution, churn",3,188,0.025,0.876,0.098,0.9308
1263580,Persisting/caching data between requests - common approach,"I'm developing an Asp.net (MVC but this doesn't really matter) application. I have a custom IHttpModule that's responsible for the PostAuthenticateRequest to change user principal   identity.I'm storing UserID and UserName in authentication cookie when user logs-in. I have an IUser (implemented by DAO and Business Objects layer, each with their own additional members) that I need all over Business Service classes. When a user wants anything I have to provide IUser object instance (usually from Business Objects layer) so providing ID from the auth ticket isn't sufficient.So I'm thinking of how and where would be best to persist logged in user's IUser data?olliI don't want to fetch it every time from the DB (based on authentication ticket's UserID data)liI can't store it in Session since I have to work inside PostAuthenticateRequest, where Session isn't ready yetliI want all the functionality to be encapsulated within my custom IHttpModuleChoices that I see:ulliCacheliCookieli(Session) - by moving from PostAuthenticateRequest to PostAcquireRequestState event and change principal/identity there, but I'd like to avoid thisProcesses that seem to complicate things are:olliUser logs-in, user data is fetched from the DB and persisted somehow for later requestsliUser logs-out, user data has to be removed from persisted medium automagicallyliUser changes own profile, user data has to be discarded and reread on next request from the DBI wan't all these to be handled automatically by HttpModule (if possible) to eliminate developer's errors of forgetting to reset these things.What I also don't want is to write/read some hardcoded variables/keys and manipulate them in other parts of the application. This would only present technical debt.QuestionsolliWhat would you suggest?liHow does SO persist user data between requests?",TD-related,architecture,suboptimal_design,3,272,0.058,0.899,0.043,0.2206
1333438,Is there a simple framework allowing for Dependency Injection in a stand alone program?,"We basically need to be able to adjust behaviour at start-up time, by providing desired classes to be produced by various factories inside our application (to avoid the hard binding of the new operator).I am aware that this is provided by several large frameworks, but I was looking for something easily used by a stand-alone Java application without being gigantic.Any suggestions?hrEdit: It is my experience that frameworks tend to grow big as part of maturing (and complex too). I need this to be retrofittable to a legacy application as part of major refactoring (technical debt), so simplicity is essential of the used libraries. I do not mind having to do a bit of coding in our application, but it must be very visible what is going on. AOP has a tendency for moving stuff out of the way, and that may make the application harder to maintain.hrEdit: We have now reached the point where we actually need to make a decision. The application will probably live for decades so we need to make a reversible decision with a framework that will be maintained for hopefully as long. I really like the static type check available with Guice, but not that the annotations bind explicitly to Guice instead of being external like in Spring. I also like that code appears to be more concise when using Guice as opposed to Spring. We need something that is robust and helpful. We do not need more than just DI at the moment. Is there a use case that definitive says go for one of these?hrEdit 2011-07-27: The final decision was to use the JSR-330 API in code, and choose on a per-project basis if to use Spring, Guice or Weld. For stand-alone applications Guice has worked well so far as the JSR-330 implementation.",TD-related,architecture,"framework, dependency, td_resolution",2,300,0.009,0.891,0.1,0.9815
1373599,In-house Frameworks vs New C Technologies,If we have developed our own ORM framework and the framework is working fine over the years then why should we learn and use brand new .net technologies like codeLINQ or codeEntity Framework or codeNHibernate or codeCSLA.NET for our upcoming software projects?Note : New frameworks need new effort to learn and teach.Note : This is just an analogy.,TD-related,architecture,"framework, in-house",2,58,0,0.926,0.074,0.5106
1520032,Ways to circumvent a bad database schema?,"Our team has been asked to write a Web interface to an existing SQL Server backend that has its roots in Access. One of the requirements/constraints is that we must limit changes to the SQL backend. We can create views and stored procedures but we have been asked to leave the tables/columns as-is.The SQL backend is less than ideal. Most of the relationships are implicit due to a lack of foreign keys. Some tables lack primary keys. Table and column names are inconsistent and include characters like spaces, slashes, and pound signs.Other than getting a new job or asking them to reconsider this requirement, can anyone provide any good patterns for addressing this deficiency?NOTE: We will be using SQL Server 2005 and ASP.NET with the .NET Framework 3.5.",TD-related,architecture,database,2,128,0.068,0.84,0.092,0.6633
1862476,Optimizing binary tree inserts to O(1) with hash map for write heavy trees,"First of all I assume I've missed something major when thinking about this, but I still wanted to post about it to see if I really didn't miss anything, on with it...I have a pretty write heavy binary tree (about 50/50 between writes and reads), and on the way home today I was thinking about ways to optimize this, especially make the writes faster - this is what I came up with.Considering that the operation add(T, x) to add x to tree T first consists of find(T, x) to see if x already exists, and in that case it doesn't return the parent so we can add it instead of one of the parents empty leaves.What if we add a hash table as an intermediate cache to the add operation, so when we call add(T, x) what really happens is that x is hashed and inserted into the hash map M. And that's it. The optimization takes place when we somewhere else asks to find(T, x), now when we search the tree we will come to a leaf node, since x isn't inserted the tree yet (it only exists in the hash map M), we hash x and compare it to the keys in M to see if it is supposed to be in the tree. If it's found in M then we add it to the tree and remove it from M.This would eliminate the find(T, x) operation on add(T, x) and reduce it to add(M, x) which is O(1). And then em(ab)/em-use the find(T, x) operation that is performed when we look up the node the first time to insert it.",TD-related,architecture,database,4,273,0.014,0.933,0.053,0.9059
2100417,Possible to host ASP.NET MVC controllers+views within a webforms project...?,"We have a legacy ASP.NET webforms application that we're engaged in stabilising and removing technical debt from. Is it possible to take a hybrid approach - ie, can ASP.NET MVC coexist with webforms within the same web-project?Are there any gotchas for that? If it emis/em possible, I assume one just has to initialise the routes table, register the ASP.NET MVC handlers, and that's hopefully it...?",TD-related,architecture,"legacy, td_reslution",5,65,0.038,0.873,0.089,0.533
2143313,In agile development how do you deal with the less-well-architected code that results from a sprint-focussed mindset,"I work on an agile project using Scrum.Sprints have come and gone and we have fulfilled milestones successfully. The system works well enough to meet the current customer requirements. However, we are left with a system in serious need of refactoring, as much of the development was performed with little eye on the future (instead the focus was on the sprint at hand).How best to deal with this? Sprint(s) dedicated to refactoring?",TD-related,architecture,"management, software_methodology",2,72,0.016,0.791,0.193,0.9367
2278722,What to do if one detects flaw in architecture of the software,Currently our team of 11 people is working on a project on asp.net platform. Timeline for the project is of 8 months and we have already done 4 months. Now working on new functionalities we find that there are some flaws in the architecture of the system due to which we are facing lot of problems. Now whom to look-up for solving this ... the Team Lead or the Project Manager... Have you ever faced this scenario ? What is the best to do then..,TD-related,architecture,management,4,85,0.031,0.893,0.076,0.5994
2685483,Whats so bad about binding your View to Property of a Model and NOT ViewModel?,I often hear a Model must be wrapped by a ViewModel that the View is not coupled to the Model/not aware of it.With MVC it is common to bind the View to the Model... nobody complains so what ?I am frightened of creating all that wrappers and doing nearly only duplicating property stuff.,TD-related,architecture,suboptimal_design,6,53,0.101,0.859,0.04,-0.5106
2718864,Restrict violation of architecture - asp.net MVP,"It's been almost 3 years since I posted this question. I must say that I have tried exploring this despite the brilliant answers here. Some of the lessons I've learnt so far -olliMore code smell come out by looking at the consumers (Unit tests are best place to look, if you have them).ulliNumber of parameters in a constructor are a direct indication of number of dependencies. Too many dependencies = Class is doing too much.liNumber of (public) methods in a classliSetup of unit tests will almost always give this awayliCode deteriorates over time, unless there is a focused effort to clear technical debt, and refactoring. This is true irrespective of the language.liTools can help only to an extent. But a combination of tools and tests often give enough hints on various smells. It takes a bit of experience to catch them in a timely fashion, particularly to understand each smell's significance and impact.",TD-related,architecture,"pattern, dependency",2,153,0.025,0.883,0.092,0.7884
2745373,Multi-tenant Access Control: Repository or Service layer?,"In a multi-tenant ASP.NET MVC application based on Rob Conery's MVC Storefront, should I be filtering the tenant's data in the repository or the service layer?1. Filter tenant's data in the repository:public interface IJobRepository{ IQueryable<Job> GetJobs(short tenantId);}2. Let the service filtertherepository data by tenant:public interface IJobService{ IList<Job> GetJobs(short tenantId);}My gut-feeling says to do it in the service layer (option 2), but it could be argued that each tenant should in essence have their own ""virtual repository,"" (option 1) where this responsibility lies with the repository.Which is the most elegant approach: option 1, option 2 or is there a better way?Update:I tried the proposed idea of filtering at the repository, but the problem is that my application provides the tenant context (via sub-domain) and only interacts with the service layer. Passing the context all the way to the repository layer is a mission.So instead I have opted to filter my data at the service layer. I feel that the repository should represent all data physically available in the repository with appropriate filters for retrieving tenant-specific data, to be used by the service layer.Final Update:I ended up abandoning this approach due to the unnecessary complexities. See my answer below.",TD-related,architecture,"suboptimal_design, database",3,197,0.08,0.88,0.041,-0.7976
2933189,using a Singleton to pass credentials in a multi-tenant application a code smell?,"I'm currently working on a multi-tenant application that employs Shared DB/Shared Schema approach. IOW, we enforce tenant data segregation by defining a TenantID column on all tables. By convention, all SQL reads/writes must include a Where TenantID = '?' clause. Not an ideal solution, but hindsight is 20/20.Anyway, since virtually every page/workflow in our app must display tenant specific data, I made the (poor) decision at the project's outset to employ a Singleton to encapsulate the current user credentials (i.e. TenantID and UserID). My thinking at the time was that I didn't want to add a TenantID parameter to each and every method signature in my Data layer.Here's what the basic pseudo-code looks like: <code>As you can see, there are several code smells here. This is a singleton, so it's already not unit test friendly. On top of that you have a very tight-coupling between CurrentUser and the HttpContext object. By extension, this also means that I have a reference to System.Web in my Data layer (shudder). I want to pay down some technical debt this sprint by getting rid of this singleton for the reasons mentioned above. I have a few thoughts on what a better implementation might be, but if anyone has any guidance or lessons learned they could share, I would be much obliged.",TD-related,architecture,"suboptimal_design, td_reslution",5,217,0.066,0.87,0.064,0.3555
3232368,MySQL/CakePHP DB Design Question,"Our real estate application has a table, Events, which has historically been linked to the Homes table via an Event.homes_id column.Recently, for the first time, we added an event type which is not connected to a home, but a realtor. The question: is it good practice to now add a realtor_id column to the Events table? Something in me rebels at the idea of having two columns, home_id and realtor_id for every record, one of which will always be null for any given record. My boss says it's efficient and avoids the overhead of creating new tables. What are the rights and wrongs of this situation?A corollary to the above question: part of our reluctance to create new tables is the fact that we're using CakePHP, and so it becomes harder to have absolute control over multiple linked tables via SQL joins. (Setting Cake's recursive property to maximum reduces the application's speed to a crawl.) Does, and should, working with Cake affect database design considerations? Or are we just working with Cake wrong?",TD-related,architecture,suboptimal_design,3,173,0.062,0.863,0.075,0.5362
3666526,How to deal with internal company frameworks and SW factories?,"Based on my own experience and on experience of my friends I see that many companies have some strange ideas to develop their own frameworks and SW factories (builds skeleton of application for you). These ideas are usually based on belief that own framework will be much better than anything else available. How to deal with such ideas and how to explain that it is not always good way to go?Why I think internal frameworks / factories are not good:ulliBudget   Resources - There is usually only some initial budget to create framework. Nobody thinks about budget needed to maintain and support framework. Nobody can even estimate budget and resources needed for maintaing. At the beginning nobody thinks about maintaining multiple versions of framework to support already existing applications.liLack of experience - Framework is usually created by people without any such experience or with support of consultants - generally much more expensive people with similar skill set.liArchitecture / design - any architectural problem in framework affects all applications build using this framework. Bad design decissions in framework force developers to code applications in the bad way.liTechnical debt - bad code in framwork is technical debt.liFalse belief of silver bullet - managers believe that own framework / factory is silver bullet. All application will be written in the same way and it will be easily maintainable. My experience is that it is simple not truth. Even with SW factory each application is specific.liInsufficient documentation - documentation is first part affected by low budget. Framework without documentation is useless. Reflector (.NET) is my best friend.liInsufficient user group - internal framework has only small user group. Small user group means small experience. If I'm using public tool / framework and I have a problem, I can ask question on SO (or similar web) or just try to find answer on google. With internal framework it is not possible.liPolicy - company policy force you to use the framework to vindicate framework costs. This goes so far that the framework is chosen before the first requirement is gathered.liComplains to framework are prohibited.liUsage of other frameworks is prohibited.Why I think companies are doing this:ulliArrogance   egoism - sombody in company believes that he can do it better. liIgnorance - ignoring existing frameworks / solutions and the fact that only good frameworks survived long enough to be popular. Ignoring user group and already available informations on the Internet.liManagement failure and incompetence - not understanding the impact (especially long term) of this decission. Decission based on incorrect informations. Management without SW development background.I understand that sometimes own solution or framework for specialized scenario is needed but I'm tired with all these great internal frameworks for creating web or desktop applications. Am I wrong? Are these frameworks really needed (.NET and Java world)? Can you provide me some example or reason why it is good to have internal framework / factory?Edit:Thanks for answers but I expected some advice how to deal with a problem as a developer (except changing a job) not as a manager.",TD-related,architecture,"framework, in-house",4,504,0.087,0.842,0.072,-0.8312
3855895,Algorithms that lead to java.lang.OutOfMemoryError: PermGen space error,"I am getting PermGen space error on Sun JVM (1.6.0_21-b06) (Ok, it's Oracle :)). Increasing of option -XX:MaxPermGen value does not help. I know that PermGen is a space intended for permanent objects like class metadata. Count of classes in project is not so big ~ 10 000. Before crash jvisualvm shows 57MB as Used PermGen.I guess that some algorithm occupies all accessible memory. Does someone know examples of algorithms that lead to PermGen overflow ?UPD. I ask such abstract question, because in the moment I can not use any profiler - code crashes so hard that jvisualvm and eclipse stop to respond. I need than kill java processes from terminal with kill -KILL {process_numer}. I work with bad organized (but commercial) code that has many threads and JMS messaging. Debugging is a mess - I need some idea first where to look.",TD-related,architecture,td_reslution,2,143,0.208,0.761,0.031,-0.9811
4380791,"Do I need to use DDD, Unit of Work, Repositories or something similar for simple web apps?","I'm working on a simple eCart system using .net4 (c). I've been doing a lot of reading about Unit of Work Pattern, Repository Pattern, and Persistence Ignorance. I think I have a grasp on the strategy and benefits to building my layers this way, but for my simple app I'm wondering if it's necessary and if anyone can point me towards good architecture for my scope.Please correct me if I'm wrong - the main benefits to using repositories are to create fewer trips to the DB and to separate application architecture from DB architecture. IE - what's good for DB performance isn't always good for application design so it's best to design what's best for both and then create an interface between the two.So here's the question - I want any business transaction that occurs to be saved to the DB as soon as it occurs, so there doesn't seem to be a point in queuing data in repositories and then saving it immediately. Why not just save it directly?Are there other benefits of DDD that I'm missing or would it be over engineering to build out such a robust architecture for every simple project that comes along? Thanks for any help.",TD-related,architecture,suboptimal_design,2,202,0.051,0.723,0.226,0.9922
4398584,How to Manage Sessions in Restful WCF Service,I want to manage Sessions with client apps of my Restful WCF Service. Client app can be a J2me application or a .NET application.What is the recommended way of maintaining sessions in RESTFUL WCF service?Idea is to recognize that the request is coming from an already authenticated client.,TD-related,architecture,interface,2,48,0,0.823,0.177,0.7804
4417655,Rails: PolyMorphic or STI or something else for User management?,"I've been banging my head against a wall trying to wrap my head around this, so any guidance would be much appreciated...I want to have a User system setup to reflect the following hierarchy: User|- email address|- password|- billing information|- contact information|- account preferences||=   Agent|=   - agent-specific information|=   - has_many Users|=   - belongs_to Manager||=   Manager|=   - manager-specific information|=   - has_many Agents, Users||=   Administrator|=   - can manage everythingreI already have a codeUser model with a href=https://github.comlataformatec/devise rel=noreferrerDevise/a and a href=https://github.com/ryanb/cancan rel=noreferrerCanCan/a setup to handle authentication and authorization, so I know how to use roles to restrict the type of user to specific actions, and so forth.What I'm lost at is how to organize these sub-class relationships both in my Rails code and in the database. As you can see from above, codeAgent, codeManager, and codeAdministrator all share the information contained in codeUser, but each has additional functionality AND information associated with it.I've read some about a href=http:/.alexreisner.com/articles/single-table-inheritance-in-rails.html rel=noreferrerSTI/a, a href=http://asciicasts.com/episodes/154-polymorphic-association rel=noreferrerpolymorphic associations/a, and a href=http://asciicasts.com/episodes/163-self-referential-association rel=noreferrerself-referential associations/a. If I use STI, the codeUser table would have to contain fields for all of my [codeAgentManagerAdministrator]-specific information, right? That would make my codeUser table huge, which is something I'd like to avoid. Conversely, if I use polymorphic, then wouldn't I have to duplicate all the common information in codeUser across all the other types of codeUser subclass tables?And to add to my confusion, I can't wrap my head around how the answer to the above question would work with the relationships between the subclasses (as in, that a codeManager has_many codeAgents, but both are subclasses of codeUser...??).I would really appreciate someone setting me straight on this through a detailed answer that gives due consideration to code readability and data integrity, that explains simply (as if to a Rails newbie) why A is the best approach and why B or emn/em is--by comparison--not a good approach for this situation, and that gives example code to implement the relationships described above. I want to solve this problem, but more importantly, I want to learn emwhy/em the solution works!",TD-related,architecture,"suboptimal_design, interface",4,343,0.038,0.845,0.117,0.9791
4449814,"When should and shouldn't I extend a class, and is it valid for MVC?","I am considering using class extension as a way to connect my model with my controller. I tried looking on the internet but could not find any information on this topic. This led me to the question of when a class should be extended and for what reasons.This is my plan:model classcontroller extends modelnew controller();new view(controller);Reason: I can make all methods and variables that the view should not touch or alter protected (i.e. protected var myVar:String). This enables me to ensure that the view still has access to the data it needs but is unable to make accidental changes.
This whole thought process derived from the fact that I don't want my view to have any influence whatsoever, while still remaining independent (i.e. I can have multiple views of the same model without having to tell the controller that an additional view has been added).To summarize:When should aclass be extended? When should it be avoided?Is my plan a valid implementation of MVC?Is there a better way to disconnect the view in a way thatmeets my demands?Thank you for reading till the end.",TD-related,architecture,"suboptimal_design, pattern",2,181,0.015,0.89,0.095,0.9507
4523197,"MongoDB tips, tricks and gotchas","I've used MongoDB (and tried MongoMapper and Mongoid adapters with Rails) for a few months now. I was previously deeply entrenched in SQL. Here are my observations:ulliThe lack of a schema and migrations doesn't mean you get a free lunch. Your application code will have to carry the logic and constraints that SQL schemas take care of. You'll have to be a lot more disciplined to manually migrate data, e.g. when you rename an attribute, or else your application code has to deal with multiple names for the same thing (in this example). This could easily lead to a lot of junk in the database and/or obscure errors. MongoDB is great because you don't have to define a priori what the stuff is you're going to store, and you can put entire arrays and object hierarchies into any attribute. In some ways that ease of use comes with a lot less safety, and I think we're still evolving a lot of the best practices around how to avoid building up a lot of technical debt here.liNo joins -- that means you kind of have to know your data access patterns (at least the ones that need to be scalable) when you design your collections.liNo transactions -- this opens the risk of race conditions if the same records in a collections are updatable from concurrent requests. For single-collection updates there are atomic operations, and these are particularly well supported and used by Mongoid (but not by MongoMapper).li16MB record limit for any record. Unlike codetext fields in SQL which can take arbitrary-size content, MongoDB has a hard limit of 16MB for any record. This is worth a consideration as you're planning to store, e.g. large arrays, object hierarchies, etc.",TD-related,architecture,"database, concurrency",2,287,0.043,0.86,0.097,0.953
4553553,Advantages / Disadvantages of Frameworks,"I am really interested in peoples experiences with Frameworks, what they have found to be the advantages/disadvantages. I know its not a programming question per-say but it is to help me to decide what frameworks are worth investigation and what aren't. emSummarised: why would you use a framework rather than a neat programming language?/em Many Thanks, J",TD-related,architecture,framework,1,57,0,0.745,0.255,0.9408
5814032,should table relationships be used if not required,"i'm working with an existing client-side legacy database that we're converting to MySQL for online use.it's effectively one giant table, and no relationships exist.for each record, there are several contact points - first name, last name, title, street, city, state, zip, etc., repeated for several entities. my initial thought was to separate each of these entities into it's own table with the above mentioned columns, and use FKs to link them up with traditional joins, etc.but, after going through the entire dataset and talking with the original author, it turns out that none of these contact points will ever repeat (each will be unique to each record), nor is any other information related to these contact points.so - AFAICT - there's no real 'use' for relationship tables, except possibly semantics or transparency. the dataset isn't huge but it's not small either (between 50,000 and 100,000 records), so i wonder if if fact it might be more efficient to just keep the single-table structure intact and skip joins altogether.is there any reason to use separate tables in a situation like this?tyia",TD-related,architecture,"legacy, database",2,180,0.025,0.903,0.071,0.8594
5834540,Raw SQL vs OOP based queries (ORM)?,"I was doing a project that requires frequent database access, insertions and deletions. Should I go for Raw SQL commands or should I prefer to go with an ORM technique? The project can work fine without any objects and using only SQL commands? Does this affect scalability in general?EDIT: The project is one of the types where the user isn't provided with my content, but the user generates content, and the project is online. So, the amount of content depends upon the number of users, and if the project has even 50000 users, and additionally every user can create content or read content, then what would be the most apt approach?",TD-related,architecture,database,3,111,0,0.942,0.058,0.6662
5895805,Properly calling the database from Model in an MVC application?,"I'm building a tiny MVC framework for learning/experimenting and small project purposes. I needed to find out the basics of the internals of the Model since a full MVC framework and ORM is overkill for just a few database calls. Class Model{}reUsing an empty class where would I have to call a codenew PDO object for database calls?What would calling a query look like inside the Model?Additionally, where can I find a beginner's web/book resource to MVC (with lots of example code)? I've heard a lot of terms such as business logic and database logic. I remember reading somewhere that you should separate business logic and database logic. I can understand the concept somewhat, I just wonder what it looks like or what they mean in code itself. I'm confused how business logic and database logic should be separated but still be inside the Model.I'm mostly looking for code/logic examples as answers, except maybe the latter paragraph.",TD-related,architecture,pattern,3,157,0.021,0.952,0.027,0.2477
6085989,No foreign key constraints and need to do a complicated delete,"I have a website which I have been working on creating very rapidly, and now am paying back some technical debt. I have a complicated issue:My site deals with scheduling hikes. Once you create a hike, it has many things associated with it:a message board, list of attendees, the group it belongs to, the carpool, route, trailhead, etc.Here is an example so you can see what I am talking about:a href=http://www.comehike.com/hikes/scheduled_hike.php?hike_id=172 rel=nofollowhttp://www.comehike.com/hikes/scheduled_hike.php?hike_id=172/aThe technical debt I am talking about is that I never made foreign keys in the DB, and now need to do a cascade delete, and I am not sure how to go about it so that I don't introduce a million bugs :)Should I make foreign keys for all the tables now? How should I do this?Thanks,Alex",TD-related,architecture,"database, td_reslution",4,129,0.065,0.899,0.035,-0.5606
6264007,TDD: possible to bootstrap when enhancing existing large app?,"Chapter about TDD from Martin's Clean Code caught my imagination. However.brThese days I am mostly expanding or fixing large existing apps.brTDD, on the other hand, seems to only be working only for writing from scratch. Talking about these large existing apps:br1. they were not writted with TDD (of course).br2. I cannot rewrite them.br3. writing comprehensive TDD-style tests for them is out of question in the timeframe. I have not seen any mention of TDD bootstrap into large monolite existing app.The problem is that most classes of these apps, in principle, work only inside the app.brThey are not separable. They are not generic. Just to fire them up, you need half of the whole app, at least. Everything is connected to everything.brSo, where is the bootstrap ?Or there is alternative technique with results of TDDbrthat'd work for expanding the existing apps that were not developed with TDD ?",TD-related,architecture,"dependency, management",2,147,0.034,0.912,0.055,0.4871
7708598,validation rules in mvc 3.0,I have one view model which is common for 3 to 4 views in this model I also define validation rules.Now problem is that in one of that view I want to overwrite that view model validation rules for two to three fields.so what I do? I don't want to make new view model for that view.,TD-related,architecture,"pattern, suboptimal_design",3,57,0.052,0.899,0.05,-0.2732
7761027,Using NoSQL database for relational purpose,"Non-relational databases are attracting more attention day by day. The main limitation is that today's complicated data are indeed connected. Isn't it convenient to connect databases as we connect tables in RDBMS? Of course, I just mean simple cases. Imagine three tables of Articles, Tags, Relationships. In a RDBMS like Mysql, we can run three queries to 1. Find ID of a given tag2. Find Articles connected with the captured Tag ID3. Fetch the contents of Articles tagged with the termreInstead of three queries, we perform a single query by JOIN. I think three queries in a key/value database like BerkeleyDB is faster than a JOIN query in Mysql.Is this idea practical? Or other issues are involved to ignore this approach?",TD-related,architecture,"database, td_reslution",3,121,0.037,0.848,0.115,0.8691
7765070,RedBean ORM performance,"I would like to know, can Redbean ORM be used for performance oriented scenarios like social networking web apps, and is it stable even if thousands of data is pulled by multiple users at same time? Also I'd like to know whether Redbean consumes more memory space?Can anyone offer a comparison study of Doctrine-Propel-Redbean?",TD-related,architecture,"framework, database",3,54,0,0.824,0.176,0.8496
7803282,Strategies for migrating live site to MVC structure?,"There is a lot of good content on SO about MVC and getting started with MVC, but I'm having trouble finding anything about how best to implement MVC structure on a pre-existing, live website.My site is a nasty mishmash of echos and concatenated HTML that would make any professional programmer throw-up, embut it works./emI'd like to spend some time tackling the mounting technical debt, however, and that means moving to a much more sane MVC structure.If at all possible, I'd like to avoid a emlet 'er rip!/em 100% rewrite and launch approach, and instead take it a section at a time. But it seems the basic controller's centralized structure is not suitable for such an approach?",TD-related,architecture,"pattern, management",3,116,0.114,0.777,0.11,-0.1386
8206212,Running two django app on apache with very similar files (project and project_development)," have a django app runs on Apache with mod_wsgi and my wsgi file looks like : <code>However, in my 'views', 'urls', 'models','forms' and other python files import necessary classes asfrom pr1.main.models import Country,City, Monthsfrom pr1.employer.modelsimportEmployerStatus...However,when I try to run pr1_developer application I need to change the headers like from pr1.main.. to pr1_developer.main.. ineveryfile.Otherwise pr1_developer runs the modules from pr1.As you except, I don't want to create two different files for each project but how can I overcome such difficulty ?One approach may writing from main... instead of from pr1.main... however, I am not sure if it is a good way to do this.I am appreciated for any suggestion.",TD-related,architecture,duplication,3,108,0.072,0.822,0.105,0.6946
8743937,Practical example of architecture using EBC?,"I was intrigued by Robert Martin's talk about ""Architecture: The Lost Years"". In it he discusses the Entity, Boundary, Control design pattern on which MVC is based. I love the idea of deferring architectural decisions. He described deferring the decision about how to implement the DB layer in his own wiki app FitNesse. I have organically deferred decisions like this in my own coding, though there wasn't a preconceived modular design that brought this about.I want to better understand this EBC architecture (which seems closely related to DCI) from a practical standpoint so that I can begin using in a small project. I want to capitalize on ""deferring decisions"" and the ability to swap out aspects of the design like the UI.Rails, for example, uses a form of EBC (MVC) but it's so heavily baked in that one could not easily substitute an alternate UI thus converting a Rails app to a console app or a desktop app. The intriguing thing about design for me is this ability to transform applications by swapping one thing out and plugging another in. That is, I wonder at the idea of designing an architecture so that one can, in a manner of speaking, swap out the UI or the persistence layer. I feel that if the architecture is well designed, the coupling will be low, and such a feat will be within grasp.I've ordered the book by Ivar Jacobson that Bob mentioned in his talk. I've search online quite a bit but all of the examples I've found show simple diagrams. I speak code. I would benefit more from looking over a few simple classes that demonstrate the concept and show how one might swap out one layer (UI, DB) for some other implementation through the use of boundary classes.If someone can't point me to a good resource illustrating this, would this be hard to whip up? Maybe we could use the standby example used in lots of software books: a video rental store (almost a relic these days). Please demonstrate how the UI or DB layer could be swapped. One thing that's confusing me is views. I can't tell from the diagrams I've seen if the views are the boundary classes themselves or if they just communicate with them. Also, Bob mentioned that the original intent of EBC was that we'd have lots of micro-views not a single macro-view (as we do in typical MVC); I'm curious what this might look like. (I prefer Ruby or JavaScript but, as beggars can't be choosers, any example would be fine.)
Thank you.",TD-related,architecture,"pattern, management",2,427,0.034,0.872,0.094,0.9775
9544102,Link to foreign key in JQGrid,"I have designed my jqgrid viewmodel as follows,
<code>
And I am binding the datasource to using my controller as follows.
return gridModel.DomainsGrid.DataBind(hmEntity.DomainProducts);
in the above model, instead of my ClientId, how can I bring ClientName from my Client table?",TD-related,architecture,"pattern, database",2,36,0,1,0,0
10113615,Salesforce SOAP vs REST,"I have been building a console app the uses the Saleforce SOAP API, and now need to use the Salesforce API in a web app.Am I correct to assume that SOAP is better suited for a non web-based app, and REST is better for a web app?If I where to create a wrapper that would be used in either reporting from local apps, or posting to salesforce from our websites, should I expose both the REST and SOAP api's, depending on what the app is? Or should I just stick to using one? What are deciding factors I should look at if I just need to pick one?",TD-related,architecture,framework,2,108,0.016,0.898,0.086,0.8053
10283592,"A BaseModel in PHP MVC, good or bad?","I'm writing my own MVC framework in PHP, just for learning purposes. It wasn't really hard to have a router/dispatcher class to call the right controller/action etc.
But now i'm at the part where i'm going to use models. Or actually, the model layer. But there's something that confuses me.
Alot of other MVC frameworks have a 'BaseModel'. I've read that this is actually bad practise, because the ""Model"" shouldn't be seen as another class. But as a real 'layer', which can contain things like the 'mapper' pattern or 'repository' pattern etc.
But to be honest, i don't see any advantages in that. To me, a 'BaseModel' class seems to be the fastest way to go, with the same results.
I can simply do something like:
<code>
But if i'd go for a repository pattern then i have to create the following: Repositories Entities DAO
Entities have Aggregates to other repositories. So basically i'm manually writing out my entire database scheme to objects...
In the end, what's the difference??? Except that i probably could have saved alot of time by simply using a BaseModel class...
But why is it still considered to be a bad thing then?? It's not that the repo pattern decouples my application more then i'm doing now. Because to me, those patterns mentioned above seem to be highly overrated. It probably would only work in an application that has a shared state; Save objects locally (in the repository) and commit them later on.
That's why i think no one can really answer this...
But i'm still hoping to see a decent answer that makes me go: ""ahhhh... What was i thinking...."". But if not, then i'm sure about my case that the BaseModel isn't a bad thing at all and that most bloggers are just a bunch of sheeps :-)",TD-related,architecture,pattern,3,293,0.076,0.814,0.11,0.8823
10485120,Good Coding Practices,"I am working on my 2nd project with Entity Framework and I would like to read some opinions about if the code below its good coding practice of not.My proposed architecture is this:img src=https://i.stack.imgur.com/LP6bl.png alt=enter image description hereSo, the website calls the business logic, business rules are evaluated there.THen it calls the DALFacade, its just that its invisible for the upper layers whether if we are accessing db2 or sql server.The EF DAL, its the one in charge of talking with database, CODE FIRST Approach.The entities class library is the project with the poco classes.Utilities its self explanatory, I might put there code like reading properties from active directory.SO here is my code, I simplified it as much as I couldOnePage:<code>Then in the EF Dal class library I use the traditionary EF 4.1 Code First Approach.I used also Repository Pattern and Unit of Work.Any observation is welcomed",TD-related,architecture,pattern,2,147,0,0.913,0.087,0.9001
10734197,PHP best orm in terms of performance?,"Which one of these is the best ORM for PHP in terms of performance? I'd like to use it in Codeigniter framework as well. I'm trying php-activerecord right now, and it doesn't act bad. I took a look to Doctrine2, DataMapper and stuff, but I cannot tell anything about performances until I build a big project (and at that time, it would be too late to change my mind).Any thoughts?",TD-related,architecture,dependency,3,70,0,0.883,0.117,0.7339
10805577,Fluent NHibernate with a weird relationship,"<code>A Manager is an Employee, also meaning that a ManagerId is an EmployeeId. There is only one manager to one employee and one employee to one manager.I have to figure out the NHibernate Fluent class map that can fill the Manager class above; Any help on how this would look is greatly appreciated!!!Please keep in mind this is a model/table that I've inherited with to much technical debt to make changes to it (from a time standpoint).-Jessy Houle",TD-related,architecture,dependency,2,78,0.032,0.923,0.045,0.2677
11335677,"When using an ORM to represent a table, is it wise to have non-table specific functions?","For example (not verbatim) /<code>Or should the ORM just be the table, and nothing more?This could be a subjective view, as everyone has their own opinions, but in programming there and things you do and things you really shouldn't do. I was just wondering if this is one of those cases.",TD-related,architecture,database,3,51,0,1,0,0
11542153,How do I abstract the domain layer from the persistence layer in Scala,"UPDATE: I've edited the title and added this text to better explain what I'm trying to achieve: I'm trying to create a new application from the ground up, but don't want the business layer to know about the persistence layer, in the same way one would not want the business layer to know about a REST API layer. Below is an example of a persistence layer that I would like to use. I'm looking for good advice on integrating with this i.e. I need help with the design/architecture to cleanly split the responsibilities between business logic and persistence logic. Maybe a concept along the line of marshalling and unmarshalling of persistence objects to domain objects.
From a SLICK (a.k.a. ScalaQuery) test example, this is how you create a many-to-many database relationship. This will create 3 tables: a, b and a_to_b, where a_to_b keeps links of rows in table a and b.
<code>
Or, something like that. I have my ideas on how I might approach this in Java, but I'm starting to realize that some of my object-oriented ideas from pure OO languages are starting to fail me. Can anyone please give me some pointers as to how approach this problem in Scala.
For example: Do I create simple objects that just wrap or extend the table objects, and then include these (composition) into another class that manages them?
Any ideas, guidance, example (please), that will help me better approach this problem as a designer and coder will be greatly appreciated.",TD-related,architecture,pattern,3,246,0.057,0.788,0.155,0.9773
11743189,Single-Source/Multi-Project template,"I would like to create a multi-project template for Visual Studio 2008 which contains two projects that access the same source files (single source for mobile and desktop development). The following multi-project template:
<code>
After some playing around with the template XML I doubt that it is possible to create such a template. Has anyone already achieved this?",TD-related,architecture,suboptimal_design,3,56,0.042,0.817,0.142,0.6124
11780345,Quick and Dirty Solution to Load Balancing Batch Jobs,"We're developing a web app and are coming to the end of development, and the client we're working with has suddenly sprung the fact on us that we will need to be able to handle load balancing.We have batch jobs running which would need to run on both servers, but we don't want them to overlap. They are selecting rows from the database, processing the objects, and merging them back into the database. One of these jobs MUST run at the same time each day, though the others run every n minutes. We have about a week at most to get something working, and it'll become technical debt for us.My question is: what quick and dirty hacks exist to get this working properly? We have a SQLServer 2008 instance and are running Java EE 6 on JBoss 5, which will be load balanced between two servers. We're using Spring 3 and JPA2 backed by Hibernate, and using the stock spring scheduler to schedule and run the jobs. Help me Obi Wan Kenobi; you're my only hope!",TD-related,architecture,"concurrency, management",6,176,0.047,0.905,0.049,0.105
11979717,System architecture for an online service serving a large number of users from multiple countries,"I really want to understand how a web system architecture would look like for a website thatolliProvide an online service with tens of thousands of users at any timeliProvide support to multiple languages so that people from many countries can use itBasically, I would like to know what considerations have to be taken. Distributed servers (servers in other countries)? Add failover? How is thing whole thing going to work?I notice that google has google.com, goolge.run, google.cn, etc. What is the rationale behind this? Does each web address serve different or same content?Any pointer or info is really appreciated.Regards.",TD-related,architecture,pattern,3,98,0,0.898,0.102,0.8501
12680062,AutoMapper - Convert two entity objects to a single DTO,"I have two EntityFramework models that I want to combine into a single DTO. Is there a way to do this? There are a couple ideas in the following question, but you would either have to create a composite model, or lose the ability to call Mapper.AssertConfigurationIsValid to verify all of the properties will be set.a href=https://stackoverflow.com/questions/2127786/is-it-possible-to-map-multiple-dto-objects-to-a-Is it possible to map multiple DTO objects to a single ViewModel using Automapper?/asingle-viewmodel-using-automappe",TD-related,architecture,pattern,2,70,0.051,0.847,0.102,0.3736
13051281,Architecture event driven advice,Lately I have upgraded my application work in an event driven architecture using Spring3.1I was wonder what do you think:ollihaving a DAO instance in each class which has the need of inserting/updating/etc record in the DB.(regular way) lishall I send messages to DAO(via jms/channels/whatever) and the message's content will be the instructions of what I should do (inserting/updating/etc record in the DB)how way number 2 is good in a loose coupling manners?maybe it's overkill ?this or any other suggestions or advice are welcome.thanks.ray.,TD-related,architecture,database,2,83,0.028,0.915,0.056,0.3094
13287499,How bad is it for a UIView to hold information on the Model (Business Object),"This question is specific to iOS development. Imagine you use codeUITableView and inside the codeUITableViewCells you show information regarding one or more of your application business objects through a bit more complex class that we'll call codeComplexBOView. Now you want to trigger a specific action when the user taps this view contained in your codeUITableCellView (the event can be triggered through a codeUITapGestureRecognizer)Most of the time what is considered best practice is to use the codetag property of the codeUIView to actually go back to your model and retrieve the correct business object.This often is suitable but in some cases it can come very handy to hold a pointer to the business object used to built your codeComplexBOView. @interface ComplexBOView : UIView{ UILabel* lblSummary; // .... UITapGestureRecognizer* tapGesture; NSObject* businessObject_;}@property (nonatomic, readonly) UITapGestureRecognizer* tapGesture;@property (nonatomic, assign) NSObject* businessObject;reThe idea behind this, is to actually directly go back to the businessObject when the user tapped the view.Two questions hereulliIs it really bad to have NSObject* information inside the UIView ?liShould this information be retained meaning the relationship between the view and the model becomes here much er (ownership of the view towards the object) ?Thanks for your advice.",TD-related,architecture,"pattern, suboptimal_design",2,197,0.026,0.929,0.045,0.2312
13660154,Best table structure for users with different roles,"We are working on a website which will feature about 5 different user roles, each with different properties. In the current version of the database schema we have a single emusers/em table which holds all the users, and all of their properties.The problem is that the properties that we need differ per user role. All users have the same basis properties, like a name, e-mail address and password. But on top of that the properties differ per role. Some have social media links, others have invoice addresses, etc. In total there may be up to 60 columns (properties), of which only a portion are used by each user role.In total we may have about 250,000 users in the table, of which the biggest portion (about 220,000) will be of a single user role (and use about 20 of the 60 columns). The other 30,000 users are divided over four other rules and use a sub-set of the other 40 columns.What is the best database structure for this, both from a DB as a development perspective? My idea is to have a base emusers/em table, and then extend on that with tables like emusers/em_ emmoderators/em, but this may lead to a lot of JOIN'ed queries. A way to prevent this is by using VIEWs, but I've read some (out-dated?) articles that VIEWs may hurt performance, like: a href=http://www.mysqlperformanceblog.com/2007/08/12/mysql-view-as-performance-troublemaker/ rel=nofollowhttp://www.mysqlperformanceblog.com/2007/08/12/mysql-view-as-performance-troublemaker//a.Does the 'perfect' structure even exist? Any suggestion, or isn't this really a problem at all and should we just put all users in a single big tables?",TD-related,architecture,database,2,255,0.038,0.883,0.078,0.8559
13834806,Develop layers first having in mind transition to Dependency Inversion principle and Inversion of Control at a later stage?,"I have a base applicaiton that will evolve. Right now UI includes BLL. DAL is a separate library that serves its purpose.I dont have time to do everything right now, so i want to bypass patterns that help with decoupling (IoC , DI as i have been proposed a href=https://stackoverflow.com/questions/13796656/removing-data-access-layer-coupling-from-user-interfacehere/a).I would like to create my BLL and have a reference for the DAL directly. This will give me the opportunity to start creating separate UIs that i need now.My question is can i do it? Can i focus right now in creating my 3 layers and gradually apply design patterns to make my code better?Added Info:I have the luxury of the time because my first app will not be used during the development of the second one. So i will have the time to optimize my coding structure. The question what i can do know to split UI into UI + BLL as effective as i can . On my mind is that i will just move the DAL init in BLL and put in UI the BLL init. Is there something else i can do that it will help me more when applying IoC/DI later on?",TD-related,architecture,"pattern, dependency",2,197,0,0.867,0.133,0.9712
13965073,Any value gained in converting a legacy code base from VB to C?,"Quick searches on the topic result in articles such as:ullia href=http://www.simple-talk.com/dotnet/.net-framework/10-reasons-why-visual-basic-is-better-than-c/ rel=nofollow noreferrer10 Reasons Why Visual Basic is Better Than C/alia href=http://www.vbrad.com/article.aspx?id=65 rel=nofollow noreferrerTop 10 reasons VB.NET is better than C/a (old article)a href=https://softwareengineering.stackexchange.com/questions/1180/vb-net-vs-c-debateThis thread/a over at the programmers stack exchange even presents some interesting and humorous arguments but most center around culture, syntax, and learn-ability. a href=http://geekswithblogs.net/GruffCode/archive/2012/12/13/converting-vb-.net-to-c-a-post-mortem.aspx rel=nofollow noreferrerThis article made the technical debt argument for why they performed the conversion./a Basically, everyone wanted to stop using VB.NET.I don't expect to drastically change the code base of a legacy system for any of the above reasons. However, the current system has major issues: poor performance and substantial logic errors. But this alone does not merit a conversion, does it? It should also be noted that the developers are equally  in each language so that doesn't have a bearing on the question.Are there any substantial benefits, such as performance gains, that would be achieved by converting 65K lines of code from VB to C? After my research, I'm not convinced that a conversion would be beneficial.",TD-related,architecture,"legacy, td_reslution, management",2,176,0.135,0.755,0.11,-0.792
14054672,What are the best practices of custom application Wordpress development?,"I have a mid size project that I need to implement on Wordpress. I am fimiliar with MVC but don't know if I can use it in conjunction with Wordpress?I intent to use wordpress loaded images, Menus and theme only from the wordpress every thing else particularly pages ( that are going to be linked with menus) isolated from wordpress. So whenever a page is requested WP controller delagates control to my controller. This is getting me headache !!!",TD-related,architecture,"pattern, suboptimal_design",2,79,0.038,0.904,0.058,0.3665
15083342,SQL statements vs MVC data access layer in PHP,"Modern MVC frameworks have their own implementation of data access layers that do not require SQL statements to be written. In terms of performance and scalability, are there any drawbacks, for instance, when using<code>instead of using prepared statements in raw SQL like $user = DB::connection()-  pdo-  prepare(SELECT * from users where `email` = ? ) ;reSince MVC frameworks like Laravel and Cakephp also allow the latter approach, I am not sure which of the two method is better in terms of performance and scalability.",TD-related,architecture,database,2,84,0.023,0.841,0.137,0.8289
15348870,We shouldn't have Segregated Core unless domain model is very complicated?,"Evan's book, pg. 430:block e Therefore, although this example may not be complicated enough to drive us to a Segregated Core .../block ea) Is author implying that unless emdomain model/em is very complicated, we shouldn't have a emSegregated Core/em? In other words, unless dealing with emcomplicated domain model/em, a emCore Domain/em should exist only in a emform of a documents/em ( ie emDomain Vision Statement/em and emHighlighted Core/em ), but should not be manifested as ema separate physical entity/em?thank you",TD-related,architecture,pattern,2,80,0,0.975,0.025,0.2168
15734485,Is there a reason for using the Repository pattern with Entity Framework if I know I will only ever use EF?,"From reading various books and articles, I seem to rather often find the usage of the Repository-pattern suggested. I get the point if you need to be able to swap out your data layer from one to another, but my question is, if I know with 100% certainty that I will not use any other tech for data access, is there any reason for using said pattern?The thing that I find myself doubting the most is that I don't really see what this extra layer of abstraction can bring to the table in this scenario. From my experience, EF with its fluent linq-to-entities -functionality should be more than enough for pretty much all my needs.The most usual cases seem to start the repositories with methods such as FindAll, Find, Add and Delete, all of which are very easily accessible directly through EF (so no code duplication to speak of).So am I just missing some big point, or is the repository more for when you need to support multiple different data access technologies?",TD-related,architecture,"pattern, suboptimal_design",3,172,0.049,0.873,0.077,0.7314
16815466,PHP dealing with concurrency,"I'm running an enterprise level PHP application. It's a browser game with thousands of users online on an infrastructure that my boss refuses to upgrade and the machinery is running on 2-3 system load (yep linux) at all times. Anyhow that's not the real issue. The real issue is that some users wait until the server gets loaded (prime time) and they bring their mouse clickers and they click the same submit button like 10 - 20 times, sending 10-20 requests at the same time while the server is still producing the initial request, thus not updated the cache and the database.Currently I have an output variable on each request, which is valid for 2 minutes and I have ""mutex"" lock which is basically a flag inside memcache which if found blocks the execution of the script further, but the mouse clicker makes so many requests at the same time that they run almost simultaneously which is a big issue for me.How are you, the majority of StackOverflow folks dealing with this issue. I was thinking of flagging the cookie/session but I think I will get in the same issue if the server gets overloaded. Optimization is impossible, the source is 7 years old and is quite optimized, with no queries on most pages (running off of cache) and only querying the database on certain user input, like the one I'm trying to prevent.Yep it's procedural code with no real objects. Machines run PHP 5 but the code itself is more of a PHP 4. I know, I know it's old and stuff but we can't spare the resource of rewriting this whole mess since most of the original developers left that know how stuff is intertwined and yeah, I'm basically patching old holes. But as far as I know this is a general issue on loaded PHP websites.P.S: Disabling the button with javascript on submit is not an option. The real cheaters are advanced users. One of them had written a bot clicker and packed it as a Google Chrome extension. Don't ask how I dealt with that.",TD-related,architecture,"concurrency, dependency",5,349,0.052,0.87,0.077,0.7902
17098554,Connecting to old MySQL servers,"I understand that PHP's mysql_* functions are deprecated and I should not be using them.However, we have several legacy MySQL 4.0 databases, which neither the mysqli_* nor PDO functions support connecting to. What is the best way to continue using the latest PHP versions and still be able to connect to these databases?(Based on the description at the top of the PDO intro page, I initially thought PDO might be an option, but the Changelog further down the page suggests that support for pre-4.1 has been dropped in PHP 5.4)I understand that MySQL 4.0 is 10 years old and the real problem here is that we're still using it. Upgrading MySQL is a separate issue that's outside the scope of both my influence and this question. What I do have control over is the PHP version that we use - and I'd hate to have to stop upgrading PHP just because we need to connect to some old databases.Updated (2):I updated the question above to reflect my new understanding that even PDO will no longer connect to these old MySQL servers.I should also clarify that we have several legacy applications accessing these databases, and we want to change these applications as little as possible. They are not in active development, and testing a change that involved rewriting large sections of code would quickly balloon into a rather large QA project.For this reason, invasive solutions such as rewriting the code or upgrading the MySQL version, are highly unlikely to be worthwhile. If they are the only solutions available, we'll probably end up doing nothing - using mysql_* as long as possible, and then freezing the PHP version (at least for these apps) as soon as the latest PHP can no longer connect.On the other hand, technically complex solutions (such as compiling something from scratch) are definitely possible, and are actually preferred to making extensive code changes.I'm now offering a bounty in the hopes of getting new answers that offer some more complex alternatives.",TD-related,architecture,"database, outdated",2,332,0.072,0.855,0.073,-0.1909
18610541,Mixing Repository implementations for different data sources,"A Repository as defined by Martin Fowler is supposed to act like an in-memory domain object collection. This allows the application (in theory) to be ignorant of the persistence mechanism.So under normal circumstances you'd have something like this: <code>However if you had some bizarre requirement that your Customer Repository was acting against a SqlServer database, your Order Repository against a MySql database and your Invoice Repository against a PostgreSQL database, how would you go about handling the Transactions for each database session?Now this is a bit of contrived example for sure but every Repository implementation I've come across seems to know at some level that it's really a particular database and ORM being used.Imagine another scenario where you have 2 repositories where one is going to a database and the other is calling a web service. The whole point of Repositories is that the application shouldn't care what data source you are going to but without jumping through some massive hoops I don't see how these scenarios can be accounted for without the application knowing at some level FYI this is going to data source x so we'd better treat it differently.Is there a pattern or implementation that addresses this issue? It seems to me if you are using Database x and ORM y for your entire application then Repositories work splendidly, but if due to technical debt that course deviates then the benefits of repositories are greatly reduced.",TD-related,architecture,"pattern, dependency",2,239,0.04,0.861,0.099,0.9401
19724082,Restful authentication for non browser consumers,"I have a web service written as an ASP MVC application which basically uses rolling cookies as its authentication mechanism. So someone sends their username and password over https to the service, it then verifies them and issues them a cookie containing a token, user identifier and timestamp as HTTPONLY and SECURE. Then whenever the users need to access pages which require authentication the cookie is sent over and verified with the timestamp and the token against the user, assuming that passes it then issues a new timestamp and sends it back down to the user.This method works to date and although there are still possibilities of CSRF (reduced by the rolling timestamp) and a few other vulnerabilities it is a risk that the current project team are willing to live with, there is a big technical debt card to look into better ways, but thats for another discussion, as our main goal was a stateless service so it could scale easily.Anyway that all to one side, the issue now is that we have been asked to expose data to other 3rd parties from the service. They however wont be consuming this data like a normal user with a browser, but as an application of some kind on any sort of platform. So now I am wondering if there is some better way for application based consumers authenticate themselves, as currently they would need to send a http request to authenticate, then take the returned cookie, and send it over for restricted requests. However the other 3rd parties then need to keep juggling this cookie whenever they want to get data from our system, which seems a bit of a pain for them. So is there another way I cannot see to accomplish this? as the 2 ways I can see to keep it stateless are to send some token over on the querystring each time, which again would require them to authenticate and store it, and would make the querystring a bit less clean. Then the other way is as we currently do it using cookies as the state mechanism.",TD-related,architecture,interface,3,351,0.048,0.876,0.076,0.9007
20003716,Is it wrong to dynamically add data-val and data-val-required in the View?,"I have a ViewModel that I can decorate with the code[Required] attribute (see below). I've come to the point where I need to let the client control which fields are required or not. They can configure this trough XML and all this info is stored in the Model when it's first created. Now I have fields that are not decorated with code[Required] but still need to get validated (as per user settings) before submitting (for example the codePhone field).  public class MyBusinessObjectViewModel{ [Required] public string Email { get; set; } //compulsory public string Phone { get; set; } //not (yet) compulsory, but might become}reIf the user will not enter the codePhone number, the data will still get posted. Wanting not to mess with custom validators, I just add the data-val and data-val-required attributes to the Html, like this: Dictionary  string, object   dict = new Dictionary  string, object  ();dict.Add(data-val, true);dict.Add(data-val-required, This field is required.);@Html.TextBoxFor(x =   x, dict); reThis forces the client side validation for all the properties that are dynamically set as required. Is this good practice? What kind of side effects can I expect?",TD-related,architecture,"pattern, dependency",2,184,0,0.894,0.106,0.9544
20357831,How do I reuse components that handle logic related to models in shell scripts for CakePHP?,"So, CakePHP is a really awesome MVC framework, but I'm looking to better understand the MVC architecture in it, especially for services and organizing logic.I currently have a lot of logic in emcomponents/em related to emmodels/em, but I want to do some processing with that same logic in a emshell/em script. I'm not sure if I'm approaching it correctly. I'm particularly concerned about technical debt and scaling maintainability. I don't want to go down this road then have to turn back. Thanks in advance for any and all pointers, best practice tips, etc.",TD-related,architecture,"pattern, management",4,93,0.054,0.763,0.182,0.9246
23648832,ViewModels in MVC / MVVM / Separation of layers- best practices?,"I'm fairly new to the using ViewModels and I wonder, is it acceptable for a ViewModel to contain instances of domain models as properties, or should the properties of those domain models be properties of the ViewModel itself? For example, if I have a class codeAlbum.cs public class Album{ public int AlbumId { get; set; } public string Title { get; set; } public string Price { get; set; } public virtual Genre Genre { get; set; } public virtual Artist Artist { get; set; }}reWould you typically have the ViewModel hold an instance of the codeAlbum.cs class, or would you have the ViewModel have properties for each of the codeAlbum.cs class' properties. public class AlbumViewModel{ public Album Album { get; set; } public IEnumerable  SelectListItem   Genres { get; set; } public IEnumerable  SelectListItem   Artists { get; set; } public int Rating { get; set; } // other properties specific to the View}public class AlbumViewModel{ public int AlbumId { get; set; } public string Title { get; set; } public string Price { get; set; } public IEnumerable  SelectListItem   Genres { get; set; } public IEnumerable  SelectListItem   Artists { get; set; } public int Rating { get; set; } // other properties specific to the View}re",TD-related,architecture,"pattern, suboptimal_design",2,206,0,0.987,0.013,0.3182
24189753,Forking vs overriding,"I am working on a reasonably large and quite customised ruby on rails spree commerce installation. I am trying to decide how best to architect it so that I can keep upgrading spree without fear of it breaking my modifications.In the past I have followed the general spree documentation and made modifications by using decorators, overrides and sometimes overriding views completely. This works fine however there are two issues.1.) It can be harder to reason about the program when classes are opened up and extended via decorators. Its much easier if you can open up the file eg Spree::Product and look at the code and then work your way up the ancestors rather than knowing that in various parts in your system the class is being opened up and modified.2.) It can be hard to upgrade Spree if you go down this route. If you have overridden a view and it changes in the next version of spree you have no way of knowing. All you can do is upgrade and hope that one of your tests or manual testing picks it up if it breaks.The benefit of the above however is of course that its a very easy way to get started with modifications and if you are making few and small modifications then its probably fine.However are there better alternatives? One approach that I have been considering is simply forking Spree and making the changes directly in the forked spree codebase. I could then simply pull any new changes from spree into my forked repo when I want to upgrade. The advantage of this approach is that git will notify me whenever there is a change in a view that I have overridden. I can then merge this manually and either ignore it or take action. Has anyone in here done this in practice? Are there any drawbacks that I am overlooking?",TD-related,architecture,pattern,3,314,0.019,0.89,0.091,0.9701
26670309,Cannot execute a custom xpath rule on XML,I am trying to create custom XML rules but they are not working. :(First my configuration :ullisonarqube 4.3lixml plugin 1.2I want to create a custom rule in xpath for an XML Quality Profile.The rule is never applied and no violation is detected.My rule : <code>I am very confused. Can anybody help me ?,TD-related,architecture,framework,4,53,0.126,0.686,0.188,0.2126
26743749,software methodology used in project,"Currently I am working on porting a benchmark application to another system. I am working alone, so I am frustrated about which software methodology I really have to use. Please give me some ideas.",TD-related,architecture,management,4,34,0.167,0.765,0.068,-0.5233
28258223,Where in the object-oriented design process is an architecture pattern chosen?,Most object oriented analysis and design books and resources describe the process where the analysis phase is followed by identifying classes. I understand that experience will often give you an idea of which architecture (if any) you should apply but is there a specific point in the object oriented design phase where this should occur? I'm about to start a large personal project and I want to make sure my choice of architecture doesn't disregard something from the analysis phase.,TD-related,architecture,"pattern, management",3,80,0,0.917,0.083,0.6829
29242469,Extremely slow and inefficient query execution from Entity Framework,"I've got Entity Framework 4.1 with .NET 4.5 running on ASP.NET in Windows 2008R2. I'm using EF code-first to connect to SQL Server 2008R2, and executing a fairly complex LINQ query, but resulting in just a Count().I've reproduced the problem on two different web servers but only one database (production of course). It recently started happening with no application, database structure, or server changes on the web or database side.My problem is that executing the query under certain circumstances takes a ridiculous amount of time (close to 4 minutes). I can take the actual query, pulled from SQL Profiler, and execute in SSMS in about 1 second. This is consistent and reproducible for me, but if I change the value of one of the parameters (a ""Date after 2015-01-22"" parameter) to something earlier, like 2015-01-01, or later like 2015-02-01, it works fine in EF. But I put it back to 2015-01-22 and it's slow again. I can repeat this over and over again.I can then run a similar but unrelated query in EF, then come back to the original, and it runs fine this time - same exact query as before. But if I open a new browser, the cycle starts over again. That part also makes no sense - we're not doing anything to retain the data context in a user session, so I have no clue whatsoever why that comes into play.But this all tells me that the data itself is fine.In Profiler, when the query runs properly, it takes about a second or two, and shows about 2,000,000 in reads and about 2,000 in CPU. When it runs slowly, it takes 3.5 minutes, and the values are 300,000,000 and 200,000 - so reads are about 150 times higher and CPU is 100 times higher. Again, for the identical SQL statement.Any suggestions on what EF might be doing differently that wouldn't show up in the query text? Is there some kind of hidden connection property which might cause a different execution plan in certain circumstances?EDITThe query that EF builds is one of the ones where it builds a giant string with the parameter included in the text, not as a SQL parameter:exec sp_executesql N'SELECT [GroupBy1].[A1] AS [C1] FROM ( SELECT COUNT(1) AS [A1]...AND ([Extent1].[Added_Time] >= convert(datetime2, ''2015-01-22 00:00:00.0000000'', 121)) ...) AS [GroupBy1]'EDITI'm not adding this as an answer since it doesn't actually address the underlying issue, but this did end up getting resolved by rebuilding indexes and recomputing statistics. That hadn't been done in longer than usual, and it seems to have cleared up whatever caused the issue.I'll keep reading up on some of the links here in case this happens again, but since it's all working now and unreproduceable, I don't know if I'll ever know for sure exactly what it was doing.Thanks for all the ideas.",TD-related,architecture,suboptimal_design,3,470,0.037,0.879,0.084,0.9646
29706399,Method or pattern to implement a Business Rules Engine in a solution?,"I am working in a young banking company. Our solution (.NET) has an important technical debt, so we refactor it following DDD principles. We are planning to use (a) Business Rules Engine(s). Business rules deal with accounting purposes, marketing purposes, risk purposes, legal stuff... we are planning to POC the BRE to be sponsored by the business. emI am looking for some feedback by people who succeded in adopting a BRE, or, a combination of BREs?/em ulliAre there tools to manage the BR repository?liIs there any pattern that might help to separate processes and BR ?liDo you know some authors who wrote about migrating a solution to aBRE ?liDo you think adopting a unique BRE can fit the needs for all domains,or is it better to prototype a custom solution for each domain ?liWhat are common pitfalls ?Thanks,",TD-related,architecture,"td_resolution, management",5,138,0.032,0.835,0.133,0.9129
30252729,What are the advantages to passing a global DB connection into each function of a model?,"I am working with an older code base that passed a db connection into most functions in each class of the models. The db connection is created as a global and passed everywhere in the application: $user = new User();$user-  loadById($db, $userId);reWhat advantages do we get by doing this vs a single connection the entire model inherits similar to the way most frameworks currently work?Any insight would be very helpful.Full Disclosure:I asked this question this way because this is how we do it at work. I don't like that we pass around the DB connection. I am trying to find a proponent of this method to see if my mind can be changed. That is why I tried to sway the discussion to the PRO side of this conversation without being blocked as a bad question. And it worked. I didn't get banned, but the great StackOverflow community didn't let me down. It appears I'm not out in left field with how I think about this issue.",TD-related,architecture,"legacy, td_resolution, database",4,167,0.023,0.903,0.074,0.8043
32274486,REST API versioning,"I currently work on a Java based web application. Recently we created some REST endpoints using Spring. The reason for this was because we developed a hybrid mobile app that integrates with our main application via these end points.The problem is that going forward we are not quite sure how to handle updates. If we update our API, e.g. we change the method signatures of the end point methods or we change the attributes on the DTOs that we return as JSON, then we would have an issue if our mobile users are running an out dated version of the mobile app.What we want to implement is something that will force our users to update the app if it is out of date. I have seen a lot of mobile apps that do this. So we thought of having an API version for our REST API and then have the mobile app check if the version it is using is the same as the version being run by our server and if not, then force the user to do an update.The problems we have are:We only have one version of our server running at any time. So how would we time our releases? What happens in the event that we release a new version of our API and our mobile app but the app store does not yet have the latest version publicly available. Then the user will be forced to do an update but the updated app is not yet available to them.How do we maintain the API version number? On the mobile app we can just configure that. But on the server it is not great to have to maintain a version number. The reason I say this is what if we make a change to a method signature or DTO, etc, and forget to update this version number manually before releasing? Surely there is a more automatic way to do this where some unique ""API key"" is generated based on the current definition of the API? We could then use this instead of an API version number.",TD-related,architecture,interface,3,350,0.047,0.919,0.034,-0.829
32896309,How to convert an instance of java.awt.geom.AffineTransform to an instance of javafx.scene.transform.Affine,"I have an old library (technical debt) that needs to stay in place for now, and it uses the AWT AffineTransform. Our new graphics code uses the JavaFX Affine. Is there a clear 1:1 mapping between the two?If there is an existing FLOSS library providing this mapping as a utility, I would appreciate that reference. If not, please describe how to convert an instance of java.awt.geom.AffineTransform to an instance of javafx.scene.transform.Affine.In lieu of a clear conversion path, I will accept a description of the compatibilities between the two classes and the challenges of working with both.",TD-related,architecture,"framework, legacy",5,96,0.02,0.858,0.122,0.8333
38440115,How do I alias a column in Elixir Ecto?,"So I have a legacy database schema that I am trying to normalize with the help of Elixir (Phoenix) and Ecto. The column definitions work fine, but they are horribly names (hooray for technical debt).Is there a way to alias a column name, i.e. meetingName becomes meeting_name when displaying and managing it through the generated api? I've looked through the Ecto documentation and can't seem to find it at all.Example, @primary_key {:meetingId, :integer, []}@derive {Phoenix.Param, key: :meetingId}schema meeting do field :meetingName, :string timestamps()endre",TD-related,architecture,"legacy, database",4,83,0.056,0.905,0.039,-0.5187
38840957,Sharing Eloquent Migrations with Team,"I am working with a couple of team members on a suite of web apps for our company. We have two projects that need to share a database. One project is public-facing, the other is for internal use only. We feel there has to be a better way to effectively share migrations. The apps are far too different to be separate branches of the same project. We have become frustrated with needing to compare Schema build information for simple database refreshes on our development server. There must be a better way. Please help!If needed, I will elaborate the reasons we choose to keep these projects separate and why we are sharing a database.Thank you.",TD-related,architecture,"database, dependency, management",4,114,0.028,0.817,0.154,0.92
39783164,Upgrading an ExtJS application from 4.1.2 to 6.x,"I'm acquiring an existing application written in ExtJS 4.1.2. It's a very large code base. The 4.1.2 application was built without CMD -- the sources are added directly to index.html. Without having much of an ExtJS background, I have the following two questions:1) Does it make sense to upgrade to 5.x first and then go from 5.x to 6.x? Or is it safe to go directly from 4.1.2 to 6.x?2) Should a new project be created and manually copied over, or can I just update the sources, in theory, to point to the new extjs lib, and back peddle fixing all client code that's broken or no longer compatible? I haven't followed the history of ExtJS much, so I'm not sure if upgrading two major revisions is even feasible with this framework. What's the best approach if CMD isn't being used in the existing app?",TD-related,architecture,"framework, outdated",3,145,0.05,0.884,0.066,0.5475
39835056,Convert EF-based app to multi-tenant by way of context overrides,"I have an Entity Framework, code-first based app that I have to make multi-tenant, which is to say that there are about a half-dozen top level entities that now need to reference the specific tenant ID. (As we get to 100's of users, no, we're not going to maintain individual schema, so please don't suggest that. :))With an object-oriented abstraction over the data access like EF, I'm trying to imagine how I can get to a place where I don't need to change any of the underlying code outside of the dbcontext to make this work. Essentially, I want to use these as my success criteria:ulliExisting data access code doesn't have to be changed. There's a ton of it, lots of it is procedural and duplicate. No repository classes, unfortunately, and as much as I want to get there, it's technical debt I have to defer.liQueries filter those top-level objects on the tenant ID. So for example, existing code gets context.Members.Where(x = x.IsAwesome) but magically also filters to where tenant ID equals tenant ID (the tenant context is available per request and available for injection).liAdding top-level entities also assigns the tenant ID. In other words, the code does something like context.Members.Add(newEntity) and newEntity magically gets its TenantID property set to that ID available via that injected component.It seems like setting the tenant ID could be done with the entity class itself (haven't thought through the injection on that, some kind of shim stuck in there), but I'm not sure how best to go about adding an additional filter for querying.",TD-related,architecture,"framework, dependency",2,260,0.061,0.878,0.061,-0.2142
40362696,Convert single file to Swift 3 in Xcode 8?,"Is there any way in codeXcode 8 or code8.1 to do a codeSwift 2.X -   Swift 3 migration for a single file in a project that's already been converted to Swift 3?For technical debt/legacy build process reasons, we are currently having to maintain both codeXcode 7 and codeXcode 8 versions of our project. This is causing headaches when we have to merge new development from codeXcode 7 over to codeXcode 8. Since the project has already been fully converted to codeSwift 3 in our codeXcode 8 branch (including a ton of hand fixes), we can't use the full-project automated converter. Therefore we are currently having to do a hand conversion from codeSwift 2.2 to codeSwift 3 for any new codeSwift files which were added in codeXcode 7, which takes a significant amount of time.I apologize if this has already been asked, I couldn't find any clear answer with Google.",TD-related,architecture, ,4,149,0.015,0.891,0.093,0.8408
41955435,Worth moving to Hibernate ORM from JDBC Prepared statements after the project is 90% done?,"I have a Rest Api Project which is using a database of around 25 to 30 tables. This project was built using JDBC Prepared statements. The project is huge. Since I got to know hibernate orm is better for maintenance I thought I should migrate to Hibernate ORM. I have a intermediate experience in Hibernate. After I started working I had to create POJO classes which are different from my previous pojo classes, because hibernate annotation uses bean classes with mapping for other tables as well. Its getting messed up everywhere changing everything.Is it worth migrating to Hinernate ORM after my project is 90% done?My Business objects are changing.Dao is different from previous ones.Controller Also needs modificatons.",TD-related,architecture,"management, database",6,117,0.02,0.868,0.111,0.8316
44206388,Spring library to share commons,"In a context of several spring boot apps, sharing some components, is that considered as a bad practice to publish an artifact used in those apps?I'm planning to reuse controllers and services abstracts and low level classes (for statistics requiring fast write access, so webservices are excluded).",TD-related,architecture,"suboptimal_design, dependency",4,47,0.109,0.837,0.054,-0.4215
44232487,"Architecture: Dependency Injection, Loosely Coupled Assemblies, Implementation Hiding","I've been working on a personal project which, beyond just making something useful for myself, I've tried to use as a way to continue finding and learning architectural lessons. One such lesson has appeared like a Kodiak bear in the middle of a bike path and I've been struggling quite mightily with it.The problem is essentially an amalgam of issues at the intersection of dependency injection, assembly decoupling and implementation hiding (that is, implementing my public interfaces using internal classes).At my jobs, I've typically found that various layers of an application hold their own interfaces which they publicly expose, but internally implement. Each assembly's DI code registers the internal class to the public interface. This technique prevents outside assemblies from newing-up an instance of the implementation class. However, some books I've been reading while building this solution have spoken against this. The main things that conflict with my previous thinking have to do with the DI composition root and where one should keep the interfaces for a given implementation. If I move dependency registration to a single, global composition root (as Mark Seemann suggests), then I can get away from each assembly having to run its own dependency registrations. However, the downside is that the implementation classes have to be public (allowing any assembly to instantiate them). As for decoupling assemblies, Martin Fowler instructs to put interfaces in the project with the code that emuses/em the interface, not the one that emimplements/em it. As an example, here is a diagram he provided, and, for contrast, a diagram for how I would normally implement the same solution (okay, these aren't quite the same; kindly focus on the arrows and notice when implementation arrows cross assembly boundaries instead of composition arrows).emMartin Style/ema href=https://i.stack.imgur.com/4Zasg.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/4Zasg.png alt=Martin Style/aemWhat I've normally seen/ema href=https://i.stack.imgur.com/sLxNc.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/sLxNc.png alt=Not Martin Style/aI immediately saw the advantage in Martin's diagram, that it allows the lower assemblies to be swapped out for another, given that it has a class that implements the interface in the layer above it. However, I also saw this seemingly major disadvantage: If you want to swap out the assembly from an upper layer, you essentially steal the interface away that the lower layer is implementing.After thinking about it for a little bit, I decided the best way to be fully decoupled in both directions would be to have the interfaces that specify the contract between layers in their own assemblies. Consider this updated diagram:a href=https://i.stack.imgur.com/62qSB.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/62qSB.png alt=Proxy Style/aIs this nutty? Is it right on? To me, it seems like this solves the problem of interface segregation. It doesn't, however, solve the problem of not being able to hide the implementation class as internal. Is there anything reasonable that can be done there? Should I not be worried about this?One solution that I'm toying around with in my head is to have each layer implement the proxy layer's interface twice; once with a public class and once with an internal class. This way, the public class could merely wrap/decorate the internal class, like this:a href=https://i.stack.imgur.com/MFdAo.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/MFdAo.png alt=Proxy and Decorator Style!/aSome code might look like this: namespace MechanismProxy // Simulates Mechanism Proxy Assembly{ public interface IMechanism { void DoStuff(); }}namespace MechanismImpl // Simulates Mechanism Assembly{ using MechanismProxy; // This class would be registered to IMechanism in the DI container public class Mechanism : IMechanism { private readonly IMechanism _internalMechanism = new InternalMechanism(); public void DoStuff() { _internalMechanism.DoStuff(); } } internal class InternalMechanism : IMechanism { public void DoStuff() { // Do whatever } }}re... of course, I'd still have to address some issues regarding constructor injection and passing the dependencies injected into the public class to the internal one. There's also the problem that outside assemblies could possibly new-up the public Mechanism... I would need a way to ensure only the DI container can do that... I suppose if I could figure that out, I wouldn't even need the internal version. Anyway, if anyone can help me understand how to overcome these architectural problems, it would be mightily appreciated.",TD-related,architecture,"dependency, interface",4,678,0.062,0.857,0.081,0.9506
44399753,What is the proper way to create an abstraction for apis with large programing surfaces?,"I'm trying to adapt a href=https://stackoverflow.com/a/5646876/3691973this/a concept to Search. Specifically, I want to begin using Elasitcsearch, but still maintain a proper abstraction layer. However, the Elasticsearch API surface is huge. It exposes not only basic connection creation (which it easily makes sense to abstract away), but also extremely powerful (and therefore potentially complex) extension methods to build indexes and queries. In fact, it's so complex that it already comes with a built in wrapper layer for use in .Net: NEST.So my question is, is it reasonable to create another abstraction layer on top of that. Something like: public interface ISearchClient{ IIndexResult Index(IIndexRequest request); ISearchResult Search(ISearchRequest request); // Other methods here as appropriate.}reand then create extension methods to expose most of the power built into NEST? That seems like a ton of wasted effort given that most of the exposed functionality of the IElasticClient used by NEST is already extension methods down into the low level libraries. Is there a way to expose the existing extension methods handed to me by NEST? Is that wise to do, or does it defeat the whole purpose of implementing my own ISearchClient middleware? Or is the best course of action to create the abstraction layer and then only expose the existing extension methods as necessary? That feels like it's intentionally creating a pile of technical debt that will never be worked through.",TD-related,architecture,"dependency, interface",3,228,0.088,0.735,0.178,0.9779
46786094,Is it possible to mix hibernate-envers versions given certain conditions?,"I have a large system (A) using hibernate 4.3.11. We want to introduce auditing on a few tables using hibernate-envers.However we want to consume the audit log on a different system (B) that uses hibernate 5.Given that system B only reads from the shared database, is it possible to mix hibernate versions in this case?",TD-related,architecture,"framework, outdated",4,55,0,0.904,0.096,0.4588
47122124,MVVM & iOS - The Missing Rules,"I've being working for a bit now with MVVM along with Swift. The principle is very simple:ViewController is responsible for the View;ViewModel is responsible for the Model;ViewController owns the View;ViewController owns the ViewModel;ViewModel own the Model;period.That's clear to me. But there are some questions I still have about it (they might sound stupid, but it's important to be as clear to newbies as the rules above):Should ViewModel be responsible for the business logic? I mean, since ViewController don't own models, it feels right to place the biz logic in ViewModel;Should ViewModel be a struct? This is a tricky one. I'm guessing ViewModel should also give an API to ViewController interact with data. Therefore, sometimes we need to use some escaping closures in order to fetch asynchronous data (e.g. HTTP calls). Structs can't hold it.Should I hide non-outlets variables from ViewController? Sometimes we need a  reference to some property in order to present views (e.g. keep the current page of an UIPageControl). Should ViewController hold this reference?How can I fire ViewController updates from ViewModel? I do read about reactive programming, but my question is wider: Sometimes ViewModel needs ViewController to respond to some actions, which is the best way to do it? Should ViewModel keep specific callbacks to specific reactions ViewController can handle? I came across Srdan Rasic's post about ""binding"" properties and I got confused (perhaps its not related to this question at all).I'll be glad if you guys can share your solutions. Thanks!",TD-related,architecture,pattern,5,244,0.053,0.817,0.13,0.9612
47793065,Angular and Micro-Frontends,"I am doing some research on how to split a huge single-page-monolith into a micro-frontend architecture.The idea:lithe page consists of several components which would be running autonomouslylieach component is managed by one dev-teamlieach team can change, update and deploy their components without breaking components of other teamslieach team chooses its own toolstackThe reason/To efficiently develop large applications you need to have many people working on it. However the number of developers per app/team does not scale well. Parallel development of multiple independent apps by independent teams however can be scaled arbitrarilyWith this in mind it is imperative that teams can choose their own toolstack and especially perform independent version-upgrades of third party-libraries (like angular, react, jquery). If this was not the case a framework-update would need to be compatible with every single component before you could deploy it to production.Does this work with Angular?/While independent version-upgrades are necessary, it would be reasonable to restrict the teams to a few supported frameworks (Angular, React, Vue, Polymer...) and for now I try to build a demo purely consisting of Angular-Apps.However even though Angular 5 is supposedly a platform-framework which supports huge multi-module apps, it seems to be almost impossible to have several independent angular-apps running in the same browser window.I managed to bootstrap several Angular-Apps (different versions, each hosted on its own server) on a single webapp by utilizing HTML-Imports. However there are several codeglobal dependencies which need to be shared between appsullizone.js can only be started oncelirouting requires url-changesliBrowser-stuff like cookies, sessionstorage, etc...There are several articles in the net on how to bootstrap multiple angular-modules but they all refer to multiple modules in the same core-app, which in turn means they all are running on the same framework-version and an update means you have to rebuild and deploy the whole monolith.Is there any solution other than codeiframes to get multiple Angular (5) Apps running on the same Page?",TD-related,architecture,"pattern, suboptimal_design",3,317,0.01,0.938,0.052,0.8501
48411220,Reasons to upgrade Retrofit and OKHttp in an existing Android project,"I am new in an Android project that makes heavy use of a web API.The project uses:ulliretrofit-1.9.0 and okhttp-2.0.0 for web API callslialso okhttp3-3.9.1 for some other web stuffI would like to upgrade the libs to:ulliretrofit-2.3.0 and okhttp3-3.9.1Beyond using the latest versions and having a single OKHttp version, I would like some really good reason to justify the upgrade.That is because the new APIs don't seem to be backward compatible and it would require the effort of refactoring all web API calls, followed by extensive testing.",TD-related,architecture,"framework, outdated",3,86,0,0.906,0.094,0.8016
49890971,What are some best practices for deploying multiple microservices at the same time?,"I have been struggling with the best way to deploy multiple microservices at the same time if there is a change that affects more than one service.While I'd be interested in any general approaches, let me provide a specific example I'm running into.Our company uses AWS and Elastic Beanstalk to deploy microservice containers for a web site that are relatively decoupled. Right now our web application consists of:A SPA written in Angular, deployed and hosted in an S3 bucket (Call it SPA)A webapi service, written in .NET Core, dockerized, and deployed to an elastic beanstalk application (Call it WebAPI)An integration service, written in Node.JS, dockerized, and deployed to an elastic beanstalk application (Call it IntService)The SPA and WebAPI talk via a REST APIThe WebAPI and IntService are loosely coupled and talk to each other through an AWS SQS Queue.If we have a change to any one of these services, our deploy process is fairly straightforward. For example, if we have a change to the WebAPI, we spin up a new elastic beanstalk application environment, deploy there, then swap the URLs (so basic blue-green deployment).However, I'm struggling with the right approach if there is a change that affects multiple services. For example, say there is a feature that requires changes to both WebAPI and IntService. Since each of these live in their own repo, they each have their own CI and CD pipelines independent of each other.If just one service is deployed, the whole app might break. How do people handle this type of deploy? Do you clone both the WebAPI and IntService environments, deploy both of them, then swap both URLs, just making sure you do it at about the same time to minimize the window of time where only one service is active?Alternatively, we were looking at using an API gateway. But would that mean every time we wanted to deploy we'd create a new API gateway stage? If we do that, is the blue-green deployment 'swap' actually happening in the API Gateway?Sorry if this is confusing, but I'm just trying to wrap my head around what I have to imagine is a fairly common problem with microservices.",TD-related,architecture,"duplication, suboptimal_design",5,359,0.033,0.938,0.029,-0.3632
52408743,Migrate monolith to microservices without touching database,We have a big monolithic application with a huge oracle db. We want to move the application to a microservices architecture using containers without doing so much at database level. We are going to change the db later on. What is the best approach to isolate services and what should we do to make it less painful when we change database in the next phase?Would it not be a problem at db level when you have multiple processes (one for each service)?,TD-related,architecture,"td_resolution, database, pattern",2,82,0.051,0.829,0.12,0.7194
52812337,Clean Architecture : why not using the entity as request model of the use case (interactor),"I have read the PPP book and clean code, coder and architecture books.I know that:Clean architecture is a layered architectureWhat is it like being open layered or close layered architectureClean architecture books suggests that each layer can access it`s inner layers, and not only the very next inner layerSo I assume that clean architecture does not force being close layered and it allows being open layered, meaning that for example UI which is in the frameworks layer can directly access Entity, jumping 2 layers in the way.And I understand that if clean architecture forced being close layered, we could not implement repository interface directly from Frameworks layer and we should implement it in the terms of next layer and this next layer should have implemented it in the terms of its next layer and so on.Now my question is, why we can't introduce Entity as the parameter type of the usecase or controller directly and why do we have to define data structures or DTOs in the middle layers and bother converting entity to data structures and return it as response, while we are allowed to use and see Entity in the controller layer because the access rule is not violated?Consider this example, suppose we have:JobViewJobControllerJobUseCase(RequestModel) : ResponseModelJobEntityNow if JobView wants to call JobController, it should pass RequestModel. Now could we simply introduce JobEntity as the RequestModel like so:JobViewJobControllerJobUseCase(JobEntity)JobEntityI know that doing like so will increase the fragility of code, because that way if we change JobEntity, then JobView has to change. But does clean architecture force SOLID principles being fragile or rigid as a rule?!",TD-related,architecture,"pattern, software_methodology",3,266,0.019,0.894,0.087,0.9426
53727707,Persisting to multiple databases in Spring,"We have a DB2 database which is used by legacy applications that we are in the process of decommissioning and we have an Oracle database that we are developing new applications for. In order to maintain compatibility with legacy applications until they are completely decommissioned and keep data in sync, we are using Atomikos for two phase commits. This however is resulting in a lot of duplicated entities and repositories and thus technical debt, because the same entities and repositories cannot be used by the same entity managers so we have to duplicate them and put them under different packages for the entity scanning.In most cases we want to read data from the legacy database and persist to both, but ideally this would be configurable.Any help on this would be greatly appreciated.",TD-related,architecture,"database, duplication, td_resolution",3,132,0.012,0.884,0.103,0.9139
53826329,Graphql Schema update rollback,"We are moving some of our API's to graphql and would like to know to handle the rollback of the deployed package (Schema)and the best practice to the same. To be more specific let's say we have a Schema S with 3 fields and then we added 4th field A . Now for some reason we cannot go forward with this package and field A. So we have to perform roll back of the package so that now the Schema doesn't have field A. Now some consumer might ask for this field A and he might get an error. We could of course ask our clients to update but there is a time gap during which we might have failed request.How do we handle this scenario,specifically an urgent rollback with in few hours or a day?",TD-related,architecture,database,6,136,0.046,0.905,0.048,-0.1901
57764595,OOP vs non-OOP implementation in Python on small scale real-time-ish application,"I am new to OOP side of python and I am wondering if it is worth to refactor my non-OOP programming code to an OOP code. my code is as follows: import timeimport numpy as npimport pandas as pddef choices_chooser(possibilities): final_choice = None while final_choice is None: temp_input = input(f'please enter one of the following: {possibilities}\n') if temp_input == 'True': temp_input = True elif temp_input == 'False':temp_input = False if temp_input in possibilities: final_choice= temp_input else: print('typo! plz enter again') return final_choicedef status_updater(dic, key, possibilities): if key in dic and type(possibilities) in {list,tuple}: print(fthe status of {key} before modification: {dic[key]}) print('now we are changing it') dic[key]= choices_chooser(possibilities) print(fthe status of {key} after modification: {dic[key]})def funcA(df):df['Be'] *= -1.5 def funcB(df):df['Ch'] *= -2 def funcC(df):df['De'] *= -3 def funcD(df):df['Ep'] *= -4 def funcE(df):df['Fi'] *= -5def funcF(df):df['Al'] *= -6func_dict = {'Al': funcA, 'Be': funcB, 'Ch': funcC, 'De': funcD, 'Ep': funcE, 'Fi': funcF} options_lst = [True, False] status = ['Null']+['Al','Be','Ch','De','Ep','Fi']status_dict = dict.fromkeys(status, False)status_count = dict.fromkeys(status, 0)status_index = 0next_status_index = 1previous_status_index = Nonenum_of_iteration = 0num_of_complete_run = 0df = pd.DataFrame(np.ones((4, len(status))), columns = status)while num_of_complete_run    1: time.sleep(0.2) num_of_iteration += 1 current_state = status[status_index] next_state = status[next_status_index] if previous_status_index is None: print(f'current state: {current_state};next_state: {next_state}; iteration: {num_of_iteration}') else: previous_state = status[previous_status_index] print(f'previous state: {previous_state}; current state: {current_state}; next state: {next_state}; iteration: {num_of_iteration}') status_updater(status_dict, next_state, options_lst) if status_dict[next_state]: previous_status_index = status_index status_index = next_status_index previous_state = status[previous_status_index] current_state = status[status_index] print(f'we have attained a new state\n' + '-----'*10) if current_state == 'Be': print('after state Beta we may directly skip to De, depending on RNG') next_state = choices_chooser(['Ch','De']) next_status_index = status.index(next_state) elif current_state == 'De': print('after state Delta we may directly skip to Fi, depending on RNG') next_state = choices_chooser(['Ep','Fi']) next_status_index = status.index(next_state) elif current_state == 'Fi': print('we are at state Fi, which means a full run has been completed') num_of_complete_run += 1 next_status_index = 1 next_state = status[next_status_index] else: next_status_index += 1 next_state = status[next_status_index] print(f'previous state: {previous_state}; current state: {current_state}; next state: {next_state}') 'do something unique at state {current_state} func_dict[current_state](df) status_count[current_state] += 1rehrThis is my attempt to create a real-time-ish application. It has status variables. Different functions are run at different states. Whether certain states will be visited next depends on the user's input. The code terminates when the status 'Fi' has been reached once. I am asking for help here because I have almost 0 knowledge when it comes to good program designs, technical debts, or basically any in-depth knowledge about what/when to do OOP and how to do it correctly. hrMy questions are the following:1) Is it worth to refactor my non-OOP programming code to an OOP code? 2) If so, what should I pay extra care and attention to in the process? if not, what can I do to improve the existing code?3) When should we convert a non-OOP code to OOP code and when shouldn't4) Do you mind posting an example of what a good OOP version of this code is like in the answer?(I mean if one had to learn how to OOP, might as well learn from a great example)Thank you guys in advance.EDIT1:changed functional peogramming to non-OOP to better reflect the situation",TD-related,architecture,"management, td_resolution",4,522,0.003,0.915,0.082,0.9875
57840475,JWT vs custom encryption for REST APIs over https,"For our REST API architecture, we are currently thinking over two options -Json Web Token - pros are that it is industry standard, we pass a key which adds a layer of access control and using which we can also add secondary authorisation restrictions at our backend, maintenance of session and related security features are provided by Django by default.Cons are that the params are open for anyone to see, it seems (and correct me if I'm mistaken) that it is possible that if someone gets access to our link, he could alter a param that is not linked with the core authentication process and thus compromise the data.An in house encryption process we developed that encrypts all the params. Pros are that we are fairly certain of it to have never been compromised, for even if the link would have gotten into the hands of someone they wouldn't have known how to decrypt it to look at the params.Cons are that we have to manage all the session data through our backend code in our tables, so we aren't able to utilize the Django features. also, the idea that what we are doing isn't industry standard.What is the right way to decide in this situation, and what are the factors that we should take into account?",TD-related,architecture,"interface, database",3,217,0,0.979,0.021,0.5423
58609435,What is the minimum version of Laravel that I can get away with using if I am forced to use PHP 7.2?,"I have an app that is based on the Laravel 4.2 framework. My host is requiring me to update to PHP 7.2. I would like to do the minimum amount of upgrade work that will keep things working? Yes, I understand that I am allowing technical debt to build up here. Sadly, I dont have the budget/time to upgrade the codebase to use Laravel 6.0. What is the minimum version of Laravel that I can get away with using if I am forced to use PHP 7.2?EDIT: Their website states the minimum version of PHP that each version supports. I want to know the reverse: what is the minimum version of Laravel that I can get away with if I have to use PHP 7.2. And no, their website doesnt give this information (at least, it doesnt give it in an obvious format).",TD-related,architecture,"framework, outdated",3,143,0.075,0.863,0.062,-0.4329
2400749,Should static analysis warnings fail the CI build?,"Our team is investigating various options for static analysis in our project, and have mixed opinions about whether we want our Continuous Integration build to fail because of warnings from static analysis.The argument against failing the build is that there are often exceptions to the rules, and attempting to work around them just to make the build succeed reduces productivity. A better approach would be to generate reports with the build, and regularly dedicate developer time to addressing the reported issues.The counter-argument is that it is easy for the technical debt to build up if the bugs are not addressed immediately. Also, if the build fails when a potential bug is introduced, the amount of time required to fix it is reduced.What are your thoughts?",TD-related,build,warnings,4,125,0.12,0.807,0.074,-0.7579
14744870,Sonar - OutOfMemoryError Java Heap Space while running sonar through jenkins,"I am using jenkins for making build by using Ant. I am also configuring sonar on this jenkins job via 'Invoke Standalone Sonar Analysis"". Everything is going fine till build making process and build successfully created. Now sonar execution is started and after some time i got an error""Exception in thread ""main"" org.sonar.batch.bootstrapper.BootstrapException: java.lang.OutOfMemoryError: Java heap spaceBuild step 'Invoke Standalone Sonar Analysis' marked build as failure ""...What all i have done to fix this issue are:Increasing java heap size viaReplaced %SONAR_RUNNER_OPTS% with -Xms256m -Xmx1024m in sonar-runner.bat file of sonar.Modify Sonar_Way quality profile and put only one or two rules active in this so that to avoid rule voilation.then run build but still getting same java heap error. One more thing i would add on this is my project source folder size is around 40mb means its a big project comparatively.Can anyboby help me out on this?? What else should i do to get this done. Your revert will be appreciable.. Thanks in Advance..",TD-related,build,warnings,4,163,0.052,0.866,0.082,0.6517
23664155,Deploying an existing docker image with Deis,"I already have a build server that I generate a docker image for an application with and then put it into cloud storage. This is not an image that can be publicly shared on the docker index.How can I run this application docker image in deis?Deis is designed to build your docker image from your git repo via a buildpack or Dockerfile (although I can't find instructions on how to use a Dockerfile instead of a buildpack). This could be considered a legacy integration issue. However, the current setup of running the build service on the application cluster is not good for me, because I want my build server to be a lot more powerful than my application server. Ideally my build server would spin up on demand, although I don't bother with that rigt now.",TD-related,build,"unfit_build_process, automation",2,136,0.03,0.882,0.088,0.7733
23791921,org.sonar.api.utils.SonarException: Can not add twice the same measure on org.sonar.api.resources.File,"I have a Jenkins Job that runs SonarRunner on a Maven project composed of several modules. The build fails when I configure SonarRunner to import Cobertura coverage reports. SonarQube Runner 2.4Java 1.7.0_55 Oracle Corporation (64-bit)Windows 7 6.1 amd64INFO: Error stacktraces are turned on.INFO: Runner configuration file: <code>If I remove the codesonar.java.coveragePlugin and the codesonar.cobertura.reportPath properties, the build succeeds, however I will not have any coverage metrics.I believe the issue is occurring because there is a conflict with Cobertura and JaCoCo trying to both measure the same files. You can see in the stack trace that the JaCoCo sensor is involved in the error. I do not wish to use JaCoCo at all.Jenkins version: 1.560brJenkins Sonar Plugin version: 2.1brSonar version: 4.3brSonar Cobertura Plugin version: 1.6.1brSonar Java Plugin version: 2.2",TD-related,build,dependency,2,128,0.099,0.876,0.025,-0.8205
24470814,SonarQube does not collect code coverage,"I have a problem to set up gradle with sonar-runner and jacoco. Everything works great excepting code coverage. I have tried everything without results.Here is my build.gradle file: <code>After that, In my Sonar I can see all metrics but not code coverage.Do You know what happens here?",TD-related,build,unfit_build_process,2,47,0.041,0.903,0.056,0.1779
24555565,Can you remove a file from the Build Item group in a sql server project?,"My team has gone years (before I joined) of not adopting sql server database projects. Primarily because there are items that have circular references therefor can't build. I realize the recommended approach is to factor out or fix the circular references. However to prove we can use them without having to fix all that technical debt, I'd like to hook my sql server project's build process to remove the items from the codeBuild item group. I'm very familiar with msbuild but so far nothing seems to be changing that file being included in the build and failing it.Setting the file(s) to codeNone instead of codeBuild works fine, until we try to do a schema compare. Where it either sets them back to build, or adds them again with a new file name ending in code_1.sql   <code>",TD-related,build,unfit_build_process,2,136,0.045,0.917,0.039,-0.431
25371485,SonarQube Build Breaker does not report failure,I want to fail the build in Jenkins when the code is not passing the quality gate. But for some reason the Build breaker plugin does not report failure and I don't know understand <code>,TD-related,build,warnings,3,35,0.061,0.812,0.127,0.3513
37362640,Why does Rust compile a simple program 5-10 times slower than gcc/clang?,Follow-up to a href=https://stackoverflow.com/questions/37362130/rust-minimal-compiled-program-sizeRust minimal compiled program size/a. rustc hello.rs   600 msreWhy does coderustc compile a simple Hello World 5-10 times slower than gcc/clang?Rust uses LLVM so it should be on par with codeclang. Anyway we are talking about a program that has only three lines of code. rustc hello.rs -C opt-level=0 -C prefer-dynamic   400 msgcc hello.c   60 msclang hello.c   110 msre,TD-related,build,td_resolution,2,62,0,1,0,0
38062841,How to resolve circular dependency in Gradle,"I am migrating a Java project from Ant to Gradle. I think the best solution is to use Gradle's multi-project support, but I cannot find a way to get rid of a circular dependency.The original project was setup to have this layout: - project/ - common/ - product-a/ - product-b/reThe relationship between codecommon, codeproduct-a, and codeproduct-b is tricky. The codecommon depends on codeproduct-a or codeproduct-b, depending on a configuration file. Likewise, codeproduct-a and codeproduct-b depend on codecommon, regardless of the configuration property. codeproduct-a and codeproduct-b will never be built at the same time.I thought a quick solution would be to use something like this in the codeproject/build.gradle: project(':product-a') { dependencies { compile project(':common') }}project(':product-b') { dependencies { compile project(':common') }}reNext, I thought about getting a way to get this closer to working for just codeproduct-a. That led me to this: project(':common') { dependencies { compile project(':product-a') }}reThis will throw an exception for having a circular dependency.I've considered refactoring codeproduct-a and codeproduct-b by setting up interfaces of the classes expected by codecommon and codeproduct-aproduct-b or by using polymorphism, but before I move forward with either of those, is there a better way to accomplish this with Gradle? I'm not ready to get rid of this technical debt yet.",TD-related,build,dependency,2,207,0.038,0.85,0.112,0.9323
46548896,How to avoid heavily changing Maven projects when new versions come out,"Specific BackgroundI have just switched from spring data neo4j 4.1.3 to 5.0.0 And this issue has arisen since I changed my pom file.Maven install fails because cannot find symbol ... class GraphRepositoryI am newer to Java Maven projects as a wholeBroad Question:If I update maven dependencies on a given project from one version of something to another and a class that I have been using heavily now gives around 100 error codes saying that whole class is now missing... how do I have this not happen.Specific Where I think I'm atI am gonna have to remove every reference to the GraphRepository and change it to Neo4jRepository since Also note that GraphRepository is deprecated and replaced by Neo4jRepository - a href=https://stackoverflow.com/questions/46408159/neo4j-4-2-graph-repo-save-method-is-now-ambiguousNeo4j 4.2 graph repo save method is now ambiguous/aBut, this just doesn't seem right. Do I really have to go through an entire project and change all that code just to update?One full line of error:code[ERROR] /.../service/SupportModelServiceImpl.java:[10,49] cannot find symbol symbol: class GraphRepository location: package org.springframework.data.neo4j.repository",TD-related,build,"outdated, dependency",5,165,0.034,0.946,0.02,-0.3182
283511,How to deal with great products written with crappy code?,"I was asked to improve and maintain an internal Web application used and approved by an important community of users. This includes performance improvements and adding features.Unfortunately, the code is bloated, sometimes very poorly written, and hard to read and change. This makes changes much more difficult to implement.Despite all of this, the application is good-looking, useful, and users like it and want changes.That's why I feel like I have been fooled. Is it really better to write crappy code for quicker great result and glory, then leave for great new projects leaving such an amount of problems behind ?I have read a lot about this topic on a href=http://codinghorror.com rel=nofollow noreferrerCoding Horror/a already, but I would like to read more from people here who are experiencing this sad reality, and how they are dealing with it. I might probably need to be given some courage too ;)emAs my primary language is not English, please feel free to rewrite this question with better grammar./em",TD-related,code,"management, td_resolution",1,164,0.092,0.701,0.207,0.9623
642102,How do you maintain a poor-quality codebase?,"To be able to maintain code that I write, I must name the variables well, document my code, keep sure nothing gets repeated, that abstractions are working so that hacks aren't needed.. and comment sparingly because comments often interrupt me reading the code.But many other codebases I've seen are more like a maelstrom. The variable names are foobar, stuff is getting calculated even if never needed, lots of hacks and patches are applied, abstractions fail, deployment scripts fail... The code is an incomprehensible and almost unusable soup.So! I'm curious. How do you manage to maintain poor-quality codebase?",TD-related,code,coding_standards,3,97,0.057,0.849,0.094,0.4376
738067,Paying off technical debt in Agile,"If you are using agile, the idea is to always be doing incremental refactoring and never build up large technical debt. that being said, if you have an agile team that is taking over software that has a decent amount of technical debt, you have to fit it in somewhere.Do you go and create developer user stories . .for example . ulliAs a developer, i have 50% test coverage over the business logic module so i have confidence in deliveryliAs a developer, the application supports dependency injection so we can swap out concretions and be more agile in the future.or is there another best practice for cleaning up this code technical debt",TD-related,code,"management, td_resolution, software_methodology",2,112,0.063,0.813,0.125,0.8115
748503,"How do you introduce unit testing into a large, legacy (C/C++) codebase?","We have a large, multi-platform application written in C. (with a small but growing amount of C++) It has evolved over the years with many features you would expect in a large C/C++ application:ullicodeifdef hellliLarge files that make it hard to isolate testable codeliFunctions that are too complex to be easily testableSince this code is targeted for embedded devices, it's a lot of overhead to run it on the actual target. So we would like to do more of our development and testing in quick cycles, on a local system. But we would like to avoid the classic strategy of copyaste into a .c file on your system, fix bugs, copyaste back. If developers are going to to go the trouble to do that, we'd like to be able to recreate the same tests later, and run in an automated fashion.Here's our problem: in order to refactor the code to be more modular, we need it to be more testable. But in order to introduce automated unit tests, we need it to be more modular.One problem is that since our files are so large, we might have a function inside a file that calls a function emin the same file/em that we need to stub out to make a good unit test. It seems like this would be less of a problem as our code gets more modular, but that is a long way off.One thing we thought about doing was tagging known to be testable source code with comments. Then we could write a script scan source files for testable code, compile it in a separate file, and link it with the unit tests. We could slowly introduce the unit tests as we fix defects and add more functionality.However, there is concern that maintaining this scheme (along with all the required stub functions) will become too much of a hassle, and developers will stop maintaining the unit tests. So another approach is to use a tool that automatically generates stubs for all the code, and link the file with that. (the only tool we have found that will do this is an expensive commercial product) But this approach seems to emrequire/em that all our code be more modular before we can even begin, since only the external calls can be stubbed out.Personally, I would rather have developers think about their external dependencies and intelligently write their own stubs. But this could be overwhelming to stub out all the dependencies for a horribly overgrown, 10,000 line file. It might be difficult to convince developers that they need to maintain stubs for all their external dependencies, but is that the right way to do it? (One other argument I've heard is that the maintainer of a subsystem should maintain the stubs for their subsystem. But I wonder if forcing developers to write their own stubs would lead to better unit testing?)The codeifdefs, of course, add another whole dimension to the problem.We have looked at several C/C++ based unit test frameworks, and there are a lot of options that look fine. But we have not found anything to ease the transition from hairball of code with no unit tests to unit-testable code.So here are my questions to anyone else who has been through this:ulliWhat is a good starting point? Are we going in the right direction, or are we missing something obvious?liWhat tools might be useful to help with the transition? (preferably free/open source, since our budget right now is roughly zero)Note, our build environment is Linux/UNIX based, so we can't use any Windows-only tools.",TD-related,code,"management, dependency",3,593,0.069,0.85,0.081,0.8671
814133,Do you ever make a code change and just test rather than trying to fully understand the change you've made?,"I'm working in a 12 year old code base which I have been the only developer on.There are times that I'll make a a very small change based on an intuition (or quantum leap in logic ;-).Usually I try to deconstruct that change and make sure I read thoroughly the code.However sometimes, (more and more these days) I just test and make sure it had the effect I wanted. (I'm a pretty thorough tester and would test even if I read the code).This works for me and we have surprisingly (compared to most software I see) few bugs escape into the wild.But what I'm wondering is whether this is just the art side of coding. Yes, in an ideal world you would exhaustively read every bit of code that your change modified, but I in practice, if you're confident that it only affects a small section of code, is this a common practice?I can obviously see where this would be a disastrous approach in the hands of a poor programmer. But then, I've seen programmers who ostensibly are reading the code and break stuff left and right (in their own code based which only they have been working on).",TD-related,code,"legacy, td_resolution",3,199,0.054,0.862,0.084,0.2144
1375337,When you're the new guy and you keep seeing dumb things - do you refactor them?,"Do you refactor when you see things like this? Or do you just plug your nose and move on?  public Collection  DataValidationRuleBase   GetFieldValidationRules(String key) { Collection  DataValidationRuleBase   found = null; try { this.mRules.TryGetValue(key, out found); } catch (ArgumentException ex) { //log the error Log.Error(ExceptionHandling.BuildExceptionMessage(ex)); return null; } return found; }re",TD-related,code,"legacy, td_resolution, management",2,50,0.064,0.883,0.053,-0.1431
1389459,TODO/FIXME plugin for Eclipse,In my project there are large no. of codeFIXME / codeTODO which are to addressed at some point of time. Actually there about 480 which can be seen from 'TASKS' list but not organised. I googled and found the a href=http://www.krupets.com/index.php?option=com_content view=article id=11 Itemid=11 rel=nofollow noreferrerTask Tag Decorator/a plugin.But unfortunately this is not working.olliCan anyone suggest a plugin for FIXME/TODOapart from this. liI would also wanted to hear from all how these situations are usually managed,TD-related,code,self-admitted,2,76,0.063,0.937,0,-0.5719
1778683,Dead code detection in PHP,I have a project with very messy code - lots of duplication and dead code here and there.Some time ago there was zero code coverage by unit-tests but now we're trying to write all new code in T.D.D. manner and lowering technical debt by covering old code by unit-tests as well(test-last technique).bBusiness logic's complexity is quite high/b and sometimes no one can answer whether some methods are used or not.How this dead code methods can be found? Extensive logging? Higher test coverage?(It is not very easy because customers want new features to come out),TD-related,code,"duplication, td_resolution, dead_code",4,94,0.214,0.772,0.013,-0.9704
1788399,Separating rapid development from refactoring/optimization,"I'm working in a team of 2 front-end developers on a web-based late-stage startup project.The site works quite well, but there's a lot of room for improvement code-wise, as the code is quite messy and disorganized.I would like to clean things up gradually by writing tests and carefully refactoring to avoid breaking anything. (Using principles from the book 'Working Effectively with Legacy Code')However, the developer I'm working with is being given a lot of high-priority feature work, and I don't want to burden him with maintenance tasks. A lot of the time he has to write messy code simply because of the time-constraints.As the team grows I'm concerned about how to manage the different concerns.I'm thinking of dividing the team into 2 groups:Does rapid development on new features, with less care on code quality.Writes unit tests, refactors code, generally optimizes things.The result I'm aiming for is to bring as much of the code under test as possible, while still keeping up the pace of new-feature development.Has this been tried before? Any thoughts?",TD-related,code,management,3,172,0.06,0.788,0.152,0.956
2485491,Legacy code - when to move on,"My team and support a large number of legacy applications all of which are currently functional but problematic to support and maintain. They all depend on code that the compiler manufacture has officially no support for. So the question is should we leave the code as is, and risk a new compiler breaking our code, or should we bite the bullet and update all the code?",TD-related,code,"legacy, td_resolution, management",5,66,0.138,0.73,0.132,-0.128
2640386,"Reuse, Rewrite, or Refactor?","At work I inherited development of a PHP-based Web site after the consultant who originally produced it bailed out and left without a trace. Literally half of the code is ripped from online tutorials, and there are thousands of lines of cruft that, being incomplete, do precious little. Hardly any of it actually works. I've been trying to pull out the usable components, such as the layout (cleverly intermixed with code), session management (delicately seasoned with unescaped, unvalidated SQL queries), and a few other things, but it's very difficult to force all of this junk into place. Further, I don't speak idiomatic PHP, being more of a Perl user, and I'm supposed to be on this project principally for maintenance, so rewriting everything seems like it would take just as long as wrestling the existing monster back into place.As an aside, I have literally never seen anything as badly written as this. Welcome me to the world of working with other people's code, I guess, but I do hope it's not this common in the real world to have such gems as these:ullicode// WHY IS THIS NOT WORKINGlicode// I know this is bad but were going for working stuff right now...licode// This is a PHP code outputing Javascript code outputting HTML...do not go furtherlicode// Not userfulI'm looking for the best advice I can get here. What would you do if you were in my position?Edit: Thank you, everyone, for your speedy and helpful advice!",TD-related,code,"td_resolution, management",4,244,0.048,0.848,0.104,0.9398
2736016,jersey restful + grizzly server + hibernate,"I can bring jersey + grizzly server up. But some problem occur during ""SessionFactory sessionFactory = new Configuration().configure().buildSessionFactory;"" error says ""SEVERE: service exception: org.hibernate.HibernateException: /hibernate.cfg.xml not found.. anyone know how to make hibernate can access hibernate.cfg.xml location.",TD-related,code,dependency,3,37,0.182,0.818,0,-0.7964
2761622,New Facebook like button HTML validation,"After adding the new facebook like button on my page, it's no longer validates using XHTML strict standard. The two errors I come across are:All of the meta property tags say that there is no attribute property;All of the variables used in the like button line are listed that there are no attributes for it. The line is as follows:<fb:like href=""http://www.pampamanta.org"" layout=""button_count"" show_faces=""false"" width=""120"" action=""like"" font=""arial"" colorscheme=""light""></fb:like>",TD-related,code,debugging,1,67,0.119,0.782,0.098,-0.1531
3344731,C optimization question,"I'm wondering what is the fastest way that I can write some code. I have a loop which executes an add on some ints. The loop will be executed many, many times and so I've thought of making comparisons to check if any operands are zero, so they shouldn't be considered to be added, as follows:<code>more than once.Sadly, I wouldn't be able to say just how frequently work1 and work2 would be zero, so assume it's likely to be a balanced distribution of each possible outcome of the IF statement.So, in light of that, is the above code faster than just writing codetempAnswer = work1 + work2 + toCarry or would all the comparisons possibly cause a lot of drag?Thanks",TD-related,code,td_resolution,4,120,0,1,0,0
3727431,Connection timing out when connecting to an IRC server with PHP,"I'm trying to connect my PHP script to IRC, but it keeps timing out. I'm on the server, so I know it's up and running, I can't tell what the problem is.Could it be an error in my code?",TD-related,code,debugging,1,39,0.169,0.831,0,-0.7964
4020374,Is it safe to omit /TD and /TR tags?,"According to a href=http://www.w3.org/TR/html401/struct/tables.htmledef-TDw3c/a code  /TD   and code  /TR   tags are optional, so the following table is perfectly valid.   table     tr     td  google   td  chrome  /table  reAnd all browsers I've tested it with render the table fine. I just wanted to ask if this is generally considered safe to use, or if older browsers, which I don't have access to, cause problems. Thanks.It reduces gzip html size on a page with many tables by a few percent.",TD-related,code,database,2,77,0.034,0.854,0.112,0.7351
4390484,"Just because something works, does it mean you don't have to refactor?","I just saw this line of code in the WP codebase.<code> Yeah. two method calls and an assignment statement in an if statement.So, my guess is, nobody is refactoring this.Are there any reasons why?",TD-related,code,"td_resolution, management",2,34,0,0.863,0.137,0.6037
4692056,Is there a situation when it's appropriate to use empty catch block?,block e Possible Duplicates:br a href=https://stackoverflow.com/questions/1234343/why-are-empty-catch-blocks-a-bad-ideaWhy are empty catch blocks a bad idea?/abr a href=https://stackoverflow.com/questions/204814/is-there-any-valid-reason-to-ever-ignore-a-caught-exceptionIs there any valid reason to ever ignore a caught exception/a /block eDo you know any situations when an empty catch block is not the absolute evil? try{ ... // What and When? ...}catch { }re,TD-related,code,suboptimal_design,1,50,0.311,0.628,0.061,-0.9067
4760074,Advice on working with legacy code,"I need some advice on how to work with legacy code.A while ago, I was given the task to add a few reports to a reporting app. written in Struts 1, back in 2005. No big deal, but the code is quite messy. No usage of Action forms, and basically the code is one huge action, and a lot of if-else statements inside. Also, no one here has functional knowledge on this. We just happened to have it in our contract.I'm quite unhappy about this, and not sure how to proceed. This application is invisible: Few people (but all very important) use it, so they don't care whether my eyes bleed while reading the code, standards, etc.However, I feel that a technical debt is to be paid. How should I proceed on this? Continue down the if-else road, or try to do this requirement the right way, ignoring the rest of the project? Starting a huge refactor, risking my deadline?",TD-related,code,"legacy, td_resolution, management",6,160,0.179,0.788,0.033,-0.9769
5554566,C - Code Analysis 2227 Confusion,I have a class property that looks as follows:<code>  Analysis is issuing a CA 2227 warning: Change RecipeList to be read-only by removing the setter. Could anyone tell me why?,TD-related,code,suboptimal_design,3,30,0.085,0.915,0,-0.34
5650391,c code flow mapping/visualization utility?,"I've been asked to re-write (from the ground up) an existing C winforms application. Unfortunately, this code has been modified by at least a dozen different developers over the past three or four years none of whom seemingly adhered to any kind of coding standard. To say that this code base is a mess would be putting it politely. Given the magnitude of the code (~24k lines) and the fact that the code is completely new to me, I'd like to find some kind of utility that will help me to more quickly understand how this application works at a high level. Bear in mind that there don't seem to be an abundance of good OOP practices in this code so I need something a little more detailed than class diagrams. I've seen references to generating sequence diagrams which might be more like what I'm looking for but I only have VS2010 Premium and I'm under the impression that this functionality is only provided with the VS Ultimate SKU. I have access to the current version of .NET Reflector and I've seen a couple of people mention that there are plug-ins for that which might be useful but I don't have any specific names.",TD-related,code,"coding_standards, td_resolution",2,204,0.017,0.916,0.067,0.8422
8156089,Flash message showing twice when using redirect_to (Rails 2),"Ok, this is a weird one. flash[:success] = 'some success message'redirect_to :controller =   'media', :action =   'index'reThe message is being displayed after the redirect, the thing is it also appears one more time after clicking on a link or go to another page in my app (after the first redirect)",TD-related,code,debugging,2,50,0.034,0.847,0.119,0.6369
8340752,Paypal Form Inside ASP.NET Form,"Cheers,I have a problem with integrating Paypal Shopping Cart to my ASP.NET C project.The problem is that Paypal Shopping Cart is inside a FORM tag, so if I place that inside my server form tag it won't work.It would look like this: <code>, but honestly, it doesn't make any sense to me since I'm not a programmer.Thank you!",TD-related,code,debugging,4,58,0.063,0.834,0.103,0.5175
10300658,How to make this object more maintainable?,"For example, I have something like this: User-FirstName-SecondName-Genderreand the codeVIPUser, which is the subclass of codeUser VIPUser extends User-GiftNum-BirthdayreBut suddenly the application need to change the policy, all the codeUser must have the codeBirthday.... And it is not a optional field, which not allow to set codenull anymore for user, it becomes the MUST fill in variable for the new register codeUser, but I can remain codenull for the existing user...So, I will need to change all the codeUser creation method, and pass the codeBirthday, it involves lot of codes. How can I make it more maintainable? Thanks.",TD-related,code,coding_standards,2,98,0.013,0.887,0.1,0.8217
10857288,Does jQuery's preventDefault() work for form's submit events?,"I have a form like this:   form method=post action=/WebApp/forgotpassword id=forgot-password     input type=email name=email id=email     input type=submit value=Submit id=submitBtn    /form  rewith the following jQuery 1.7.2 code: $('formforgot-password').on('submit', function(e) { console.debug('Form submit'); e.preventDefault(); return false;});reSure enough, I click on the Submit button, and then Form submit is printed in the console. However, the browser (Firefox in my case) still redirects to the JSON returned by the service at /WebApp/forgotpassword.I haven't seen any other questions that seem to indicate that jQuery is broken, so I assume I'm using it wrong.Thanks for your help!",TD-related,code,debugging,3,90,0.034,0.905,0.061,0.3382
10987336,c multiforms DataSet,"On the first form I have:<code>, on the secondForm I need the same DataSet(dsUni) to writeXml from changed dgv02.brBut, i got the errors:brThe name 'dsUni' does not exist in the current contextbrPlease, give me a solution for this case.",TD-related,code,debugging,4,39,0,0.937,0.063,0.3182
11768087,Is eval() always wrong?,"I know eval() and exec() should be avoided, but in this situation it seems like the best choice: I'm getting values from checkboxes and textboxes in wxPython and putting them in my config class. Here's how I'm using eval(): config = wx.Config()checkBoxes = ['option_1', 'option_2']for key in checkBoxes: config.Write(key, str(eval('self.m_checkBox_'+key+'.GetValue()'))reThere aren't any security problems because there isn't any user-input to eval, and it seems pretty clear to me. Is there a better way to do this?",TD-related,code,coding_standards,2,76,0.045,0.668,0.287,0.9771
12296647,How to manage a project on ruby on rails 2.3?,I have a large ruby on rails 2.3 which was now a disaster because of the slowness and many bugs. I'm the only programmer and every day I've done debugging and tearing my hair off because of this. The users are already using the product but so many bugs and data are scattered.I was employed without prior knowledge of project development and management. Now I'm suffering of having more overtime and a crisis on my codes to be fixed.And also I've created this app while learning rails so there are codes there that became stranger to me.What should I do? What are your suggestions?What books do I need to read about more?Please I need some help.Thanks.,TD-related,code,management,6,116,0.11,0.869,0.021,-0.915
12340381,"Learning principles of Dependency Injection, applicable in this situation?","I have been doing a lot of reading and tutorials on Dependency Injection via Ninject in the hopes of re-factoring one of my applications to be more flexible and scalable in the future. My web app is built on top of an API that gives me access to the back-end infrastructure.Part of my technical debt that I'm trying to clear up is the repeated code that comes with every single API call that I have to make. The API has about 45-50 methods for fetching and managing different entities.The following (greatly simplified) code example illustrates a recurring pattern that is found emeverywhere/em in my code. Can Ninject/DI help make things easier for me? <code>It should be noted that I do not have access to the code for all of the request and response objects, they are part of a shared library that I reference.",TD-related,code,"interface, dependency, td_resolution",4,144,0.017,0.867,0.116,0.9152
13725118,C++ input operator overload,"I'm trying to overload the input operator on a UserLogin class I've created. No compile-time errors are thrown, however the values are not set either.
Everything runs, but it the content of ul remains: string id is sally Time login is 00:00 Time logout is 00:00
Entry Point
#include <iostream>
#include ""UserLogin.h""
using namespace std;
int main() {
UserLogin ul;
cout << ul << endl; // xxx 00:00 00:00
cin >> ul; // sally 23:56 00:02
cout << ul << endl; // Should show sally 23:56 00:02
// Instead, it shows xxx 00:00 00:00 again
cout << endl;
system(""PAUSE"");
}
UserLogin.h
#include <iostream>
#include <string>
#include ""Time.h""
using namespace std;
class UserLogin
{
// Operator Overloaders
friend ostream &operator <<(ostream &output, const UserLogin user);
friend istream &operator >>(istream &input, const UserLogin &user);
private:
// Private Data Members
Time login, logout;
string id;
public:
// Public Method Prototypes
UserLogin() : id(""xxx"") {};
UserLogin( string id, Time login, Time logout ) : id(id), login(login), logout(logout) {};
};
UserLogin.cpp
#include ""UserLogin.h""
ostream &operator <<( ostream &output, const UserLogin user )
{
output << setfill(' ');
output << setw(15) << left << user.id << user.login << "" "" << user.logout;
return output;
}
istream &operator >>( istream &input, const UserLogin &user )
{
input >> ( string ) user.id;
input >> ( Time ) user.login;
input >> ( Time ) user.logout;
return input;
}",TD-related,code,debugging,2,182,0.023,0.922,0.055,0.836
17455303,Cannot add more than one row to a table dynamically using ASP/C,"I have a web app with HTML tables containing input boxes everywhere in it. I want to be able to add rows to these tables from the C side of things. To accomplish this, I use an asp button that calls this method:<code>This works beautifully...for exactly one row. I can click the button, it adds a row. If I click it again, it doesn't do anything. More specifically, I suspect it's removing the currently added row, restoring the document to the 'default' state, and then adds a row (effectively doing nothing).Assuming I'm right, I need to somehow be able to append a row to another dynamically created row, instead of just replace it. If I'm not right, I just need a means to be able to continually add rows on a button press.How would I go about doing this?EDIT: I should specify, all this could be done in a loop, all at once. I was hoping to get it to work on a button press just for the sake of testing, but it can all be neatly tucked into a loop of some kind. I've had (some) success dropping it in one.",TD-related,code,database,2,192,0.009,0.869,0.122,0.9572
18146293,SSIS The expression for variable 'Variable' failed evaluation. There was an error in the expression,"So here we have an error I keep getting in my SSIS package but I can't see what is wrong with the statement. I have even tried another sql statement from a project that works and it still raises the error.The system is VS 2005 running 64 bit debugger, on XP machine. The project has amongst other things a script task then a sql task, the script task outputs the month value to a variable (Dts.Variables(monthName).Value = month), which I then use to create dynamic table name in SQL statement. I haven't got to the excel sheet bit yet as I am trying to get the sql task stage working.So i have a variable at package level called SQLTableCreate, and in that I have the properties set to:<code> failed and returned error code 0xC00470A6. The expression cannot be parsed. It might contain invalid elements or it might not be well-formed. There may also be an out-of-memory error.Error at Package: The expression for variable SQLTableCreate failed evaluation. There was an error in the expression./block eThere is also a default SQL statement for the variable SQLTableCreate, which uses the current excel connection manager table name. When I put my dynamic statement in the expression section of properties it fills the value and valuetype property of the SQLTableCreate variable with the message:block e The expression for variable SQLTableCreate failed evaluation. There was an error in the expression./block e",TD-related,code,debugging,2,235,0.116,0.776,0.109,-0.4311
18921381,rally.sdk.ui.StandardReport.ReleaseDefectTrend does not produce accurate results outside of Rally using loginkey,"I am trying to create a Release trend chart, but I am getting different results if I run the code inside a rally app versus running the app outside of rally using a valid login key. Below is the code in question. After getting the chart to work correctly, I would love to be able to show some subset of the data, similar to the actual ReleaseDefectTrend chart inside of Rally, that lets you specifiy XXX number of days/weeks/months/etc. Are there setting(s) for the config of the chart that will allow you to do this.Thanks in advance!   <code>",TD-related,code,debugging,2,98,0,0.884,0.116,0.8871
22538494,"Creating Dictionarystring, DictionaryT, T[][]","In C, what is the syntax for instantiating and initializing a dictionary containing as values an array of dictionaries, those dictionaries themselves containing arrays as values?For example, (I believe), Dictionary  string, Dictionary  string, string[]  []  ?reHere's an example of what I'm trying to do: private static readonly Dictionary  string, Dictionary  string, DirectoryInfo[]  []   OrderTypeToFulfillmentDict = new Dictionary  string, Dictionary  string, DirectoryInfo[]    () { {Type1, new [] { ProductsInfo.Type1FulfillmentNoSurfacesLocations, ProductsInfo.Type2FulfillmentSurfacesLocations } } }rewhere Type1Fulfillment..., and Type2Fulfillment... are already constructed as  Dictionary  string, DirectoryInfo[]  . reThis throws the following compiler error: Cannot convert from System.Collections.Generic.Dictionary  string, System.IO.DirectoryInfo[]  [] to System.Collections.Generic.Dictionary  string, System.IO.DirectoryInfo[]  reEdit: The problem was, as Lanorkin pointed out, that I was missing the final code[] in the new codeDictionary  string, Dictionary  string, DirectoryInfo[]    (). Still, it goes without saying that this probably isn't something anyone should be trying to do in the first place.",TD-related,code,debugging,2,144,0.056,0.925,0.019,-0.644
22746948,class inherits unrelated defaults for spliterator() from types java.util.Set and java.util.List,"I have class that implements Set and List. Programs works fine in Java6 and Java7 public class SetList  V   implements Set  V  , List  V  { ....}reWith Java 8 , this does not compile. Error is block e java: class trials.SetList inherits unrelated defaults for spliterator() from types java.util.Set and java.util.List/block ejava/util/Set.java:394  ...@Overridedefault Spliterator  E   spliterator() { return Spliterators.spliterator(this, Spliterator.DISTINCT);}rejava/util/List.java ...@Overridedefault Spliterator  E   spliterator() { return Spliterators.spliterator(this, Spliterator.ORDERED);}reDoes it mean I cannot have class that implement both Set and List in Java 8? (It looks like time has come to pay our technical debts.)",TD-related,code,debugging,3,94,0.05,0.874,0.076,0.3089
24275273,Recursive function in php storing results without using static,I wrote the following recursive function to keep looping through result looking for code$result-  pages-  next and calling out to curl fetching the next page and aggregating the results. Finally it returns all results as a single object. <code>However I really don't like using codestatic and it feels poorly implemented and a source of technical debt. What is a more elegant way to do this?UpdateBeing called with: return $this-  pager($this-  get_curl_request(https://api/request/here));reemOpen to changing how it is called./em,TD-related,code,debugging,2,77,0.063,0.893,0.044,-0.1269
26568477,XPages: Using postNewDocument to populate fields from an agent,"I am trying to pre-populate some fields on an XPage (that creates a new doc) using an old LotusScript agent. My code on the XPage is:pre class=lang-xml prettyprint-overridecode   xp:dominoDocument var=document1 formName=myForm     xp:this.postNewDocument    ![CDATA[{javascript: var agent = database.getAgent(MyAgent); document1.save(); agent.runOnServer(document1.getNoteID()); }]]    /xp:this.postNewDocument    /xp:dominoDocument    xp:inputText value={document1.fname} id=fname styleClass=formInputText     xp:this.defaultValue    ![CDATA[{javascript: document1.getItemValueString(fname);}]]    /xp:this.defaultValue    /xp:inputText  reThe agent (for this example) is:pre class=lang-vb prettyprint-overridecodeDim agent As NotesAgentDim db As NotesDatabaseSub Initialize Dim rDoc As NotesDocument Dim s As New NotesSession Set db = s.CurrentDatabase Set agent = s.CurrentAgent Set rDoc = db.GetDocumentByID(agent.Parameterdocid) rDoc.fname = Barney rDoc.lname = Rubble Call rDoc.Save(True, True)End SubreI know the agent is running (Agent log shows this and the fields are completed on the doc if I check the doc properties in Notes Client) however the field on the XPage is always blank? Is it possible to prepopulate from a LS agent? I added the document1.save() so I know I get a valid NoteID passed over (again which is the same - checked by logging) - any insight gratefully received...",TD-related,code,debugging,4,169,0,0.961,0.039,0.7306
26747737,How do I declare a variable that's accessible from everywhere in my Rails application?,"Just wondering how would one do to have something like devise has with current_user, a globally available variable in what I'm guessing is a session ?By this I mean, to get anything in a view from somewhere else, you need the @ prefixWhat is then this kind of variable ? How make such a variable available 'globally ?",TD-related,code,coding_standards,2,58,0,0.942,0.058,0.466
26802657,Find hardcoded Strings in legacy application,I inherited a Java-Application with many emmany/em hardcoded Strings that should have been localized. THe code-base is huge and I need an overview about all the used hardcoded String values in the code. Is there a tool (or an IDE-function; I use Eclipse and IntelliJ IDEA) that extracts all strings from Java-classes?,TD-related,code,td_resolution,3,52,0,0.9,0.1,0.6124
27092820,storing arrays into mySQL with php explode(),"I am making a website for a cars show, i want to store images in the database (just the URL) and what i want to do is for all the images to be added to the same cell in the table.then at retrieval time, i want to use the explode() command in php so i can seperate each URL and use a loop to display them.the problem i am facing it i do not know what i should use for a delimiter, i cannot use anything that can be used in windows, mac or Linux which can be used in a file name, and i am afraid of using a system reserved key and cause a problem.i am also concerned about the data type that will hold this information, i am thinking TEXT is best here but i heard many saying it causes problem.to be clear, the idea is:when someone uploads 3 images, the images will be uploaded into a folder, then the names will be taken and put into 1 string (after the directories names are added) with a separator between them that then will be stored in the database.Then, i take that string, use explode() and store the separated data in an array and use a loop to display an image with the source being the stored data in the array. i need a special delimiter or another way... can someone help me do this or tell me another way of saving the images somehow without a potential risk! i have seen many website which uses dynamic bullet points (lists) but i was never able to get a code or even an idea of how to do them.EDIT:The current way i am using is having 10 rows, 1 for each image.. but the problem here is that the user will not be able to add more than 10 images, and if he has less than 10 images then there will be few empty images being displayed. (i know a solution for the empty images, but it is impossible to add more images..)",TD-related,code,database,3,344,0.03,0.894,0.077,0.9275
28909882,Dealing with malformed XML,"I'm dealing with malformed XML in perl that's generated by an upstream process that I can't change (seems like this is a common problem here). However, as far as I've seen, the XML is malformed in only one particular way: it has attribute values that contain unescaped less-than signs, e.g.:   tag v=   2  reI'm using perl with a href=http:/3rl.org/XML::LibXML rel=nofollowXML::LibXML/a to parse, and this, of course, generates parse errors. I've tried using the recover option, which allows me to parse, but it simply stops when it encounters the first parse error, so I'm losing data that way.It seems like I have two general choices:olliFix the input XML before I parse it, perhaps using regular expressions.liFind a more forgiving XML parser.I'm leaning towards option 1, as I'd like to catch any other errors with the XML. What would you recommend? If 1, can someone guide me through the regex approach?",TD-related,code,coding_standards,4,149,0.142,0.8,0.058,-0.895
30036167,Switching to cout from printf - Complex format specifier patterns,"I have to rewrite a logging system in C++ as part of project requirements (everything has to be C++ instead of C now), and there are a number of ways in which we log things like mathematical data and pointer addresses. It is fairly common to see a log like: log(%3.4f %d %zp %5.8f, ...);reIn C++, using codecout instead of codeprintf, it seems a bit more of an involved process to setup such a logging format, eg, taking the following snippet from C++ Primer Plus (Prata): ios_base::fmtflags initial;initial = os.setf(ios_base::fixed); // save initial formatting stateos.precision(0);os.setf(ios::showpoint);os.precision(1);os.width(12);reThis looks like it will set the width and precision for all floating point items in the argument list, and won't allow me to have different values for different variables.Can codecout even generate such a string in a simple manner with just one line of code, or should I use codesprintf to prepare my strings and then feed them to codecout?Thanks!",TD-related,code,logging,3,155,0.027,0.877,0.097,0.8698
31422443,Best Practices for Using Multi Level HashMap in Java,"We have a situation where we are ending up using multi-level hash maps; that is, a hash map inside of a hash map, three or four levels deep.Instinctively this felt wrong somewhere. I have read posts here that talks about how to iterate/use a multi-level hash map, but hardly any of them say what is the best practice for this.Why are multi level hash maps bad, and what would be the better design, if any?Here is the sample design of multi-level hash maps that we have: Map  String, Object1   map1;class Object1 { String version; Map  String,Object2   map2;}class Object2 { Map  String,List  Object3     map4; Map  String,String   map5;}re",TD-related,code,coding_standards,3,106,0.061,0.852,0.087,0.5927
32900178,Do I really need to convert my project currency to NSDecimalNumber?,"Yes, I know I should use codeNSDecimalNumber to deal with currency, money, price... a href=https://stackoverflow.com/questions/421463/should-i-use-nsdecimalnumber-to-deal-with-moneyI've read this./a The problem is, I adapted an existed project, which use codeNSString and codeNSNumber (codefloat, codedouble, codeCGFloat...) as currency. They deal with floating point by using codeNSNumberFormatter, as I can see it's not a big problem (yet?). Those currency is stored to coredata.Now, if I want to convert all of those currency into codeNSDecimalNumber, I'll have to do a massive refactor in the code and migration in coredata. Here come the question:block e ol liIf (I assume) codedouble, codeCGFloat, codeNSNumber can hold the value as large as codeNSDecimalNumber, why should I use codeNSDecimalNumber since I can use other with codeNSNumberFormatter? Is it because of performance? liIn case of the necessary of the converting, can I do an auto migration with the help of MappingModel only, of course), or do I have to adapt a custom migration policy? /block eBecause the coredata use both codeNSString and codeNSNumber as currency, so please help me find a solution to migrate from both data type. I'm not used to work with codeNSDecimalNumber in coredata. Thanks in advance.EDITOkay, I got it that NSDecimalNumber is necessary. Please help me answer the second question: Can I do auto migration, using mappingModel + the thing like codeFUNCTION($source.price, decimalValue) (this is incorrect since decimalValue return codeNSDecimal, not codeNSDecimalNumber). Do I really have to write a custom migration policy?",TD-related,code,coding_standards,4,235,0.023,0.856,0.121,0.964
32986043,Patch C/C++ function to just return without execution,"I want to avoid one system function executing in a large project. It is impossible to redefine it or add some codeifdef logic. So I want to patch the code to just the coderet operation.The functions are: void __cdecl _wassert(const wchar_t *, const wchar_t *, unsigned);reand: void __dj_assert(const char *, const char *, int, const char *) __attribute__((__noreturn__));reSo I need to patch the first one on codeVisual C++ compiler, and the second one on codeGCC compiler.Can I just write the coderet instruction directly at the address of the code_wassert__dj_assert function, for x86/x64?UPDATE:I just wanna modify function body like this: *_wassert = `ret`;reOr maybe copy another function body like this: void __cdecl _wassert_emptyhar_t *, const wchar_t *, unsigned){}for (int i = 0; i    sizeof(void*); i++) { ((char*)_wassert)[i] = ((char*)_wassert_empty}reUPDATE 2:I really don't understand why there are so many objections against silent codeasserts. In fact, there is no asserts in the codeRELEASE mode, but nobody cares. I just want to be able turning on/off the asserts in the codeDEBUG mode.",TD-related,code,debugging,4,168,0.02,0.903,0.077,0.7469
35798480,Writing new code in async but calling sync,"I am writing some new code and would like to write it using async and await, but the calling code is not currently written in async. Is it right to write the new code in async and call it sync until the calling code supports async?Or should I write the code sync and then convert it at a later date? And would it be considered technical debt? public Result Execute( Paramerters parameters ) { return ExecuteAsync( parameters ).Resu }public Task  Result   ExecuteAsync( Paramerters parameters ) { ...}/ Execute is on an interface and is called from some other code that is not yet async. Is it correct to create the async version and call it from codeExecute until the code calling codeExecute is converted to async?My old code is written in .net 4.5.1 but is not yet converted to async.",TD-related,code,td_resolution,4,140,0.023,0.907,0.07,0.6767
36345611,Decreasing memory consumption in R -- pass by reference / data.table,"I've already achieved a substantial speed up (~6.5x) by moving subsetting operations from base codedata.frame operations to codedata.table operations. But I'm wondering if I can get any improvement in memory. My understanding is that R does not natively pass-by-reference (eg. a href=https://stackoverflow.com/questions/2603184/r-pass-by-referencesee here/a). So, I'm seeking a method (short of re-writing a complex function in codeRcpp) to do so. codedata.table provides some improvement [after editing my question to include typo caught by @joshua ulrich below]. But I'm looking for a larger improvement if possible.ulliAnother option is possibly the a href=https://cran.r-project.org/webackages/R.oo/R.oo.pdf rel=nofollow noreferrerR.oo package/a, though I haven't yet found a good tutorial. (emI still need to read a href=http://www.ci.tuwien.ac.at/Conferences/DSC-2003roceedings/Bengtsson.pdf rel=nofollow noreferrerthis/a./emliWould a href=http://stat.ethz.ch/R-manual/R-develbrary/methods/html/refClass.html rel=nofollow noreferrerreference classes/a help at all?emIn my actual use case, I'm doing simulation in parallel of numerous datasets with optimization via simulated annealing. I'd rather not re-write both simulated annealing and my loss function calculations in Rcpp due to the increased dev time and increased a href=https://en.wikipedia.org/wiki/Technical_debt rel=nofollow noreferrertechnical debt/a./emExample of problem:/What I'm largely concerned with is removing some subset of observations from a dataset and adding in another subset of observations. A very simple (nonsensical) example is given here. Is there a way to decrease memory usage? My current usage appears to pass-by-value and therefore memory usage (RAM) is roughly doubled.  library(data.table)set.seed(444L)df1   - data.frame(matrix(rnorm(1e7), ncol= 10))df2   - data.table(matrix(rnorm(1e7), ncol= 10))prof_func   - function(df) { s1   - sample(1:nrow(df), size= 500, replace=F) s2   - sample(1:nrow(df), size= 500, replace=F) return(rbind(df[-s1,], df[s2,]))}dt_m   - df_m   - vector(numeric, length= 500L)for (i in 1:500) { Rprof(./DF_mem.out, memory.profiling = TRUE) y   - prof_func(df1) Rprof(NULL) df   - summaryRprof(./DF_mem.out, memory= both) df_m[i]   - df$by.self$mem.total[which(rownames(df$by.self) == \rbind\)] Rprof(./DT_mem.out, memory.profiling = TRUE) y2   - prof_func(df2) Rprof(NULL) dt   - summaryRprof(./DT_mem.out, memory = both) dt_m[i]   - dt$by.self$mem.total[which(rownames(dt$by.self) == \rbind\)]}pryr::object_size(df1)80 MBpryr::object_size(df2)80 MB EDITED: via typo / fix from @Joshua Ulrich. improvement in memory usage via DT. still not pass-by-referencequantile(df_m, seq(0,1,.1)) 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% 379.00 428.60 440.10 447.70 455.36 459.20 466.48 469.89 474.40 482.10 512.60 quantile(dt_m, seq(0,1,.1)) 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% 76.80 84.50 84.50 92.10 92.10 92.10 92.10 107.30 116.46 130.20 157.00 reAppendix:/  speed improvement:-----------------------------------------------library(data.table)library(microbenchmark)set.seed(444L)df1   - data.frame(matrix(rnorm(1e7), ncol= 10))df2   - data.table(matrix(rnorm(1e7), ncol= 10))microbenchmark( df= { s1   - sample(1:nrow(df1), size= 500, replace=F) s2   - sample(1:nrow(df1), size= 500, replace=F) df1   - rbind(df1[-s1,], df1[s2,]) }, dt= { s1   - sample(1:nrow(df2), size= 500, replace=F) s2   - sample(1:nrow(df2), size= 500, replace=F) df2   - rbind(df2[-s1,], df2[s2,]) }, times= 100L)Unit: milliseconds expr min lq mean median uq max neval cld df 672.5106 757.65188 814.1582 809.6346 864.6668 998.2290 100 b dt 68.1254 85.73178 139.1256 120.3613 148.8243 397.7359 100 a re",TD-related,code,database,5,433,0.015,0.912,0.073,0.9749
37146306,Is a for loops scope unique,"I ran into this while performing some technical debt duties. What is the scope of the variable codefoo ? Is it really already defined? function fn(){ for (var i = 0; i    m.length; i++) { if(condition) for (var j = 0; j    m.length; j++) { var foo = bar; } else var foo = fubar }}reUPDATE: The question is about the scope of the variables defined within a conditional block. Since this isn't nested in a function/closure there is no unique scope.Here is a snippet to illustrate:div class=snippet data-lang=js data-hide=false&xD;div class=snippet-code&xD;pre class=snippet-code-js lang-js prettyprint-overridecodevar x = foo,&xD; a = [];&xD;&xD;for(var i=0;i  10;i++){&xD; var x = {value:1+i};&xD; a.push(x)&xD;}&xD;&xD;document.write(  pre   + &xD; x.value + \n + &xD; JSON.stringify(a,null, ) + &xD;   re  &xD; );re&xD;/div&xD;/div&xD;",TD-related,code,coding_standards,3,122,0.116,0.884,0,-0.8992
38154674,What is the 'AngularJS' way to disable an 'option' HTML5 element?,"What is the 'AngularJS' way to disable an 'option' HTML5 element?I'm using AngularJS v1.2.25.Plunk Link:a href=https:/lnkr.co/edit/fS1uKZ rel=nofollow noreferrerhttps:/lnkr.co/edit/fS1uKZ/a   !-- CODE BEGIN --    !DOCTYPE html    html     head     script data-require=angular.js@2.0.0 data-semver=2.0.0 src=https:/.angularjs.org/2.0.0-beta.6/angular2.min.js    /script     link rel=stylesheet href=style.css /     script src=script.js    /script     /head     body     select     option value=volvo  Volvo  /option     option value=saab  Saab  /option     option value=opel  Opel  /option     option value=audi  Audi  /option     /select     select     option value=volvo  Volvo  /option     option value=saab  Saab  /option     option value=opel  Opel  /option     option value=audi  Audi  /option     /select     select     option value=volvo  Volvo  /option     option value=saab  Saab  /option     option value=opel  Opel  /option     option value=audi  Audi  /option     /select     select     option value=volvo  Volvo  /option     option value=saab  Saab  /option     option value=opel  Opel  /option     option value=audi  Audi  /option     /select     /body    /html    !-- CODE END --  reI'm making a 'form' element and there are several 'select' element tags with several 'option' element tags.The 'option' element tags have identical attributes throughout all four of the 'select' element tags.I want the user to rank the car manufacturers. When they select a manufacturer, I want to disable that 'option' element in all four 'select' element tags.I found the following question/answer, but is this the 'AngularJS' way? (a href=https://stackoverflow.com/questions/21969798/disable-option-in-selectDisable option in select/a)They are using jQuery and I know that AngularJS contains 'jQuery Lite', but is that implementation the 'AngularJS' way?I found this documentation at the AngularJS site:htt9$://docs.angularjs.org/api/ng/directive/ngDisabledThis is the accompanying Plunk link:htt9$:/lnkr.co/edit/?p=previewI can appreciate the example provided by the AngularJS team. I was thinking about modifying ng-model and/or ng-disabled. I would like to avoid 'hacking' AngularJS 'core' files.Do I decouple ng-model and/or ng-disabled?Or, should I craft a custom filter?I come from a jQuery background, and I'm trying to adhere to AngularJS best practices as much as possible. I want to prevent excessive 'technical debt'.",TD-related,code,debugging,4,282,0.01,0.922,0.068,0.9386
38785607,How to edit a MonoBehaviour's properties on a prefab in the UnityEditor from Script,"Assume I have a simple codeMonoBehaviour public class FooScript : MonoBehaviour { public int someValue = 0;}reI make GameObject, attach a codeFooScript. I make a prefab from that and delete in instance in the scene.In the editor I can select the prefab in the project and I can edit codesomeValue. Assuming I know the path to the prefab how I can make an edit time script that makes edits to the codeFooScript instance inside the prefab?What've tried GameObject prefab = AssetDatabase.LoadAssetAtPath  GameObject  (pathToPrefab);GameObject root = ???? // WHAT DO I CALL HERE!?FooScript fooScript = root.GetComponent  FooScript  ();fooScript.someValue = 789;reActually in that case codeprefab is nullIf switch to Object prefab = AssetDatabase.LoadMainAssetAtPath(prefabPath); GameObject root = prefab as GameObject;/ prefab is not null but coderoot isNext I tried this Object[] objs = AssetDatabase.LoadAllAssetsAtPath(prefabPath);foreach (var o in obs){ Debug.Log( type: + (o.GetType().Name));}reThat prints type: GameObjecttype: Transformtype: FooScriptreBut using that is a hacky solution as I'd have to try every GameObject and or FooScript. I means I suppose as a pragmatic solution it might work but it feels like adding technical debt I'll have to fix later Other things I've tried is creating a new prefab with a new GameObject and a new FooScript and calling codePrefabUtility.ReplacePrefab GameObject newGameObject = new GameObject();FooScript fooScript = newGameObject.AddComponent  FooScript  ();fooScript.someValue = 789;Object prefab = AssetDatabase.LoadAssetAtPath  GameObject  (prefabPath);PrefabUtility.ReplacePrefab(newGameObject, prefab, ReplacePrefabOptions.ConnectToPrefab);GameObject.Destory(newGameObject); // don't want this in the scenereBut that's not working for me. The values in the prefab get replaced but all instances in the scene get disconnected.To reiterate. I'm NOT trying to edit an instance of a prefab. I'm trying to edit the prefab itself from a script at edit time.",TD-related,code,debugging,4,273,0.018,0.915,0.067,0.9212
41949241,How to apply extended styles to child selectors of a different className with CSS pre-processor?,"I have a need to prefix Bootstrap classNames. I don't mean using code.my-prefix .bs-class as a wrapper, I mean actually prefixing BS classNames eg; code.my-bs-class.I've explored doing this programmatically (using a Gulp process) however some of the selectors are a bit complex for me to safely convert, let alone treating mixin complexity.So I wondered about extending BS with LESS functionality and while with simple use cases this works fine, eg; // BS.btn { color:red;}// Prefixed BS.my-btn {  :extend(.btn);}reDoing the same with nested selectors does not work as I'd hope, and I suspect it won't.Taking this codepen: a href=http:en.io/davewallaceen/MJrMVj rel=nofollow noreferrerhttp:en.io/davewallaceen/MJrMVj/a you can see a simple example of what I would like to happen, however the CSS output is: .btn-group .btn,.ui-btn-group .btn { color: red;}reas opposed to: .btn-group .btn,.ui-btn-group .ui-btn { color: red;}reIs what I am trying to achieve possible, if so, how?Note: I'm open to alternative approaches to prefixing BS, however the technical debt incurred by modifying BS source is most undesirable, unless it is minimal.EDIT: I have broadened this question to include any CSS pre-processors, so as to not restrict ourselves to LESS, if another technology can achieve it.",TD-related,code,debugging,3,190,0.053,0.879,0.068,0.4001
44140807,How to check if ui-bootstrap-custom-tpls.js is required,"Context: I am optimizing a website that has been adding technical debt since 2015. The site loads a lot of stuff; JQuery and Angular.js, bootstrap.js and ui-bootstrap-custom-tpls.js. I think some of this stuff is not being used any longer.Goal: Improve load time of a website by removing unused css and js.Issue: codeui-bootstrap-custom-tpls-1.2.0.min.js is loaded on every page. One or more pages emmay/em be using it. I'm not sure.QUESTION -- How can I check if/where codeui-bootstrap-custom-tpls-1.2.0.min.js is used?",TD-related,code,framework,4,77,0.033,0.89,0.077,0.5267
44507045,Change authKey of a user,"Using SNMP version 3, I am creating a user. Right now, I have it set up where I clone a user and that works just fine. However, I need to change the new user's authKey. How can I do this? I know the oid for authKeyChange, however, I don't know how to generate the new key. How do I generate that key? Can it be done using SNMPSharpNet? If there is an easier way to do this while I'm creating the user, I can do that as well. ANY way to change the authKey (and privKey, but one step at a time) is much appreciated. I'm using VB.net if it means anything.",TD-related,code,coding_standards,3,112,0,0.878,0.122,0.8762
47939166,Injecting Dependencies to a Singleton class,"I have a singleton instance defined like this: public class Singleton { private static Singleton INSTANCE = new Singleton(); private Singleton() { } public Singleton getInstance() { return INSTANCE; }}reNow, due to some changes, this class has to depend on a few(3) dependencies. So, those dependencies have to be injected here.How can we achieve dependency injection for a Singleton class designed this way?The problem is that there are already a lot of callers on codeSingleton.getInstance() and hence cannot make the getInstance method to accept the dependencies.P.S: I understood using Singletons are not always a cleaner way :)(This is existing code and I have to live with it:))P.S: I'm using Guice for dependency injection.",TD-related,code,dependency,4,113,0.04,0.912,0.048,0.222
48109146,LD_BIND_NOW Can Make the Executable run Slower?,"I am curious if an executable is poorly written that it has much dead code, referring to 1000s of functions externally (i.e. .so files) but only 100s of those functions are actually called during runtime, will LD_BIND_NOW=1 be worse than LD_BIND_NOW not set? Because the Procedure Linkage Table will contain 900 useless function addresses? Worse in a sense of memory footprint and performance (as I don't know whether the lookup is O(n)).I am trying to see whether setting LD_BIND_NOW to 1 will help (by comparing to LD_BIND_NOW not set):1. a program that runs 24 x 5 in terms of latency2. saving 1 microsecond is considered big in my case as the code paths being executed during the life time of the program are mainly processing incoming messages from TCP/UDP/shared memory and then doing some computations on them; all these code paths take very short time (e.g. < 10 micro) and these code paths will be run like millions of timesWhether LD_BIND_NOW=1 helps the startup time doesn't matter to me.",TD-related,code,dead_code,5,169,0.089,0.846,0.065,-0.6452
48165828,Build warnings vs IntelliSense warnings,"I just joined a company with legacy code.The build has over 10000 warnings.90% of the warnings are obsolete warnings.My coworkers don't want me to disable those warnings, because it is useful for them in IntelliSense.My question is: is there a practical way, where I can still see the warning in the editor in Visual Studio, but it does not show up in the build.log?",TD-related,code,warnings,4,64,0.12,0.85,0.031,-0.3941
48675142,XML error :1:1: Content is not allowed in prolog running from jar - but is OK in Eclipse. Why?,"I have been round and round and round looking for this odd situtation. I have tried various suggestions, mostly related to BOM issues, but I still get this 'BOM-like' error, when running from an executable jar file, that was exported from Eclipse. I don't get the error when running the code in Eclipse. The platform is Windows Server 2012r2The actual parsing is being done in a Groovy class using the XmlSlurper, whose input is an xml string passed from Java. I am assuming that the problem is in the Java code that creates the string. I got this error when I ran my first test in Eclipse. Eventualy, I checked the encoding in np++ (used to edit the file, but not create it) and it said UTF-8 + BOM. I changed that to UTF-8 rather than refresh my memory on handling BOMs, from some years ago. That solved the problem.When I export the Eclipse project to an executable jar, I get the ' Content is not allowed' parse exception from the same xml file (OK, it's copied to a different folder).I have tried using the Apache BOMInputStream to wrap the InputStream from the file (this worked for me in the past). This time it doesn't.The result from (BomInputStream) getBOM() is emfalse/em. But, it's also false when I set the encoding to UTF-8 + BOM! (that's running in Eclipse and the jar) In case it's relevant, the start of the Groovy code is: def ClientConfig parse (String clientConfigXML) { def config = new XmlSlurper(false, false).parseText(clientConfigXML);reI'd be delighted to find that someone can help. I haven't included the Java code as it's the normal stuff you find in Q A for this topic, and it's full of commented-out code right now.Time for bed... Best regards, John[Answer:If you try to parse a .properties file that starts with a comment, in the belief that it is xml, you get the .1:1: Content is not allowed... error from the xml parser. That was due to me being careless. Thanks for the prompt below that got me to check this basic fact.The good thing to come out of this, is that my code is now BOM-proof. I will keep the use of the BOMInputStream - eliminated a little technical debt.]",TD-related,code,debugging,4,374,0.065,0.864,0.071,0.6198
48827249,Alternative method for Switch Statements,"According to some articles: ullia href=https://stackoverflow.com/questions/126409/ways-to-eliminate-switch-in-codeWays to eliminate switch in code/alia href=https://stackoverflow.com/questions/32003932/how-to-use-design-pattern-in-place-of-switch-caseHow to use design Pattern in place of switch case/aThe theory says that it is easy, but in practice this is often difficult.Never mind. Let's get to the heart of this thing.The code looks like this:   public class SomeType { // Some properties. } public enum SomeTrigger { Loaded, Initial, Timer, Final } public class SomeBaseObject { // // I am not allowed to change this class. It is not mine. // protected Dictionary  string, SomeType   Input; protected Dictionary  string, SomeType   Output; // Timer is evaluated every 2 sec. public virtual void Execute(SomeTrigger trigger, string value) { switch (trigger) { case SomeTrigger.Loaded: break; case SomeTrigger.Initial: break; case SomeTrigger.Timer: break; case SomeTrigger.Final: break; default: break; } } // The rest of code... }reAnd the class that I want to improve: public class SomeSpecificObject : SomeBaseObject { private bool isInitializationCompleted; private string connection; public override void Execute(SomeTrigger trigger, string value) { switch (trigger) { case SomeTrigger.Loaded: this.OnLoaded(); break; case SomeTrigger.Initial: this.OnInitial(); break; case SomeTrigger.Timer: this.OnTimer(); break; case SomeTrigger.Final: this.OnFinal(value); break; default: break; } } private void OnLoaded() { // Read Input and Output collection. } private void OnInitial() { // Initialization (connect to the server). // Bla bla bla this.connection = //Value from the plug-in; this.isInitializationCompleted = true; } private void OnTimer() { if (isInitializationCompleted) { // Do something // Connection is using here. // Calculate values on a Input collection, etc. } } private void OnFinal(string value) { if (isInitializationCompleted) { // something with value // Connection is using here. // Clear state. } else { // Connection is using here. // Cancel inistialization } } }reWhat should I do? Every field is using but every trigger. Additionally the one case is a little specific (OnFinalMethod needs argument). Based on the above articles, I have tried to refactor this code, but unsuccessfully. My attempts to apply some tips: public interface ITrigger { void Execute(); } public class LoadedTrigger : ITrigger { public void Execute() { throw new NotImplementedException(); } } // // Exactly the same class for the rest cases. // public class TriggerHandler { private Dictionary  SomeTrigger, ITrigger   triggerDictionary; public TriggerHandler() { triggerDictionary.Add(SomeTrigger.Loaded, new InitialTrigger()); // and for the rest } public void HandleTrigger(SomeTrigger trigger) { triggerDictionary[trigger].Execute(); } }reHow the objects should communicate with each other? E.g. TimerTrigger objects needs to know that the initiation is successful. What shall I do with the special case object?Any idea? :)",TD-related,code,coding_standards,5,409,0.031,0.872,0.097,0.9792
48831614,Interview: How to handle SQL NOT NULL constraint on the code end,"I was recently asked this question in an interview an I'm having trouble formulating the question well enough to find an answer via search engine. If my SQL database has a NOT NULL constraint placed on the name column, how would I be able to create that row, filling it with other data, without tripping the name NOT NULL constraint, assuming that you don't have the proper data to insert into the name field?My off the cuff response was to insert an empty string into the name field, but I feel like that's too hacky. Does anyone know the proper response?",TD-related,code,coding_standards,1,101,0.032,0.902,0.066,0.5362
48937039,Why promote language standard from -std=gnu++98 to -std=gnu++11,"I have a relatively well-maintained, rather large code base using -std=gnu++98. What are the advantages of upgrading the language standard from gnu++98 to gnu++11 ?If there are advantages, is it enough to just change from -std=gnu++98 to -std=gnu++11 ? Are there other options that should go along with this change (thinking about how -pendantic -pedantic-errors accompanies -std=c89 or -ansi for C)",TD-related,code,outdated,3,61,0,0.913,0.087,0.6553
50062296,GCC warnings for user types using QVariant::Type in a switch block,"Basically we're keeping the track of object types in a variable of QVariant::Type and then doing something like that switch(values[i].type){case QVariant::Bool: logic; break;case QVariant::Int: logic; break;case QVariant::LongLong: logic; break;case QVariant::String: logic; break;case QVariant::Double: logic; break;case QVariant::DateTime:case QVariant::Date:case QVariant::Time: logic; break;case QVariant::User+1:{ logic;break;}case QVariant::User+2:{ logic;break;}default: break;}reThe problem is: gcc produces warnings along these lines for User+X statements:  warning: case value 1025 not in enumerated type QVariant::Type [-Wswitch]reNow, I could suppress that of course, but is that the recommended way or am I doing something fundamentally wrong here? P.S. The question isn't about emwhy/em the warning is produced: I understand why. The queston is more about using QVariant::Type with user types in a proper way and if simply suppressing is correct or what am I doing here is just plain wrong and warning is an indication of a bigger design decision problem.",TD-related,code,warnings,4,140,0.154,0.809,0.037,-0.9555
50223617,Generating total cyclomatic complexity for Java 8,"I would like to understand the quality of a large Java 8 codebase. To do this I am interested in generating a (McCabe) cyclomatic complexity score for each individual project, relative to the total number of lines of code per project. This will help to understand emrelative/em quality and determine if developers' subjective sense of technical debt is correct. This will also allow me to graph such metrics over time which will help to understand if quality is increasing or decreasing. At least, these are my hypotheses.Are there any tools that can generate such complexity scores? Tools such as Checkstyle and PMD can evaluate complexity of methods etc. against a threshold, but this is not what I need; I need a total complexity score for a given codebase. I have heard of tools such as JavaNCSS but alas this is no longer maintained.",TD-related,code,coding_standards,2,143,0.051,0.878,0.071,-0.0772
51005814,Unnecessarily using volatile keyword -- is that dangerous?,"Is there ever any harm in making a variable volatile in Java if it doesn't actually need to be marked volatile? ... or is it just unnecessary as I have often read.As someone dabbling in multi-threading, but not a master computer scientist, I'm currently going with if in doubt, make it volatile.",TD-related,code,coding_standards,3,52,0.105,0.895,0,-0.6705
51540201,Entity Framework new object vs DbSet.Create,"We are migrating a web application from EF 4.0 to EF 6. The entities were earlier based on ObjectContext, but now we are looking at DBContext. The code heavily depends on lazy loading. Entities are added using following syntax:var user = new EntityModel.User();user.DepratmentId=25;context.Users.Add(user);context.SaveChanges();var name = user.Department.Name;the original code would easily assign department name into variable name. After Entity framework upgrade to EF6 with DBContext, user.Department is null. I understand that when we are using DBContext, Lazy Loading works only with Proxies. It would work fine if the code was changed to following:var user = context.Users.Create();user.DepratmentId=25;context.Users.Add(user);context.SaveChanges();var name = user.Department.Name;Problem at my hand is that we can not make this change in the whole code base. Given the large volume of code, this is practically impossible. Does someone have a solution to this?",TD-related,code,"outdated, td_resolution",4,131,0.065,0.834,0.101,0.6652
51860506,Executing Onload attribute js in the right context,"I'm dealing with the task of overriding document.write (the calls to document.write are from third party js so yes i know its crappy and no one uses it except ads :( ) So in one of the document.write calls the html string contains an iframe with onload attribute set , and because i'm using appendChild instead of document.write when i append the iframe i need to execute the onload js after several modifications that my code does. i've tried doing something like this:let Eval = function(str){return eval(str);}.call(node,OnloadJs);I'm calling eval with the node as the context (this) because the js that runs inside the onload have the this set to the current node. anyway i'm getting some problems when the onload event contains:function(){ae.Adrendered(j,Y,0);ae.AdrenderedFinish()}and the error i'm getting is :SyntaxError: Unexpected token (its an anonymous function , any ideas how to deal with it effectively?",TD-related,code,"td_resolution, coding_standards",2,143,0.089,0.841,0.07,-0.4601
52263650,Forwarding of an object's public attributes/vars in API Responses a good practice?,"So one of our API's has the function of receiving limited raw data, enriching it, and then returning it to the requestor. Currently the controller explicitly builds the response object. However since we constantly increase the attributes/variables in the response the controller is becoming rather Phat (Yes with a Ph). One way of making the code more DRY would be to automatically forward any public (meaning non private or protected) variables from the various object instances. To give more context:ulliNo sensitive data is handled by this API (Users, Order, Payments)liThe API is not public (Requires an Active Registered User)liThe data returned is all enriched data originating from the requestor's raw, non-structured dataTo be more specific: What I mean by forwarding is to have the controller iterate through all public attributes of the used objects and automatically include them in the response objectSo far the only cons I can think of is are:ulliDevelopers accidentally exposing an attribute/variable by forgetting to make it private or protected liPotentially exposing some traces of source code blueprints (But considering they would only be public vars/attributes and nothing else this one seems rather paranoid)My guess is I'm missing more.",TD-related,code,interface,4,193,0.053,0.907,0.039,-0.2023
52276154,"Is it important to fix all warnings, notices, errors?","Is it important to handle all warnings when you're writing code? A dev who has more seniority in my company insists the warnings are harmless. Admittedly, some of them are:block e Warning: Division by zero Notice: Undefined index/block eSometimes these errors aren't affecting logical output, but it's making it really hard for me to debug. We're writing in PHP he's developing directly on our production server that has error reporting turned off. When I pull the code onto my local machine I get hundreds/thousands of warnings like this. I'm not confident that this is best practice, and I don't want to pick up bad habits. I'm looking for a second opinion on best practices.",TD-related,code,warnings,2,114,0.181,0.688,0.131,-0.4146
52523547,Modify a TypeScript type alias from @types type,"Using Typescript 3, I'm using a definition from DefinitelyTyped but I need to edit a type alias. I am using @types/json-schema for the TS definitions which is easy to use. But since I want to add a custom schema type, when I have a type that isn't one of the defined types it will obviously complain. For example, I have this schema: { properties: { foo: { type: 'myCustomFormat' } }, required: [ 'foo' ], type: 'object'}reAnd of course codemyCustomFormat is not a valid json schema type. @types/json-schema defines these types via: export type JSONSchema4TypeName = 'string' | 'number' | 'integer' | 'boolean' | 'object' | 'array' | 'null' | 'any'reIs there a way to modify that type alias in my own type definition and have all uses of codeJSONSchema4TypeName updated since @types/json-schema obviously uses codeJSONSchema4TypeName further in it's definition? So like I'd like to do: import { JSONSchema4TypeName } from 'json-schema';export type JSONSchema4TypeName = JSONSchema4TypeName | 'myCustomFormat';reThe closest I'm able to do is this: import { JSONSchema4, JSONSchema4TypeName } from 'json-schema';export type JSONSchema4TypeName = JSONSchema4TypeName | 'uuid';export interface JSONSchema4 { type?: JSONSchema4TypeName | JSONSchema4TypeName[];}reand I import that codeJSONSchema4 from my definition instead of json-schema and that feels like it creates technical debt so wondering if there was a better way.",TD-related,code,"coding_standards, database",2,211,0.033,0.848,0.119,0.9496
52690013,Where to put my standard library headers when creating classes in C++?,"Correct me if I am wrong, the ifndef stuff in the beginning of C++ headers specifically help avoid code from being repeated?So (according to best practice) where do I put basic library headers like    iostream or    string ?Let me clarify the question with an exampleLets say I have a program that creates Employee classes and stores info about them..like their names or somethingolliI have an int main() that uses std::cout ALOT to display info to console. It may even use hard coded string variables to store info into one of the classes (i know hard coding is bad just bear with me it will help clarify things for me)liI have a header called Employee.h with all my private variables..in this case the name of the employee.. and it also had the function declarations. Lets pretend it uses a string data type in one of the constructors.lian Employee.cpp that does setting and getting...cool Lets also pretend it has some weird function that manipulates the Employee name (which is a string) and add like yolo in front of it..cool. So this file will also require acsess to the    string librarySo far: all three of my files want to use the    string header and only the main.cpp wants to use the    iostream header.My question(s):Seems like the    string header can be placed in the Eployee header and not the main.cpp and the program will compile and run just fine...but if i put it in the main and not the Employee header the compiler goes wild. So should I include it in both main and header or just the header?Does this best practice change if I make a second class called Companies that also uses the string library? P.S. can somone please explain how common preprocessors link stuff..like why does the computer throw erros when    string is only included in main but not the header...I thought this stuff was all linked together...Im dumb pls explain(I think i understand all the mumbo jumbo about obj files but then how doe preprocessors and compilers know that the header code isnt being repeated in both the class .cpp and the main .cpp?Thank you for patience if you read through that, i also appreciate any help thrown this way towards a c++ noob like me.",TD-related,code,"framework, coding_standards",1,376,0.046,0.869,0.085,0.9326
52868909,Java mkdir() folder in which you can't create subfolders or files ( throw access denied),"block e We want to add 100% coverage on our Spring Boot Java program we run so there are 2 strange tests that require us to create a folder and a file with access permission denied ./block eFor the file was pretty straight forward : File file = new file(....path...);.... just creating the file with some simple code...//now deny permissionsfile.setReadable(false);file.setWritable(false);//Some code trying to write on that filethrowing exception (happy junit test is passed)reBut the i want to create a directory let's name it codeparentDir and make it impossible the same java program can create files or folders inside it.So in the same logic : File parentDir= new file(....parentDirPath...);parentDir.mkDir();parentDir.setReadable(false);parentDir.setWritable(false);//Some code to create another folder inside the parentDirFile childDir= new file(....parentDirPath/childDir...);directoryExistsOrElseCreate(childDir.toPath());//WHOT IT CREATES THE FOLDER even if i don't want ...reWhy it is still able to create new files and folders on the codeparentDir?hrUpdate , just digged into the code and found out that we are using codeFiles.createDirectories(path); instead of codefile.mkDir();The method i am testing is this : public void directoryExistsOrElseCreate(final Path path) { try { if (Files.notExists(path)) { log.warn(Directory={} does NOT EXIST, creating..., path); Files.createDirectories(path); } else { log.warn(Directory={} ALREADY EXISTS, skipping..., path); } } catch (final IOException e) { log.error(Error during creating directory: path={}, error={}, path.toString(), e.getMessage()); throw new AtsGenericException(AtsGenericErrorCode.IO_ERROR, new Object[]{e.getMessage()}); }}re",TD-related,code,debugging,1,213,0.048,0.825,0.126,0.8878
53306450,Trying to find a solution to long running SQL code where I think NESTED SQL statement is the culprit,"I have a SQL statement that has a weird 2nd nested SQL statement that I think is causing this query to run for 6+ min and any suggestions/help would be appreciated. I tried creating a TEMP table for the values in the nested SQL statement and just do a simple join but there is nothing to join on in the SQL code so that is why they used a 1=1 in the ON statement for the join. Here is the SQL code: Declare @TransactionEndDate datetime;Select @TransactionEndDate = lastmonth_end from dbo.DTE_udfCommonDates(GETDATE());Select ''''+TreatyName as Treaty,cast(EndOfMonth as Date) as asOfDate,Count(Distinct ClaimSysID) as ClaimCount,Count(Distinct FeatureSysID) as FeatureCount,Sum(OpenReserve) as OpenReserveFrom ( Select TreatyName, EndOfMonth, dbo.CMS_Claims.ClaimSysID, FeatureSysID, sum(IW_glGeneralLedger.TransactionAmount)*-1 as OpenReserve From dbo.CMS_Claims Inner Join dbo.CMS_Claimants On dbo.CMS_Claims.ClaimSysID = dbo.CMS_Claimants.ClaimSysID Inner Join dbo.CMS_Features On dbo.CMS_Features.ClaimantSysID = dbo.CMS_Claimants.ClaimantSysID Left Join dbo.IW_glGeneralLedger On IW_glGeneralLedger.FeatureID = dbo.CMS_Features.FeatureSysID Left Join dbo.IW_glSubChildAccount On dbo.IW_glSubChildAccount.glSubChildAccountID = dbo.IW_glGeneralLedger.glSubChildAccountSysID Left Join dbo.IW_glAccountGroup On dbo.IW_glAccountGroup.glAccountGroupID = dbo.IW_glSubChildAccount.glAccountGroupSysID Left Join dbo.IW_BankRegister On dbo.IW_BankRegister.BankRegisterSysID = dbo.IW_glGeneralLedger.BankRegisterID Left Join dbo.IW_BankRegisterStatus On dbo.IW_BankRegisterStatus.BankRegisterStatusSysID = dbo.IW_BankRegister.BankRegisterStatusID **Left Join (Select Distinct dbo.DTE_get_month_end(dt) as EndOfMonth From IW_Calendar Where dt Between '3/1/2004' and @TransactionEndDate) as dates on 1=1** Left Join dbo.IW_ReinsuranceTreaty On dbo.IW_ReinsuranceTreaty.TreatySysID = IW_glGeneralLedger.PolicyTreatyID Where dbo.IW_glGeneralLedger.TransactionDate Between '1/1/2004 00:00:00' And EndOfMonth And dbo.IW_glAccountGroup.Code In ('RESERVEINDEMNITY') And ( (dbo.IW_glGeneralLedger.BankRegisterID Is Null) Or ( (IW_BankRegister.PrintedDate Between '1/1/2004 00:00:00' And EndOfMonth Or dbo.IW_glGeneralLedger.BankRegisterID = 0) And (dbo.IW_BankRegisterStatus.EnumValue In ('Approved','Outstanding','Cleared','Void') Or dbo.IW_glGeneralLedger.BankRegisterID = 0)) ) Group By TreatyName, dbo.CMS_Claims.ClaimSysID, FeatureSysID, EndOfMonth Having sum(IW_glGeneralLedger.TransactionAmount)      0) As DataGroup By TreatyName,EndOfMonthOrder By EndOfMonth, TreatyNamereThis nested SQL code only provides a table of End of Month values in one column called EndOfMonth and this is what I'm trying to fix: Select Distinct dbo.DTE_get_month_end(dt) as EndOfMonth From IW_Calendar Where dt Between '3/1/2004' and @TransactionEndDatere",TD-related,code,"debugging, database",3,282,0.005,0.849,0.146,0.9884
54575612,use rxjs to observe changes in an array in angular 4,"I have the following property in a component:  get isUploading() { return this.files.length    0    this.files.some((f) =   f.state === FileUpLoadState.uploading); }reI then have a progress component that is bound to that property:   md-progress-bar *ngIf=this.isUploading mode=indeterminate  loading...  /md-progress-bar  reI have an upload function that loops through an array of file objects and directly mutates the array of objects:  upload(){ this.files.forEach(async (uploadedFile) =   { uploadedFile.state = FileUpLoadState.uploading; try { uploadResponse = await this.blobStorageService.upload(uploadedFile.file, { maxSingleShotSize, progress: (progress) =   file.progress = progress. }); uploadedFile.state = FileUpLoadState.success; this.uploadActions.persistUpload({ ...uploadedFile, ...uploadResponse }); } catch (err) { uploadedFile.error = err.message; uploadedFile.state = FileUpLoadState.error; } }); }reI am coming from the react world were observing property changes like this is not something you do. Would using an rxjs observable be a better way or what is the common idiom for doing this in angular?",TD-related,code,coding_standards,2,136,0,0.878,0.122,0.9217
54636985,Resolve Intermittent Performance Issue Due to Parameter Sniffing,"I've got a procedure exhibiting performance issues due to parameter sniffing. The procedure is costly but generally executes in an acceptable amount of time amid typical load. However, it will periodically perform poorly. When this happens, we see sessions executing the procedure go parallel. We'll see the number of sessions executing the routine start to pile up. We resolve the issue by pulling the procedure's plan from the cache, killing the active sessions, and monitoring for an immediate re-occurrence (like when a bad plan ends up back in the cache).The procedure is in a typical OLTP database (lots of small DML queries).When the subject query performs poorly, it causes a CPU spike and degrades performance of the associated service. During business hours, the procedure is executed more than 5 times a minute (don't have an exact count). The plan for the procedure is here: a href=https://www.brentozar.comastetheplan/?id=S1aEVQJBN rel=nofollow noreferrerhttps://www.brentozar.comastetheplan/?id=S1aEVQJBN/aAll columns in the query (join and projected columns), are covered by indexes.Here are the options I'm weighing:olliWe can apply Option Recompile to the problematic select statement inside the routine.liWe could do a little research and find a parameter value that generates a plan that is generally good for everything. We'd then add the following OPTIMIZE FOR to the function. This will incur a little technical debt as we may need to adjust this value overtime.liWe could introduce branching logic in the procedure. If the parameter value were X or in range-X, we'd execute sproc, and if not, we'd run sproc. Again, incurs a little technical debt.liWe could change the problematic statement to dynamic SQL. This will cause a plan to be generated for each unique SQL statement. If we get tons of unique calls of this procedure, it could bloat the plan cache.liSlap a MAXDOP of 1 on the problematic select statement.Options I've factored out:olliWe can optimize for unknown. This will change record estimates the density vector, and optimize operations for that.Have I missed any sensible options? What options make the most sense?",TD-related,code,td_resolution,2,331,0.09,0.794,0.116,0.8583
54776653,Automating detection of when shared_ptr should really be unique_ptr,"I'm working with a large c++ code base that has evolved and organically grown over the last 10 years. One of the items I've been looking at is when shared_ptr's (via make_shared) are overused, where they could easily be unique_ptr's instead.We've made diligent progress and seen great performance when refactoring to use said pointers properly; however, I'm wondering if there is some way that we could automate the detection of when a pointer is actually misused and could qualify for a unique_ptr instead. This would be both for sweeping the code base (clang-tidy style) to make the refactoring burden easier, as well as for an ongoing mode, of detecting when pointer misuse happens and preventing it at the precommit level.I've flipped thru various articles and stack overflow posts, as well as flipped thru both gcc and clang compiler options, and haven't quite found what I've been looking for.",TD-related,code,"legacy, td_resolution, management",2,148,0.025,0.871,0.104,0.9062
54975082,How to get timezone offset to correctly display on 24h format,"I'm running into an issue where my app is being accessed from different parts of the world. And, I have a chart to display peak access times. If accessed from a different part of the world (than the origin) I need it to reflect the converted origin time. However, the way it is currently set up, the calculation renders codefooPoint.hour with the value of for example code28 instead of code00:03 (am).I can pinpoint that this occurs in the codeelse conditional, since, for example, if they would be Accessing from Australia, with a codefooPoint.hour = 20 and codethis.state.timeZoneOffset = -8. code20 - (-8) = 28 and I would like it to display as code00:04. I know my calculations are wrong, so can anyone help me format this correctly please?I failed to mention that codefooPoint.hour is actually a data point I get in the codefoo object (which is fetched from an API), so that represents the avg. peak time of certain location. When viewed from another location in a different part of the world, I need to take into account the time zone difference to display in the chart the peak time but on their time zoneIs a library a low technical debt solution?I have this array of objects as such: foo: { hour: 20}reI obtain the timezone offset as such:codelet tzOffset = new Date().getTimezoneOffset() / 60;and store it in stateThen I have: foo.forEach((fooPoint) =   { fooPoint.hour = fooPoint.hour - this.state.timeZoneOffset    0 ? fooPoint.hour - this.state.timeZoneOffset + 24 : foorPoint.hour - this.state.timeZoneOffset;});re",TD-related,code,debugging,2,250,0.047,0.923,0.031,-0.6867
55118442,RxJS / Angular 7 : forkjoin with different callbacks,"I'm kinda new to rxjs (we've been stuck with angularJS for a long time and finally getting out of our technical debt).Using angular7, I have a list of requests like this. Using forkJoin, I manage it like this : let requests = []for (let asset in this.assets){ if(asset.enabled) requests.push(this.apiService.postAsset(oAsset))}return forkJoin(requests)reAnd it works fine, I get my array of responses.however I'm a bit stuck trying to figure out how to get different callbacks depending on asset type.I'd like something like private saveAssets(): Observable  any  { let requests = [] for (let asset in this.assets) { //asset exists already if(asset.id) { requests.push(this.apiService.putAsset(asset) .subscribe(response =   { // do something with asset })) } else { requests.push(this.apiService.postAsset(asset) .subscribe(response =   { asset.id = response.id // do some more thing with asset })) } } return forkJoin(requests) //keep the forkjoin because I want to do something when everything is done}reBut it won't work. Error given codeERROR TypeError: You provided an invalid object where a stream was expected. You can provide an Observable, Promise, Array, or Iterable.is related to function calling the one doing the request which looks like this (it worked fine without the single 'subscribes') : this.saveAssets() .subscribe(responses =   { console.log(responses) })reAny help, or hint about thing to look for, would be much appreciated... I'll allocate more time learning RxJS but for now I'm just trying to get this small thing to work in a not-too-dirty way.Thank you so much !",TD-related,code,"framework, outdated, td_resolution",3,236,0.014,0.864,0.122,0.9309
56746248,PHP submit blank screen - script not running on POST?,"I have a script that pulls an XML page and uses a form to update and save the values back. When I click the submit button it works, but then the page loads blank. I just want the page to refresh. There are about 100 different threads on this, and nothing I have tried has worked to resolve the issue. Out of curiosity, I just tried to run the window.location script and nothing else, and this piece actually doesn't work at all.pre class=lang-php prettyprint-overridecode  ?php//if (isset($_POST['submit'])) {if ($_SERVER['REQUEST_METHOD'] == 'POST') {//$ctstatus-  nodeValue = $_POST['ctstatusform'];//htmlentities($xml-  save('test.xml'));echo '  script type=text/javascript  window.location=http://google.ca;  /script  ';} ?  reThe inner contents of the form don't really matter at this point, I just want it to refresh the page after I hit the submit button.I previously used isset but from reading it seems like that's obsolete, and my form action= used to be blank. Either way my XML save works, but nothing to refresh the page. I also tried header and that didn't work either.    form method=POST action=  ?php echo htmlspecialchars($_SERVER[PHP_SELF]);?       input class=save name=submit type=submit value=Save /     /form  reOut of curiosity I tried an onClick function with a timer and this does work but it's not ideal at all, especially because the page could technically refresh before the POST is finished writing the file. I'd rather know why the echo doesn't execute.",TD-related,code,debugging,2,225,0.035,0.882,0.083,0.8708
57508021,Postgres bulk insert/update that's injection-safe. Perhaps a function that takes an array?,"I'm working on paying back some technical debt this week, and it hit me that I have no idea how to make multi-value inserts safe from accidental or malicious SQL injections. We're on Postgres 11.4. I've got a test bed to work from that includes a small table with about 26K rows, here's the declaration for a small table I'm using for testing: BEGIN;DROP TABLE IF EXISTS data.item CASCADE;CREATE TABLE IF NOT EXISTS data.item ( id uuid NOT NULL DEFAULT NULL, marked_for_deletion boolean NOT NULL DEFAULT false, name_ citext NOT NULL DEFAULT NULL,CONSTRAINT item_id_pkey PRIMARY KEY (id));CREATE INDEX item_marked_for_deletion_ix_bgin ON data.item USING GIN(marked_for_deletion) WHERE marked_for_deletion = true;ALTER TABLE data.item OWNER TO user_change_structure;COMMIT;reI've been inserting to this table, and many others, using multi-value inserts, along the lines of: BEGIN;INSERT bundle up hundres or thousands of rows ON CONFLICT do what I needCOMMIT or ROLLBACK on the client sidereWorks fine. But how do you make a multi-value statement safe? That's what I can't figure out. This is one of those areas where I can't reason about the problem well. I don't have the appetite, aptitude, or patience for hacking things. That I can't think up an exploit means nothing, I would emsuck/em as a hacker. And, for that matter, I'm generally more concerned about errors than evil in code, since I run into errors a whole lot more often.The standard advice I see for safe insertion is to use a prepared statement. A prepared statement for an INSERT is pretty much a temporary, runtime function for interpolation on a code template. For me, it's simpler to write an actual function, like this one: DROP FUNCTION IF EXISTS data.item_insert_s (uuid, boolean, citext);CREATE OR REPLACE FUNCTION data.item_insert_s (uuid, boolean, citext) RETURNS intAS $$INSERT INTO item ( id, marked_for_deletion, name_)VALUES ($1,$2,$3)ON CONFLICT(id) DO UPDATE SET marked_for_deletion = EXCLUDED.marked_for_deletion, name_ = EXCLUDED.name_;SELECT 1; -- No clue what to return, but you have to return something.$$ LANGUAGE sql;ALTER FUNCTION data.item_insert_s(uuid, boolean, citext) OWNER TO user_bender;reAll of that works, and I've tried some timing tests. I truncate the table, do a multi-value insert, truncate, do a series of function call inserts, and see what the difference is. I've tried multiple runs, doing the operations in different orders, etc. Both cases use a BEGIN/COMMIT block in the same way, so I'll end up with the same number of transactions on either test. The results vary more across tests than within them, but the multi-value insert is always faster. Congratulations to me for confirming the obvious.Is there a way to safely do bulk inserts and updates? It occurred to me that I could write a function that takes an array or arrays, parse it out, and run the code in a loop within the function. I'd like to test that out, but get flummoxed by the Postgres array syntax. I've looked around, and it sounds like an array of objects and a foreach loop might be just what I'm after. I've looked around, and this is a topic that has been addressed, but I haven't found a straightforward example of how to prepare data for insertion, and the the unpacking of it. I'm suspecting that I won't be able to use SQL and a plain unnest() because 1) I want to safe the inputs and 2) I might have functions that don't take all of the fields in a table in their input. To make things a bit easier, I'm fine with functions with fixed parameter lists, and array inputs with fixed formats. I'll write code generators for my various tables, so I don't need to make the Postgres-side code any more complex than necessary.Thanks for any help!Note: I got a message to explain why this question is different than my newer, related question:a href=https://stackoverflow.com/questions/57517980/improving-a-function-that-upserts-based-on-an-input-array/5751975257519752Improving a function that UPSERTs based on an input array/aAnswer: Yes, it's the same starting point. In this question, I was asking about SQL injection, in the second question I was trying to focus on the array-input solution. I'm not quite sure when to split out new questions, and when to let questions turn into multi-part threads.",TD-related,code,"td_resolution, debugging",5,681,0.057,0.853,0.09,0.9722
58438905,Implementing Redux into a Firebase application,"I am currently developing a application the uses firebase on the backend. I am using the hook recipe useAuth from useHooks.com. I managed to make the axios call within the useAuth hook to get the user signed in, but in order to avoid technical debt as the project scaled up, I need to manage user authentication through Redux, if this is indeed the best way to go about it. My store currently looks like import { createStore, applyMiddleware } from 'redux'import {firestoreReducer} from 'redux-firestore'import thunk from 'redux-thunk'import {combineReducers} from 'redux'import authReducer from './reducers/auth.reducer'import {firebaseReducer} from 'react-redux-firebase'const rootReducer = combineReducers({ auth: authReducer, firestore: firestoreReducer, firebase: firebaseReducer})const storeRedux = createStore(rootReducer,applyMiddleware(thunk))export default storeReduxreMy Action file export const doLogin = (email, password) =   { return dispatch =   { axios .post(api + /auth, { email: email, password: password }) .then(response =   { dispatch({ type: AUTH_LOGIN, email: response.email }); }) .catch(error =   { console.log(There is no user with the given username and password); //alert(Username does not exist); }); };};and my reducer.const authReducer = (state = initState, action) =   { switch (action.type) { case AUTH_LOGIN: console.log(login error); return { ...state, authError: Login failed }; case LOGIN_SUCCESS: console.log(login success); return { authError: null }; default: return state; }};reexport default authReducer;I am not sure what is the best practice to properly check auth of the user, I am using a custom API that the axios call makes.",TD-related,code,"framework, coding_standards",4,228,0.071,0.862,0.067,0.2748
58671396,Why does ListT.Sort(IComparerT) and ListT.Sort(ComparisonT) handle corner cases differently?,"1, codeSort(IComparer  T  ) will try to use codeComparer  T  .Default when its parameter is null.brcodeSort(Comparison  T  ) will throw an codeArgumentNullException.brIs there any reason against trying to use codeComparer  T  .Default.Compare when the comparison parameter is null?2, codeSort(IComparer  T  ) won't throw an exception for lists with less than two elements even if T is not codeIComparable.brOn the other hand, codeSort(Comparison  T  ) always throws codeArgumentNullException when the parameter is null.brShouldn't this method allow the same sort of looseness?",TD-related,code,debugging,1,80,0.023,0.928,0.049,0.4393
58914903,Xamarin Forms vertically align labels of different font sizes to the same baseline,"I have two labels side by side in a horizontally oriented stack layout. The labels have different font sizes. I would like to make the baseline (bottom edge) of each label text the same regardless of the font size. However the default behaviour of xamarin forms is not to do that. The following code    StackLayout Orientation=Horizontal      Label FontSize=12 Text=A Noble Spirit    /Label     Label FontSize=18 Text=Embiggens The Smallest Man    /Label     /StackLayout  reResults in the following view running on android.a href=https://i.stack.imgur.com/Lw3Dv.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/Lw3Dv.png alt=Figure 1, different baseline for labels of different font size/aI've tried many different combinations of setting the vertical text alignment and the vertical options attributes on the labels. The best I've been able to come up with (and what I think should work) is adding vertical options = end to them both. This improves things a bit but there's still a mismatch, so that the bigger label's text (embiggens) starts higher up than the smaller label - like so:    StackLayout Orientation=Horizontal      Label VerticalOptions=End FontSize=12 Text=A Noble Spirit    /Label     Label VerticalOptions=End FontSize=18 Text=Embiggens The Smallest Man    /Label     /StackLayout  rea href=https://i.stack.imgur.com/GrT1l.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/GrT1l.png alt=Figure, good but not great/aAs you can see, somewhat of an improvement, but still not aligned. This is driving me up the wall a bit. I'm starting to think it may be a bug in Xamarin Forms for android. (I'll add to this question later when I can get an example running on iOS to see if it's android specific.).I CAN hack it to sort of work by adding top margin to the smaller label that is equal to the difference in font size, which is gross and I don't want to introduce that technical debt and upkeep into my system. But here it is to show it. Hoping not to have to resort to this...    StackLayout Orientation=Horizontal      Label FontSize=12 Margin=0,6,0,0 Text=A Noble Spirit    /Label     Label FontSize=18 Text=Embiggens The Smallest Man    /Label     /StackLayout  rea href=https://i.stack.imgur.com/JJ7Rn.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/JJ7Rn.png alt=Figure 3, Hacky Sack/a",TD-related,code,coding_standards,1,326,0.025,0.863,0.111,0.9789
59022719,AWS Fargate - fails health check while instance is up,"I am a similar question to some posts, but none of the specific issues relate as far as I can tell. I will post my stack later in this post.I have: ALB-----  Listener-  target group-  Fargate service-  task definition80/http -  8080/http -   8080/httpreThe problem is my health checks fail. When the Fargate task spins up an instance, I can go to that instance using the health check URL, and i get a 200 response. however, any attempt to go through the load balancer results in a gateway timeout.  $ curl -fv http://172.31.47.18:8080/healthz* Trying 172.31.47.18...* TCP_NODELAY set* Connected to 172.31.47.18 (172.31.47.18) port 8080 (0)   GET /healthz HTTP/1.1   Host: 172.31.47.18:8080   User-Agent: curl/7.54.0   Accept: */*      HTTP/1.1 200 OK   Transfer-Encoding: chunked   Date: Sun, 24 Nov 2019 15:33:39 GMT   Server: Warp/3.2.27   * Connection 0 to host 172.31.47.18 left intactOKreHowever, the health check never passes on the LB.ollithe security group used for every thing right now is wide open. I wanted to eliminate that as an issue. lithe fargate nodes are set up for public IPs. This has been driving me crazy for the last couple of days. I stood up an EC2 backed ECS, and everything works on EC2. I should point out that the entire stack builds just fine in Fargate, except for not getting any traffic either from the load balancer or something. The error in the service events says  service test-graph (port 8080) is unhealthy in target-group tg--test-graph due to (reason Request timed out).reHopefully someone has an idea.  TaskDef0: Type: AWS::ECS::TaskDefinition DependsOn: Cluster0 Properties: ExecutionRoleArn: arn:aws:iam::xxxxx:role/ECS_Hasura_Execution_Role TaskRoleArn: arn:aws:iam::xxxxx:role/ecsTaskExecutionRole Family: !Ref 'ServiceName' Cpu: !FindInMap - ContainerSizeMap - !Ref ContainerSize - Cpu Memory: !FindInMap - ContainerSizeMap - !Ref ContainerSize - Memory NetworkMode: awsvpc RequiresCompatibilities: - FARGATE ContainerDefinitions: - Name: !Ref 'ServiceName' Cpu: !FindInMap - ContainerSizeMap - !Ref ContainerSize - Cpu Memory: !FindInMap - ContainerSizeMap - !Ref ContainerSize - Memory Image: !FindInMap - ServiceMap - !Ref ServiceProvider - ImageUrl PortMappings: - ContainerPort: !Ref 'ContainerPort' HostPort: !Ref ContainerPort Protocol: tcp ALB0: Type: AWS::ElasticLoadBalancingV2::LoadBalancer DependsOn: TaskDef0 Properties: Name: !Join - '-' - - lb- - !Ref ServiceName Scheme: internet-facing IpAddressType: ipv4 LoadBalancerAttributes: - Key: deletion_protection.enabled Value: false - Key: idle_timeout.timeout_seconds Value: 60 - Key: routing.http.drop_invalid_header_fields.enabled Value: false - Key: routing.http2.enabled Value: true SecurityGroups: - sg-xxxxxx allow HTTP/HTTPS to the load balancer Subnets: - subnet-111111 - subnet-222222 - subnet-333333 Type: application targetGroup0: Type: AWS::ElasticLoadBalancingV2::TargetGroup DependsOn: ALB0 Properties: Name: !Join - '-' - - tg- - !Ref ServiceName Port: !Ref TargetGroupPort Protocol: !Ref TargetGroupProtocol TargetType: ip VpcId: !FindInMap - ServiceMap - !Ref ServiceProvider - VpcId all other paraneters can be changed without interruption HealthCheckPort: traffic-port HealthCheckEnabled: !FindInMap - LBTGMap - Parameters - HealthCheckEnabled HealthCheckIntervalSeconds: !FindInMap - LBTGMap - Parameters - HealthCheckIntervalSeconds HealthCheckPath: !FindInMap - ServiceMap - !Ref ServiceProvider - HealthCheckPath HealthCheckProtocol: !FindInMap - ServiceMap - !Ref ServiceProvider - HealthCheckProtocol HealthCheckTimeoutSeconds: !FindInMap - LBTGMap - Parameters - HealthCheckTimeoutSeconds HealthyThresholdCount: !FindInMap - LBTGMap - Parameters - HealthyThresholdCount UnhealthyThresholdCount: !FindInMap - LBTGMap - Parameters - UnhealthyThresholdCount Matcher: HttpCode: !FindInMap - ServiceMap - !Ref ServiceProvider - HealthCheckSuccessCode TargetGroupAttributes: - Key: deregistration_delay.timeout_seconds Value: !FindInMap - LBTGMap - Parameters - DeregistrationDelay - Key: slow_start.duration_seconds Value: !FindInMap - LBTGMap - Parameters - SlowStart - Key: stickiness.enabled Value: !FindInMap - LBTGMap - Parameters - Stickiness Listener0: This is the fixed response test listener Type: AWS::ElasticLoadBalancingV2::Listener DependsOn: ALB0 Properties: DefaultActions: - Type: fixed-response FixedResponseConfig: ContentType: text/html MessageBody:     Working  /    p  The load balancer test listener is operational     StatusCode: 200 LoadBalancerArn: !Ref ALB0 Port: 9000 Protocol: HTTP Listener1: This is the port 80 listener Type: AWS::ElasticLoadBalancingV2::Listener DependsOn: ALB0 Properties: DefaultActions: - Type: forward TargetGroupArn: !Ref targetGroup0 LoadBalancerArn: !Ref ALB0 Port: 80 Protocol: HTTP Listener2: This is the port 8080 listener Type: AWS::ElasticLoadBalancingV2::Listener DependsOn: ALB0 Properties: DefaultActions: - Type: forward TargetGroupArn: !Ref targetGroup0 LoadBalancerArn: !Ref ALB0 Port: 8080 Protocol: HTTP Listener3 : This is the port 443 listener Type: AWS::ElasticLoadBalancingV2::Listener DependsOn: ALB0 Properties: Certificates: - CertificateArn: !FindInMap - CertificateMap - !Ref AWS::Region - CertifcateArn DefaultActions: - Type: forward TargetGroupArn: !Ref targetGroup0 LoadBalancerArn: !Ref ALB0 Port: 443 Protocol: HTTPS Service0: Type: AWS::ECS::Service DependsOn: Listener2 Properties: ServiceName: !Ref 'ServiceName' Cluster: !Ref Cluster0 LaunchType: FARGATE DeploymentConfiguration: MaximumPercent: !FindInMap - ECSServiceMap - Parameters - MaximumPercent MinimumHealthyPercent: !FindInMap - ECSServiceMap - Parameters - MinimumHealthyPercent DesiredCount: !Ref 'DesiredTaskCount' NetworkConfiguration: AwsvpcConfiguration: AssignPublicIp: ENABLED SecurityGroups: this is allow all ports and IPs - !FindInMap - SecurityGroupMap - !Ref AWS::Region - sg0 Subnets: - !FindInMap - SubnetMap - !Ref AWS::Region - subnet0 - !FindInMap - SubnetMap - !Ref AWS::Region - subnet1 - !FindInMap - SubnetMap - !Ref AWS::Region - subnet2 TaskDefinition: !Ref 'TaskDef0' LoadBalancers: - ContainerName: !Ref 'ServiceName' ContainerPort: !Ref 'ContainerPort' TargetGroupArn: !Ref 'targetGroup0' Tags: - Key: Application Value: !Ref Application - Key: Customer Value: !Ref Customer - Key: Role Value: !Ref Role - Key: InternetAccessible Value: !Ref InternetAccessible - Key: CreationDate Value: !Ref CreationDate - Key: CreatedBy Value: !Ref CreatedByMappings: ServiceMap: GraphQL-Ohio: ImageUrl: xxxxx.dkr.ecr.us-east-2.amazonaws.com/hasura/graphql-engine HealthCheckPath: /healthz HealthCheckSuccessCode: 200 HealthCheckProtocol: HTTP VpcId: vpc-xxxxx LBTGMap: Parameters: HealthCheckEnabled: True HealthCheckIntervalSeconds: 30 HealthCheckTimeoutSeconds: 5 HealthyThresholdCount: 5 UnhealthyThresholdCount: 2 DeregistrationDelay: 300 SlowStart: 0 Stickiness: false SubnetMap: There is technical debt here to keep this up to date as subnets change us-east-2: subnet0: subnet-111111 subnet1: subnet-222222 subnet2: subnet-333333 SecurityGroupMap: us-east-2: sg0: sg-xxxxxre",TD-related,code,debugging,2,848,0.029,0.874,0.097,0.9935
59098501,Using the results of one query to make another query and populate an HTML select,"Edit: will move this to the top to avoid confusion:I have no say or power of decision on the database's structure, so I must work with what I've got. Otherwise, as most comments stated this issue would be simplified greatly by normalizing and cleaning up the tables.hrI've got a database table which contains car models and some categories (national car, imported car, pick-up truck, van, etc). Something of note is that these categories are represented in integer codes.This table has 10 category columns for each row (Use1, Use2, Use3, etc), so each car can have up to 10 of them.Then I have another table which contains the descriptions corresponding to each category code (e.g. national car = 1, imported car = 2, and so on).I have a form which contains two HTML select elements, one for cars and the other for categories.   div class=form-group row     label class=col-sm-2 form-control-label  Cars  /label     div class=col-sm-6     select class=form-control id=car_model name=car_model onchange=fetch_categories(this.value);     option  Car 1  /option     option  Car 2  /option     option  Car 3  /option     /select     /div    /div    div class=form-group row     label class=col-sm-2 form-control-label  Category  /label     div class=col-sm-4     select class=form-control name=category     option  Select a car first...  /option     /select     /div    /div  reI need to populate the category select based on the value of the cars select. This is being done by using Ajax (part which works as intended and is probably irrelevant to the subject).The Ajax function sends the car data to a php script which successfully gets all of it's corresponding categories through a query.What I'm struggling with is using the results from that query to fetch the descriptions of all the categories that came from it through another query.I've tried doing a foreach to iterate all results from query 1 and then executing query 2 then formulating the code  option   tags, but I'm not getting it right.   ?php$car_model = $_POST['get_car'];$query = SELECT CodUso1, CodUso2, CodUso3, CodUso4, CodUso5, CodUso6, CodUso7, CodUso8, CodUso9, CodUso10 AS categories FROM cars WHERE car_model = '$car_model';$stmt = $pdo-  prepare($query);$stmt-  execute();$result = $stmt-  fetchAll();foreach ($result['categories'] as $u): if ($result['CodUso1'] != 0 || $result['CodUso2'] != 0 || $result['CodUso3'] != 0 || $result['CodUso4'] != 0 || $result['CodUso5'] != 0 || $result['CodUso6'] != 0 || $result['CodUso7'] != 0 || $result['CodUso8'] != 0 || $result['CodUso9'] != 0 || $result['CodUso10'] != 0) { $query = SELECT description FROM categories WHERE code = '$u'; $stmt = $pdo-  prepare($query); $stmt-  execute(); $result2 = $stmt-  fetchAll();?     option value=  ?php echo $u ?       ?php echo $result2; ?     /option    ?php}endforeach;exit;?  reThe resulting code  option   elements must contain the car code as value and the description as it's description.I apologize if the explanation is too convoluted, if you need any further information or clarification please let me know.Edit: example of var_dump from the first query's result: array(20) { [CodUso1]=   string(3) 101 [0]=   string(3) 101 [CodUso2]=   string(3) 502 [1]=   string(3) 502 [CodUso3]=   string(3) 305 [2]=   string(3) 305 [CodUso4]=   string(3) 406 [3]=   string(3) 406 [CodUso5]=   string(3) 103 [4]=   string(3) 103 [CodUso6]=   string(3) 508 [5]=   string(3) 508 [CodUso7]=   string(3) 455 [6]=   string(3) 455 [CodUso8]=   string(1) 0 [7]=   string(1) 0 [CodUso9]=   string(1) 0 [8]=   string(1) 0 [coduso]=   string(1) 0 [9]=   string(1) 0 }reScreenshots of tables:img src=https://i.stack.imgur.com/GW9ous.png alt=Table 1img src=https://i.stack.imgur.com/TFBa9s.png alt=Table 2Keep in mind these are the actual names of the tables and columns, I changed them in the above code for illustration purposes.",TD-related,code,database,1,546,0.01,0.961,0.029,0.8714
298380,How to manage frequently modified production code?,My project invovles me to make a lot of changes on the production code. The requirement keeps coming up and I need to make changes and deploy it as soon as possible. I sometimes end up creating patch work sort of code because some of the requirement would not fit into the overall design of the software. How can this be handled effectively? Any design pattern to handle this?,TD-related,design,pattern,2,69,0.03,0.893,0.077,0.5187
369683,Is there a way to avoid spaghetti code over the years?,"I've had several programming jobs. Each one with 20-50 developers, project going on for 3-5 years.Every time it's the same. Some programmers are bright, some are average. Everyone has their CS degree, everyone read design patterns. Intentions are good, people are trying hard to write good code but still after a couple of years the code turns into spaghetti. Changes in module A suddenly break module B. There are always these parts of code that no one can understand except for the person who wrote it. Changing infrastructure is impossible and backwards compatibility issues prevent good features to get in. Half of the time you just want to rewrite everything from scratch.And people more experienced than me treat this as normal. Is it? Does it have to be? What can I do to avoid this or should I accept it as a fact of life?Edit: Guys, I am impressed with the amount and quality of responses here. This site and its community rock!",TD-related,design,"management, dependency",2,163,0.039,0.824,0.138,0.9471
611296,Rewrite C code in Java or use JNI?,"I'm currently developing on a project written in Java. We have a bunch of algorithms written in C/C++ (at least a couple hundred) that need to be incorporated in our project. Our two options are to use JNI to call this code, or to rewrite all the algorithms in Java.I am aware of the consequences of using JNI, it can open up a whole new set of problems, which is why rewriting all the code in Java is even being considered. But the thought of rewriting it seems...wrong. The algorithms have been tested and work as far as I know, they're just in the wrong language.In this situation, would JNI make this task easy? Or would it cause more headache than rewriting the code in Java would?hrEDIT 1: Related Question - a href=https://stackoverflow.com/questions/402408/usefulness-of-jniUsefulness of JNI/ahrEDIT 2: FYI - Our Java project is not meant to be portable in any way. That might eliminate one of the downsides of JNI in that it supposedly reduces portability.",TD-related,design,td_resolution,2,165,0.036,0.919,0.045,0.3631
646653,Premature refactoring?,"We have all heard of a href=http://en.wikipedia.org/wikirogram_optimizationWhen_to_optimize rel=noreferrerpremature optimization/a, but what do you think about premature refactoring? Is there any such thing in your opinion? Here is what I am getting at.First off, reading Martin Fowler's seminal work a href=http://refactoring.com/ rel=noreferrerRefactoring/a quite literally changed my life in regards to programming. One thing that I have noticed, however, is that if I start refactoring a class or framework too quickly, I sometimes find myself coded into a corner so-to-speak. Now, I suspect that the issue is not really refactoring per se, but maybe prematureoor design decisions/assumptions.What are your thoughts, insights and/or opinions on this issue? Do you have any advice or common anti-patterns related to this issue?EDIT:From reading your answers and reflecting on this issue more, I think I have come to the realization that my problem in this case is really an issue of premature design and not necessarily premature refactoring. I have been guilty of assuming a design and refactoring in that direction to early in the coding process. A little patience on my part to maintain a level of design agnosticism and focus on refactoring towards clean code would keep me from heading down these design rabbit trails.",TD-related,design,"management, td_resolution",2,200,0.056,0.926,0.018,-0.8156
648923,When must you use poor design to finish a project?,"There are many different bad practices, such as memory leaks, that are easy to slip into a program on accident. Sometimes, they might even be able to jury-rig your program together. I'm working on a project right now and it works if I deliberately put a memory leak in my code. If I take the leak out, the code crashes. Obviously this is bad, and needs to be (and will be) fixed soon.My question is, when do you decide to deliver code in this state, if it's not possible to release code without these poor practices, in time?",TD-related,design,"management, td_resolution",3,98,0.14,0.809,0.051,-0.8572
659240,Ruby on Rails ActiveRecord conditional validation (and more..),"Everything is working fine. What I want now is to make an (unobtrusive) hidden iframe in-place upload script using javascript. My problem is that I cannot just upload the image without the rest of the data, because it will fail validation (no name present) and also I cannot send the rest of the form without the image (same thing, fails validation).So basically what I need (and don't know how to achieve) is to conditionally apply the model validations according to what the action is currently in progress (uploading the image or editing other data).I hope I was clear enough. Any help is appreciated. Thanks.",TD-related,design,debugging,2,104,0.077,0.75,0.173,0.8519
702797,What optimizations are OK to do right away?,"One of the most common mantras in computer science and programming is to never optimize prematurely, meaning that you should not optimize anything until a problem has been identified, since code readability/maintainability is likely to suffer.However, sometimes you might know that a particular way of doing things will perform poorly. When is it OK to optimize before identifying a problem? What sorts of optimizations are allowable right from the beginning?For example, using as few DB connections as possible, and paying close attention to that while developing, rather than using a new connection as needed and worrying about the performance cost later",TD-related,design,"management, td_resolution",2,101,0.146,0.81,0.044,-0.881
800620,Is it possible to maintain a 43 page query?,"I always thought an SQL compiler would break but apparently nesing can nearly be infinite. Is this code to be trashed immediately or is there some glimmer of hope that something like this can function?This query doesn't really belong to me so I cannot post it... However let's just pretend it is a href=http://forums.oracle.com/forums/message.jspa?messageID=13265161326516 rel=nofollow noreferrerthis one/a: [SELECT /*+ NOPARALLEL bypass_recursive_check */ SP_ALIAS_190, ((CASE SP_ALIAS_191WHEN 1THEN 'PROVIDER::ALL_PROV::'WHEN 0]re",TD-related,design,database,2,68,0.023,0.873,0.105,0.782
828764,Why do we refactor?,"I would like to know the reasons that we do refactoring and justify it. I read a lot of people upset over the idea of refactoring. a href=http:/better.com/blogs/jeremy.miller/archive/2008/05/15/why-do-we-refactor.aspx rel=nofollow noreferrerRefactoring was variously described/a as:olliA result of insufficient upfrontdesign.liUndisciplined hackingliA dangerous activity that needlessly risked destabilizingworking codeliA waste of resources.bWhat are the responsible reasons that lead us to refactor our code? /BI also found a similar question here a href=https://stackoverflow.com/questions/140677/how-often-should-you-refactorhow-often-should-you-refactor/a, it doesn't provide the reason for refactoring.",TD-related,design,td_resolution,1,76,0.131,0.808,0.061,-0.6808
1625145,How do I prevent the repetition of business logic?,"OK. So here's my simplified scenario. We have a system which handles orders for a number of clients. We want staff users to be able to view all orders and we want client user to only be able to view orders which relate to them.When attempting to view a particular record we make use of the following function in our OrderSecurity class: Public Function CanViewOrder(order) If currentUser.MemberOfStaff() Then CanViewOrder = True Else CanViewOrder = (order.ClientId = currentUser.ClientId) End IfEnd FunctionreAt points when we want to display a list of orders to a user we can the following function defined in a OrderService class Public Function GetOrders() If currentUser.MemberOfStaff() Then GetOrders = GetAllOrders() Else GetOrders = GetAllOrdersForClient(currentUser.ClientId) End IfEnd FunctionreThis is OK for the above but doesn't hold up well as the rules get more complicated. Say, for example, we add another user type which represents a less trusted staff member who can only view orders from a sub-set of clients. We'd then have to add logic to the CanViewOrder and GetOrders functions (and potentially in the data access classes) which in my mind violates the DRY principle.So, my question is: Am I missing a trick here - is there some way I can combine the business logic for permission to view orders in one place which both of these functions can use?Or am I worrying too much and should just get on and have the logic in two places?(In this particular application I'm using ASP Classic - don't hate the player, hate the game - but I'd be interested in how you solve this problem in any language)",TD-related,design,duplication,4,268,0.065,0.832,0.102,0.7343
1716563,Java/J2EE standard practices and design choices,"I have a couple of design/architectural questions that always come up in our shop. I said our, as opposed to me personally. Some of the decisions were made and made when J2EE was first introduced so there are some bad design choices and some good.olliIn a web environment, how do you work with filters. When should you use J2EE filters and when shouldn't you? Is it possible to have many filters, especially if you have too much logic in them. For example, there is a lot of logic in our authentication process. If you are this user, go to this site and if not go to another one. It is difficult to debug because one URL path could end up rendering different target pages.liProperty resource bundle files for replacement values in JSP files: It seems that the consensus in the Java community is to use bundle files that contain labels and titles for a jsp parsing. I can see the benefit if you are doing development with many different languages and switching the label values based on locale. But what if you aren't working with multiple languages? Should every piece of static text in a JSP file or other template file really have to be put into a property file. Once again, we run into issues with debugging where text may not show up due to misspelling with property value keys or corrupt property files. Also, we have a process where graphic designers will send us html templates and then we convert them to jsp. It seems it more confusing to then remove the static text, add a key, add the key/value in a property file, etc.E.g. A labels.properties file may contain the Username: label. That gets replaced by some key and rendered to the user.ol start=3liUnit Testing for all J2EE development - we don't encourage unit testing. Some people do but I have never worked at shop that uses extensive unit testing. Once place did and then when crunch time hit, we stopped doing unit testing and then after a while the unit tests were useless and wouldn't ever compile. Most of the development I have done has been with servers, web application development, database connectivity. I see where unit testing can be cumbersome because you need an environment to unit test against. I think unit test manifestos encourage developers not to actually connect to external sources. But it seems like a major portion of the testing should be connecting to a database and running all of the code, not just a particular unit. So that is my question, for all types of development (like you see in CRUD oriented J2EE development) should we write unit tests in all cases? And if we don't write unit tests, what other developer testing mechanisms could we use?Edited: Here are some good resources on some of these topics.a href=http://www.ibm.com/developerworks/javabrary/j-diag1105.html rel=nofollow noreferrerhttp://www.ibm.com/developerworks/javabrary/j-diag1105.html/a",TD-related,design,coding_standards,2,479,0.043,0.923,0.033,-0.7189
2103010,IoC and constructor over-injection anti-pattern resolution,"emThis question is a result of a post by Jeffery Palermo on how to get around branched code and dependency injection a href=http://jeffreypalermo.com/blog/constructor-over-injection-anti-pattern/ rel=nofollow noreferrerhttp://jeffreypalermo.com/blog/constructor-over-injection-anti-pattern//a/emIn his post, Jeffery has a class (codepublic class OrderProcessor : IOrderProcessor) that takes 2 interfaces on the constructor. One is a validator codeIOrderValidator and an codeIOrderShipper interface. His method code branches after only using methods on the codeIOrderValidator interface and never uses anything on the codeIOrderShipper interface.He suggests creating a factory that will call a static method to get the delegate of the interface. He is creating a new object in his refactored code which seems unnecessary.I guess the crux of the issue is we are using IoC to build all our objects regardless if they're being used or not. If you instantiate an object with 2 interfaces and have code that could branch to not use one of them, how do you handle it?emIn this example, we assume <code>",TD-related,design,dependency,2,155,0,0.97,0.03,0.5267
2281619,Tips for avoiding second system syndrome,"Lately I have seen our development team getting dangerously close to the 'second system syndrome' type ideas while we are planning the next version of our product. While I'm all for making improvements and undoing some of the mistakes of our past, I would hate to see us stuck in an endless loop of rewriting and never launching anything.Is there a good design / development method that lends itself to building a better version 2.0 while avoiding second system scenarios?",TD-related,design,management,2,80,0.152,0.758,0.09,-0.6705
2282530,Options for handling a frequently changing data form,"What are some possible designs to deal with frequently changing data forms?I have a basic CRUD web application where the main data entry form changes yearly. So each record should be tied to a specific version of the form. This requirement is kind of new, so the existing application was not built with this in mind.I'm looking for different ways of handling this, hoping to avoid future technical debt. Here are some options I've come up with:ulliCreate a new object, UI and set of tables for each version. This is obviously the most naive approach.liKeep adding all the fields to the same object and DB tables, but show/hide them based on the form version. This will become a mess after a few changes.liBuild form definitions, then dynamically build the UI and store the data as some dictionary like format (e.g. JSON/XML or maybe an document oriented database) I think this is going to be too complex for the scope of this app, especially for the UI.What other possibilities are there? Does anyone have experience doing this? I'm looking for some design patterns to help deal with the complexity.",TD-related,design,churn,3,188,0.043,0.892,0.065,0.752
2346635,"What should be written first, XHTML or CSS?",What should be written first while making CSS layouts XHTML code or CSS code?olliWrite Whole HTML first then writeCSS according to HTMLliWrite HTML for an design element andCSS simultaneouslyliWrite whole CSS first then writeHTML according to HTMLa href=http://net.tutsplus.com/tutorials/html-css-techniques/30-css-best-practices-for-beginners/ rel=nofollow noreferrerI read on this article's point 7/a Create Your HTML First is this advice best to follow?Edit:/a href=http://net.tutsplus.com/videos/screencasts/how-to-convert-a-psd-to-xhtml/ rel=nofollow noreferrerand in this tutorial author also write HTML First then write css using Edit CSS option of web developer toolbar/a i think this is best way.,TD-related,design,coding_standards,2,84,0,0.88,0.12,0.897
2452806,Java data structure to use with Hibernate to store unknown number of parameters?,"Following problem: I want to render a news stream of short messages based on localized texts. In various places of these messages I have to insert parameters to customize them. I guess you know what I mean ;)My question probably falls into the Which is the best style to do it? category: How would you store these parameters (they may be Strings and Numbers that need to be formatted according to Locale) in the database? I'm using Hibernate to do the ORM and I can think of the following solutions:ullibuild a combined String and save it as such (ugly and hard to maintain I think)lido some kind of fancy normalization and and make every parameter a single row on the database (clean I guess, but a performance nightmare)liPut the params into an Array, Map or other Java data structure and save it in binary format (probably causes a lot of overhead size-wise)I tend towards option 3 but I'm afraid that it might be to costly in terms of size in the database. What do you think?",TD-related,design,coding_standards,5,176,0.027,0.91,0.062,0.7929
2472172,Can you create a trigger on a field within a table?,"Is it possible to create a trigger on a field within a table being updated?So if I have: TableA Field1 Field2 ....reI want to update a certain value when Field1 is changed. In this instance, I want to update Field2 when Field1 is updated, but don't want to have that change cause another trigger invocation, etc...",TD-related,design,debugging,2,56,0,0.837,0.163,0.5499
2699056,PHP OOP Design Patterns: Should I Create two separate classes for registration and form validation?,"I have two types of registration, registration A and registration B, each will have some of the same fields and some different fields. I was going to create abstract class registration and both A and B would have their own classes that extend from registration. Should I create a separate Validation class with separate A and B validation classes that extend? or is there a better pattern to use for something like this?",TD-related,design,suboptimal_design,4,73,0,0.81,0.19,0.885
3207611,Best Practices for Passing Data Between Pages,"The ProblemIn the stack that we re-use between projects, we are putting a little bit too much data in the session for passing data between pages. This was good in theory because it prevents tampering, replay attacks, and so on, but it creates as many problems as it solves.
loss itself is an issue, although it's mostly handled by implementing Session State Server (or by using SQL Server). More importantly, it's tricky to make the back button work correctly, and it's also extra work to create a situation where a user can, say, open the same screen in three tabs to work on different records.And that's just the tip of the iceberg.There are workarounds for most of these issues, but as I grind away, all this friction gives me the feeling that passing data between pages using session is the wrong direction.What I really want to do here is come up with a best practice that my shop can use all the time for passing data between pages, and then, for new apps, replace key parts of our stack that currently rely on Session.It would also be nice if the final solution did not result in mountains of boilerplate plumbing code.Proposed SolutionsSession As mentioned above, leaning heavily on Session seems like a good idea, but it breaks the back button and causes some other problems. There may be ways to get around all the problems, but it seems like a lot of extra work. One thing that's very nice about using session is the fact that tampering is just not an issue. Compared to passing everything via the unencrypted QueryString, you end up writing much less guard code. Cross-Page Posting In truth I've barely considered this option. I have a problem with how tightly coupled it makes the pages -- if I start doing PreviousPage.FindControl(""SomeTextBox""), that seems like a maintenance problem if I ever want to get to this page from another page that maybe does not have a control called SomeTextBox. It seems limited in other ways as well. Maybe I want to get to the page via a link, for instance. QueryString I'm currently leaning towards this strategy, like in the olden days. But I probably want my QueryString to be encrypted to make it harder to tamper with, and I would like to handle the problem of replay attacks as well. On 4 guys from Rolla, there's an article about this. However, it should be possible to create an HttpModule that takes care of all this and removes all the encryption sausage-making from the page. Sure enough, Mads Kristensen has an article where he released one. However, the comments make it sound like it has problems with extremely common scenarios. Other Options Of course this is not an exaustive look at the options, but rather the main options I'm considering. This link contains a more complete list. The ones I didn't mention such as Cookies and the Cache not appropriate for the purpose of passing data between pages. In Closing...So, how are you handling the problem of passing data between pages? What hidden gotchas did you have to work around, and are there any pre-existing tools around this that solve them all flawlessly? Do you feel like you've got a solution that you're completely happy with?Thanks in advance!Update: Just in case I'm not being clear enough, by 'passing data between pages' I'm talking about, for instance, passing a CustomerID key from a CustomerSearch.aspx page to Customers.aspx, where the Customer will be opened and editing can occur.",TD-related,design,coding_standards,3,588,0.073,0.779,0.148,0.9926
3506787,Override strongly typed @page masterpagefile,I am working with a third party asp.net application that uses master pages and nested master pages. My needs are to dynamically set the master page files for each page(.aspx). The application by default sets the master page file in the ly typed @Page directive for each page. I don't want to change the ly typed directive on each page (over 50 pages) because I am lazy and I want to minimize conflicts with future upgrades.My solution was to use the base masterpage class and override the OnPreInt event like this: protected override void OnPreInit(EventArgs e) { this.MasterPageFile = ~/MasterPages/MyMaster.master; }reEverything works perfectly. My question is: Is this a bad idea and why? It just seems too easy to be true.thanks.,TD-related,design,suboptimal_design,2,121,0.084,0.716,0.2,0.9517
4711851,Writing JavaScript according to SOLID,Have any one used the SOLID programming principle (or any of it's parts) while developing JavaScript?I've just started up on reading on it but can't seem to find anyone that used it for JS. The only part I find easy to implement/use is the Single responsibility principle.What I'm looking for is articles or example where these principles are used. And are there any argument's why one shouldn't use some parts?For example the Interface segregation principle says that the notion that many client specific interfaces are better than one general purpose interface.But from my knowledge there's no such thing as interfaces in JS (nice if it would be).,TD-related,design,coding_standards,2,107,0.024,0.891,0.085,0.7862
5964276,Name of anti pattern for complexity,"Is there a standard anti-pattern or something that could be referenced, to argue that when a system reaches a given complexity it will become unmaintainable and will collapse?Something like systems are never finished they are just abandoned, just a more serious version.",TD-related,design,management,2,42,0.16,0.755,0.085,-0.5095
5980892,Insight into memory usage of a few web applications I have,"I have 3 PHP web based applications that I'm evaluating for memory usage. One is a Wordpress website with minimal extensionslugins, another is a social networking application built with Code Igniter, and another is a project management system built from scratch (BFS).The average memory used to render a page for each of these applications are as follows:ulliWord Press Project - 13 MBliCode Igniter Project - 3 MBliBFS Project - 4 MBMy reaction and questions to the numbers are:a) Wow, wordpress uses 433% more memory than the CI project. And I haven't even installed any fancy WP plugins yet. Is WP considered a memory hog? If so, should I be concerned about this website sitting on the same server as some business critical web applications?b) Nice, the BFS project is in the same ball park as the code igniter project. I had some ideas on how to optimize memory usage in the BFS project. I ran some experiments against the idea and was able to improve memory usage by 25% (thus, yielding 3mbage load, just like CI prj). Refactoring the entire system will take 1-2 weeks worth of work. My questions on this matter are:i) Is it worth it to optimize for 25% memory efficiency? Keep in mind WP uses 433% more memory and while doing less than the BFS and CI projectii) if yes to i), is TODAY the day to do it? This BFS project is in start up phase with ambitious plans for new features. Do I risk incurring dangerous amounts of technical debt going forward if I don't optimize today?Ok, so those are my questions",TD-related,design,management,3,268,0.035,0.81,0.155,0.9848
7413315,Single Responsibility Principle in OOP,"In my application design, I usually map objects to the important tables in the database. The objects then handle everything relating to that data (including linkage tables). So I for example have built an Activity object, with properties like name and due_date, methods like load() and save(), and also methods like<code>, which return (arrays of) other objects. Is this 'bad' OOP because it violates the Single Responsibility Principle?",TD-related,design,coding_standards,2,68,0.046,0.86,0.094,0.3612
7533644,Prevent freezing during reconstruction of complex WPF UI?,"OK lets face it, during render and a layout pass a WPF UI will freeze....Any escape from this?Someone talked about XAML serialization and Desrialization but does it really work? All I see is a momentary lapse and frozen window for complex UIs which are deserialized.Will I ever be able to achieve swift UI loading?P.S. I am not talking about loading view data on background thread and stuff. It is anyways a norm now-a-days. But is there ANY (this should sound desperate) way to not produce a hanged Window for complex UIs? By complex I mean heavy styles, deeply hierarchical templates, non virtualized panels etc.",TD-related,design,debugging,5,104,0,0.934,0.066,0.668
10041702,Updating Controls from Multiple Pages on Windows Phone,"All, I am new to Windows 7 Phone. My situation is that I have a main page which contains a ScrollViewer which in turn houses a StackPanel. I want to populate this StackPanel with multiple sub-StackPanels (at runtime) which are to hold an Image Thumb nail a hyperlink and some basic information about the image.
This is all good when I do this from the main page, but I want to know how to update this control (which is on the main page), but from any page other than the main page. I would like to know what is considered best practice for updating a page's control (like that outlined above) from another page.
Obviously there are a number of ways to pass data between pages
<code>
then in other page simply
<code>
and many others. But what is best practice for updating a generic control from a different page?
Note: There are many question about data access and passing between pages.
Passing data from page to page
How to pass the image value in one xaml page to another xaml page in windows phone 7?
Passing image from one page to another windows phone 7
and more. This is not what I am asking.like Silverlight), where the UI codebehind implements event handlers that directly access data, and refactors it using the MVVM pattern.",TD-related,design,suboptimal_design,2,213,0,0.891,0.109,0.9729
10661678,Should the view fire events?,"I have a class for part of a GUI. It is a toggle switch that has a codeswitch public member function that puts the GUI switch into whatever position you want. When you click on the GUI element, I would like an codeonToggle event fired along with the GUI calling the codeswitch function.Here are my choices (that I'm considering and want your advice on) to implement this:1) Make a codesetOnclick public member function that my controller can use to assign the firing of the event to the element and take care of the codeswitch function call. <code> I can just put the event firing and codeswitch function call inside the class itself element.onclick = function()<code>I think it would be nice to have the GUI classes (such as my toggle switch) entirely devoid of any logic or functionality, but I'm not sure if this is necessary.I'm not using an MVC framework, but I do like to apply the principles of separating functionality between MV and C.Can you think of any potential downsides to either method in the future?",TD-related,design,td_resolution,2,177,0.046,0.89,0.064,0.2862
11610421,How can I downcast to class' type E or at least make it in a safe way without warnings?,"I have super abstract class Node and 50 types of subclasses SubNode. I have a generic Class   E extends Node   which has a private var List  E   and a method which unfortunately has to accept superclass Node ALWAYS, cannot move it to just E:<code>Any solution (Reflection?) able to compile without warnings, throwing a CastException instead of adding any object due to type erasure??...I dont want to have to write same function for any type of subclass:<code>It would be so nice having a method like<code>or  <code>Should throw CastException if non-E }re",TD-related,design,warnings,3,90,0.026,0.785,0.19,0.9223
13322530,C++ global structure creates name conflict,"I have written a quite extensive framework that drives characters in a physical simulation. Even though everybody warned me not to do it, I used a global public data structure for storage of information and called it State. It's not in a namespace either. I make it globally accessible by declaring extern State state;. The reason why I did this is because this structure is needed everywhere in the application and I find it extremely convenient to just include my State.h and then write to state.var anywhere and read state.var anywhere. The framework is changing rapidly, too, and I also find comfort in not having to care about passing data around, synchronizing etc. when new components are introduced. Anyhow, now the s*** hit the fan. I want to use one of Qt's GUI classes and it already has it's own member called state of type State. Their state is at least in a namespace, but it doesn't seem to matter, since inside the class I'm already using that namespace.What can I do now?",TD-related,design,"in-house, framework",2,173,0.027,0.945,0.028,0.0194
13376409,Re-assigning IDs in a non-IDENTITY type field in SQL Server database,"emWARNING: This tale of woe contains examples of code smells and poor design decisions, and technical debt./emIf you are conversant with SOLID principles, practice TDD and unit test your work, emDO NOT READ ON/em. Unless you want a good giggle at someone's misfortune and gloat in your own awesomeness knowing that you would never leave behind such a monumental pile of crap for your successors.So, if you're sitting comfortably then I'll begin.In this app that I have inherited and been supporting and bug fixing for the last 7 months I have been left with a DOOZY of a balls up by a developer that left 6 and a half months ago. Yes, 2 weeks after I started.Anyway. In this app we have codeclients, codeemployees and codevisits tables.There is also a table called codeAppNewRef (or something similar) that ... wait for it ... contains the next record ID to use for each of the other tables. So, may contain data such as :- TypeID Description NextRef 1 Employees 804 2 Clients 1708 3 Visits 56783reWhen the application creates new rows for codeEmployees, it looks in the codeAppNewRef table, gets the value, uses that value for the ID, and then updates the codeNextRef column. Same thing for codeClients, and codeVisits and all the other tables whose codeNextID to use is stored in here. Yes, I know, no auto-numbering codeIDENTITY columns on this database. All under the excuse of when it was an Access app. These ID's are held in the (VB6) code as longs. So, up to 2 billion 147 million records possible. OK, that seems to work fairly well. (apart from the fact that the app is updating and taking care of locking / updating, etc., and not the database)So, our users are quite happily creating codeEmployees, codeClients, codeVisits etc. The codeVisits ID is steady increasing a few dozen at a time. Then the problems happen. Our clients are causing database corruptions while creating batches of visits because the server is beavering away nicely, and the app becomes unresponsive. So they kill the app using task manager instead of being patient and waiting. Granted the app does seem to lock up.Roll on to earlier this year and developer Tim (real name. No protecting the guilty here) starts to modify the code to do the batch updates in stages, so that the UI remains 'responsive'. Then April comes along, and he's working his notice (you can picture the scene now, can't you ?) and he's beavering away to finish the updates.End of April, and beginning of May we update some of our clients. Over the next few months we update more and more of them.Unseen by Tim (real name, remember) and me (who started two weeks before Tim left) and the other new developer that started a week after, the ID's in the visit table start to take huge leaps upwards. By huge, I mean 10000, 20000, 30000 at a time. Sometimes a few hundred thousand.Here's a graph that illustrates the rapid increase in IDs used.img src=https://i.stack.imgur.com/90MBp.jpg alt=Take a look at his graphRoll on November. Customer phones Tech Support and reports that he's getting an error. I look at the error message and ask for the database so I can debug the code. I find that the value is too large for a long. I do some queries, pull the information, drop it into Excel and graph it.I don't think making the code handle anything longer than a long for the ID's is the right approach, as this app passes that ID into other DLL's and OCX's and breaking the interface on those just seems like a whole world of hurt that I don't want to encounter right now.One potential idea that I'm investigating is try to modify the ID's so that I can get them down to a lower level. Essentially filling the gaps. Using the codeROW_NUMBER functionWhat I'm thinking of doing is adding a new column to each of the tables that have a Foreign Key reference to these Visit ID's em(not a proper foreign key mind, those constraints don't exist in this database)./em This new column could store the old (current) value of the Visit ID (oh, just to confuse things; on some tables it's called codeEventID, and on some it's called codeVisitID).Then, for each of the other tables that refer to that codeVisitID, update to the new value.Ideas ? Suggestions ? Snippets of T-SQL to help all gratefully received.",TD-related,design,"suboptimal_design, td_resolution",4,741,0.05,0.847,0.103,0.986
13974091,Stack trace a mysql error,"I have an app in which we have a custom database abstraction class. It's all nicely tuned and works pretty well.We have recently added better error logging to file and database for query and connection errors.One thing we've found ourselves wanting is the ability to run a trace on the files involved in the call. I.E to remove an old bit of code etc.We have used some output buffering, with debug_print_backtrace() but am not satisfied with the disorganised output this puts to log. Any one come across a nice handler for this which makes terminal log reading beautiful?Also the app is fairly legacy code and queries are very much mixed into views and output. Is there any safe way that we could force a redirect to an /error.php page if a query fails without re-writing the app?",TD-related,design,"database, legacy",2,137,0.059,0.835,0.106,0.7195
15934965,Passing and persisting a connection string in WPF using MVVM pattern?,"My app needs to be able to store the connection string from the login module to be available to all other modules in the application, of which there are 50 or so. I originally intended to make the connection string available through broadcasting and subscribing to a new/changed connection string event, but because most/all of the 50 modules are loaded on demand they are unable to subscribe to the event during the login process since they are loaded after the login process. Based on my understanding I need a different approach to make the connection string available.I then thought about placing the connection string in the shell and attempting to expose it to any loaded module but I cannot find a way to do that without breaking the MVVM pattern and introducing unwanted dependencies.If anyone knows of a way to implement either of the above two options I would be very interested to know if it could be done while folowing the MVVM pattern.I am thinking now that the best approach would be to use some variation of a singleton for the connection string as a shared service. I would love for the Unity Container to be able to store the connection string and I could use a service locator to access it in any module but I do not know how to do this. Any examples that are similar in nature have been in MEF and/or Silverlight. Has anyone done this in WPF or have an example of how to write a connection string singleton and add it to the Unity Container? A guide, tutorial, or some code snippets would be greatly appreciated! Note: I am using Prism and Unity, Oracle on the backend and the app will be deployed on a Citrix server (where in the name of security they have blocked developers from writing to the app.config) which is why I cannot use that approach. Also will using a Singleton for the connection string cause problems when multiple users run the app off of Citrix? Will every user have their own singleton connection string? If not, then my whole question changes, is there a good approach I can use to passersist the connection string between all of my modules?",TD-related,design,pattern,2,372,0.032,0.885,0.083,0.9766
17870406,My OOP design feels sloppy (C++),"I am writing a game in Cocos2D-x and I am struggling with feeling like my OO is sloppy. I can't shake the feeling and I can place m finger on why.Game Scene classul liIn This a Layer is createdLayer Classul liresponsible for creating itself liAlso calls HUDS when needed licontains std::vectors of objects on the layerObject Classullihold everything about itselflihas a sprite member variable that is on the layerHUD1ullicalled when the user taps the layer and the touch even occurs in the Objectliis a Menu of things that you can do to the ObjectliWhen you click a menu item it needs to change values in ObjectliWhen you click a menu item it actually runs code in Object (object::doSomething())What feels sloppy I think is that there is a lot of dependency on these classes together.I feel like I should abstract this out and create a class that controls all of this happening instead of some code in Object, Layer, HUD, etc.Can anyone talk to me about how this is laid out and if I am making an OO mistake?",TD-related,design,coding_standards,3,178,0.03,0.875,0.095,0.8083
19528385,Should a node (vertex) know about its neighbours in a graph?,"I am trying to implement a graph in dart.I thought of creating the classes Node (vertex), Edge and Graph.The main idea is that the Graph has a List of Nodes and a List of Edges.Later I will implement some search algorithms on the graph.I think of also adding a List of neighbours to each Node (List neighbours) so each Node knows its neighbours (successor nodes to be precise) . My thought here is that getting the successor nodes of one node is quicker when the node has this information than when the algorithm has to check the edge list each time. I know that changes (deletion of edges, nodes, adding new edges, node) would also cost more because I'd have to update them in two locations. But at the moment I don't plan to make the graph too dynamic after its creation.Do you think this approach makes sense or might my way have some mayor flaw?",TD-related,design,coding_standards,3,156,0,0.941,0.059,0.7964
19736075,Handling multiple Ajax requests,"I'm developing an application which requires multiple ajax requests, such that codeOption2 will be only available when codeButton2 will be clicked and its response returned. Similarly, codeOption3 will be available only when codeButton3 has been clicked. Following is the general structure of the code. I'm building the app in codephp   codemysql. <code>Currently, everything works. The application will be for a maximum of 10,000 users. I just wanted to know if there was any way better of doing this/or any frameworks available that I can incorporate.Also: What may be the problems that may arise using this way and ways to clear out those problems.",TD-related,design,concurrency,2,103,0.051,0.898,0.051,0.0258
21163490,Singleton alternative for arbitrary objects,"Yesterday I asked a question regarding singletons and templates (a href=https://stackoverflow.com/questions/21148611/meta-programming-with-singletonMeta programming with singleton/a), and that kicked off quite a debate about singleton use. I'm personally not a fan of them, but for my particular problem I can't figure out an alternative. I'd like to describe my problem and would love feedback on ways I can create a robust solution.Background: The software I'm working on has been around for 15 years and spans multiple exe's and dll's (it's for Windows); I've been working on it for 6 months.I have a class, Foo that's in a shared library. Foo is an object with a very small lifetime (~5 seconds), and can be created in any thread, any process, and at any time. I'm now extending Foo with new functionality, and a requirement is a function called FooInit() must be run before any Foo objects can be executed, and FooDestroy() when the process exits.The problem is, creation of Foo objects is arbitrary - any part of the code can, and does, call: Foo* foo = new Foo();reboost::call_once inside Foo's ctor works for FooInit(), but doesn't help me solve the problem of calling FooDestroy(). Referencing counting Foo doesn't help, because there may be [0,n] in memory at any one time with more to be created, so I can't call FooDestroy() when the count gets to 0.My current solution is to create and use a FooManager singleton inside of Foo's ctor. The singleton will call FooInit(), and at some time in the future FooDestroy() will eventually be called. I'm leaning towards this solution because it appears to be the safest and lowest risk.Any feedback is appreciated.",TD-related,design,pattern,2,272,0.089,0.772,0.139,0.9465
21697596,How to merge metadata from several copies of Oracle database into single (reference) database,"What we have: some developers worked (pl/sql developer) with several copies of same Oracle DB   they made changes in same pakages in different copies of DB. Changes was made mostly in packages, but tables was also changed. And one package could be modified by multiple developers :(What we want: merge metadata from this copies of DB into single/reference DB. Is there any simple   safe way to do this?",TD-related,design,"duplication, database",3,68,0,0.926,0.074,0.6486
21905692,Using if expression in getter,"Is it correct to just use a public emproperty/em or should I rather make a private field code_count? I have read some info on the topic, but I can't find an answer. public int Count{ get { if (this._feeds.IsValueCreated) { return this._feeds.Value.Count; } else { return this._dbConnection.Table  T  ().Count(); } }}public FeedRepository(SQLiteConnection dbConnection){ this._dbConnection = dbConnection; this._feeds = new Lazy  IList  T    (() =   _dbConnection.Table  T  ().ToList());}re",TD-related,design,coding_standards,3,67,0.061,0.939,0,-0.5023
23056418,Preferable way of making code testable: Dependency injection vs encapsulation,"I often find myself wondering what is the best practice for these problems. An example:I have a java program which should get the air temperature from a weather web service. I encapsulate this in a class which creates a HttpClient and does a Get REST request to the weather service. Writing a unit test for the class requires to stub the HttpClient so that dummy data can be received in stead. There are som options how to implement this:Dependency Injection in constructor. This breaks encapsulation. If we switch to a SOAP web service in stead, then a SoapConnection has to be injected instead of HttpClient.Creating a setter only for the purpose of testing. The normal HttpClient is constructed by default, but it is also possible to change the HttpClient by using the setter.Reflection. Having the HttpClient as a private field set by the constructor (but not taking it by parameter), and then let the test use reflection to change it into a stubbed one.Package private. Lower the field restriction to make it accessible in test.When trying to read about best practices on the subject it seems to me that the general consensus is that dependency injection is the preferred way, but I think the downside of breaking encapsulation is not given enough thought.What to you think is the preferred way to make a class testable?",TD-related,design,"dependency, coding_standards",2,225,0.044,0.911,0.045,0.2846
24142926,Communication between 2 threads C++ UNIX,"I need your help with wxWidgets. I have 2 threads (1 wxTimer and 1 wxThread), I need communicate between this 2 threads. I have a class that contains methods to read/write variable in this class. (Share Memory with this object)My problem is: I instanciate with new this class in one thread but I don't know that necessary in second thread. Because if instanciate too, adress of variable are differents and I need communicate so I need even value in variable :/I know about need wxSemaphore to prevent error when to access same time.Thanks you for your help !EDIT: My codeSo, I need make a link with my code. Thanks you for all ;)It's my declaration for my wxTimer in my class: <code>, I make a new for this class. But in other thread (wxThread), what I need to do to communicate ?If difficult to understand so sorry :/",TD-related,design,"concurrency, interface",2,148,0.097,0.81,0.093,-0.1719
25742973,Why shouldn't I directly access Instance properties for write operations?,"So I read this a href=http://bjorn.tipling.com/advanced-objects-in-javascript rel=nofollowblog entry/a recently. The author says:block e Although directly accessing and setting properties on instances still sets off my internal bad-javascript buzzer. Over time I have been trained by bugs and technical debt to avoid arbitrarily setting values on instances as a means to pass information around./block eI heard that advice before, yet I still don't know what is bad about it in particular.I see the possibility of validating values before actually setting them, but how should I handle a bad one? And is this the only reason to use a setter instead?",TD-related,design,interface,2,99,0.108,0.837,0.054,-0.7438
25984718,Is it ever OK to call a model class method from within a view,"I was in the process of implementing a slide show for my spree store, when I came across a gem that does it. In part of the ReadMe file, I noticed it calls a model class method directly from the view: a href=https://github.comriviterag/spree_slideror-roll-your-own rel=nofollowhttps://github.comriviterag/spree_slideror-roll-your-own/aHere's the code:   % if Spree::Slide.published.count    0 %     section id=slideshow     ul class=slide     % Spree::Slide.published.order('position ASC').each do |s| %     li         %= s.slide_name %    /     %= link_to image_tag(s.slide_image.url), url_for(s.slide_link) %          % end %          a title=  %= t(:previous) %   class=slider-prev    %= t(:previous)%    /a     a title=  %= t(:next) %   class=slider-next    %= t(:next) %    /a     /section    % end %  reI was doing the same with my own slider, but had flagged the model call as something to move into the relevant controllers (there'd be a few) later. However, really, it seems like it's most self-contained, and easiest to understand and maintain, when the model is called directly from the view like this.I'd always been lead to believe a View accessing a Model class directly gave good programers nightmares. But in this context, is fetching data directly from the view OK? Why or why not?",TD-related,design,"pattern, in-house",3,182,0,0.885,0.115,0.9661
26109102,Is Feature Branching still (or ever) considered a bad practice?,"Coming from the TFS world and having just gotten comfortable enough with Git, I am about to propose to my team that we should incorporate the Gitflow workflow as pointed out by the famous article by Vincent Dressen going forward.Almost all modern-day literature surrounding branching strategies voice the effectiveness of the Gitflow workflow, which is an extended version of feature branching, but dated articles from influential engineers, such as Martin Fowler's Feature Branch article (2009), discredit feature branching in general in favor of continuous integration.Some of his critics stated that Fowler's opposition to feature branching was in part because he was using SVN as his VCS, which was an ineffective tool for merging and therefore led Fowler to recommend a branching anti-pattern ""merge paranoia"".Fowler then responded in 2011 by saying DVCS systems may make merging easier, but they still don't solve semantic conflicts. Now in 2014, we have language aware merge tools such as Semantic Merge, which might solve this problem altogether.My questions areIs feature branching and continuous integration mutually exclusive?How relevant is Fowler's article in modern day development, especially with our accessibility to tools like SourceTree, Git, Jenkins, and other code review software that make feature branching and the like much easier?",TD-related,design,coding_standards,2,203,0.053,0.813,0.134,0.9642
26805744,"Large class with many properties, but what if I only need one or two?","I'm modifying an app for performance gains. The app has a class with many properties. Typically this class is populated in its entirety by a primary key that pulls a large query from a database. The application is in great part slow because this happens constantly throughout, even though much of the time only one two properties in the class are needed in a given section of code. The existing large class has only a default constructor and all of its properties are nullable or have default values. In code below ignore lack of constructors and how these objects are populated. public class Contract{ public enum ContractStatus { Draft, Active, Inactive } private Int32 contractId = DALC.DefaultInt32; private String name = DALC.DefaultString; private ContractStatus status; private ContractType contractType = null; private CurrencyType currencyType = null; private Company company = null;}reAs you can see it has its own properties, and also references other classes (e.g. ContractType, Company).A few approaches I've thought of in light of common design patterns:1) re-factor this hugely and break up those smaller sub-sections into their own classes with their own properties. Then reconstruct that large class with all of the smaller ones when it is needed. This will be quite laborious, though even if it sounds ideal and consistent with SOLID OOD principles.2) Create new classes that simply contain the large class, but only expose one or two of its properties. I'm still creating a full blown version of the original, large class, but I will only populate the data I need. This will be via simple DB query, thus the bulk of the class will sit there unused and its null default classes it's referencing won't ever be constructed. public class ContractName{ Contract contract; public ContractName() { contract = new Contract(); } public String Name { get { return contract.Name; } set { contract.Name = value; } }}re3) Add new constructors to existing large class with a parameter indicating what chunks of code I want to actually populate. This sounds messy and kind of nasty and wrong, and would leave me in the scenario where if Contract is created by a contract ID in one section of code it has different info than if created by contract ID elsewhere.Thanks for any ideas!",TD-related,design,antipatterns,4,376,0.051,0.872,0.077,0.6827
27777508,Best practice for injecting DAO's,"I am in a process of paying my a href=http://en.wikipedia.org/wiki/Technical_debt rel=nofollowTechnical Debt/a and one of the problem I have facing is the uses of DAO's with CDI injection.I did write a blog about a href=http://theelitegentleman.blogspot.com/2014/04/daos-as-ejbs-you-are-doing-it-wrong.html rel=nofollowDAO injection/a (using CDI, of course) and it works wonders and I will use the reference of the blog for my question. I am now in a situation where I have so many database tables (normalized, of course) and creating DAO's for each tables is not the issue. The issue is when a service (let's assume and EJB Session Bean) has references to many DAO's, like in the example below: @Statelesspublic class CustomerServiceEJB implements CustomerServiceLocal, CustomerServiceRemote, CustomerService { private static final Logger LOGGER = Logger.getLogger(CustomerServiceEJB.class.getName()); @Inject @JPADAO private CustomerDAO customerDAO; @Inject @JPADAO private CustomerAccountDAO customerAccountDAO; @Inject @JPADAO private CustumerCredentialDAO customerCredentialDAO; //And rougly 15 more DAO's.}reAs you can see, if we need to use various DAO's, the class has instances of all DAO's and that means that the CDI container will have to inject all of them prior to being used.One solution I came up with was to create a codeDAOManager where all references of the DAO's are listed in the manager.Example: public interface DAOManager { public CustomerDAO getCustomerDAO(); public CustomerAccountDAO getCustomerAccountDAO(); public CustumerCredentialDAO getCustomerCredentialDAO(); //Etc}reAnd it's JPA's representation: @JPADAOpublic class JPADAOManager implements DAOManager { @PersistenceContext private EntityManager entityManager; public CustomerDAO getCustomerDAO() { return new JPACustomerDAO(entityManager); } //Etc...}reFinally, in codeCustomerServiceEJB, I can inject the DAO as follows: @Inject @JPADAOprivate DAOManager daoManager;reMy question: Is my approach correct? If not, what is the best approach? Also, what do I need to take into consideration when using DAO's with CDI? emAdded question:/em Should codeJPADAOManager return a DAO in lazy-loading fashion?",TD-related,design,coding_standards,4,281,0.01,0.937,0.053,0.89
28877414,Real advantages of using Moo(se) over Perl OO,"I am currently working at a company, where we are doing Perl development. However the code is really messy, uses really old Perl idioms, so I've decided to emslowly/em clean it up and teach my coworkers about Modern::Perl, good software design, OOP - abstraction, coupling, inheritance, SOLID principles etc. I have a disadvantage, that I am working here only for a month, so I'm quite new here.My question is: can I (if so how) convince them of considering switching to Moo(se) from plain Perl OO? What are the advantages of it? I need really good reasons for them to consider. Is there a big cost performance-wise with using those modules? I know from experience, that it is very comfortable to use those modules (also traits are really good), but I am afraid that they will deny switching because of performance reasons.So. Is there an advantage and how would you describe it to Perl developers, who are stuck in the pre-2000 era?",TD-related,design,"td_resolution, legacy, management, in-house",2,161,0.058,0.841,0.102,0.6329
29567280,Is there any drawback with Laravel's use of facades?,"There are some criticism [see below] to the Laravel's extensive use of facade, which seems is an anti-pattern, e.g.block e Singleton facades only upside is that they are relatively easy to use, but technical debt introduced from such shortcuts is hard to even estimate./block eSample code: $value = Cache::get('key');reSo, using the above example code, can anyone show me how this code can be better written in PHP, if we are not using facades?",TD-related,design,antipatterns,2,73,0.087,0.84,0.074,0
29624223,PaperTrail doesn't play nice with Carrierwave and `remove_previously_stored_files_after_update` option,"I need to version images for my Rails app. I'm using Carrierwave for file uploads, and PaperTrail for versioning.While versioning seems to work pretty well, it seems though that reifying a version doesn't play nice with Carrierwave's coderemove_previously_stored_files_after_update config deactivated: in this situation, a simple codereload of the reified model instance doesn't work anymore, only an explicit fresh load from the database (using codeModel.find 123) works.I have created a a href=https://github.com/jmuheim/test-carrierwave-papertrail rel=nofollowdemo Rails app/a to demonstrate the problem.The codeUser model mounts two uploaders:ullicodeAvatarUploader, which removes the file after update (default)licodeKeepingFilesAvatarUploader, which doesn't remove the file after update, using the coderemove_previously_stored_files_after_update option set to codefalseCode of codeAvatarUploader:  encoding: utf-8class AvatarUploader    CarrierWave::Uploader::Base storage :file def store_dir uploads/{model.class.to_s.underscore}/{model.id}/{mounted_as} endend/  of codeKeepingFilesAvatarUploader:  encoding: utf-8class KeepingFilesAvatarUploader    CarrierWave::Uploader::Base storage :file def store_dir uploads/{model.class.to_s.underscore}/{model.id}/{mounted_as} end configure do |config| config.remove_previously_stored_files_after_update = false endendreThe only difference is the coderemove_previously_stored_files_after_update option.Here's the code of the codeUser model: class User    ActiveRecord::Base has_paper_trail only: [:name, :avatar, :keeping_files_avatar] mount_uploader :avatar, AvatarUploader mount_uploader :keeping_files_avatar, KeepingFilesAvatarUploaderendreI have written some specs which demonstrate the unexpected behaviour. As they are a bit long to post, see here:a href=https://github.com/jmuheim/test-carrierwave-papertrail/blob/master/spec/models/user_spec.rbL20 rel=nofollowhttps://github.com/jmuheim/test-carrierwave-papertrail/blob/master/spec/models/user_spec.rbL20/aAll specs pass except the one that I set to codepending, here's the output:  1) User versioning reloading the model after reify sets keeping_files_avatar to the original value See http://stackoverflow.com/questions/29624223apertrail-doesnt-play-nice-with-carrierwave-and-remove-previously-stored-file Failure/Error: expect(user.keeping_files_avatar.file.filename).to eq 'original-image.jpg' This upload field isn'!       FAILING LINE      ! expected: original-image.jpg got: new-image.jpg (compared using ==) ./spec/models/user_spec.rb:20:in `block (4 levels) in   top (required)  'Finished in 0.20704 seconds (files took 1.51 seconds to load)4 examples, 0 failures, 1 pendingreIt would be really nice to get this to work. I don't need this functionality right now, but I don't want to add any technical debt to my project (especially this one could lead to very unforeseen problems as one usually relies on simply doing a codereload on a model to refresh its attributes).",TD-related,design,td_resolution,1,304,0.061,0.901,0.038,-0.8381
30279575,"Strategies to speed up access to databases when working with columns containing massive amounts of data (spatial columns, etc)","First things first, I am an amateur, self-taught ruby programmer who came of age as a novice engineer in the age of super-fast computers where program efficiency was not an issue in the early stages of my primary GIS software development project. This technical debt is starting to tax my project and I want to speed up access to this lumbering GIS database.Its a postgresql database with a postgis extension, controlled inside of rails, which immediately creates efficiency issues via the object-ification of database columns when accessing and/or manipulating database records with one or many columns containing text or spatial data easily in excess of 1 megabyte per column.Its extremely slow now, and it didn't used to be like this.One strategy: I'm considering building child tables of my large spatial data tables (state, county, census tract, etc) so that when I access the tables I don't have to load the massive spatial columns every time I access the objects. But then doing spatial queries might be difficult on a parent table's children. Not sure exactly how I would do that but I think its possible.Maybe I have too many indexes. I have a lot of spatial indexes. Do additional spatial indexes from tables I'm not currently using slow down my queries? How about having too many for one table?These tables have a massive amount of columns. Maybe I should remove some columns, or create parent tables for the columns with massive serialized hashes?There are A LOT of tables I don't use anymore. Is there a reason other than tidiness to remove these unused tables? Are they slowing down my queries? Simply doing a count method on some of these tables takes TIME.PS:- Looking back at this 8 hours later, I think what I'm equally trying to understand is how many of the above techniques are completely USELESS when it comes to optimizing (rails) database performance?",TD-related,design,"database, coding_standards",5,315,0.046,0.898,0.056,-0.4753
30439379,How to compare strings after rendering with render_to_response in Django?,"I want to refactor many template files related to HTML written by Django.The files are messy and consist of copy   paste.Since our project will long, this Technical debt should be returned.Thus, I'd wanted to write the test between before and after refactoring.I only want to compare these renderings, contexts are not but needed here and creating contexts for the tests tires me because there are many template files.So I created the context which always return Hoge as dummy and it worked well on shell. class X(Context): def __getitem__(self, key): return Hoget = Template(b{{ m }}a)t.render(X()) -   bHogeareHowever when I used the similar method (render_to_string) in the file related to test, it emitted VariableDoesNotExist Exception.Of course, on shell, render_to_string works well.It seems that django.template.base.Variable._resolve_lookup occur the exception, I assign the method, returning the former Context X(), to _resolve_lookup. Like the following. Variable._resolve_lookup = lambda him, context: X()re(--I know this way is really bad but my purpose is only testing to compare the renderings)However, after that, soon the following exception was caused. django.core.urlresolvers.NoReverseMatch: Reverse for 'xxx_list' with arguments '()' and keyword argumentsreI also know these Exceptions are happened in the template file whose want some response from Django.Then I heard here.What things should I do?Should I try to test step by step?",TD-related,design,debugging,2,210,0.057,0.872,0.071,-0.1654
30459273,Override .objects in Model Django outside models.py,"I want to override Classes in codemodels.py to get call stacks at runtime. I know that we can do following in Django in order to override manager and hence customize QuerySet API - So, in codemodels.py class A(models.Model): objects = SomeClass()reand in codeSomeClass  class B(Manager): def get_query_set(): override the way you wantreBut, in order to make things simpler I am thinking to use decorator to override the same - So, in codemodels.pycode@ decoratorForOverridingclass A(models.Model): passin codedecorator.py def decoratorForOverriding(cls): cls.objects = SomeClass()reError I get is  AttributeError: 'NoneType' object has no attribute '_meta'reAny idea what is going on?Should I make the codeclass A as an abstarct class? That did not do the trick either.",TD-related,design,coding_standards,1,112,0.021,0.952,0.027,-0.276
31004648,Simple Injector fails if using verify before setting dependency resolver for MVC 4,"We have an ASP.NET MVC 4 based application that's a couple of years old, and I'm working on ridding it of some technical debt. One of the things I'm doing is introduce dependency injection, so that we can better separate the business logic from the data access implementation, and make it less painful to write isolated unit tests. I've gone with Simple Injector, but I'm having some issues.I've followed the a href=http://simpleinjector.readthedocs.org/en/latest/mvcintegration.html rel=nofollowMVC integration guide in the Simple Injector documentation/a. It describes the initialization process like this:olliCreate a containerliRegister types in the containerliVerify the container (optional)liOverride the default dependency resolverSo, here's the way this is implemented in the application so far. I've removed logging statements for clarity, and added marker comments for the steps above: // 1var container = new Container();var webRequestLifestyle = new WebRequestLifestyle();// 2container.Register  IOrganizationService  ( delegate { var proxy = new OrganizationServiceProxy( organizationServiceManagement, clientCredentials); proxy.EnableProxyTypes(); return proxy; }, webRequestLifestyle);container.RegisterSingle  ILoggerProvider  (LoggerProvider); // static fieldcontainer.Register  IExternalLinkRepository, ExternalLinkRepository  (webRequestLifestyle);container.Register  IQueueRepository, QueueRepository  (webRequestLifestyle);container.RegisterMvcControllers(Assembly.GetExecutingAssembly());container.RegisterMvcIntegratedFilterProvider();// 3container.Verify(VerificationOption.VerifyAndDiagnose);// 4DependencyResolver.SetResolver(new SimpleInjectorDependencyResolver(container));reThe above code fails on step 3 when attempting to instantiate the MVC controllers, throwing codeSystem.InvalidOperationException: An error occurred when trying to create a controller of type 'MyProject.MyNamespace.MyController'. Make sure that the controller has a parameterless public constructor.Which makes sense, because my controllers are set up for constructor injection. For example: public MyController(ILoggerProvider loggerProvider){ Logger = loggerProvider.Get(GetType());}reThe default MVC controller activator wouldn't know what to do with this. However, what I don't understand is why the codeContainer.Verify method of Simple Injector hits the default controller activator of MVC at all. Shouldn't the container innately use Simple Injector's dependency resolution to test the dependency graph? Looking through the exception call stack, it originates at codeSystem.Web.Mvc.DefaultControllerFactory.DefaultControllerActivator.Create, so it definitely goes outside the bounds of Simple Injector at some point.However, when I swap the order of steps 3 and 4: DependencyResolver.SetResolver(new SimpleInjectorDependencyResolver(container));container.Verify(VerificationOption.VerifyAndDiagnose);reIt successfully verifies the container, and dependency injection works as expected in the application as well. This seems to fix the problems for now. Still, I'm wondering:olliWhy does Simple Injector use MVC's default controller activator to test dependency resolution? Is this expected/documented anywhere?liAre there any side effects to setting the custom resolver first, then verifying? I'm asking because this is contrary to the guide found in the documentation. It seems to work as expected, and if either of them fail the application will crash anyway, so from the application's point of view it doesn't seem to matter.",TD-related,design,"dependency, td_resolution",2,400,0.061,0.872,0.067,0.5944
31035769,Python: is RuntimeError acceptable for general use?,"Is it acceptable to use the RuntimeError exception for general application use? raise RuntimeError('config file is missing host address')reI've got some code with a couple of one-off situations like this and would prefer to avoid creating one-off exception classes for each of them. All the situations are fatal, and my goal is to get a clear message to the console. Basically I'm looking for something similar to the deprecated raise 'config file is missing host address're",TD-related,design,warnings,2,76,0.118,0.77,0.112,-0.128
31390505,Frontend resource optimisation: Requests vs caching,"I'm currently working on a big site which has quite a bit of technical debt we need to work away. There is quite a bit of js and css being loaded in the site. Currently the files are aggregated and minified in layers. One layer is used on each page, while the other layers are only loaded on pages that actually use them. For example: page 1: - default.css - page1.css - some-feature.css - default.js - page1.js - some-feature.jspage 2: - default.css - page2.css - default.js - page2.jspage 3: - default.css - page3.css - some-feature.css - some-other-feature.css - default.js - page3.js - some-feature.js - some-other-feature.jsreNow, besides these resources there are a lot of external resources loaded as well, used for tracking, advertising, social integration etc.I have the feeling that these resources would be served faster (both on initial and subsequent requests) if they were aggregated and minified in one single js and one single css file per page. For example codepage1.css + page1.js and on another page it would be codepage2.css + page2.js. Although this would result in less requests, it would also end up in loading some general content twice (like the original codedefault.css)What would be the preferred way of loading these resources? And do you have any test results on this?",TD-related,design,td_resolution,5,213,0.013,0.955,0.032,0.4137
32657877,Interface segregation and single responsibility principle woes,"I'm trying to follow the Interface Segregation and Single Responsibility principles however I'm getting confused as to how to bring it all together.Here I have an example of a few interfaces I have split up into smaller, more directed interfaces: public interface IDataRead{ TModel Get  TModel  (int id);}public interface IDataWrite{ void Save  TModel  (TModel model);}public interface IDataDelete{ void Delete  TModel  (int id); void Delete  TModel  (TModel model);}reI have simplified it slightly (there were some codewhere clauses that hindered readability).Currently I am using SQLite, however, the beauty of this pattern is that it will hopefully give me the opportunity to be more adaptable to change should I choose a different data storage method, like Azure for example.Now, I have an implementation for each of these interfaces, here's a simplified example of each one: public class DataDeleterSQLite : IDataDelete{ SQLiteConnection _Connection; public DataDeleterSQLite(SQLiteConnection connection) { ... } public void Delete  TModel  (TModel model) { ... }}... public class DataReaderSQLite : IDataRead{ SQLiteConnection _Connection; public DataReaderSQLite(SQLiteConnection connection) { ... } public TModel Get  TModel  (int id) { ... }}// You get the idea.reNow, I'm having a problem bringing it all together, I'm certain the general idea is to create a codeDatabase class which uses interfaces as opposed to the classes (the real implementation). So, I came up with something like this: public class Database{ IDataDelete _Deleter; ... //Injecting the interfaces to make use of Dependency Injection. public Database(IDataRead reader, IDataWrite writer, IDataDelete deleter) { ... }}reThe question here is how should I expose the codeIDataRead, codeIDataWrite, and codeIDataDelete interfaces to the client? Should I rewrite the methods to redirect to the interface? Like this: //This feels like I'm just repeating a load of work.public void Delete  TModel  (TModel model){ _Deleter.Delete  TModel  (model);}reHighlighting my comment, this looks a bit stupid, I went to a lot of trouble to separate the classes into nice, separated implementations and now I'm bring it all back together in one mega-class.I could expose the interfaces as properties, like this: public IDataDelete Deleter { get; private set; }reThis feels a little bit better, however, the client shouldn't be expected to have to go through the hassle of emdeciding/em which interface they need to use.Am I completely missing the point here? Help!",TD-related,design,antipatterns,6,371,0.045,0.854,0.101,0.9655
32962674,Dependency injection with many subclasses,"I have a class in Guice that gets ~10 argument in the constructor using dependency injection.This class has many derived classes. The constructors of all the derived classes are just passing all the argument to super.Adding a new argument to the constructor of the base class would require to add this argument to all the constructors of all the derived class.  class MyBaseClass { @Inject MyBaseClass(arg1,arg2,arg3, ..., argn) { this.arg1 = arg1 .... } } class MyDerivedClass1 extends MyBaseClass{ @Inject MyDerivedClass1(arg1,arg2,arg3, ..., argn) { super(arg1,arg2,arg3, ..., argn) } } class MyDerivedClass2 extends MyBaseClass{ @Inject MyDerivedClass2(arg1,arg2,arg3, ..., argn) { super(arg1,arg2,arg3, ..., argn) } }reOne solution I had is to wrap all the arguments in one class and inject that class to the base class and all the derived classes. This way when adding a new argument to that injected class it will be injected to all the derived classes.Something like:  class MyBaseClassSettings { @Inject MyBaseClassSettings(arg1,arg2,arg3, ..., argn) { this.arg1 = arg1 ... } } class MyBaseClass { @Inject MyBaseClass(MyBaseClassSettings settings) { this.settings = settings; } } class MyDerivedClass1 extends MyBaseClass{ @Inject MyDerivedClass1(MyBaseClassSettings settings) { super(settings) } } class MyDerivedClass2 extends MyBaseClass{ @Inject MyDerivedClass2(MyBaseClassSettings settings) { super(settings) } }reAssuming that the args are not really related to each other (one is a connection to the DB, the other is an helper that's assigning threads to tasks, another one does parts of the actual logic, and another one holds geographical configuration for the class... (just examples)) Would this solution considered to be ok?In case it is, what would be a good naming for the wrapper class?",TD-related,design,"dependency, pattern",4,263,0.061,0.864,0.075,0.1431
34385632,Denormalization influence on code,"I am a product owner. My company has a denormalized database due to technical debt. I want to try and change that at least for future development. I have a question for one of my arguments. In the database the translations for article descriptions are stored in the same table as the article. The fieldnames are desc_English, desc_Spanish etc.I want to point out that you need to compare strings in the code for matching the fieldname. Which in my imagination leads to blurry, hard to maintain and slower code. I've seen if statements of 1400 lines to match text strings on other topics. Is this a valid argument or are there simple ways to bypass this problem with enums or something?Thanks for your time.",TD-related,design,management,2,124,0.109,0.87,0.021,-0.8757
36383684,Consequences of making an Async function synchronous,"em(I apologize in advance if some partarts of the question are considered too basic. I've done my research about async-await, but for me it is not an easy concept to grasp. Either that or I haven't found the right resources.)/emI've always read (or that is what I interpreted) that the way to make an asynchornous call synchronous is to put 'await' in front of it.So the code resulting from this statement is as shown in this simple code: // CODE 1:public void async MyFunction(){ await SomeFunctionAsync();}reThat is: 1) put codeawait in front of the Async function, 2) put codeasync in your function, because now it contains an codeawait. But in my experience sometimes behaves a bit funnily. The symptoms I've noticed are that sometimes it behaves like a thread that escapes my control. So the first question would be: what happens when you call codeMyFunction() and this function contains the codeasync keyword? My understanding is that (confusingly enough) it should not be called codeMyFunctionAsync() because that is reserved for functions that return a codeTask....so the alternative that I've come up with (that seems to behave like a synchronous class consistently) is this type of code: // CODE 2:public void MyFunction(){ var task = SomeFunctionAsync(); Task.WaitAll(task);}reSecond question: could someone explain the downsides (if any) of codeCODE 2? Also, the implicit question is that I am interested in knowing about any misconception that I might have about the async-await pattern.",TD-related,design,concurrency,3,238,0.013,0.91,0.077,0.9287
37468850,How to serialize record sum data type in Aeson without tag?,"I have data type with multiple constructors, for example  data AB = A { ab :: Text , a :: Text } | B { ab :: Text , b :: Text } deriving (Generic)reRight now when I use Aeson to serialize codeA it generated to following JSON: { tag: A, ab: some text, a: some text}reI know that it's possible to use a href=https://hackage.haskell.orgackage/aeson-0.11.2.0/docs/Data-Aeson-TH.htmlt:SumEncoding rel=nofollowcodeSumEncoding/a to manipulate how constructor will be handled, but could not find what I want.Is it possible somehow to omit codetag field in serialized JSON? I need only one way serialization (no reason to keep it to deserialize it), but data type is pretty big to write how to serialize it manually.",TD-related,design,debugging,2,117,0,0.958,0.042,0.6486
37583686,Relationship between GraphQL and database when using connection and pagination?,"It is very easy to set up pagination with Relay however there's a small detail that is unclear to me.both of the relevant parts in my code are marked with comments, other code is for additional context.const postType = new GraphQLObjectType({name: 'Post',fields: () => ({id: globalIdField('Post'),title: {type: GraphQLString},}),interfaces: [nodeInterface],})const userType = new GraphQLObjectType({name: 'User',fields: () => ({id: globalIdField('User'),email: {type: GraphQLString},posts: {type: postConnection,args: connectionArgs,resolve: async (user, args) => {// getUserPosts() is in next code block -> it gets the data from db// I pass args (e.g ""first"", ""after"" etc) and user id (to get only user posts)const posts = await getUserPosts(args, user._id)return connectionFromArray(posts, args)}},}),interfaces: [nodeInterface],})const {connectionType: postConnection} = connectionDefinitions({name: 'Post', nodeType: postType})exports.getUserPosts = async (args, userId) => {try {// using MongoDB and Mongoose but question is relevant with every db// .limit() -> how many posts to returnconst posts = await Post.find({author: userId}).limit(args.first).exec()return posts} catch (err) {return err}}Cause of my confusion:If I pass the first argument and use it in db query to limit returned results, hasNextPage is always false. This is efficient but it breaks hasNextPage (hasPreviousPage if you use last)If I don't pass the first argument and don't use it in db query to limit returned results, hasNextPage is working as expected but it will return all the items I queried (could be thousands)Even if database is on same machine (which isn't the case for bigger apps), this seems very, very, very inefficient and awful. Please prove me that Im wrong!As far as I know, GraphQL doesn't have any server-side caching therefore there wouldn't be any point to return all the results (even if it did, users don't browse 100% content)What's the logic here?One solution that comes to my mind is to add +1 to first value in getUserPosts, it will retrieve one excess item and hasNextPage would probably work. But this feels like a hack and there's always excess item returned - it would grow relatively quickly if there are many connections and requests.Are we expected to hack it like that? Is it expected the return all the results?Or did I misunderstand the whole relationship between database and GrahpQL / Relay?What if I used FB DataLoader and Redis? Would that change anything about that logic?",TD-related,design,"dependency, interface",3,366,0.058,0.878,0.064,-0.4406
37770984,"Does Haskell have variables? Or, easiest way to read configuration data?","I have written my medium-sized Haskell app with hard-coded config variables (like Google OAuth ClientId   ClientSecret). Now that I'm prepping the app for a production deployment, I need to move all these config variable out of the source, to either: (a) environment variables, or (b) a plain-text config file.Here's what the code, currently, look likes: googleClientId :: T.TextgoogleClientId = redactedgoogleClientSecret :: T.TextgoogleClientSecret = redactedgenerateOAuthUserCode :: IO (OAuthCodeResponse)generateOAuthUserCode = do r   - asJSON =     post https://accounts.google.com/o/oaut/device [client_id := googleClientId, scope := (email profile :: T.Text)] return $ r ^. responseBodyreWhat's the fastest/easiest way to get codegoogleClientId and codegoogleClientSecret from an environment variable (or config file)? I tried the following: googleClientId :: T.TextgoogleClientId = undefinedgoogleClientSecret :: T.TextgoogleClientSecret = undefinedmain :: IO()main = do googleClientId   - getEnv GOOGLE_CLIENT_ID googleClientSecret   - getENV GOOGLE_CLIENT_SECRET -- Start the main app, which internally will call generateOAuthUserCode at some point.reThe expectation was that the global codegoogleClientId and codegoogleClientSecret will be re-bound, but my editor immediately started showing a warning that the binding shadows an existing binding, indicating that Haskell is creating a new binding, instead of changing the existing one.So, two questions here:olliFirst, the pragmatic one. How to solve the problem at hand, without getting into the Reader monad, which might involve changing a lot of function signatures across my app.liSecond, the one oriented to learning. Haskell has immutable emvalues/em, which is understood and appreciated. Does it even have immutable emvariable binding/em? Is it not possible to get dynamic variable bindings, like in Common Lisp?Edit: What about the following approach?what about the following approach? outerFunc :: String -   String -   IO ()outerFunc googleClientId googleClientSecret = do -- more code comes here where generateOAuthUserCode :: IO (OAuthCodeResponse) generateOAuthUserCode = do r   - asJSON =     post https://accounts.google.com/o/oaut/device [client_id := googleClientId, scope := (email profile :: T.Text)] return $ r ^. responseBody -- more functions depending upon the config variablesre",TD-related,design,"td_resolution, antipatterns",4,309,0.022,0.9,0.078,0.9486
38065534,Race Condition in React setState,"The Problem:Multiple children of a component are having events triggered near simultaneously. Each of these events are handled by codehandleChange style functions which use React's immutability helpers to merge complex objects into the state of the controlling component, via something similar to; this.setState(React.addons.update(this.state, {$merge: new_value_object}));reThis works fine when the events trigger independently, but when multiple events cause updates to the state in this way, each is individually merging from the emold/em version of the state. I.e. (psuedo-code, not intended to execute). function logState() { console.log(this.state) }logState(); // {foo: '', bar: ''}var next_value_object_A = {foo: '??'}var next_value_object_B = {bar: '!!'}this.setState(React.addons.update(this.state, {$merge: new_value_object_A}), logState); this.setState(React.addons.update(this.state, {$merge: new_value_object_B}), logState);reWould produce; {foo: '??', bar: ''}{foo: '', bar: '!!'}reTerrible solution that I don't want to use:The following seems to work, but also seems to be a emmajor/em anti-pattern; setSynchronousState: function(nextState){ this.state = React.addons.update(this.state, {$merge: nextState}); this.setState(this.state);}reThis relies on modifying the State directly. I don't see any immediate problems in running this code, and it does solve the problem at hand, but I have to imagine that I'm inheriting some massive technical debt with this solution.A slightly better version of this solution is; getInitialState: function(){ this._synchronous_state = //Something return this._synchronous_state;},_synchronous_state: {},setSynchronousState: function(nextState){ this._synchronous_state = React.addons.update(this._synchronous_state, {$merge: nextState}); this.setState(this._synchronous_state);}reWhich successfully avoids touching codethis.state directly, though now we have the issue of conflicting information being passed around the application. Each other function now needs to be congnizant of whether it is accessing codethis.state or codethis._synchronous_state.The Question:Is there a better way to solve this problem?",TD-related,design,concurrency,1,246,0.078,0.808,0.115,0.874
38580847,NodeJs : maintain a script running for a given time?,"I have quickly and poorly written a Node.Js script without any kind of error handling which does the job and eventually crashes once in a while upon encountering an error. Careless but efficient.To keep it running, I can use npm forever and have it restart forever. Fancy.Now let's say I want it to run for 12 hours (with some module / code to restart it after a crash) and then stop completely.Any simple way of achieving such a behavior ?",TD-related,design,antipatterns,5,80,0.112,0.869,0.019,-0.7264
40979856,Managing complex prefab hierarchies in Unity3D,"I asked this question in a few places, and still haven't figured it out completely yet, so maybe some smart people here will have an idea how to approach that.What's the best way of maintaining a deep nested hierarchy of prefabs in a project? Say, we have a few GUI screens, made of smaller, generic components. For the sake of simplicity, let's call the former views, and the latter - components. Views deal with semantics (e.g. inventory view, store view); components are configurable, but have no business logic attached to them whatsoever (for instance, a button cares only about its OnTap callback/event handler).Both views and components can be nested.GUI views need to be reused across multiple scenes.The main issue with this approach in Unity is the fact that any nested hierarchy, once turned into a prefab, loses references to its children prefabs, like in this (completely made up, yet still valid) example:code- storeView - UIViewHeader - UIHeaderLabel  Text   - UIList - UIListItem - UIThumbnail - UITitleLabel  Text   - UISubTitleLabel  Text   - UIPrimaryButton  Button   - ...I'd like to keep all of these, small UI* components in separate prefabs, but also keep the storeView prefab so I can easily add it to different scenes. Unfortunately, as soon, as we create the storeView prefab, all of the UI* prefab references are lost.Given that, we could try a different approach, in which instead of having a storeView prefab with content, we keep it empty and pick one of these few options:olliattach a behaviour to storeView and load child prefabs during run-timeullicons: makes designer workflow more complex, puts the complexity in the script, which might be more error prone from the dev perspective toolipros: makes it easier to reuse the storeView between scenes, component prefabs can be styled, modified globallylikeep the storeView as an empty prefab, and reassemble it in every scene that requires itullicons: components need to be wired up manually, it's still easy to save the entire storeView accidentally and lose the prefab referenceslipros: guarantees that component prefab references are maintained, allows for slight differences between views (imho that's an issue actually, since these should belong to the configuration layer)lisave the entire storeView as a prefabullicons: scales terribly, makes iterating on new features or small UX changes more time consuming (additional QA, acceptance tests, etc...)lipros: it's a quick and dirty solution that works well with small projectsliuse Prefab Evolution or similarullicons: I assume the package will be rendered obsolete by Nested Prefabs, which are on the roadmap? Requires depending on 3rd party code and might not be flexible enough (any opinions here, guys?)lipros: From many (mixed) reviews I've seen, some have been quite positive. The more complex a project gets, the less positive these reviews are, however.liwrite a bunch custom Editor scripts:ullicons: time consuming, also - seems like something that should be provided by the platform, even if it deals mainly with gameslipros: complete control over the behaviour, can be improved by developers with designers' feedback. One might argue that being disciplined about having implementation, tests and designer-friendly tools as feature requirements sounds like a good design practice (resulting in less technical debt, easier maintenance)Here's my personal, v. idealistic, unrealistic solution to that*:/Use a componentised architecture, where child prefab references are stored in complex prefabs by default. Internally think of them as UIView and subviews on mobile (Cocoa), or component classes in React or better, functional components - React/Cycle/Elm/anything that goes well with FRP (yes, I know these approaches differ in so many ways, but the key is composability, achieved either by functional composition, decorators, et cetera, et cetera...).ullicons: I assume that my difficulties here come from my lack of experience with Unity and there's a more obvious, perhaps idiomatic solution (which I'm kindly asking for:) ) lipros: makes testing and iterating on new features way easier, makes prefabs way more powerful, whilst not losing any of their benefits (please correct me if I'm wrong, I'm still getting familiar with Unity)liplease don't think I'm expecting all of that from Unity, but that's one of the possible directions even if 1% of that is true.Just to make it clear, it's not a rant regarding Unity, as a developer working previously with mobile (native) and web, I find it impressing how many of my problems it solves, and how ridiculously simple some of these solutions are.",TD-related,design,pattern,4,721,0.074,0.772,0.154,0.9968
43196496,Recurring tasks in .NET Core Console App,"The short version is - how do I (in 2017 having .NET Core 1.1 released) run recurring tasks in .NET Core console app with Microsoft's dependency injection?The long story and code snippets./The goal/I have 4 (and will have more) services each of which has say one method that performs certain isolated task and interacts with database. Specifically, I have one service that removes old data from database, one service that caches data (run through data in DB and stores aggregated results in other table), one that generates random data and so on... The idea is to run those tasks with different intervals, say every 20 seconds, or once a day. Current dirty implementation/I have a service that for each task has a codewhile(true) loop that spawns a service with DI, runs task, codeThread.Sleep(interval), checks exit condition (class-wide flag) and codecontinue/break. Most of the methods are codeasync.Current problems/First of all, I know that codewhile(true) and codeThread.Sleep(interval) is a huge hack (technical debt). Second, I have memory leak and I feel like the way I spawn/dispose service has something to do with it. Finally, the code encounters random errors and all exceptions are swallowed. I am not able to catch them in any known to me way.The solution I want/I want to achieve the goal, but if possibleulliavoid large frameworks, like Hangfire and Quartz. I feel like I do not need a fraction of what they can.likeep app a console app. Although this is a helper for ASP project, I want it to be a console app and be able to run it like codedotnet daemons.dll and it does its job indefinitely until I codeCtrl+C it. It also should not grow in memory and CPU/threads consumption. It is OK if it eats up considerable amount of RAM as long as it is a stable number.liuse Microsoft DI. That's how all my services are built.likeep my services codeasync. I may reuse them in different scenarios including unit testing.Code snippets/Example of how I run recurring task: private async Task RunCacheServiceAsync(){ // Make sure the service is set to run. _status[ServiceManagerServices.Cache] = true; _logger.LogInformation(LoggingEvents.ServiceManager.AsInt(), Cache service started.); while (true) { var metrics = await _serviceProvider .GetRequiredService  DataContext  () .Metrics .ToListAsync(); // Run the tasks var tasks = metrics .Select( (metric) =   Task.Factory.StartNew(async () =   { await _serviceProvider .GetRequiredService  ICacheService  () .CacheMetric(metric); }) ); // Wait completion of all tasks await Task.WhenAll(tasks.ToArray()); // Wait Thread.Sleep(_intervals[ServiceManagerServices.Cache]); // Check exit condition if (!_status[ServiceManagerServices.Cache]) { break; } }}reExample of the task that I need to be periodic: public async Task CleanDataPointsAsync(){ var toTimestamp = DateTime.Now - _maxAge; // remove data points of all types _context.RemoveRange( _context.NumericDataPoints.Where(dp =   dp.Timestamp    toTimestamp) ); await _context.SaveChangesAsync(); _logger.LogInformation(LoggingEvents.Clean.AsInt(), Cleaned old data.);}reThe questionlease, suggest a general approach I can take to achieve the goal considering constraints. Any feedback on posted code and reasoning is appreciated!",TD-related,design,"dependency, concurrency",4,470,0.015,0.883,0.102,0.9881
43350993,Can I mock SqlConnection.BeginTransaction c?,"I have to work with some legacy code that I cannot change. I have to write classes of that implement an interface called ""ITask"" that has a method called ""RunTask"" that accepts a concrete type called Schedule e.g;public void RunTask(Schedule thisSchedule){//I have to do stuff with thisSchedule, no I can't fix that name...}Although the legacy code does not use unit testing I would dearly like to use it for my work but the problem is ""thisSchedule"". I have made a fake version of Schedule that derives from it and am attempting to take control over how all the methods within it function (it is probably a fool's errand). So far I have been successful by exploiting the alarming number of virtual methods or by using reflection but I have hit my first show-stopperI cannot connect to the real database and I have a method that is often called;public void BeginTransaction(){MyTransaction = MyConnection.BeginTransaction(IsolationLevel.RepeatableRead);}internal SqlConnection MyConnection = new System.Data.SqlClient.SqlConnection();This throws an exception because the connection is closed, Ideally I would like to be able to set a flag stating that the method was called and then just swallow the exception but I would be happy to simply ignore the exception.Anything, no matter how nasty that will allow me to get past this method call would be an acceptable answer. It's that or defeat.I am not allowed to use paid-for services like typeMock or shims in visual studio enterprise.EDITusing System;using Microsoft.VisualStudio.TestTools.UnitTesting;using System.Data;using System.Data.SqlClient;namespace PredictionServicesTests{[TestClass]public class UnitTest1{[TestMethod]public void BeginTransaction_WhenCalled_SetsTransactionStartedToTrue(){Schedule schedule = new FakeSchedule();schedule.BeginTransaction(); //It would be enough to simply get past this line to the AssertAssert.IsTrue(((FakeSchedule)schedule).TransactionStarted); //This would be nice, but isn't vital}class Schedule{private SqlTransaction MyTransaction;internal SqlConnection MyConnection = new System.Data.SqlClient.SqlConnection();public void BeginTransaction(){MyTransaction = MyConnection.BeginTransaction(IsolationLevel.RepeatableRead);}}class FakeSchedule : Schedule{public bool TransactionStarted { get; set; }}}}Please remember I cannot change the Schedule class, if only things could be that simple!The ITask interface;interface ITask{void RunTask(Schedule thisSchedule);}",TD-related,design,"legacy, interface, mock",5,309,0.088,0.8,0.112,0.7514
44521612,Ant-Ivy post-retrieve-trigger,"I am trying to tackle some technical debt in our Ant/Ivy system and one of my current tasks is to address some post-retrieve behaviors we currently have. By default, our build system retrieves Ivy dependencies and then extracts compressed artifacts (tar, tar.bz2, gzip, zip only) to a dependency folder, so that our projects have a consistent dependency location: (project.root)/dependency/.archive   - the compressed dependency location (project.root)/dependency/extracted-foo`   - the uncompressed dependencyreThe extraction occurs in a a href=http://ant.apache.org/ivy/history/latest-milestone/settings/triggers.html rel=nofollow noreferrercodepost-retrieve-artifact trigger/a so that we get the benefit of some of the metadata (paths, names, types, etc., all prefixed with 'dep'.We currently have one property that can be set to turn off this default behavior for all the dependencies specified in an ivy.xml file. Thus, we are left with an all-or-nothing situation. If we want something in-between, we currently have to use our build.xml file and write some custom code. This is painful because the metadata is not readily available.I would like to retain the use of the all-or-nothing flag but allow projects to selectively extract items - we have several projects whose build.xml files would be greatly simplified if we could knock the extraction process down to an attribute on the artifact itself.Thus, my thinking is to use an a href=http://ant.apache.org/ivy/history/2.1.0/concept.htmlextra rel=nofollow noreferrercodeextra/a attribute on the a href=http://ant.apache.org/ivy/history/2.1.0/ivyfile/dependency-artifact.html rel=nofollow noreferrercodeartifact/a tag to inject this information and override the codeivy.retrieve.pattern to search for this attribute.Ivy.xml   ivy-module version=2.0 xmlns:e=http://ant.apache.org/ivy/extra     dependencies     dependency org=my.org name=foo rev=${foo.version} conf=${conf.archive}-  * transitive=false     artifact name=megapin type=war e:expand=expand/     /dependency     /dependencies    /ivy-module  reBuild.xmlThis is where I think I'm having trouble getting the codeexpand extra attribute to show up. Question 1: This does add the extract attribute to the artifact name at retrieve time. I can use the codecontains clause to check if that is there in the codedep.to Is there a way to retrieve the codeextra attributes (e.g., code${dep.extra.expand} ?   property name=ivy.retrieve.pattern value=${dependency.dir}/[conf]/[artifact]-[rev])(-[expand]).[ext]/    roperty     target name=ivy-post-retrieve-trigger     local name=doexpand/     condition property=doexpand     contains string=${dep.to} substring=expand casesensitive=false/     /condition     !-- this step works if the flag is set properly, so I'm leaving out these non-relevant steps--     ...extract if:isset=doexpand... /   reivysettings.xmlThis file basically has the trigger and other resolver settings.    triggers     ant-call target=ivy-post-retrieve-trigger prefix=dep event=post-retrieve-artifact/    /triggers  reQuestion 2: Any suggestions on a noexpand name? My concern with the code  contains   clause is that the expand is going to get hit all the time. I think I am close to getting this working - but the only information I get is: codeProperty doexpand has not been set and thus it is skipping the extraction step. Q3 Any tips/advice/examples on how to use the codeextra attribute on a codetrigger with Ant/Ivy?",TD-related,design,dependency,4,431,0.017,0.952,0.031,0.5903
44671237,Converting to namespaces in PHP,"I am currently working as a student on php project which has grown since the beginning of time and has about 1800 php-files.The problem is: it is completely without namespaces, or any of the PSR-4, etc. recommendations. The technical debt is  with this one :).We want to use composer (and twig and some libraries more) and having problems including this (especially composer). I think it's because of the overwrite of code__autoload() via codespl_autoload_register() in the composer-autoloader?Is there a good and fast way to start integrating namespaces without rewriting the whole project?",TD-related,design,"td_resolution, coding_standards",6,91,0.087,0.868,0.044,-0.6199
47374207,master slave exposes technical debt,"Using rails and postgresql.I wrote my app without having in mind to use a master slave configuration. Now, I've gotten master slave set up in the app and now I'm running into some technical debt. The same process in my app writes to the db and then immediately reads from the db. The read is not taking place on the read db but the data isn't there. Before, this wasn't efficient but it didn't cause any problems because both dbs were the same. Now, this is blowing up in my face. The problem for me is that its difficult to find all the places in the code where this problem exists. Can someone can please suggest to me a technique to get my tests to run in such a way where the reads and the writes use different dbs that aren't updated so that I can figure out where my issues are?Other solutions will also be welcomed!",TD-related,design,"dependency, duplication",5,157,0.09,0.845,0.064,-0.6601
48198790,"Is this circumstance, is it better to use an SSIS package, or just script out the job?","Forewarning: I wasn't entirely sure if this question should be in here (SO) or in The Workplace because it isn't so much about programming, as much as it is convincing my co-worker that I think their method is bad. But it's still programming related. So MODs, please feel free to relocate this question to 'the workplace'. Anyway...At work we have large SSAS cubes that have been split into multiple partitions. The individual who set up these partitions scheduled every partition to be processed everyday. But in hindsight because the data in these partitions is historic there is no need to process each partition everyday. Only the current partition should be processed after the latest data has been added into the cube's data source.I gave my coworker a task to automate this process. I figured all they need to do is get the current date, and then process the partition corresponding to that date range. Easily scriptable.My coworker creates an SSIS package for doing this...Cons:ullithe ssis package is hard to source controllithe ssis package will be hard to testlithe ssis package is a pain in the ass to debuglithe ssis package requires Visual Studio and Visual Studio Data Tools to even openlilastly, I feel SSIS packages lead to heavy technical-debtPros:ulliit's easier for my coworker to do (maybe)Correct me if I'm wrong on any of those but just the first reason is enough for me to scrap all of their work.Needless to say I'm extremely biased against anything done in SSIS. But processing a cube can be scripted out in codexmla (ref: a href=https://docs.microsoft.com/en-us/sql/analysis-services/instances/schedule-ssas-administrative-tasks-with-sql-server-agent rel=nofollow noreferrerlink/a). And then using a SQL Server Agent job you can schedule that script to run a specific times. The only tricky part would be changing out the empartition name/em that is processed within the script. Furthermore, the script/job can be kept in source control and then deployed to the MSSQL server whenever a change is made.Am I being too critical here? I'm just trying to keep the next developers from ripping their hair out.",TD-related,design,"management, database",4,338,0.087,0.86,0.053,-0.8753
51053820,C++ Code with conditional constexpr annotations vs. ODR and linker,"I've seen a lot of library code that uses the following pattern for C++11 / C++14 / C++17 support. I'm interested in understanding whether / why / to what extent this is okay in regards to ODR violation and linker issues.I'll refer to a snippet from Howard Hinnant's Date library which is proposed for standardization recently.a href=https://github.com/HowardHinnant/date/blob/master/include/date/date.h rel=nofollow noreferrerhttps://github.com/HowardHinnant/date/blob/master/include/date/date.h/aFirst we check things like code_MSC_VER and code__cplusplus to try to figure out what compiler and standard of C++ we are targetting (in some cases this can only be done roughly), and define some tokens to be either codeconstexpr keyword, or blank. if defined(_MSC_VER)    (!defined(__clang__) || (_MSC_VER    1910))// MSVC if _MSC_VER    1910// before VS2017 define CONSTDATA const define CONSTCD11 define CONSTCD14 define NOEXCEPT _NOEXCEPT else// VS2017 and later define CONSTDATA constexpr const define CONSTCD11 constexpr define CONSTCD14 constexpr define NOEXCEPT noexcept endifelif defined(__SUNPRO_CC)    __SUNPRO_CC   = 0x5150// Oracle Developer Studio 12.6 and earlier define CONSTDATA constexpr const define CONSTCD11 constexpr define CONSTCD14 define NOEXCEPT noexceptelif __cplusplus   = 201402// C++14 define CONSTDATA constexpr const define CONSTCD11 constexpr define CONSTCD14 constexpr define NOEXCEPT noexceptelse// C++11 define CONSTDATA constexpr const define CONSTCD11 constexpr define CONSTCD14 define NOEXCEPT noexceptendifreThen, many member functions and such are annotated using these macros: // date composition operatorsCONSTCD11 year_month operator/(const year  y, const month  m) NOEXCEPT;CONSTCD11 year_month operator/(const year  y, int m) NOEXCEPT;CONSTCD11 month_day operator/(const day  d, const month  m) NOEXCEPT;CONSTCD11 month_day operator/(const day  d, int m) NOEXCEPT;CONSTCD11 month_day operator/(const month  m, const day  d) NOEXCEPT;CONSTCD11 month_day operator/(const month  m, int d) NOEXCEPT;CONSTCD11 month_day operator/(int m, const day  d) NOEXCEPT;CONSTCD11 month_day_last operator/(const month  m, last_spec) NOEXCEPT;CONSTCD11 month_day_last operator/(int m, last_spec) NOEXCEPT;CONSTCD11 month_day_last operator/(last_spec, const month  m) NOEXCEPT;CONSTCD11 month_day_last operator/(last_spec, int m) NOEXCEPT;reNow, let's suppose I have a program that consists of some libraries compiled at C++11 standard, and some libraries compiled at C++14 standard, and many of them include this file and use these functions.This means that, functions marked codeCONSTCD14 will be marked codeconstexpr in C++14 translation units, and will not be marked codeconstexpr in C++11 compilation units. Let's assume that such functions are ODR-used in both kinds of translation units.ulliDoes this violate the ODR?liIs the ODR meaningless here because the standard document only refers to a single language standard and does not specify interoperability between standards?liDoes codeconstexpr affect the name mangling of a function?liShould I expect to find both C++11 and C++14 versions of such functions when the final program is linked, or should I expect that if they are inline, the linker will pick either the C++11 or C++14 versions and they will be the same if the only difference is a constexpr annotation?liShould I expect programs like this (depending on the same library at varying language standards, where codeconstexpr annotations may vary based on language standard used) to work, and this arrangement of compiling the same headers at different language standards as a minor technical debt, or should this situation be regarded as a bug?",TD-related,design,"framework, outdated",2,486,0.028,0.947,0.025,-0.5109
52588346,How to choose class in Vue.js depending on multiple values?,"I'd like to choose class of an element bases on codeimportance:        Importance:   span :class=importance ? (calculate class here)     /span   {{someText}}     reLet's say the class vlue should be codeimp0 ,codeimp1,codeimp2, codeimp3 or codeimp4, depending on whether codeimportance equals 0,1,2,3 or 4.You may ask why not calculate the value in a method function?The answer is: to keep the class value synced with the result of a separate method which also gets codeimportance as input parameter after the class is rendered. So wondering how can I achieve this? Update: I managed to do it with a convulted ternary conditional:  :class=importance==0 ? 'imp0': (importance==1? 'imp1': (importance==2 ? 'imp2': (importance==3 ? 'imp3': 'imp4'))) rebut wondering if there is a more clean way to do so?",TD-related,design,dependency,1,120,0.035,0.89,0.076,0.7078
53332530,How can i use dtsExec command in stored procedure to execute ssis package by passing entire configuration from a table?,"I'm assuming you are not going to upgrade to project deployment for these package and stick with package deployment.There is no codeDTEXEC command line switch that lets you define a SQL Server table to load a config from.The easiest way to use package configuration from a SQL Server table is to open the package up in SSDT, go the SSISackage Configurations and set it up. Then you don't need to pass anything on the codeDTEXEC command line at all.a href=https://docs.microsoft.com/en-us/sql/integration-servicesackage-configurations?view=sql-server-2014sql-server rel=nofollow noreferrerhttps://docs.microsoft.com/en-us/sql/integration-servicesackage-configurations?view=sql-server-2014sql-server/aIf you don't want to make a package change and you insist on passing it through codeDTEXEC then I suppose you could write a wrapper that pulls the config data out of a table and one by one applies those configs using the code/SET switch.But I really encourage and recommend you to upgrade these packages to the project deployment model. Don't waste your time with this old method. You're just introducing technical debt.You should also know that codexp_cmdshell is generally considered to be a security issue.",TD-related,design,database,2,167,0.02,0.895,0.084,0.8963
54027948,Use redux if all the data is in ajax requests or database,"I am new to react, specifically in native and I am in the dilemma if I use redux to maintain the data store if most of these will be in local database. At the moment I have thought about having a categories with a single case that would be of the SET_DATA type and every time I need to filter the data I call asynchronous actions methods that load the necessary data and perform the dispatch for the reducer. An example of my code is like this (where ALL_CATEGORY and BY_NAME_CATEGORY are queries):categoryAction: import {SET_CATEGORIES} from ../constants/actionTypes;import {ALL_CATEGORY, BY_NAME_CATEGORY} from ../constants/db/load;import {dbTransaction} from '../database/dbbase';export const setCategories = (data) =   { return { type: SET_CATEGORIES, payload: data };};export const allCaregories = () =   { return (dispatch) =   { dbTransaction(ALL_CATEGORY) .then((data)=   { dispatch(setCategories(data)); }).catch((error)=   console.log('ALL_CATEGORY ERROR')); };};export const byNameCaregories = () =   { return (dispatch) =   { dbTransaction(BY_NAME_CATEGORY) .then((data)=   { dispatch(setCategories(data)); }).catch((error)=   console.log('BY_NAME_CATEGORY_CATEGORY ERROR')); };};reAnd de categoryReducer is: import {SET_CATEGORIES} from ../constants/actionTypes;const initialState = [];const categoryReducer = (state = initialState, action) =   { switch (action.type){ case SET_CATEGORIES:{ return action.payload; } default: return state; }};export default categoryReducer;reThis works, but my query is why not choose to create methods to directly call the local database without using redux? Is there any advantage using redux or is it just to separate the application in layers?Same case if the data were 100% in a web service, what would be the advantage of using redux if the data will always be obtained from an external source to redux",TD-related,design,database,3,251,0.016,0.953,0.032,0.5483
54428531,Vuejs passing props from object into dynamic components,"I am making a dashboard app where someone can add any widget in any order to their dashboard. It's all working but Im trying to kill some technical debt and clean up. For simplicity, lets say a dashboard can have 2 widgets (Clock and Weather). These widgets need some data from the dashboard record. The widgets can be in any order on the page.Im including them like so.div class=snippet data-lang=js data-hide=false data-console=true data-babel=false&xD;div class=snippet-code&xD;pre class=snippet-code-js lang-js prettyprint-overridecodedata () {&xD; return {&xD; widget1: 'Clock',&xD; widget2: 'Weather',&xD; widgetData: {&xD; weather: {&xD; long: '12.23.34',&xD; lat: '23.34.45'&xD; },&xD; Clock: {&xD; timeFormat: '24Hour',&xD; dateFormat: 'US'&xD; }&xD; }&xD; }&xD;}re&xD;/div&xD;/div&xD;Then in the HTMLdiv class=snippet data-lang=js data-hide=false data-console=true data-babel=false&xD;div class=snippet-code&xD;pre class=snippet-code-html lang-html prettyprint-overridecode  component v-bind:is=this.widget1 :widgetData=widgetData    /component  &xD;&xD;  component v-bind:is=this.widget2 :widgetData=widgetData    /component  re&xD;/div&xD;/div&xD;Now what I want to do isdiv class=snippet data-lang=js data-hide=false data-console=true data-babel=false&xD;div class=snippet-code&xD;pre class=snippet-code-html lang-html prettyprint-overridecode  !-- if this.widget1 is Clock then :widgetData should equals widgetData.Clock --  &xD;&xD;  component v-bind:is=this.widget1 :widgetData=widgetData.this.widget1    /component  &xD;&xD;  !-- if this.widget2 is Weather then :widgetData should equals widgetData.Weather --  &xD;&xD;  component v-bind:is=this.widget2 :widgetData=widgetData.this.widget2    /component  re&xD;/div&xD;/div&xD;so that the this.widget1 will populate both the :is and drill down into the :widgetData object so Im not passing the whole object to each componentMy example take into consideration only 2 widgets but in reality a simple dashboard can have up to 9. I've tried pretty much every thing such as div class=snippet data-lang=js data-hide=false data-console=true data-babel=false&xD;div class=snippet-code&xD;pre class=snippet-code-html lang-html prettyprint-overridecode:widgetData=widgetData.{{this.widget1}}&xD;:widgetData=widgetData.${this.widget1}re&xD;/div&xD;/div&xD;etc. Any ideas?",TD-related,design,interface,3,237,0.04,0.907,0.053,0.3257
57029060,Reused cached views of child Fragments not visible when re-attaching parent Fragment,"More than looking for a solution, I would like to understand if I am getting this wrong (in which case I'll definitely need a solution), please do bear with me.em(TL;DR ? - go to Using cached views)/emProject setup/I am using Android's JetPack component, mainly codeLiveData and codeNavigation. At the time of posting, I am using the latest available and deemed stable (or so I hope) :ulliappcompat_version = '1.1.0-rc01'liconstraintlayout_version = '2.0.0-beta1' // beta 02 is VERY buggylikotlin_core_version = '1.0.2'likotlin_version = '1.3.41'lilifecycle_version = '2.2.0-alpha02'limaterial_version = '1.1.0-alpha07'linavigation_version = 2.1.0-alpha06lirecyclerview_version = '1.1.0-beta01'livectordrawable_version = '1.1.0-rc01'App Navigation/Because I have to use a codeBottomNavigationView and the default behavior (in use with codeNavigation) is to constantly re-create fragments, therefore losing any tab-specific navigation progress, I found a solution on this a href=https://issuetracker.google.com/issues/80029773 rel=nofollow noreferrerGoogle Issue (80029773)/a using codeNavigationExtensions.kt (a href=https://github.com/googlesamples/android-architecture-components/tree/master/NavigationAdvancedSample rel=nofollow noreferrerlink/a).Since I am not knowlegeable in Kotlin and without going into too many details, I recently rewrote codeNavigationExtensions.kt as I gained more knowledge how fragments work and how the manager works.I felt using this kotlin extension was a technical debt I would have to get rid off someday.Custom Navigation/But because I had to do rewrite it, I came with a simple solution: why not using nested fragments to handle nested navigation, one per tab in the codeBottomNavigationView ?That's what I did. I created a codeNestedNavigationFragment that takes two arguments:ollicodeARG_NAVIGATION_GRAPH_ID, the nested navigation graph ID to be used in association of the selected tab;licodeARG_NAVIGATION_GRAPH_ARGS, optional arguments required by the codestartDestination of said nested navigation graph.Fairly simple. One navigation graph per tab.It's layout, also very straightforward:   ?xml version=1.0 encoding=utf-8?    layout xmlns:android=http://schemas.android.com/apk/res/android xmlns:tools=http://schemas.android.com/tools xmlns:app=http://schemas.android.com/apk/res-auto     FrameLayout android:layout_width=match_parent android:layout_height=match_parent android:background=@android:color/white android:clickable=true android:focusable=true tools:contex=com.mycompany.custom.navigation.NestedNavigationFragment     fragment android:id=@+id/nav_host_fragment android:tag=@string/nested_navigation_fragment_nav_host_fragment_tag android:name=androidx.navigation.fragment.NavHostFragment android:layout_width=match_parent android:layout_height=match_parent app:defaultNavHost=true /     /FrameLayout    /layout  reAlso using the recently added codeOnBackPressedDispatcher in use with codeapp:defaultNavHost=true, I have fairly good control over the navigation.Then, as you will see, the codeNavHostFragment will use the codeNestedNavigationFragment's child FragmentManager to display a nested navigation using nested (child) fragments. That's very important to keep that in mind for what will follow.Fragment Transaction - BottomNavigationView/I said I rewrote codeNavigationExtensions.kt. No need to show code, it's as simple as following.Upon selecting a tab, a single codeFragmentTransaction will...olliattach the associated codeFragment, if it exists, using codeFragmentManagerfindFragmentByTag or create a new instance and add it to the same codebackstack (same stack string name) ;liDetaching any previously added / attached Fragment, using codeFragmentManagerfindFragmentByTag while looping through codeFragmentManagergetFragments ;That's it.Using cached views/There we go, we finally get to my point. Thank you for bearing with me so far.As I got more knowledgeable with Fragments, especially with lifecyle (livedata) and navigation, I came to release that my fragments instance are saved (a behavior I was indeed looking for).So, instead of constantly re-creating my views, I kept a reference of them in order to re-display them in any subsequent call to my nested fragment codeonCreateView method.It worked quite well for a time until I had to implement an external library that exposes a fragment with it's own custom nested navigation (emyes, it gets that complicated/em - two-levels of nested navigation !).Hence the reason I decided to rewrite my codeBottomNavigationView's navigation.And there is my problem: upon re-attaching a previously detached Fragment, the content is blank. And, after working with background colors, I came to understand that using codeattach and codedetach do work as expected and does hide / display my codeNestedNavigationFragments, but their content is nowhere to be seen.Using the debugger, I came to realize that while my codeNestedNavigationFragments codeonCreateView methods are indeed called, the same cannot be said for the previously displayed nested (child) fragment!The solution I found so far (as stated in the intro), is to not re-use the same view of my codeNestedNavigationFragments. I have to re-create the view each time.Doing so caused the nested fragments codeonCreateView to be finally called and allowed them to use cache views ! Hourah !Hourah ... ? Really ? Well I suppose not, if, in turn a nested fragment starts using a nested navigation graph. That's what I happen with that aforementionned external library ! Thankfully enough, I am work on this library so I can fix this. And that's why I came here, to see if my logic is faulted.Conclusion/That's why, upon discovering this, I came to ask your opinion about re-using cached views of fragments.It does not seem to cause any issue with fragments that are not nested, but as soon you get nested fragments, all hell breaks loose.Is that normal behavior ? Did I do something wrong ? Is there a better way to that ? Some Fragment's view are heavy, and re-creating them would be too costly...Thank you for reading and looking forward to your thoughts and answer !",TD-related,design,pattern,5,774,0.036,0.906,0.059,0.8948
57605194,Angular 7: Overwrite parent class of third party components,"I have to work with many components of a third party library that all extend an abstract class which behavior I have to alter. To make it more clear, see the following lines of sample code:pre class=lang-js prettyprint-overridecodeabstract class ThirdPartyParentClass { parentMethod() { // I need to alter this method... }}class ThirdPartyComponent1 extends ThirdPartyParentClass { componentMethod() { parentMethod(); // ...because it gets called here... }}class ThirdPartyComponent2 extends ThirdPartyParentClass { componentMethod() { parentMethod(); // ...and here... }}// ...and in a few other places.reOne obvious solution would be to extend the parent class, overwrite the respective method, and duplicate the code of all its components, making them extend my custom parent class instead. However, since the third party library is currently under heavy development, I fear that I would introduce a lot of technical debt by doing so.Is there another possibility to reach this goal?",TD-related,design,"framework, in-house",5,143,0.04,0.804,0.157,0.8977
58207580,React Native Global Object With Separate Files,"I have a new React Native app that right now has everything in one file. In the name of reducing technical debt and increased modularity, I would like to begin moving each of my several screen components to separate files. The issue is that there is some state (user data) and functions (networking, persistent data) that are global and used on various screens through out my App.Due to this, I am unable to both move my screen code to separate files and leverage global state throughout my application: var globalState = { val: Default,}class HomeScreen extends React.Component { render() { return (   View    /View   ) } someFunction = () =   { Alert.alert(globalState.val); }}class LoginScreen extends React.Component { render() { return (   View    /View   ) } someFunction = () =   { globalState.val = Something; }}reBasically, I want access to globalState from both screens but have them in a separate file. I want each screen to emshare/em the globalState object so that one screen can update information and have the other screen access that information. I would like to solve this without using any additional libraries like Redux.",TD-related,design,"td_resolution, antipatterns",2,186,0.01,0.888,0.102,0.8847
58648666,Layout Attributes within Styles,"I've been with a dilemma for a while that I don't know how to solve it properly. I want to use DRY (Don't Repeat Yourself), but not apply bad practices in styles (such as set the layout attributes inside them).This is my case...To have the text styles encapsulated in my projects, I usually use the following:I have a style called codeWrap_Content   style name=WrapContent     item name=android:layout_width  wrap_content  /item     item name=android:layout_height  wrap_content  /item    /style  reOn the one hand, I have a style called codeTv that inherits from codeWrapContent:   style name=Tv parent=WrapContent     item name=android:fontFamily  @font/font_foo  /item     item name=android:textColor  @color/color_foo  /item    /style  reAs you can see, apart, the codeTv style has a default font and text colorIf for example I want to use a font size of 15sp, I apply this style:   style name=Tv.15     item name=android:textSize  15sp  /item    /style  reAnd so on...Well, the issue is that all the codeTextView of my project I set codewrap_content both width and height.Therefore, doing things like this simplifies the layouts XML a lot and it increases the readability and grouping common behaviors.Example:   TextView style=@style/Tv.15 android:text=@string/foo/  reAnd if in any case, I want to change any attribute, I have only to overwrite it from where I call it.The dilemma is that I am mixing codetextAppearance styles with codelayout ones. I have thought about separating this ... but I have not just resolved the main issue, that I am setting layout attributes on it, something that I should know nothing more than its own view, and not its container.But what does not convince me at all is to do something like this:   style name=Tv     item name=android:fontFamily  @font/font_foo  /item     item name=android:textColor  @color/color_foo  /item    /style    style name=Tv.15     item name=android:textSize  15sp  /item    /style    TextView style=@style/Tv.15 android:layout_width=wrap_content android:layout_height=wrap_content android:text=@string/foo/  reI don't want to repeat a million times with the same attributes if these are common. Or yes I see what it brings ... technical debt. Therefore, it does not seem like a valid option.I have searched quite a lot and the truth is that I have not found anything that convinces me and I would like to reach something elegant, since it is something that I use at all times and I don't like it.Well... what do you think about it?Thank you so much!!!hrEDITED 2019-11-08I have thought a new approach adding a new layer of styles, the code@style/TextAppearance. It is like this:   style name=WrapContent     item name=android:layout_width  wrap_content  /item     item name=android:layout_height  wrap_content  /item    /style    style name=TextAppearance     item name=android:fontFamily  @font/font_foo  /item     item name=android:textColor  @color/color_foo  /item    /style    style name=TextAppearance.15     item name=android:textSize  15sp  /item    /style    style name=Tv parent=WrapContent     item name=android:textAppearance  @style/TextAppearance  /item    /style    style name=Tv.15     item name=android:textAppearance  @style/TextAppearance.15  /item    /style  reThis add a little bit of complexity to the system, but it splits the layout and the textAppearance attributes. Moreover, it allows use the codeTextAppearance style for buttons, editTexts an so on.",TD-related,design,"antipatterns, duplication",2,464,0.023,0.872,0.105,0.9888
58892455,Is it advisable to add more brokers to kafka cluster although the load is still low,"although we do not have any perfomance issues yet, and the nodes are pretty much idle, is it advisable to increase the number of kafka brokers (and zookeepers) from 3 to 5 immediately to improve cluster high availability? The intention is then of course to increase the replication factor from 3 to 5 as a default config for critical topics.",TD-related,design,duplication,1,60,0.036,0.774,0.19,0.8271
335378,How do you flag code so that you can come back later and work on it?,"In C# I use the #warning and #error directives,#warning This is dirty code...#error Fix this before everything explodes!This way, the compiler will let me know that I still have work to do. What technique do you use to mark code so you won't forget about it?",TD-related,documentation,td_documentation,2,46,0.068,0.891,0.041,-0.3099
1097090,How do I map custom types in Linq to Sql?,"I have a Customer class that contains a property, MyProperty, which is of a custom type MyCustomType. I want to persist the property value in the database as text. In the designer I've set the Type to 'MyType' and the Server Data Type to 'varchar(10)'. When I build the project I get the following error:DBML1005: Mapping between DbType 'varchar(10)' and Type 'MyType' in Column 'MyProperty' of Type 'Customer' is not supported.Now that make sense, as Linq to Sql has no way of knowing how to convert my custom type. So I'm assuming I have to implement some kind of Parse(string) and ToString() methods on MyCustomType however I can't find any documentation on this.So, how do I map custom types in Linq to Sql?",TD-related,documentation,lack_of_documentation,3,123,0.056,0.913,0.03,-0.4874
1937730,Where do you record Technical Debt in TFS?,"I'd like to find a way to record the Technical Debt we incur in TFS.I need to record each item outside of a specific iteration to ensure that it is visible and easily-reported all the time. I've considered creating a separate Area for technical debt, but am unsure how well-suited that field actually is.What are some common approaches that I might consider? Am I even barking up the right tree by trying to find a right place to put this?",TD-related,documentation,td_documentation,4,80,0.08,0.855,0.065,-0.2982
2916319,Documenting a Access Application for Developers,"I need to document a MS-Access application that was created, developed and maintained completely by a power-user over 10 years.This is an interesting situation because what they want is a manual so that a future developer can come in without prior domain knowledge and make changes to the frontend or the backend in a timely manner.There are a few questions on my mind for this little project:What is a good manual design creatingapplication? Microsoft Word doesn't quite cut it.What kind of things would you, the developer, need to know in order to make changes to thingslike forms, reports, tables or other Access objects?Anything else I missed? Any pitfalls?",TD-related,documentation,reverse_engineering,3,108,0.021,0.871,0.109,0.814
3902389,What are the crucial key items in recording technical debt?,I'm setting up a technical debt register at The Office and want to make it a fairly comprehensive tool.What are the key pieces of information that we should be recording?,TD-related,documentation,td_documentation,2,30,0.081,0.812,0.107,-0.0516
4025486,Is there any automated metrics collector for my Java project?,"I'm trying to collect software code metrics in my Java project on every cycle of continuous integration. I'm interested mostly in size-related metrics like number of classes, number of methods, function points, lines of code, etc. I would like to get a summary report with these metrics in some XML file. Later I will use it in project report, or somehow else. Is there any free open-source tool which I can integrate with Maven for this purpose?",TD-related,documentation,"metrics, automation",2,77,0,0.831,0.169,0.891
4657212,Are there any language or specification changes planned for a future release of Scala?,"Is there some kind of backlog of Scala's design issues or mistakes, which are planned/not planned to be solved in a future release?I know that there is Trac and the SID process, but in both cases you only see the changes after they have been made. Maybe I miss some existing infrastructure where language/specification changes can be collected and discussed?",TD-related,documentation,"reverse_engineering, logging",1,60,0.066,0.908,0.026,-0.3527
6488108,standard way to tag/annotate code that can be optimized?,"I am looking for a way to mark somehow the code that can be optimized, so that me or anyone who comes after me on the project, knows what and how can be optimized when performance becomes a challenge.Reason why I don't optimize at the moment is that code clarity is most of the times more important than code optimization, based on my and many other's experience (e.g. check Effective Java Programming of Joshua Block). Thus I prefer to keep code clear and easy to understand (which basically means, implement things the way anyone would do it, try no fancy stuff until really needed). Though, when performance becomes an issue, it is good to know exactly where to look into and do the optimizations at the cost of loosing from code clarity.I would like to be able to mark the places where code can be optimized and give some hints on how though.The way I was thinking to do so is by using an annotation like: public class UserDao { @Optimizable (hint=cache returned data; ) public List  User   getUsers(int userType) { //some code getting user and checking if user is of that type. }}reIs there a standard - community wide used - way to mark your code for such? Or do you have a better idea of how to do it?Using annotation makes it easy for tools to check for optimizable code and generate some reports for that. Another way might be to use a javadoc like tag, but not sure how easy a tool might be able to discover that.Thanks,Stef.ADDED:/Ok, seems that Rick's answer covers all ways of doing this in comments.How about annotations though? I find this to have some advantages as you can discover code issues/optimization options even if you don't have source code and optimize by offering a new implementation for those methods/classes and take advantage of polymorphism. Do you know if there are any standard annotations for such?",TD-related,documentation,td_documentation,3,323,0.028,0.851,0.121,0.9713
10256767,Best practice for creating a Roadmap in Jira,"We want to implement a solid road map for our product development road map. We use Jira (4.4.3) and Greenhopper for our project management and bug tracking but the Jira Roadmap feature simply shows you a list of the versions you have defined.However, we currently use our Versions for each sprint, e.g. Week 16, Week 17, etc. which contain all of the tasks/issues for that week's sprint.img src=https://i.stack.imgur.com/mSkiw.png alt=Versions ScreenshotWe currently use Components to keep track of major feature sets and to categorize (e.g. Integrate with xyz API, Migrate emails to SendGrid, Bugs: Code, or Technical Debt).img src=https://i.stack.imgur.com/Ar3yQ.png alt=Components ScreenshotThe Jira Roadmap feature shows the list of versions and the progress towards each. However, we're already using Versions for tracking our weekly sprints, and some of these roadmap features will span many releases/versions/sprints.img src=https://i.stack.imgur.com/z6m1t.png alt=Roadmap ScreenshotHow can we keep track of our complete roadmap within Jira? We would really like to see a list of our major initiatives in this roadmap instead of a list of all of our weekly sprints (e.g. Enable Selenium on CI server, Extranet MVC3 conversion, Upgrade production to R2).",TD-related,documentation,management,2,184,0,0.947,0.053,0.8334
15638937,Can I capture which templates have been used/not used during an XSL transformation?,Is it possible to log/capture which XSL templates are used and/or not used during an XML transform using codelxml? I'm looking to report on and prune unused templates to reduce technical debt.,TD-related,documentation,logging,2,32,0.075,0.925,0,-0.3612
17783036,PHP: How to document array when they are method parameters,"What's the best way to document the elements of an array when it is a parameter to a method? For example, using the PHPDoc headers, I might have something like: @param array $datareWhat this doesn't tell me is what elements are mandatory in the array, and what are optional elements. I imagine this should go in the explanation of the method. Something like: array: $data============ int $id Required name $string Required town $string Optionalre",TD-related,documentation,reverse_engineering,2,74,0,0.863,0.137,0.8591
19661992,Dojo Testing Frameworks: Dojo Objective Harness vs Intern,"I have recently adopted the Dojo Toolkit as my first JavaScript library, and am at the threshold of technical debt where I need to begin testing. I first looked into the Dojo Object Harness (DOH) unit test framework, and have learned the most by looking into the practice test cases in the dojo toolkit source:pre class=lang-none prettyprint-overridecode common/dojo/util/doh/tests common/dojo/dijit/testsrehowever, even with these examples, I cannot get around an error that I believe is a bug in the DOH source code. this is my error:pre class=lang-none prettyprint-overridecode1 tests to run in 1 groups------------------------------------------------------------GROUP tests.testSomeDialog has 1 test to run Error: test timeout in ../../../../net/js/tests/test_SomeDialog.html ERROR IN: function (){ // FIXME: implement calling into the url's groups here!! return this.d; }FAILED test: ../../../../net/js/tests/test_SomeDialog.html 15003 msWOOHOO!!------------------------------------------------------------| TEST SUMMARY:------------------------------------------------------------ 1 tests in 1 groups 1 errors 0 failuresreI have been unable to resolve this 'test timeout' error because the tutorials are [at least partially] out of date, and the community seems small. QUESTION 1: Has anyone been faced with this 'test timeout' error?I have also seen that SitePen has recently changed to a new testing framework, which would explain a lot of my problems: a href=http://www.sitepen.com/blog/2013/05/01/intern-javascript-testing/ rel=nofollowhttp://www.sitepen.com/blog/2013/05/01/intern-javascript-testing//a",TD-related,documentation,lack_of_documentation,2,193,0.105,0.881,0.013,-0.9493
24594145,Django custom User model vs. profile model,"I have a Django 1.5 app that currently has 2 different models for every user: the built-in codeUser model, and my own codeMyUser model which contains information that is also used in the authentication process.I would like to merge these two models into one, or at least reference one from the other.If I was to build a new app, I would do codeAUTH_USER_MODEL = 'myapp.MyUser', but a href=https://docs.djangoproject.com/en/1.5/topics/auth/customizing/substituting-a-custom-user-model rel=nofollowaccording to the docs/a, changing the user model makes many changes to the DB and might be difficult to migrate in an existing app.On the other end, the docs also say that a referenced profile model should only codestore non-auth related information about a site user.So my question is: in an existing app, what is the preferred way to merge my custom user model with the built-in codeUser model?",TD-related,documentation,lack_of_documentation,2,137,0.025,0.962,0.013,-0.3612
26494455,Trick sonar into ignoring commented code,"I was wondering if there is a way to trick sonar into neglecting commented out code while still keeping it inside. I would like to leave the snippet of code in there for modifications at a later date but would also like to increase compliance.I have this for examplecode// bdgItems.setGpIncrease(zero); and this is where i get compliance issuses. on the other hand regular comments like code// get data points is no cause for issue. I'd like to keep the commented code in there to pick up where I left off in the next cycle of development, but like i said, reduce the issues. Ive tried a few ways in tricking it like code// [DELETE THIS] bdgItems.setGpIncrease(zero); or code// bdgItems . setGpIncrease ( zero ); with spaces in between words but it still knows! I was wondering if some of you vets knew any tricks [i'm fairly new to sonar].Thanks in advance!",TD-related,documentation,td_documentation,2,151,0.053,0.78,0.167,0.9656
30705151,Technical debt on custom web rule in sonarqube 5.1,I am facing issue in technical debt with custom web rules. I have web plugin but no technical debt is assigned to rules. I want code or annotation through which i can assign some constat/issue value to each rule and can calculate debt from that.I used following anotations while creating web rules. @Rule@WebRule@RuleTagsreThank you in advance.,TD-related,documentation,td_documentation,4,56,0.174,0.71,0.116,-0.5719
32229487,List all Classes WITHOUT Javadocs,Is there any simple way to analyze source code to list the number of classes that don't have any javadocs? As part of a technical debt exercise I want to list all these files and share the list out among the team to have the original authors write them. Note: We are using gradle as build systemUPDATE...So empty javadocs get created by default but our devs havnt filled them in much. Id like to be able to see all classes that dont have any description in the doc at class level. I dont mind about methods too much.,TD-related,documentation,"lack_of_documentation, reverse_engineering",3,98,0.031,0.866,0.103,0.631
53191087,How can I count number of lines of actual comments?,"I have a bunch of MATLAB script/function files that I and the rest of my team need to work on. We have little to no idea what most of the files do, and little to no idea which ones belong together and which ones are separate. We do know we have a total of 36,000 lines. I'd like to know how many of those lines are comments.Easy, right? Just count how many of them start with the comment start character %.Well, no. I don't want to count blocks of code that have been commented out as comments, since they don't actually tell me anything. And I'd prefer not to count empty lines used to make one comment line a headline % %%%%%%%%% headline% %%%%%%%%relike so.So how can I get a sensible estimate of how many lines of actual informative comments I have? Is there an easy way to distinguish natural language (possibly containing code snippets) from pure code?hrYes, I know code should be self-explanatory as far as is practical, but the code we have inherited clearly is not. Yes, I know we should probably refactor this mess. The purpose of figuring out how much comments we have is to highlight the technical debt we have here, so that we can allocate resources to this refactoring.",TD-related,documentation,"metrics, dead_code",2,215,0.079,0.86,0.061,-0.4655
175437,Tool for finding package namespace conflicts in java code,We have a number of projects that use the same and/or similar package names. Many or these projects will build jar files that are used by other projects. We have found a number of foo.util foo.db and foo.exceptions where the same class names are being used leading to name space conflicts. Does anyone know of a tool that will search a set of java code bases and automatically find name space conflicts and ambiguous imports?,TD-related,infrastructure,"td_resolution, duplication, automation",2,75,0.07,0.896,0.035,-0.5574
394223,How do you decide when to upgrade a library in your project?,"I work on a project that uses multiple open source Java libraries. When upgrades to those libraries come out, we tend to follow a conservative strategy: olliif it ain't broke, don't fix itliif it doesn't have new features we want, ignore itWe follow this strategy because we usually don't have time to put in the new library and thoroughly test the overall application. (Like many software development teams we're always behind schedule on features we promised months ago.)But, I sometimes wonder if this strategy is wise given that some performance improvements and a large number of bug fixes usually come with library upgrades. (i.e. Who knows, maybe things will work better in a way we don't foresee...) What criteria do you use when you make these types of decisions in your project?",TD-related,infrastructure,"framework, outdated",2,132,0.018,0.866,0.115,0.8815
410822,What (if any) technical debt am I incurring with Ruby on Rails?,"I'm a big fan of ruby on rails, and it seems to incorporate many of the 'greatest hits' of web application programming techniques. Convention over configuration in particular is a big win to my mind.However I also have the feeling that some of the convenience I am getting is coming at the expense of a href=http://en.wikipedia.org/wiki/Technical_debt rel=nofollow noreferrertechnical debt/a that will need to be repaid down the road. It's not that I think ROR is quick and dirty, as I think it incorporates a lot of best practices and good default options in many cases. However, it seems to me that just doesn't cover some things yet (in particular there is little direct support for security in the framework, and plugins that I have seen are variable in quality).I'm not looking for religious opinions or flamewars here, but I'd be interested to know the community's opinion on what areas Rails needs to improve on, and/or things that users of Rails need to watch out for on their own because the framework won't hold their hand and guide them to do the right thing.",TD-related,infrastructure,framework,2,183,0.028,0.85,0.122,0.9309
1464958,Do you employ any tools for managing technical debt?,"The site I work with on a day-to-day basis has its share of shortcomings and we often make design decisions to get us by right now with the intention of fixing those up later.I've found that making the time to actually go back and fix them, let alone remembering what the full list of to-do items is can be challenging at best.Can you recommend any tools, resources or tricks that help you effectively manage your technical debt?",TD-related,infrastructure,td_documentation,2,77,0.071,0.789,0.14,0.7096
3115022,maven findbugs 'high water mark',"[findbugs is the example here, question is applicable to any such maven plugin]I attended a build lecture not long ago and a pattern that was talked about that I quite liked was: when adding a new tool to the chain and you start with n violations, you should keep n decreasing (a high water mark) and fail the build only when current check exceeds the last value of n.findbugs has just been introduced to our build and we were looking for a way to implement this pattern. We couldn't see any way to do it via the plugin configuration, so was curious if anyone out there could mention how they have achieved this. I guess the obvious way is to customize the plugin, but before we go charging ahead, would like to hear thoughts from others.",TD-related,infrastructure,"metrics, warnings",2,136,0.033,0.902,0.065,0.5164
5798102,CakePHP and Rails: slowly port old php functionality to new rails,"I am a rails developer working on a cakephp site. The more work they send me, the more php code I write and thus the more dependence on php we introduce. What I want is to stop writing new features in php and start writing them in rails. Our resources are limited and the existing php site is huge so a full port from cake to rails is not possible.Is there some way to write new features in a rails app while maintaining and allowing access to all the functionality of the old php (and vice-versa)? It seems I would need a route aware app to traffic requests to either php or rails, but then we run into the issue of, for example, existing user functionality written in php not being available to the rails app and vice-versa.What about something to translate ruby into php? That way I could start writing my model stuff in ruby/rails rather than php.I feel like my question is muddled by the fact I do not know how to ask the questions I want to answer, so hopefully this is understood.As always, thanks in advance!",TD-related,infrastructure,"framework, outdated, td_resolution",4,190,0.016,0.896,0.088,0.9286
10812553,Can maven-sonar-plugin make a local analysis?,"I'm configuring a multi-module maven project that force the execution of emsonar:sonar/em in the emverify/em phase. I also use the build-breaker-plugin of sonar to avoid deploying the module if some alerts are thrown by sonar.The problem with this approach is that the developer should go to the sonar server to check the alerts. This is not that bad but if several users try to analyses the same module at the same time is impossible to know if the last/current analysis have your alerts.emCONTEXT: we have a CI system that builds all the modules each hour. So sometimes this collides with some developer deploy (that force the analysis)/emIMHO, only the CI system should commit the analysis to the sonar server, because the CI have the lasted committed and deployed code. But the developer should only check locally his changes. So, why we are forcing the analysis in the developer build? To avoid deploying modules that does not respect the code quality thresholds (The build-breaker plugin of sonar helps on this).There is a way to configure the maven-sonar-plugin to do this?ullilocal analysis in the developer build. liserver analysis in the CI build",TD-related,infrastructure,"warnings, deployment",2,190,0.067,0.879,0.054,-0.4065
11333668,Extending/overriding System.Net.Mail.SmtpClient Send(message As MailMessage) method,"Scenario
Around 20 ASP.net(VB) applications share the same code framework and when deployed also shares a common web.config. Throughout the various applications we use System.Net.Mail.SmtpClient/MailMessage to send e-mails and now we would like to implement an e-mail opt-out feature for our users with a minimal amount of change to the existing code. That leaves out the simplest approach; inheriting a class from SmtpClient, say OurSmtpClient, and override the Send() method to remove all users that have opted to not receive e-mails, as that would mean we would have to change all New SmtpClient() to New OurSmtpClient() throughout the apps.
Alternatives
We've previously used tagMapping to remap tags to our in-house, derived alternatives, are there anything similar for classes so that all SmtpClient automatically becomes OurSmtpClient and thus will use the overridden Send() method?
We've also looked at Extensions, but the problem here is that we can't override existing methods, only add new ones?
Next alternative we have considered is reflection, but we couldn't get our minds around on how to actually implement it.
Events .. Oh, if there was a Sending event ...
Code (cause everyone likes it)
Here is the inherit approach, just to understand what we are looking for:
<code>
Any suggestions? How can this be done without changing the code in the existing applications and only in the shared code (lives in App_Code in the apps) or the shared web.config?",TD-related,infrastructure,"td_resolution, dependency, deployment, automation",3,223,0.015,0.92,0.066,0.8823
12308388,Why are we not using one CSS file instead of many CSS files?,"I recently stumbled across a project that has 27 different CSS files used by the same theme, and they are for specific sections in the application, rules split like this: there's a CSS file for the menubar, there's two more files for contact forms, another one does the footer, specific-page formatting, two more for galleries, so on.So I asked lead what's the reasoning for so many CSS files and if it's safe to concatenate.His reply was that all files sum 126KB, bandwidth matters and there's 500+ CSS rules, so best not concatenate to prevent selector collisions.I know that 126KB of uncompressed CSS files is an awful lot, but I also know (from the best practices guide) that all these files should be downloaded single shot, so browsers will cache one biggie instead of downloading them one by one across the browsing session.Why should I not keep myself from gluing all these files together? Is it a big deal?",TD-related,infrastructure,framework,3,158,0.019,0.884,0.097,0.9301
14337271,Is the use of Auto Mocking containers good or bad practice?,"I've recently been working on a project that has started to get fairly dependency heavy and have been exploring the idea of using an AutoMocking container to clean up my tests a bit and make them less brittle.I've heard arguments against using them by TDD/BDD purists, stating things like: It isn't immediately obvious which dependencies are required by the test subject, or you can add dependencies that you don't really need. Neither sounds like a particularly  argument against using them.From my perspective, introducing one would allow me to refactor as required, removing and introducing dependencies in line with business requirements, without constantly having to return to the tests and introduce new mocks/stubs just to get the code to compile.Is AutoMocking considered to be a good/bad practice? Are there specific situations when it should be or should not be used?",TD-related,infrastructure,"dependency, automation, mock",2,139,0.037,0.895,0.068,0.5372
22681476,Remove unused js and css files from existing visual studio project,"For a new development project, I started with MVC4 template in VS2012. I also added few more Nuget packages, js and css. Admittedly made a mistake to considered the source as starting point for new project rather than starting with empty project. I am considering cleaning up unwanted files (NuGet references, js, css, images, etc) as technical debt which I would like to tackle in current sprint.Thinking what should be the most efficient approach, I searched and found many gentlemen has already faced this situation:ollia href=https://stackoverflow.com/questions/5665979/visual-studio-remove-unused-filesFor images/alia href=https://stackoverflow.com/questions/7858325/is-there-a-plugin-for-visual-studio-to-clean-up-cssFor css/alia href=https://stackoverflow.com/questions/3157066/removing-all-unused-references-from-a-project-in-visual-studio-projectsFor references/aI have read the suggestions and it seems first they are old, second there is no single solution but we have to employ different tools for different type of file e.g. css, image.Since I am using Resharper 8.1, I checked if it comes to rescue. It provides a solution level Code Cleanup dialog box which is useful however it is mostly limited to formatting (and a bit FxCop related stuff).I am curious if someone has faced and solved this challenge recently (with some tool preferably)? Is there any new tool that can be employed for this task?If no tool available, how would you go about it?",TD-related,infrastructure,"framework, td_resolution, outdated",2,196,0.063,0.819,0.118,0.9239
25609494,use same ravenhq db with two different applications,"Ok, I know that this is not an opptimal approach, but I was thining of using the same ravenhq db with two different applications.Why I'm thinking of it, is because I have two really small web-applications that is going to use ravendb as db. And I have one registered paid ravenHq database.My two applications is not going to share any documents. And both apps data is not going to grow especially big. So my question is. Is this possible to do, or will there be any complications?//thanks",TD-related,infrastructure,"framework, database, duplication",4,87,0.027,0.955,0.018,-0.1857
28134896,eZ Publish 5.x vs Symfony2 - Which and why?,"I'm in the planning stages for a new project involving eLearning and content management/delivery.I've dabbled in Symfony2 before and I quite like it's flexibility and extensibility. But I have recently discovered EZ Publish is now running on the Symfony2 stack with version 5.My question is, what does EZ bring to the table? Will it save me time and money in realising the end product? Or will it ultimately prove to be a hindrance if it is designed to be 'easy' rather than flexible?Thoughts and suggestions are welcome :) Thanks for your time",TD-related,infrastructure,"framework, outdated",6,92,0.031,0.698,0.271,0.9816
28971227,Is anyone using Babel/6-to-5 in a production Rails app?,"The benefits of using ES6 for Rails frontend are very attractive. I've made a topic branch in our Rails app that uses a href=https://babeljs.io/ rel=nofollowbabel/a to transpile ES6 to ES5 via the asset pipeline. It works well, but as always I am weary of technical debt. Is there anyone that has good/bad reports of using such a system in production?",TD-related,infrastructure,"framework, outdated",1,60,0.094,0.792,0.114,-0.1787
29692626,why is Issues tab not present in my repo's github page?,I want to create issues in my repo to create technical debts present in the repo. But I am not able to see the issues tab. For other repos the issues tab present below the pulkl request tab. How can I enable the issues tab for my repo ?,TD-related,infrastructure,td_documentation,2,49,0,0.908,0.092,0.3071
30942032,Checking doubles for equality and Sonar issues,"We are checking the quality of our code using Sonar, and Sonar found code which compares a float or double for equality with a constant value like this: if (x == 0.0) {  }reThe value the variable is compared with (code0.0) is constant, and in case the variable can be equal to this value, the value also isn't computed but only set via a constant. This is typically used to check whether a variable hasn't been set yet or is still at initialization state, e. g. code-1.0 might be used for not yet set in cases where the value can only be positive.So, since these values are never emcomputed/em but only emset from constants/em, the Sonar complaint is not useful for us. Only for computed values (or fractured ones which are not precisely representable as floats or doubles) a complaint about a test for equality makes sense.The question I have now is: What is the best practice to change the code so that Sonar does not complain about this anymore?I see several options:olliExtract the test-for-unset into a special test function; but that would only reduce the number of occurrences (to 1), not the issue in general.liMark the code for Sonar to ignore it with a special decorator. But we would like to avoid using such decorators.liHide the comparison behind sth like code(0.0   = x    x   = 0.0) or code!(x != 0.0) (which currently seems to be okay for Sonar).liCalling codeDouble.doubleToRawLongBits() to compare the bits of the values like this: code(Double.doubleToRawLongBits(x) != Double.doubleToRawLongBits(0.0)).liOther ideas?None of these solutions I really like and I thought, maybe, there is a better one out there I can't think of.",TD-related,infrastructure,metrics,2,275,0.048,0.75,0.202,0.9923
31039136,Are there any tools like landscape.io which work with Mercurial/BitBucket?,I want to use a tool like landscape.io to keep track of technical debt that people might be accidentially introducing into an open-source project. Unfortuanately that tool only seems to work with GitHub.Is there a similar tool that offers static code analysis as a hosted service that's also compatible with BitBucket and Mercurial?I'm certain that I could get most of this using a hand-rolled linter running under Jenkins but I'd rather not have to maintain this. It's a nice thing to have not really a core part of the project I want to spend too much time on. In other words I want a ready to roll solution.My project is in Python 3.x,TD-related,infrastructure,td_documentation,1,113,0.016,0.854,0.13,0.8608
32798162,Logging in Java in 2015 - what does a properly configured environment look like?,"My Eclipse/Tomcat project is a tangled mess of slf4j, log4j, JULI, logback, etc. As a result my console has an abundance of useless messages from various libraries and it is hard to get the logging output I want from my own code. I've resorted to using System.out to get stuff done.The server deployment environment is in similar bad shape.What I'm wondering is, where can I find a reference implementation, or checklist, that outlines what a correct configuration of all these logging frameworks is supposed to look like?",TD-related,infrastructure,"logging, deployment",3,87,0.112,0.846,0.042,-0.7506
33139575,Integrate SonarQube C ruleset to TeamCity for Code Analysis Build Break,"Is there someone know here How to integrate SonarQube C# Ruleset in TeamCity for Code Inspection instead using the Resharper(Inspection.NET)?We don't want to go to sonar site(localhost:9000) to check the C# code issue instead we want to automate this in team city with build break if there is validated rules in C# sonar.Currently i used FXcop for my Code Inspection but the ruleset from the fxcop is not complete vs from the sonar ruleset for C#, Fxcop contain only the Microsoft Ruleset but not the rulset like in this rule list (bug,pitfall,cwe,convention etc...)Please help.Regards",TD-related,infrastructure,"td_documentation, automation",5,94,0.047,0.876,0.077,0.6203
33580821,SonarQube shows technical debt added and removed but no changes to issues,"Using SonarQube 5.1.2 we started with a fresh project, ran analysis twice with no source code changes between the first and second analysis. Then we selected 'changes since previous analysis'. The Issues and Technical debt widget shows Added: 24min and Removed: 24min but no actual issues (the issue counts against each severity are zero).Drilling down on the added debt and opening a class shows 5 classes with debt that makes up the 24min but opening the source of a class only shows pre-existing issues. For instance, one class shows 4 minutes of added debt but opening the source shows only 2 pre-existing issues which add up to 20 minutes (8 minutes and 12 minutes). The supposedly changed files do have a blue bar on the left which spans the whole file and when you hover over it reads: 'New since previous analysis'.In short, SonarQube is reporting technical debt changes that don't correlate to issues added or removed. Is this a bug with the widget?",TD-related,infrastructure,td_documentation,1,164,0.111,0.851,0.038,-0.891
34719472,Specifing technical debt for custom FxCop rule,"Just as simple as the title expects:How can I specify the technical debt for a custom FxCop rule. There is no field to enter this, neither in the dialog while creating a new custom rule nor in the dialog for editing it.",TD-related,infrastructure,"metrics, td_documentation, logging",2,42,0.11,0.839,0.051,-0.3612
39430597,Migrating Django 1.3 to 1.10 Unwanted suffix added to admin urls,"When I use any link on the admin page a ""change/"" suffix is added to my url's and they are not found. Things start out OK, but after jquery is loaded RelatedObjectLookups is loaded and subsequent urls have a ""/change"" appended. I've been looking at this problem for a few hours and have no idea where to go.This is what my test server output looks like:September 10, 2016 - 16:21:49Django version 1.10.1, using settings 'adsync.settings'Starting development server at http://192.168.56.101:8080/Quit the server with CONTROL-C.[10/Sep/2016 16:21:55] ""GET /admin/ HTTP/1.1"" 200 5558[10/Sep/2016 16:22:05] ""GET /admin/auth/user/ HTTP/1.1"" 200 6876[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/css/base.css/ HTTP/1.1"" 302 0[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/css/changelists.css/ HTTP/1.1"" 302 0[10/Sep/2016 16:22:05] ""GET /admin/jsi18n/ HTTP/1.1"" 200 3217[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/js/core.js/ HTTP/1.1"" 302 0[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/js/vendor/jquery/jquery.js/ HTTP/1.1"" 302 0[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/js/jquery.init.js/ HTTP/1.1"" 302 0[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/js/admin/RelatedObjectLookups.js/ HTTP/1.1"" 302 0WARNING Not Found: /admin/auth/user/static/admin/css/base.css/change/Not Found: /admin/auth/user/static/admin/css/base.css/change/[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/css/base.css/change/ HTTP/1.1"" 404 1870WARNING Not Found: /admin/auth/user/static/admin/css/changelists.css/change/Not Found: /admin/auth/user/static/admin/css/changelists.css/change/[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/css/changelists.css/change/ HTTP/1.1"" 404 1891[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/js/actions.js/ HTTP/1.1"" 302 0[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/js/urlify.js/ HTTP/1.1"" 302 0[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/js/prepopulate.js/ HTTP/1.1"" 302 0[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/js/vendor/xregexp/xregexp.js/ HTTP/1.1"" 302 0WARNING Not Found: /admin/auth/user/static/admin/js/core.js/change/Not Found: /admin/auth/user/static/admin/js/core.js/change/[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/js/core.js/change/ HTTP/1.1"" 404 1864WARNING Not Found: /admin/auth/user/static/admin/js/vendor/jquery/jquery.js/change/Not Found: /admin/auth/user/static/admin/js/vendor/jquery/jquery.js/change/[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/js/vendor/jquery/jquery.js/change/ HTTP/1.1"" 404 1912WARNING Not Found: /admin/auth/user/static/admin/js/jquery.init.js/change/Not Found: /admin/auth/user/static/admin/js/jquery.init.js/change/[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/js/jquery.init.js/change/ HTTP/1.1"" 404 1885WARNING Not Found: /admin/auth/user/static/admin/js/admin/RelatedObjectLookups.js/change/Not Found: /admin/auth/user/static/admin/js/admin/RelatedObjectLookups.js/change/[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/js/admin/RelatedObjectLookups.js/change/ HTTP/1.1"" 404 1930WARNING Not Found: /admin/auth/user/static/admin/js/actions.js/change/Not Found: /admin/auth/user/static/admin/js/actions.js/change/[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/js/actions.js/change/ HTTP/1.1"" 404 1873WARNING Not Found: /admin/auth/user/static/admin/js/urlify.js/change/Not Found: /admin/auth/user/static/admin/js/urlify.js/change/[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/js/urlify.js/change/ HTTP/1.1"" 404 1870WARNING Not Found: /admin/auth/user/static/admin/js/prepopulate.js/change/Not Found: /admin/auth/user/static/admin/js/prepopulate.js/change/[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/js/prepopulate.js/change/ HTTP/1.1"" 404 1885WARNING Not Found: /admin/auth/user/static/admin/js/vendor/xregexp/xregexp.js/change/Not Found: /admin/auth/user/static/admin/js/vendor/xregexp/xregexp.js/change/[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/js/vendor/xregexp/xregexp.js/change/ HTTP/1.1"" 404 1918[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/img/search.svg/ HTTP/1.1"" 302 0[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/img/icon-yes.svg/ HTTP/1.1"" 302 0WARNING Not Found: /admin/auth/user/static/admin/img/search.svg/change/Not Found: /admin/auth/user/static/admin/img/search.svg/change/[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/img/search.svg/change/ HTTP/1.1"" 404 1876WARNING Not Found: /admin/auth/user/static/admin/img/icon-yes.svg/change/Not Found: /admin/auth/user/static/admin/img/icon-yes.svg/change/[10/Sep/2016 16:22:05] ""GET /admin/auth/user/static/admin/img/icon-yes.svg/change/ HTTP/1.1"" 404 1882You can see the early on ""../base.css"" is loaded, but a subsequent url searches for ""../base.css/change"", and it is not found.I'm relatively new to Django and javascript. I am good with Google searches and having no luck in finding relevant information.Any help or suggestions would be appreciated.",TD-related,infrastructure,"framework, debugging",6,351,0.133,0.82,0.047,-0.9918
39449130,SonarLint displaying issues only in files changes,"I'm looking to improve the code base of the department I'm working and I want to do it in a incremental way.My idea is that I only want to be running SonarQube and SonarLint in the files that the developer is changing.In sonarqube we have:a href=https://blogs.msdn.microsoft.com/visualstudioalm/2016/06/02/sonarqube-code-analysis-issues-integration-into-pull-requests/ rel=nofollowhttps://blogs.msdn.microsoft.com/visualstudioalm/2016/06/02/sonarqube-code-analysis-issues-integration-into-pull-requests//aIs there a way to do the same in SonarLint?With a code base with a big technical debt, if SonarLint is going to list the issues of all the current files and I only want to list the issues of the files that the user has changed.Let me know your thoughts or any other way to achieve something similar",TD-related,infrastructure,"metrics, logging",4,105,0.024,0.909,0.066,0.3182
44012776,Tracking method bloat over time with nDepend,"We are looking at using nDepend to start tracking some of our technical debt, particularly around hard to maintain methods and cyclomatic complexity. I believe this is possibly by taking a baseline report and then running a new analysis to provide the delta. Below is a very basic Powershell I've put together that does this.  $nDepend = C:\_DEVELOPMENT\nDepend\NDepend.Console.exe$targetFile = C:\_DEVELOPMENT\AssemblyToTest\CodeChallenge.Domain.ndproj$projectFolder = Split-Path -Path $targetFile$outputFolder = nDepend.Reports$previous = Clear-Host See if we already have a .ndar file in the output folder, if we do back it up so we can do a comparisonif (Test-Path $projectFolder\$outputFolder\*.ndar){ Write-Output Backing up previous NDAR report Copy-Item $projectFolder\$outputFolder\*.ndar $projectFolder\previous.ndar $previous = .\previous.ndar}The output path appears to be relative to the .ndproj file  $nDepend $targetFile /Silent /OutDir .\$outputFolder /AnalysisResultToCompareWith .\previous.ndarreHere is the rule I've configured in nDepend: - failif count    1 bobsfrom m in Methodswhere m.NbLinesOfCode    10where m.WasChanged()select new { m, m.NbLinesOfCode }reThe goal of this is not to break the build if we have methods over 10 lines, but rather to break the build if somebody edits an existing method that is too big and does not improve it (or make it worse). However the where m.WasChanged() part of the rule isn't being triggered regardless of how much code I add. If I comment it out it will alert me that there are plenty of methods that exceed 10 lines, but I only want to know about recently changed ones.Am I using the rule wrong? Or perhaps my powershell is incorrectly using the /AnalysisResultToCompareWith parameter?",TD-related,infrastructure,"metrics, logging",5,249,0.045,0.933,0.022,-0.7512
44516680,Re-including a module on-the-fly,"I am currently working on technical debt identified by SonarQube for a Node.js application. My application allows on-the-fly switching between a live and mock datasource. To achieve this I destroy the previous require from cache and re-require it. When running SonarQube it does not like require statements. It does suggest import statements. However that may not be suitable in this case. Simplified version of existing code: var config = require('../config');var polService = require(config.polService);var root = require('../root');function doingStuff(liveOrMock) { setEnvironment(liveOrMock); delete require.cache[require.resolve(root.path + /config)]; config = require('../config'); polService = require(config.polService);}reThe codesetEnvironment function sets codeprocess.env.NODE_ENV = liveOrMock, which is used in codeconfig.js. We export the codeconfig module using codemodule.exports = localOptions[process.env.NODE_ENV]; This code picks a single key-pair from a JSON. The value that comes back is used to choose which module is being used for a restService.Being able to change what module is being used is for codepolService is the purpose of the code.",TD-related,infrastructure,"metrics, logging, mock",3,152,0.08,0.904,0.017,-0.8456
45777339,Deploy python deb test project using make-deb and dh-virtualenv,"In development I use Anaconda to manage environments. I have not yet developed a python project for production. In this context I have two related questions.First, which solution incurs lower technical debt: A. Install Anaconda on production servers; or B. deploy python as deb packages?Second, what is the simplest structure of python project folders and files to test the functionality of make-deb and dh-virtualenv as described in the last section of Nylas blog article? Nylas blog (How We Deploy Python Code: Building, packaging   deploying Python using versioned artifacts in Debian packages)a href=https://www.nylas.com/blogackaging-deploying-python/ rel=nofollow noreferrerhttps://www.nylas.com/blogackaging-deploying-python//aMake-deb:a href=https://github.com/nylas/make-deb rel=nofollow noreferrerhttps://github.com/nylas/make-deb/adh-virtualenv:a href=https://github.com/spotify/dh-virtualenv rel=nofollow noreferrerhttps://github.com/spotify/dh-virtualenv/aFor a test I would only add Requests package to a standard Python 2.7 environment and write one module to download and save a small csv file. Then I would like to test make-deb and dh-virtualenv to deploy to a cloud server or Raspberry pi server. Then I want to run code to verify the download app works as expected on the server. Then I want to further develop the application and test deployment tools using make-deb and dh-virtualenv to see if I can more effectively manage development for production.Edit: Based on some further research so far it appears Anaconda cannot be made to export a requirements.txt file. It appears the options are to use virtualenv, make-deb, and dh-virtualenv; or to use Anaconda and Miniconda roughly as described in the following blog articles:a href=https://tdhopper.com/blog/2015/Nov/24/my-python-environment-workflow-with-conda/ rel=nofollow noreferrerhttps://tdhopper.com/blog/2015/Nov/24/my-python-environment-workflow-with-conda//aa href=https://www.thoughtvector.io/blog/deployment-with-anaconda/ rel=nofollow noreferrerhttps://www.thoughtvector.io/blog/deployment-with-anaconda//a",TD-related,infrastructure,deployment,2,238,0.02,0.92,0.06,0.8153
53615894,Visual Studio 2017 Code Analysis - What options are there?,"After discovering the Run code analysis on solution option in visual studio 2017 I began looking for other similar tools, I found a href=https://stackoverflow.com/questions/580168/visual-studio-code-analysis-vs-stylecop-fxcopVisual Studio Code Analysis vs StyleCop + FxCop/a From here I've found out about StyleCop and then also found Web Accessibility Checker within NuGet by manualy searching through.So this leads me to my question, Focusing on C, .Net, HTML, CSS, JS and international web standards.What other tools can be used to provide this kind of analysis / hinting / refactor suggestions or are there any extended rulesets?",TD-related,infrastructure,"metrics, logging",2,90,0,0.973,0.027,0.3182
55252183,Ionic Framework and AngularJS,"Let me preface these questions with the statement, I'm not a web developer. Most of my work has been done in Python for data analytics. Cutting right to it, I'm in a scenario where I'm learning web technologies such as HTML/CSS, JS, Ionic, and AngularJS in order to debug a pretty horrendous mobile app written by previous developers.The app was built in the Ionic framework using Cordova plugins and AngularJS (yes, not the new Angular 6-7). My questions are:olliI have the newest version of Ionic installed on my computer that supports Angular 6-7. Will I have to roll it back to a previous version for it to support AngularJS?liCan my app encounter some serious problems in the next year (or less) if it is not rewritten using the new Angular?",TD-related,infrastructure,"framework, outdated",1,130,0.071,0.867,0.062,0.1179
20788,What tools do you use for static code analysis?,"This question on Cyclomatic Complexity made me think more about static code analysis. Analyzing code complexity and consistency is occasionally useful, and I'd like to start doing it more. What tools do you recommend (per language) for such analysis? Wikipedia has a large list of tools, but which ones have people tried before?Edit: As David points out, this is not a completely unasked question when it comes to C/UNIX based tools.",Not-TD-related,Other,,,,0,0.922,0.078,0.5666
38635,What static analysis tools are available for C#?,"What tools are there available for static analysis against C# code? I know about FxCop and StyleCop. Are there others? I've run across NStatic before but it's been in development for what seems like forever - it's looking pretty slick from what little I've seen of it, so it would be nice if it would ever see the light of day.Along these same lines (this is primarily my interest for static analysis), tools for testing code for multithreading issues (deadlocks, race conditions, etc.) also seem a bit scarce. Typemock Racer just popped up so I'll be looking at that. Anything beyond this?Real-life opinions about tools you've used are appreciated.",Not-TD-related,Other,,,,0,0.833,0.167,0.9692
60394,Calculate code metrics,"Are there any tools available that will calculate code metrics (for example number of code lines, cyclomatic complexity, coupling, cohesion) for your project and over time produce a graph showing the trends?",Not-TD-related,Other,,,,0,0.958,0.042,0.0772
85114,How do you structure a development sprint?,"So I have a backlog of features and we are about to get started on a sizable project. I am working on defining the structure of our sprints and I'm interested in the communities feedback.What I'm thinking is:ulliOne day sprint planningulliFill the backlog and figure out what each dev will go after this sprintliThree weeks of developmentulliGO! GO! GO!liDaily stand up meetingulliCheck to see if anyone needs help or feels off trackliTwo days of sprint reviewullicode reviews happen here, stakeholder presentationsliOne day sprint retrospectiveulliwhat did we get done in the last sprint? how can we do better next time?Sprints should always end on a Tuesday (to avoid too much weekend stress).Anything else? There is obviously more to agile than this. I want to provide the team with a simple outline of how we are going to operate as we get this project started.",Not-TD-related,Other,,,,0.015,0.908,0.077,0.8356
104196,Benefits of static code analysis,What are the benefits of doing static code analysis on your source code? I was playing around with FxCop and I was wondering if there any benefits beyond making sure you are following the coding standards.,Not-TD-related,Other,,,,0,0.763,0.237,0.8074
169765,How do you get non-technical folks to appreciate a non-UI problem?,"Suppose you're working on an enterprise project in which you have to get management signoff in order for you to develop a new feature set. Usually your management has no problem signing off on some bright shiny new UI feature. Unfortunately they have a hard time appreciating some behind-the-scenes issues that are crucial to the application's well-being such as transactions, data integrity, workflow routing, configurability, security, etc. Since they're non-technical and these issues are not immediately visible, it's not obvious to them that this is crucial.How have you convinced them that these infrastructural issues have to be dealt with and that it is important to their business process?",Not-TD-related,Other,,,,0.073,0.8,0.128,0.765
212850,Scrum/Agile: How do you plan in internal improvements?,"I have now worked on two different teams that use the Agile/Scrum approach in the last two years and both teams were eager to improve the way they approach software development. In the first team, we could easily convince our product owner to get time for internal things like improving the build system, setting up better integration tests, having a better release strategy etc. Right now the PO is also willing to give us time, but he is more pushing back, which is reasonable as he also must get his things done. Anyway my question is now, how do other teams handle this? Do you create an improvement story and put it on the table during planning or do you keep a bucket of time around for such things? How difficult is it in your experience to convince the product owner to do get time for improving? After all these kind of improvements will benefit the team, but not directly or immediately the prodcut owner/business.",Not-TD-related,Other,,,,0.032,0.784,0.184,0.9733
315000,How to study design patterns?,"I have read around 4-5 books on design patterns, but still I don't feel I have come closer to intermediate level in design patterns?How should I go studying design patterns?Is there any good book for design patterns?I know this will come only with experience but there must be some way to master these?",Not-TD-related,Other,,,,0,0.909,0.091,0.7013
327199,What will we do after Access?,Microsoft seems hell-bent on deprecating the swiss-army-knife of database tools. What else comes close for facading/file-swapping/cloning/name-your-acronym-connecting arbitrary database servers/spreadsheets/CSV's/flatfiles?What weird kinds of functionality have you squeezed out of Access? And what else is there to take its place?,Not-TD-related,Other,,,,0.057,0.943,0,-0.3049
410719,Why does NotImplementedException exist?,"This really, really urks me, so I hope that someone can give me a reasonable justification for why things are as they are.NotImplementedException. You are pulling my leg, right?No, I'm not going to take the cheap stab at this by saying, hang on, the method is implemented - it throws a NotImplementedException. Yes, that's right, you have to implement the method to throw a NotImplementedException (unlike a pure virtual function call in C++ - now that makes sense!). While that's pretty damn funny, there is a more serious problem in my mind.I just wonder, in the presence of the NotImplementedException, how can anyone do anything with .Net? Are you expected to wrap every abstract method call with a try catch block to guard against methods that might not be implemented? If you catch such an exception, what the heck are you supposed to do with it??I see no way to test if a method is actually implemented without calling it. Since calling it may have side effects, I can't do all my checks up-front and then run my algorithm. I have to run my algorithm, catch NotImplementedExceptions and the some how roll back my application to some sane state.It's crazy. Mad. Insane. So the question is: Why does the NotImplementedException exist?As a preemptive strike, I do not want anyone to respond with, because designers need to put this in the auto-generated code. This is horrid. I would rather the auto-generated code not compile until you supply an implementation. For example, the auto generated implementation could be throw NotImplementedException; where the NotImplementedException is not defined!Has anyone ever caught and handled a NotImplementedException? Have you ever left a NotImplementedException in your code? If so, did this represent a time bomb (ie, you accidentally left it there), or a design flaw (the method should not be implemented and will never be called)?I'm very suspicious of the NotSupportedException also... Not supported? What the? If it's not supported, why is it part of your interface? Can anyone at Microsoft spell improper inheritance? But I might start another question for that if I don't get too abuse for this one. Additional info:a href=http://www.lostechies.com/blogs/jimmy_bogard/archive/2008/10/12/notimplementedexception-and-the-interface-segregation-principle.aspx rel=noreferrerThis/a is an interesting read on the subject.There seems to be a  agreement with a href=http://blogs.msdn.com/brada/archive/2004/07/29/201354.aspx rel=noreferrerBrad Abrams/a that NotImplementedException is for functionality that is just not yet implemented, but really should (and will be). Something like what you might emstart/em with when you are building a class, get all the methods there throwing NotImplementedException, then flush them out with real codeComments from a href=http://blogs.msdn.com/jaredpar/archive/2008/12/12/notimplementedexception-vs-notsupportedexception.aspx rel=noreferrerJared Parsons/a are very weak and should probably be ignored: NotImplementedException: Throw this exception when a type does not implement a method for any other reason.The a href=http://msdn.microsoft.com/en-usbrary/system.notimplementedexception.aspx rel=noreferrerMSDN/a is even weaker on the subject, merely stating that, The exception that is thrown when a requested method or operation is not implemented.",Not-TD-related,Other,,,,0.088,0.862,0.049,-0.8663
437190,How to cope with slow feedback when pair programming?,"I work in an Extreme Programming team, pair programming every day. Recently more and more often I get to do stuff that gives slow feedback, on order of 3 minutes. For example: change some thing, recompile, run and see wheather the performance is improved. I see it coroding the quality of pair programming, and I think it affects pairs more that solo programmers. If I am alone I can do sth else, but what if I am pair programming? How would you deal with it?",Not-TD-related,Other,,,,0.019,0.95,0.031,0.2287
506545,What are best practices for transferring knowledge?,"If you end up in a situation that main developer of project you are working on decides to leave.He has all the knowledge, been in project from it's very beginning.If you are lucky you might get something like two month of him still on a project,if not it might be just a month leave notice.What are best practices for knowledge drain, transfer?What has proved been usefully for you in past? Pairing, presentations, documentation?",Not-TD-related,Other,,,,0.015,0.822,0.162,0.9125
592354,What failed conversion/rewrite of software have you done?,What conversion/rewrite have you been involved with that failed? What where the languages and framework involved in the process? How large was the software in question? Finally what is the top one or two thing you learned from being involved with the process.This is related to this a href=https://stackoverflow.com/questions/592350/what-successful-conversion-rewrite-of-sofware-have-you-donequestion/a.,Not-TD-related,Other,,,,0.074,0.891,0.035,-0.466
608748,How to avoid the 80/20 rule in software development,"It seems that no matter what my project is, I get through 80% of the work fairly fast. Users and management get excited thinking things are way ahead of schedule, but the pesky 20% of work remaining seems to take 4 times as long as the previous 80%. When we have our regular check ins or stand ups on the project, I feel like a broken record saying ""yes things have gone OK so far, but there is still quite a bit left to do...""For the most part, my estimates are fairly accurate, but I am human. What is the best approach for convincing users that the last 20% of work really does take 80% of the time? It seems like more and more users and management believe IT is easy and magic happens at the snap of some fingers...In general, we do track tasks at what I believe to be a fairly low level. Not necessarily at a create label or textbox, but we are pretty detailed... We also track our estimate to completion on all tasks, which I feel is a more important number than the original estimate when you're in the middle of the project.I think it comes down to the perception of the users and management. Even though they may know the estimate to completion, they still get wrapped up in the emotions and perceptions on what they are seeing and the estimate numbers take a back seat. This is what I'm trying to figure out how to contain or manage expectations to.EDITTurning into a community wiki as this is rather subjective. Should have been that way from the beginning.",Not-TD-related,Other,,,,0.045,0.815,0.14,0.9822
616911,Scrum-board / Task Board and Color Coding,What would you recommend as far as a good color-coding for use on a Storyboard? Is this a good pattern from your experience?bra href=http://maxheapsize.com/static/ScrumBoardCheatSheet.pdf rel=nofollow noreferrerhttp://maxheapsize.com/static/ScrumBoardCheatSheet.pdf/abrWhat is the most standard color-coding?,Not-TD-related,Other,,,,0,0.739,0.261,0.8334
710122,We made it reliable. What's next? Usability?,"I'm working in a small development group. We are building and improving our product.Half a year ago we couldn't think about higher characteristics, such as usability, because we had so many problems with our product. Many bugs, high technical debt, low performance and other problems kept us from being able to focus on usability.With time we've improved our process substantially. What we've done:ulliReal Agile iterationsliContinuous integrationliTesting(unit-tests, functional Smoke tests, performance)liCode quality is 'good'liPainless deployment processSo we are now producing stable, reliable releases. The following  e (paraphrased) describes our current situation:block e first - make it work; after that, make it reliable; after that, make it usable/block eWe are geeks, so we can't 'make' a great UI by ourselves.So what should we do? What direction can you recommend?Maybe we should hire Usability experts part-time or full-time?How can we explain the importance of Usability to our stakeholders?How do we convince them that this is useful?",Not-TD-related,Other,,,,0.091,0.81,0.099,0.298
715126,How to get users/clients implicated in iterative development?,"What do you do when your (external) client's users don't have the time/will to actively participate in iterative development? How do you ""force"" them to get implicated? Remember that often they must do this while still completing all their regular duties and that the IT department, who sponsors the software project, doesn't have the power to free some key users of their regular work.",Not-TD-related,Other,,,,0,0.912,0.088,0.7149
726565,Tracking and prediciting quality level,"What techniques do people recommend to track the quality level of a new program? Are their ways to take a poorly defined term like quality level, quanitify it and then make predictions? Currently I use bug rates and S curves but I am looking for other ways to evaluate, estimate and predict quality levels.",Not-TD-related,Other,,,,0,0.924,0.076,0.4329
738331,Does the Scrum process ultimately divest team members from their respective skills?,"My organization has been experimenting with the introduction of more ""Agile"" methods. We've been trying the Scrum approach for a short while, and most of the team has, more or less, adapted to it. I like it as a whole, but I'm concerned about one potentially severe impact of the methodology: as teams are consistently focused on features and backlog items, and testers are more integrated with the overall development process, it seems like skill sets are becoming blurred, and people are sensing less respect for their individual abilities.Some of our developers are excellent at server-side technologies and optimization of heavy-weight data provisioning. Others have invested a large amount of their careers learning GUI technologies and have developed a fundamental understanding of users and usability in an application. Neither skill set is better than the other, but they are certainly different.Is this an inevitable result of the Scrum process? Since everyone on the team (as I understand it) contributes to satisfying the next feature/requirement, backlog item, or testing goal at hand, the underlying philosophy seems to be ""anyone can do it."" This is, in my experience, simply not true. Most engineers (developers, testers, etc.) have a particular skill set they have honed over the years, and the Scrum methodology, in my mind, tends to devalue those very abilities they were previously respected for.Here's an example for clarification:If a sudden change of technology occurs on the server-side data provisioning, and every item on the to-do list for the sprint is based on this new change, the GUI developers (who likely haven't had time to become acclimated with the new technology) might not be able to contribute to the sprint. At the very least, they will need to invest time to get ramped up, and then their code will be suspect because of their lack of experience.I understand the need for rapid development to discourage ""role silos"" but doesn't this discount one fundamental reality: people develop skills in accordance to necessity, their interests, or their experiences. People seem to be less motivated when they perceive their position is one of ""plug-ability"" (e.g. we can ""plug"" anyone in to do this particular task). How does Scrum address this? If it doesn't, has anyone addressed this when adopting the Scrum methodology?",Not-TD-related,Other,,,,0.038,0.843,0.119,0.9879
750464,Comments in source code,"How to keep the source code well documented/commented? Is there a tool to generate a skeleton for comments on the Unix platform for C++?In general, how many lines of comments is recommended for a file with around 100 lines of code?",Not-TD-related,Other,,,,0,0.89,0.11,0.533
759863,ASP.NET MVC users - do you miss anything from WebForms?,"There are lots of articles and discussions about the differences between ASP.NET WebForms and ASP.NET MVC that compare the relative merits of the two frameworks.I have a different question for anyone who has experience using WebForms that has since moved to MVC:What is the number one thing that WebForms had, that MVC doesn't, that you really miss?EditNo-one has mentioned the WebForms validation controls. I am now working on some code that has a few dependant validation rules and implementing client-side validation for these is proving slow.",Not-TD-related,Other,,,,0,0.953,0.047,0.4588
797807,How to make developers follow coding standards?,"How can I make developers follow coding standards? In our company:olliI've given documents and they don't have the patience to read it and follow it.liI've tried telling them again and again please do it this way they nod their heads, but still do it the wrong wayliWe're doing a project for the third time and still they don't seem to follow it properly.I'm now so tired of this. What is the best way to set standards for coding and make sure they follow them?Edit:/There are just about 10 developers in my team. They're over pressurized and do not take the time to put comments and do the code neatly since there's more pressure to complete the product from our management. What would be the solution for this?",Not-TD-related,Other,,,,0.085,0.791,0.124,0.563
798243,Metrics for measuring successful refactoring,"Are there objective metrics for measuring code refactoring?Would running findbugs, CRAP or checkstyle before and after a refactoring be a useful way of checking whether the code was actually improved rather than just changed?I'm looking for metrics that can be can determined and tested for to help improve the code review process.",Not-TD-related,Other,,,,0.054,0.713,0.233,0.8758
841222,identifying code improvements,"We've just gone through a pretty major system rewrite and I have been asked to find and identify areas of the code that have been improved. as a way to justify to the customer that the effort we've spent was worthwhile. Identifying the areas isn't really the hard part but I'm struggling with how to best present this information. Any suggestions on this, or if anyone ahs done something similar in the past would be appreciated.",Not-TD-related,Other,,,,0.043,0.758,0.199,0.9127
844215,How do you manage non-user facing work in a strict scrum shop?,"We're a medium sized engineering shop (10-20). We are great at prioritizing and structuring work on our user facing stories and making customers happy. But the cobbler's children have no shoes. If it isn't about customers, we have 0 process. I'm looking for systems to ensure we correctly prioritize and accomplish the non user facing work to keep a dev shop running: QA environments (pretty heavy, in our case), continuous integration systems, the packaging, and so forth. Now, resources are always limited. We don't want to give the cobblers children 10 pair of the fanciest shoes, and specialized bike shoes to boot. We want to do the right, necessary work, with the same scrummy discipline that is applied to the rest of our development. Tell me what system works for you: how to you prioritize and organize non-user facing work ? I want systems that are simple and integrate smoothly with scrum. (I'm aware of a red box at the top of this text, indicating that Stack Overflow's automated question parser thinks this is a subjective question that can't be answered - I think there are likely 2 or 3 excellent answers that can be or have been proven viable - and process is integral to programming. So here is some psuedocode representing our process. Fix this algorithym). IBacklog GetBacklogForWork(IWork requestedWork){ if(requestedWork.IsUserFacing) return new PrioritizedBacklogRepository(); // Everything else. Priority largely based on spare time and who thinks its a neat idea return new RandomizedPriorityRepository();}void HandleIncomingSuggestionsForWork(IEnumerable(IWork) ideas){ foreach(work in ideas) GetBacklogForWork(work).Insert(work);}re",Not-TD-related,Other,,,,0.036,0.874,0.09,0.9524
903572,Consequences of doing good enough software,"Does doing good enough software take anything from you being a programmer?Here are my thoughts on this:Well Joel Spolsky from JoelOnSoftware says that programmers gets bored because they do good enough (software that satisfies the requirements even though they are not that optimized). I agree, because people like to do things that are right all the way. On one side of the spectra, I want to go as far as:olliOptimizing software in such a way as I can apply all my knowledge in Math and Computer Science I acquired in college as much as possible.liDo all of the possible software development process say: get specs from a repository, generate the code, build, test, deploy complete with manuals in a single automated build step.On the other hand, a trait to us human is that we like variety. In order to us to maintain attraction (love programming), we need to jump from one project or technology to the other in order for us to not get bored and have fun.I would like your opinion if there is any good or bad side effects in doing good enough software to you as a programmer or human being?",Not-TD-related,Other,,,,0.047,0.81,0.143,0.9581
941512,What's the difference between a bug tracking and an issue tracking system?,I'm looking for both an explanation of why and when you would use each system emand/em what features differentiate a bug vs. issue tracking application.,Not-TD-related,Other,,,,0,1,0,0
988114,How to apply agile to personal projects?,After learning about source control the first thing I did is do a project with svn. After learning about git I used it in a personal project. After learning about UML/Design Patterns/Design Principles/TDD I applied them to a personal project. How can I do the same to agile development? Is agile just for teams and big projects? How do I set up these iteration things?,Not-TD-related,Other,,,,0,1,0,0
1034107,How do you handle a pool of unrelated small bugs in Scrum?,"We've recently adopted Scrum on the job and are running into trouble with a bunch of tiny bugs that appear after code has been accepted. These include things such as spelling errors, and other single line fixes. To create stories of size 0.5 for every little thing seems like a waste of time. It takes more time to write the story and point it than it does to make the fix. If there were only one or two of these per sprint, it would be easy to just fix them and not worry about creating stories for them. However, if there are 10 or 20 or more because the application is large, this can start to add up to significant amounts of developer time that aren't being accounted for via Scrum. While it may be easy to say the QA staff and product owners should be more thorough before the original story is accepted in the first place, I'm the developer so that is essentially out of my hands.A couple imperfect ideas we've come up with so far:ulliHave a story that says 90% of bugs fixed in the app where you then guess how many bugs will emerge in that sprint and how many can be fixed and then point it based on the anticipated workloadliHave a story of size, say, 8 that is ALWAYS accepted at the end of the sprint where you fix as many bugs as you can. This obviously requires a great deal of trust that everybody is actually doing an 8's worth of workliRecord bugs but do not work on them until the next sprint. They can be pointed individually or as a group. This has the advantage of being more Scrummy but causes a three week delay for what are essentially 1 hour fixes.Any suggestions?",Not-TD-related,Other,,,,0.037,0.881,0.081,0.8237
1047112,Can burnout happen when doing Scrum sprints continuously?,"I'm with a pretty small startup and we started using a form of a Scrum/Agile development cycle. In many ways I enjoy Scrum. We have relatively short sprints (2 weeks) and I like the Burn Down Chart to track the team's progress. I also like the Feature Board so I always know what I should be doing next. It feels good taking down a feature's card from the board, completing it and then putting it in the burn down pile.However, we are now entering in our 18th Sprint release cycle and I'm starting to feel a little burnt out. It isn't that I don't like job or my co-workers, it is just that these sprints are... well, emsprints/em. From start to finish I literally feel like I'm racing against the clock to maintain our development velocity. When we are done with the sprint we spend one day planning the next sprint's feature set and estimates and then off we go again.For people who work in a mature Agile/Scrum development process, is this normal? Or are we missing something? Is there normally time in a Scrum enviornment that is unassigned/untracked to get done some minor things and to clear your head?",Not-TD-related,Other,,,,0.011,0.843,0.146,0.9775
1047885,What are the essential concepts all programmers should learn and use?,"I'm currently learning to program, and I didn't take CS classes so I'm basically starting out on the bottom. I have been putting together code on and off for many years, but haven't really had a good understanding of essential concepts needed for enganging in bigger projects. Object-orientation is an obvious one, and I feel I'm beginning to understand some of the concepts there. Then there is a lot of buzz and methodology, such as MVC, UML, SCRUM, SOLID and so foth and so on.. I've looked at many of these but I'm always stumped as most explanations seem to require some understanding of other concepts.I want to learn this stuff the right way, so where do I begin? What are the overarching constructs I need to understand that enable me to understand all the underpinnings of software architecture/design/development?What am I missing? Are there constructs and concepts that can and should wait until I've cleared the foundation?",Not-TD-related,Other,,,,0.046,0.916,0.038,-0.4816
1078975,How to understand Microsoft Dynamics products?,"What is the difference? They all are business management solutions. They do the same? Some sort of different editions? Do they use same platform?Dynamics NAVblock e Microsoft Dynamics NAV 2009 is a comprehensive business management solution that helps people work faster and smarter, and gives your business the flexibility to adapt to new opportunities and growth./block eDynamics AX block e Microsoft Dynamics AX 2009 is a comprehensive business management solution for mid-sized and larger organizations that works like and with familiar Microsoft software to help your people improve productivity./block eDynamics GPblock e Microsoft Dynamics GP is a richly featured business management solution that allows you to use familiar, powerful software to operate and grow your business./block eDynamics SLblock e Microsoft Dynamics SL is a business management solution specialized to help project-driven midsize organizations obtain reports and business analysis, while helping increase efficiency, accuracy, and customer satisfaction./block e",Not-TD-related,Other,,,,0.017,0.648,0.335,0.993
1096519,Software Development Analysis,"What do you think of Mr. King's software development analyst at http://devadept.com/?I ask because reading his blog has made me rethink how I should be coding software. I mean, I used to concern myself with just getting a project done, but I think I may be missing something and his blog makes me feel that way.Am I just a programmer ""playing"" software architect? I don't know, but one thing is for sure, and that is his blog has made me want to become a better coder and architect.",Not-TD-related,Other,,,,0.032,0.868,0.1,0.7013
1128022,How to incorporate training time into estimation of agile projects,"When working on an agile development project, how do you incorporate into the estimation of time for user stories/use cases/etc. the time it takes to train new developers on unfamiliar technology being used by the project?? How do other managers handle this?Of course, my question assumes that one has deemed the technology in question necessary to complete the project successfully ... or perhaps it could be considered paying down a bit of technical debt!",Not-TD-related,Other,,,,0.032,0.916,0.052,0.3678
1230329,What are some of the best-written open-source projects you have seen?,"What are some of the open source projects out there that you would hold up as shining examples of projects that correctly and effectively use enterprise sofware patterns and best practices such as Inversion of Control, Model-View-Controller, Unit Testing, etc.?For purposes of this question the project should:Include source code that illustrates the pattern in use, andBe doing something important and useful, i.e. not using the pattern frivolously just because it is flavor of the week. Hence the words, ""Correctly and Effectively"" in the question It should be software that you could show to the people who work for you and enthusiastically be able to say, ""I want you to do it the way these guys did it.""",Not-TD-related,Other,,,,0,0.849,0.151,0.9559
1234224,What is CSLA Framework and Its use?,What is CSLA Framework and Its use ?,Not-TD-related,Other,,0,,0,1,0,0
1237515,Story estimates in Scrum,"We started a project that will be managed with Scrum/XP. We wrote the whole product backlog upfront for evaluation purposes. We're making sure all stories are customer-centric and we're evaluating them bystory business value: MoSCoW technique - Must, should, could, would/won't have this implementedstory effort/complexity (= story points): 1, 2, 3, 5, 8, 13, 21, 100 - related to story complexity/effort rather than ideal days duration100 story points may have some stories with Would/Won't have because they actually are bigger complex stories that will be broken down later if needed.Calculated story importance is based on value&effort by not overlapping MoSCoW stories.But without 100 point stories our stories so far (also broken down) has complexity between 2 and 8 which we think is an appropriate story size to avoid micromanagement. But some stories became related or dependant on each other. We have stories that may take more if done first, and less if some other story would be done before them.QuestionsIs it possible to adjust story points later on during development, as we can do with story tasks where we can re-evaluate them, add new, remove existing or is this not the case with stories? Because changing their complexity, will also change end date estimates based on planned velocity. What's the best practice in this case?",Not-TD-related,Other,,,,0.039,0.894,0.067,0.6767
1268963,Why is preprocessor usage less common in languages other than C/C++/ObjC?,"I've been a Java and VB.Net programmer for about 4 years and a C programmer for about 6 months. I've also used a bunch of dynamic languages like Perl, Python, PHP, and JavaScript.I've never had a need for a preprocessor.My question is: why do you see such extensive use of preprocessors in C, C++, and Objective-C but rarely (or never) see it in languages like Java, C, or Scala?",Not-TD-related,Other,,,,0,0.895,0.105,0.7003
1297156,Unmaintainable code behind to the non-technical,"How would you explain to a non-technical person why writing code (business-logic) behind the onclick event is a bad practice and leads to unmaintainable code?Edited:I have to explain management why some refactoring is needed, also why some code is not passing code review. To some people in management this only means more funding. I came up with this example because at some point of a discussion somebody said: ..put the code behind the button and forget all that model-view-controller hype, you will finish your task faster.",Not-TD-related,Other,,,,0.063,0.937,0,-0.6597
1364561,Has Agile really worked for you as a Developer?,"I have met a lot of people for whom Agile has worked really well, and most of them tend to be managers and architects who plan and delegate the work. However I really haven't found much good developers convinced that Agile is working for them.Of course you can say if Agile isn't working for you, you aren't doing it right. But whatever remixes of Agile are out there, is it working for you as a Developer? And why? Does anyone else think, within a traditional (or close to) team structure, Agile feels more like a form of micromanagement than self-management?",Not-TD-related,Other,,,,0.017,0.905,0.078,0.7247
1372341,Scrum: Technical items in a backlog that is managed by a non technical PO?,Should technical items such as Upgrade sever from v1 to v2 or Increase startup performance or Refactor login module to reduce code complexity go in to the product backlog and if so how should a non technical product owner be able to prioritize them v.s other more functional backlog items?Should there be a separate backlog for technical stuff? Should we have a joint PO role with two persons that could prioritize functional and technical stuff on the product backlog?,Not-TD-related,Other,,,,0.06,0.912,0.028,-0.5534
1433741,What is a good ratio of refactoring time versus development time?,"I'm trying to build a plan on how we could spend more time refactoring. So I wanted to compare with the industry standards but I have hard time to find studies or metrics on that.I feel that 20% of dev time spent on refactoring seems a good ratio, but I don't have anything to show for it.In my mind, for 100% or dev time:ulli50% is spent writing code, debugging, etc...li30% is spent writing unit-testsli20% is spent refactoring codeSo around 1 line of code for 2 written end up being in the shipped product.Obviously design time, documentation time, etc is integrated in these percentages.What is an industry standard? As a rule of thumb, what is your team using?Thanks,Olivier",Not-TD-related,Other,,,,0.014,0.948,0.037,0.5588
1472805,"What is the best MVC, Doctrine2, Datamapper practice?","I am looking into using Doctrine2 with my Zend Framework setup. I really like the datamapper pattern, mainly because it seperates my domain models with my database.My question is what is the best practice for using Doctrine and DQL with my controllers?controllers uses Doctrine DQL/EntityManager directly for saving/loading my domain models?create my own classes in the datamapper pattern for saving/loading my domain models, and then use Doctrine internally in my own classes?The pros. for #1 is of course that I don't need to create my own datamapper models, but again, with #2 I can later replace Doctrine (in theory)What would you do?",Not-TD-related,Other,,,,0.014,0.933,0.054,0.6186
1484687,Self Testing Tips?,Basically I'm wondering if anyone has any tips for ensuring your code is well tested without getting any help from anyone else in a limited time frame?In the past I've always been able to find someone else to do testing on my code or had a dedicated quality assurance team go over everything and find all the errors.I'm usually pretty careful but I always find there a things I miss and when I test them I just don't see them.However in my current job I've been given two PHP web applications to write in a very limited time frame and I've been told I need to do all the testing myself despite my feedback that this wasn't a good idea.I was wondering if anyone else had this problem before and could offer some insight?I was thinking perhaps it would be good to write a quick test plan before coding each area and also to double check the requirements before doing testing.,Not-TD-related,Other,,,,0.109,0.829,0.062,-0.8719
1557841,Misusing the term Code Freeze,"I'm just curious if the community considers it acceptable to use the term ""Code Freeze"" for situations where we stop development except for testing and fixing bugs.Development Situation We're just finishing up our third and final sprint, which will be followed by a ""Code freeze"" and 2 weeks of Q/A testing. It is a big release and some components development have transcended all 3 sprints. Historically even though we call it a ""Code Freeze"" we still commit code to fix bugs.Problem Every release I try and correct my manager and co-workers that we should be calling it a ""Feature Freeze"", because it's pretty obvious that we're going to find bugs and commit code to fix them as soon as we start heavy testing. But they still persist in calling it a ""Code Freeze"". Sometimes we still have known bugs and declare a ""Code Freeze"".The Wikipedia definition seems to agree with me hereAnalysis I suspect that calling these situations a ""Code Freeze"" is some sort of willful Double Think to provide false confidence to stake holders. Or we are pretending to be in a ""Code Freeze"" situation because according to Scrum after every sprint we should have a shippable piece of software and it is the expectation we are following Scrum. So we must call it what Scrum expects instead of what it really is.ConclusionAm I over analyzing this? I just find it to be unhealthy to ignoring realities of situations and should either give it up calling it something it's not or fix the root problem. Has anybody else had similar experiences with Code Freezes?",Not-TD-related,Other,,,,0.063,0.848,0.089,-0.2047
1603648,How to convince a client that all next projects/enhancements should be done via TDD (with some agile practices)?,"We are a small team (3 developers) and one of our main clients is about to submit a bunch of new feature requests and a follow on project to us to get estimates on cost and delivery times. Our last project with them was a 'success' in that they are coming back to us but I know we could have done a much better job (we used waterfall... testing was an after thought and as a result unit-testing code coverage is significantly lower than we feel comfortable with, not to mention the never-ending 'we are ALMOST done' problem).I have just finished reading 'Art of Unit Testing' and 'Working Effectively with Legacy Code' and I have used TDD on a pet project of mine outside of work and now I can never go back to waterfall and testing after the fact. What I want to know is are there are good 'easy to digest' videos for non-developers that clearly show the benefits of TDD along with Agile practices in a business sense? I'd be super happy if there are any sub 10 minutes videos but I'm also OK with longer videos (and I will reference them to a time index in it). If there are no good videos then a written source is next best thing.I want nothing more than for them to be on board and really excited with the transition.For me it is not an option to 'just do it' as there will definitely be a learning curve for the other two developers and without doubt the first number of iterations may be stressful and bumpy and that needs to be communicated to our client.[I have answered my own question below with a number of videos I found since asking the question... they are not perfect for my use but definately my plan B if no-one else knows of a better one]",Not-TD-related,Other,,,,0.04,0.762,0.199,0.9954
1708911,.NET Team - Best Practices and Methods,What best practices and methods would you enforce on a new .NET development team?Cheers,Not-TD-related,Other,,,,0,0.741,0.259,0.6369
1724381,"Explaining why Just add another column to the DB is a bad idea, to non programmers","I have sales people and bean counters who are trying to sell customizations to clients, which is fine. But when a complex change request comes in that I send back a large estimate for, they get confused. Often they come back at me with Why can't you just add another column? which by another, they mean a dozen or so custom columns PER client.So far all I can come back with is We are trying to keep the database well normalized which means nothing to them. I tell them I can create a system of tables that allows each client to define their own set of custom fields, but of course that takes more time and money than just adding a few columns. And of course they want to have their cake and eat it too.So how can I make them understand?",Not-TD-related,Other,,,,0.021,0.917,0.062,0.5514
1727307,refactor refactor refactor your code. What does this mean exactly and why do it?,I often heard from professionals blog something like refactoring your code whenever the chance you get. What is it exactly? Rewriting your code in simpler and fewer lines? What is the purpose of doing this?,Not-TD-related,Other,,,,0,0.864,0.136,0.6174
1731438,Do good tests enable sloppy coding?,"Let's say you're coding, and you come across an opportunity for simple code resuse (e.g. pulling a common piece of code out to an accessible place like a Utility class or base class). You might find yourself thinking, I know it's good to do this, but I have to get this done now, and if I need to make a change to this code, and forget to change it in the other place, my testing framework will let me know.In other words, you let the awesome tests you (or another developer) has written to remind you to change the code in the other places too.Is this a legitimate problem that we might find in ourselves or other developers?",Not-TD-related,Other,,,,0.048,0.86,0.092,0.6542
1819523,What is better: set up underestimated or overestimated deadlines?,"Suppose you are a project manager. You can estimate an effort in days for specific task for specific developer. After performing estimation you obtain some min and max values.After this you delegate a task to developer. Actually you also set up deadline.brWhich estimation is better to use when set up deadline: min or max?As I see min estimation can result in stress for developer, max estimation can result in using all the time which is allocated to developer even if task can be complete faster (so called a href=http://en.wikipedia.org/wiki/Student_syndrome rel=noreferrerStudent syndrome/a). Which other pros and cons of two approaches?EDIT:Small clarification: I speak about setting up deadlines for subordinates when delegating the task, NOT for reporting to my boss.EDIT:To add one more clarification: I can keep in mind my emreal/em estimation, provide to boss slightly larger estimation, to subordinates - slightly smaller.And this questions touches the following thing: is it good idea to provide to developer underestimation to make him working harder?",Not-TD-related,Other,,,,0.017,0.943,0.04,0.5484
1828057,System stories for agile architecture,"While trying to apply agile principles to our development process, in particular scrum principles and XP-like user stories, we faced a problem about the architecture.Maybe we are still too much linked to the architecture-centric development, however we are trying to maintain a  component based development, mixed with the agile modeling principles. Our aim is to have a small design up front, prone to evolutions during the development.What I'm looking for is something that could let me place into my backlog stories about my architecture and the components inside of it: development stories, not only usage stories.System story could be a different kind of user story, which tells something that is not strictly related to business value, but that is instead linked to architecture and quality concerns of a system.Edit:I found a href=http://www.springerlink.com/content/t7116q17687u8685/ rel=noreferrerthis research/a of the Aalborg University about emdeveloper stories/em.Have you any experience, idea or opposition?Thank you in advance! (this is my first question! :D)",Not-TD-related,Other,,,,0.016,0.973,0.011,-0.1862
2015947,Software development metrics and reporting,"I've had some interesting conversations recently about software development metrics, in particular how they can be used in a reasonably large organisation to help development teams work better. I know there have been Stack Overflow questions about which metrics are good to use - like this one, but my question is more about which metrics are useful to which stakeholders, and at what level of aggregation.As an example, my view is that code coverage is a useful metric in the following ways (and maybe others):For a team's own internal use when combined with other measurements.
For facilitating/enabling/mentoring teams, where it might be instructive when considered on a team-by-team basis as a trend (e.g. if team A and B have coverage this month of 75 and 50, I'd be more concerned with team A than B if the previous month they'd had 80 and 40).For senior management when presented as an aggregated statistic across a number of teams or a whole department.But I don't think it's useful for senior management to see this on a team-by-team basis, as this encourages artifical attempts to bolster coverage with tests that merely exercise, rather than test, code.I'm in an organisation with a couple of levels in its management hierarchy, but where the vast majority of managers are technically minded and able (with many still getting their hands dirty). Some of the development teams are leading the way in driving towards agile development practices, but others lag, and there is now a serious mandate from the top for this to be the way the organisation works. A couple of us are starting a programme to encourage this. In this sort of an organisation, what sort of metrics do you think are useful, to whom, why, and at what level of aggregation?I don't want people to feel their performance is being assessed based on a metric that they can artificially influence; at the same time, the senior management are going to want some sort of evidence that progress is being made. What advice or caveats can you provide based on experience in your own organisations?EDITWe are definitely wanting to use metrics as a tool for organisational improvement not as a tool for individual performance measurement.",Not-TD-related,Other,,,,0.019,0.853,0.128,0.9917
2052101,Corp IT Systems direction. Invest in A or B?,"This is more of a general question about which direction would be a better investment for the company. Our company's core business application is written in Visual FoxPro and is about 9+ years old. The database is huge 15+ gigs and the core logic is complex and to make matters worse the data model is terrible. The two guys that built it and have maintained it all these years are at least in their 50's, so needless to say retirement or possibly death could come within the next decade or so.This VFP app drives all our core business functions and requires terminal services and citrix to access it from the outside world. Our web apps have to interface with it via ODBC and we are always having performance issues with it. The servers that run this system are also very old, like Win 2000 server and are falling apart.Recently we have been having meetings about upgrading the systems that run this core app as well as other services like email and file storage. The biggest expense however is buying new server hardware, OS licensing, Terminal Services licensing, Citrix licensing etc to solve some performance and outside access issues we are currently having as well as just generally bringing us to date on our systems. The price tag is going to be in the $55K to $65K price range. So as a web developer my point of view is that this is a huge waste of money! My solution would be to invest that money in rewriting the core system to run on the web based .Net platform. This would eliminate the need for Terminal Server and Citrix licensing along with the pricey hardware and configuration management to run it on. I don't see the point in investing this kind of money in an antiquated system that should be on it's way out anyways.I am looking to get some convincing arguments as to why this is a waste of money. Hopefully there is someone here that has faced this type of situation before that can give me some points of view. The hardware upgrade seems to be the easiest road to take because they will just have a consultant come in and do it all. A software development project would take longer, require more resources and possibly cost a little more money.",Not-TD-related,Other,,,,0.048,0.868,0.084,0.9003
2086175,Using Oracle Zero Date,"I have an application with existing data, that has Zero in the date column.When I look at it from sqlplus I see:00-DECEMBwhen I use the dump function on this column, I Get:Typ=12 Len=7: 100,100,0,0,1,1,1I need to work with the existing data from .Net (no changes to the data,or the data structure or even existing sql statements) How the hack do I read this value, or write it.The db version varies, from 8 to 11.Help would be appreciated",Not-TD-related,Other,,,,0.034,0.886,0.08,0.5346
2105304,How to determine web application end of life?,"This question could bring a lot of opinions to the table, but what I will like to get is a set of measures that will help me and my company determine the end of life of a product that we sell.We sell a CMS system, with this system we create a few sub-products ulliWebsitesliProposal CreatorliMarketing Campaign TrackerWe are ready to start our road planning (for 2010 and 2011) and we are trying to figure when will be the end of the life of our application. Some of you might think that a very well architected application (I don't think our application is well architected) does not need to have an end of life, but this app that we are using goes back at least 6-7 years and has almost no documentation (real life). At this moment only ONE person knows how to change core functionality (scary).Please advice,GeohremThanks to All! I really appreciate your comments, opinions and thoughts on this topic./emI will address a few of the post back questions in the list belowulliThere is one developer that is able to maintain the core functionality of our product. (only and only one)liThere are two developers that are able to increase functionality to a certain point. Both developers are constrained by the limitations of the core product, and they both have to work within those limits.liA very important note. The product that we are considering to put to end-of-life is for the most part being built by a contractor. The contractor is the only developer able to maintain the core functionality. We only develop on top of the contractor framework.I will keep adding answers while I read you all responses.",Not-TD-related,Other,,,,0.014,0.871,0.116,0.9828
2113353,Calculating how much time you can save by estimating the code you write in a year,"I write a lot of code, but not full-time. When I look back at my projects of the past year and I do a (very) rough count (counting only code lines, no comments or white lines) I come to about 19.000 for a year that make it into a project. If I can automate parts of that, I could deduct the profit in time and money.For estimating time-saving for larger projects, I need averages. How many code lines does man write in a year, on average, in C# (or other language of choice)? And, looking at your own situation, would you consider your hand-written code could (partially) be automated and by what gain?",Not-TD-related,Other,,,,0.026,0.894,0.08,0.7912
2158080,How does one create an enthusiastic development team?,"block e If you have a room full of capable developers, what can be done to encourage those developers to become excited and enthusiastic about software and software development/block eThe correct question is actually What can be done to encourage those developers to become excited and enthusiastic about software and software development in our company.It's quite simple actually. The answer has never been a secret. It's just nobody listens to it.Very simply elements:ulliLet those enthusiastic developers work among other passionate people. Remove those who don't care from the team. Otherwise they will act like diseased cells proliferating apathy and depression to the other team members.liAspire to develop a quality and professional productliEstablish a professional and effective processliTrust and respect people. Value their knowledge. Respect their opinions. Actually, it's part of a bigger strategy: let your developers be able to make a difference and let them see they can really influence and change things.liLet them grow professionally and let them see this growth is appreciated and needed by youNow what doesn't help at all.ulliPay them badly. Developers are also humans (for the most part) and they also have their bills to pay.liReject their initiatives, proposals and improvement suggestions. Tell them each time they come up with something that their attempt to introduce change make them a foreign und unwelcome element in the company.liHave low quality product and have no interest to make it better. Hacks, copyaste code, accumulating technical debts, things falling apart after each release, that does not motivate developers.liHave badly run development and chaotic process. Tasks, projects and small decisions taking a new vector every few days will finally remove desire to be involved from anybody. Failing schedules because of unpredicted work load and feature set, they all go down the road. It will suffice to run out of coffee some day for some of them to start moving elsewhere.liHave a boring and uninteresting social environment. Developers having nobody to talk to to share their interests will finally feel dull. Not everyone is interested in taxes, football and kindergarten issues as the only topics on social gatherings.",Not-TD-related,Other,,,,0.109,0.735,0.156,0.9632
2218872,Obscure software engineering terms,"I hear a lot of terms which aren't well known amongst programmers (or perhaps the ones I work with at work aren't very good apart from a few), such as technical debt (which I studied and even see first hand at work).What other obscure/not-well-known terms are there? This is especially useful to know as interviewers sometimes mention complex terms and if I don't know what they mean, it can screw up the interview as it is in progress.Thanks",Not-TD-related,Other,,,,0.103,0.818,0.079,0.0145
2219821,What Project management lessons and best practices can we learn from the engineering and construction industry?,"It is a well known fact that IT projects fail with an alarming rate (some surveys suggest that the failure rate is more than 60%). Typically, project managers try to recover from these failures either by squeezing their resources to work extra hours or by compromising the quality of the deliverables (reduce testing effort, reduce scope etc.). Unfortunately, software quality is not deemed as very important by the business leaders. I wonder if this is true about other professions as well ? How are projects managed, for example, in the construction industry where the cost of failures is very high and where a single mistake can be catastrophic ? Mega engineering projects like the Eurotunnel and Petronas towers required thousands of people and billions of dollars to construct and yet most of these projects were completed successfully within or sometimes even before time.Are there some lessons we can learn on how projects are planned and managed in other industries ?",Not-TD-related,Other,,,,0.129,0.788,0.083,-0.8421
2228614,What is the best dictionary for software development terminology?,"On stack overflow, I see that there is referred to Wikipedia a lot. However, I'm often not sure whether they are the definite authority for very specific software development related concepts. For example, I have recently looked for definitions of the terms web server/service and RPC/IPC, and the responses I get very often refer to Wikipedia (directly and indirectly).Hence my question: which sources do you trust the most for definitions of software development jargon?",Not-TD-related,Other,,,,0.026,0.884,0.09,0.5773
2252772,How to demonstrate to management that mediocre developers are hurting team,"I am in the precarious position of managing a team of developers at a small company. I say managing because although I assign work and provide feedback on their performance I have no recourse in actually disciplining an individual. Some of my team I don't know what to do with, they are unable to work on their own, require massive amounts of hand holding and when left along generally wreak havoc on the project usually to a point of failure. When failure does occur I am left to salvage the project and push it (some times limping) across the finish line. These developers not only lack skills with programming concepts, but generally ability to formulate a solution to a problem in code. Simple things like writing loops are tough for them let alone designing and implementing a solution to a problem.We have tried pair programming, offering to pay for classes, buying books, allocating time during the work day to training and even taking whole days to train the team. The other senior developer and I do not know what to do, but our productivity is being throttled with having to deal with these individuals day to day. Management is forcing us to give them work and their major complaint is how things aren't getting done quickly enough.None of our management team works directly with any of the developers other than myself and the other senior developer. Management is non-technical and believes every developer is created equally, and that we obviously need more people on these projects to get them done faster.I am already preparing a document with sections from The Mythical Man Month and Code Complete to send to management to hopefully illustrate with statistics that what is really hindering us is having to drag the mediocre folks through the development cycle.What other resources are out there? Books, articles, general advice anything would be helpful.",Not-TD-related,Other,,,,0.07,0.853,0.077,0.6737
2259157,Scrum. Dealing with low prioritized stories that will introduce architecture change,"today in the university we had a Scrum practicing exercise (simulating the whole process of creating a software solution) and I came up with an issue that couldn't quite understand.Let's say we've had defined our stories and give them a proper prioritization. And there is a story with very little priority... it's going to be done in on of the last sprints, maybe.The problem is, what if this story introduces a huge architecture change to our solution's design? For example from stand-alone application, you will have to go for client-server architecture, because of this story only.In my point of view: isn't it natural to mark somehow which stories are for certain to be done (in some particular moment of time), those that a critical to be done, but it's not critical when, so the team to have them in mind and make better decisions designing his solution. Or how are you dealing with this problem? If it is a problem.Thanks in advance! And excuse my probably lame question.",Not-TD-related,Other,,,,0.104,0.805,0.091,-0.551
2345760,Java refactor to Generics industry standards,There seems to be some debate over refactoring to utilize java generics within my current team. The question I have is what are the current industry standards in terms of refactoring older Java code to take advantage of some of these features? Of course by industry standards I am referring to best practices. A link to a book or a site with these listed will be awarded the answer vote as that is the least subjective way to handle this question.,Not-TD-related,Other,,,,0,0.891,0.109,0.836
2354482,What is your ratio Bug fixing vs Enhancements?,"In the spirit of this question I wanted to have a sense of what is the proportion of time split between fixing bugs and implementing new features. If possible try to give an estimate for the product as a whole as opposed to individual developer stats and try to make an average over the course of a typical year. Do provide a general descriptive of the product/project to allow comparison. Specifically :Maturity of projectIs it still actively developed or strictly in maintenance ?Size estimate of the product/projectSize of team developing it (all inclusive)What is your team score on the Joel test.Ex :approx 80% time spent bug fixes 20% new stuffMature software (20 years old)Actively developed1.5M Line of Text, approx 700k - 900k LOC12-15 actively coding in it.we got 5/12 for sure, some would say 7/12.",Not-TD-related,Other,,,,0,0.894,0.106,0.9118
2456310,scrum and refactoring,If everything in scrum is all about functional things that a user can see is there really any place for refactoring code unrelated to any new functional requirements?,Not-TD-related,Other,,,,0,1,0,0
2510567,Sprint to the finish: how to keep all team-members busy in the final days of a Scrum sprint?,"Given that the tasks in a specific sprint will not divide perfectly into the team, and all finish on the same date, what do you do to keep everyone working as the sprint moves into its final stages?Inevitably it seems like there will be one or two people freed-up. If all the other tasks are emdone-done/em, and the remaining tasks are already underway, then what?Do those team-members pick up items from the top of the product backlog, as they are likely to be needed in the next sprint anyways to get a head start?What do you or your teams do?",Not-TD-related,Other,,,,0.033,0.917,0.051,-0.2565
2693143,Software Metrics in Agile Methodologies,"Agile is a business oriented thing, Agile is about maximizing the customer value while minimizing waste to provide the most optimal ROI. This is what should get measured. And to do so, I use the system that Mary Poppendieck a href=http://groups.yahoo.com/group/scrumdevelopment/message/13433 rel=nofollow noreferrerrecommends/a. This system is based on three holistic measurements that must be taken as a package: olliCycle timeulliFrom product concept to first release orliFrom feature request to feature deployment orliFrom bug detection to resolutionliBusiness Case Realization (without this, everything else is irrelevant)ulliP L orliROI orliGoal of investmentliCustomer Satisfactionullie.g. a href=http://en.wikipedia.org/wiki/Net_Promoter rel=nofollow noreferrerNet Promoter Score/aSure, at the team level you can track things like test coverage, cyclomatic complexity, conformance to coding standards, etc, but high quality is not an end in itself, it's just a mean. Don't misinterpret me, I'm not saying high quality doesn't matters, high quality is mandatory to achieve sustainable pace (and we include no increase of the technical debt in our Definition of Done) but still, the goal is to deliver value to the customer in a fast and profitable way.",Not-TD-related,Other,,,,0.05,0.859,0.091,0.7674
3018891,How would I go about licensing a WPF windows application,"I have developed a small application that I would like to try and sell but I am unfamiliar with how best to go about this. olliHow would I go about locking the program down for trial use1.liHow would I go about dealing with accepting payments?Bearing in mind that I am a one man band with not a lot of money, I was hoping for a solution that would be free or a low cost, effective, secure and simple to implement and maintain. This is not something that I have a lot of experience with as I have typically developed for the public sector where they buy a solution as a whoel and we have never licensed it.Any help would really be appreciated.Thanks,B",Not-TD-related,Other,,,,0.042,0.713,0.245,0.9812
3242133,Test Driven Development Refactoring Design Complexity,I am currently studying test driven development. I am inquiring about an improvement in design if we refactor after the development of every couple of units as opposed to dedicated refactoring sessions that are more spaced apart in time.I am aware that the technical debt will be larger. But I am wondering what other impacts. Maybe the refactoring process is not as effective when there is a larger time interval because...?Thank you..,Not-TD-related,Other,,,,0.07,0.876,0.055,-0.2688
3258426,How can I make OS X recognize drive letters?,"I know. Heresy. But I'm in a bind. I have a lot of config files that use absolute path names, which creates an incompatibility between OS X and Windows. If I can get OS X (which I'm betting is the more flexible of the two) to recognize emQ:/foo/bar/bim.properties/em as a valid absolute file name, it'll save me emdays/em of work spelunking through stack traces and config files.In the end, I need this bit of Java test code to print SUCCESS! when it runs:<code>reAnyone know how this can be done?UPDATE: Thanks for all the feedback, everyone. It's now obvious to me I really should have been clearer in my question.Both the config files and the code that uses them belong to a third-party package I cannot change. (Well, I emcan/em change them, but that means incurring an ongoing maintenance load, which I want to avoid if at all possible.)I'm in emcomplete/em agreement with all of you who are appalled by this state of affairs. But the fact remains: I can't change the third-party code, and I really want to avoid forking the config files.",Not-TD-related,Other,,,,0.05,0.809,0.141,0.9561
3410609,How to best present unit testing to management?,"I am preparing a presentation about unit testing to managers. My team has been writing unit tests for years now but other areas of the company seem to have a hard time adopting it. I can get developers excited about it, but if there is not a buy-in from management, it will not become a standard.Do you guys have suggestions how to best approach management about this? What are some things you have tried in the past that worked? What are things that did not work?",Not-TD-related,Other,,,,0.018,0.875,0.107,0.8702
3477706,Development cost versus maintenance cost,"I'm trying to explain the ratio of development versus maintenance costs to our sales department, and currently I have mostly my gut feeling that we spend about 60% of the time with maintenance.We have some persons on the team who tends to sell custom solutions, that we have to build, and if the sales people doesn't understand the total cost of development, then they will not be able to sell for realistic prices.Another problem is that we are expanding our service, and have a need to refactor some of the underlying infrastructure in order to reduce time to market and other measure points.Do you have any good suggestions on what I should refer to in order to build a solid argument? And what points should I bring up in order to give them a good understanding of the problem?Maybe there is some great text out there somewhere that I can point to.",Not-TD-related,Other,,,,0.033,0.871,0.096,0.8343
3505601,agile friendly way to integrate two separate applications/teams,"We have two distinct agile teams, each working on separate, but related, applications.brEach team has, until now, been able to work in an independent fashion (distinct code bases, persistence stores, sprints, backlogs etc). Recently, product management decided that these applications will become even more closely integrated. On a side note, the size of each team (comprised of QAs, Devs, BAs) will be increasing over the next 6-12 months.Management has decided to keep the agile process largely intact, since it has worked well (two teams working independently as much as possible) but have floated the idea of a contract-based service layer as means of integrating the applications. In each sprint, any story that requires integration with the other application will be identified. At that point, an additional integration story will be added to the other teams backlog. That team will then be tasked with fulfilling the contract. In the meantime, the other team can continue their original story work, substituting a mock/fake service until the other team produces a working service.Since Agile preaches a KISS philosphy, several people on the teams have taken issue with the complexity of this approach. They are advocating continued used of stored procedure sharing as a leaner/simpler integration methodology that has worked well in the past. I prefer contract based programming for all sorts of reasons, but the main reason is it's ability to provide compile time visibility into the behavior your application is expected to provide. You also get clear boundaries around who owns what code, and whose code you are likely to break if you break your contract. Stored procedures do none of that. Since we have already reaped many benefits from agile, I'd like to think that there is already an agile-friendly way to deal with this kind of app integration/synchronization. Does creating a contract based SOA layer meet the agile smell test? Is there a third option I haven't considered?",Not-TD-related,Other,,,,0,0.894,0.106,0.9873
3585276,What is the point of scaffolding?,"I don't understand the significance of something like rails, codeigniter, etc. and scaffolding. From what I read, and maybe it's just wrong, scaffolding isn't used in the production environment. I don't know what it's for. It's neat but I don't know what I am supposed to do with it.Thanks.",Not-TD-related,Other,,,,0.073,0.847,0.079,0.0754
3593256,How to integrate QA into the Sprint,"One of the challenges with Scrum is how to fit QA into the process. Sure, QA works with the developers on each individual user story during the Sprint, but what about giving QA time with the fully completed sprint to do a full regression and load test before releasing into production?I've seen 2 approaches:launch into production on the last day of the Sprint; orlaunch into production a week after the SprintBoth approaches have their challenges so I'm wondering what most shops do that release every Sprint?",Not-TD-related,Other,,,,0,0.897,0.103,0.755
3856152,How bad is it to abandon THE rule in C (aka: return 0 on success)?,"in a current project I dared to do away with the old 0 rule, i.e. returning 0 on success of a function. How is this seen in the community? The logic that I am imposing on the code (and therefore on the co-workers and all subsequent maintenance programmers) is:.0: for any kind of success/fulfillment, that is, a empositive/em outcome==0: for signalling no progress or busy or unfinished, which is emzero information/em about the outcome  0: for any kind of error/infeasibility, that is, a emnegative/em outcomeSitting in between a lot of hardware units with unpredictable response times in a realtime system, many of the functions need to convey exactly this ternary logic so I decided it being legitimate to throw the minimalistic standard return logic away, at the cost of a few WTF's on the programmers side.Opininons?PS: on a side note, the Roman empire collapsed because the Romans with their number system lacking the 0, never knew when their C functions succeeded!",Not-TD-related,Other,,,,0.036,0.892,0.072,0.7616
3933510,"How do you respond to the argument No time to test/develop clean code, because of the deadline?","Ok, I think this question is at the wrong place and I'll head over to a href=https://softwareengineering.stackexchange.com/https://softwareengineering.stackexchange.com//a to read/ask about it. Thanks all for your answers up to this point. :)hrapologies ;) emI'm sorry if this question is a little bit subjective, but I can not come up with a better title. I'll correct it if you know something better./emIn my organization there is a lot of buzz about this whole automated testing and continuous integration thing, but one argument I constantly hear is this:block e How should I develop good, clean, easy to maintain code and write unit tests, if the deadline is already set and it is only half of my estimate?/block eI'm a developer myself, so I can understand this. But I always try to respond that not only the developers need a paradigm shift, but the management too.If you are a developer and your estimates are cut half, no matter what you estimate, you are not going anywhere, no matter how complex or trivial your problems are. You need the backup of the management guys, the emOne Guy/em who is giving the money.Conclusion?/Can you give me some help, may it be a good URL to read about this development/management conflict, a book or maybe a personal insight? Did you survive a large process shift like this in a Waterfall company that is now doing Lean development? Or do you know this argument and have a clever answer to it?And please, help me rename or move this question. :-)Update/Thanks for all the answers already! :) I think I have to make clear that my point wasn't the emdo it twice as fast/em statement from management. It's about the negative point of view that comes with this statement from a developer.Is there anything I can do to help people to understand that this is not the default in software development? That the PM is not actively preventing writing good code and that maybe both sides need a bit more education about the pros/contras of clean code bases, good coverage and lots of automated tests?",Not-TD-related,Other,,3,,0.085,0.733,0.182,0.99
3985742,Best practices moving from Java to Groovy,"I'm versed in Java, and starting to experiment with Groovy. Because the two are integrated so well, I find myself writing in Java whatever I can because it's so easy. What specific tips can you offer that would speedup my work with Groovy?Meaning - in what areas do groovy excel over java, and where should I stick to Java?",Not-TD-related,Other,,,,0,0.841,0.159,0.8703
4078688,List of agile best practices,"I am trying to define which agile practices we are going to use, and I am having difficulty defining the list of agile best practices. I would like my list to be more from a technical point of view (the engineer's angle of view), and should define how SW engineers should approach the development. The list should be related to the management as least as possible.If it matters, we are programming in c++.It is fairly easy finding lots of best practices, and this is the list I managed to form so far :olliRefactoringliSmall release cyclesliCoding standardliCollective ownershipliSystem metaphorliPlaning gameliWhole teamliScrum daily meetingsliPair programmingliTest Driven DesignliBehaviour driven developmentliContinuous integrationliCode and design reviewsliActive stakeholdersliDocument lateliExtensive use of design patternsWe are already using some of the practices from the list. Some we are not going to use.Are there good agile practices that I could add to the list?PS I can add a small description of the practices, if requested.EDITAs I said, we are already using some agile practices (mostly the practices that proves to be the best) :olliContinuous integration - this is very good practice. Getting the fast feedback on the latest check-ins is very useful. Having a down time because someone broke a build can be very frustrating, especially if it last longer.liSystem metaphor - it helps little, because having descriptive class and function names helps understand the code betterliCode standard - we created the coding standard before getting into the coding. Using uniform code style is good, because anyone can take another's code and work on it like on it's own.liTDD - before started coding, we set up the environment to easy create unit tests, but only until recently we started adopting the TDD principles. I personally tried it several years ago, and it didn't go so well, but now I love it. Unfortunately, not all team members are doing it - only half team.liScrum daily meetings - we tried daily meetings and they didn't go so well. As well as on my previous job, daily meetings usually turns into 30+ minutes discussions. I guess we missed good scrum master (or leader, how is it called?)liRefactoring - we did refactoring, but only if someone from the team creates a change request. We didn't do it like on purpose : Lets sit now, and reduce our technical debt.liSmall release cycles - right now we have huge release cycles (6 months), and for next release we are planing to break the cycle into 4-6 inner releases.liCode and design reviews - we did the initial design review (like 5 years ago), and few designs reviews of some minor sub-components during this period. We did code reviews of some classesliDocument late - we did it for this release. Only required documentation means writing documentation less and more fun coding. Developers are loving it :)liUse of design patterns - we are already using design patterns where appropriate.Because of the structure of our organization we can not use other practices, but as you can see the list is long, and you can not pick everything.Also, now we are only 4 SW developers, each maintaining approximately 80 kLOC and working on new stuff. Therefore we can not do for example pair programming, or collective ownership.",Not-TD-related,Other,,3,,0.021,0.858,0.122,0.9943
4745301,WPF arrange items in a grid with virtualization,"I'm looking for way to present equally sized elements in a fixed number of rows and any number of columns. (Think of iTunes' or Picasa's album view. I believe some platforms refer to this as a 'gridview')A codeWrapPanel would do the job, but I'm binding against a very large collection of objects, so I need virtualization.I've been looking around the web, and found both commercially available codeVirtualizationWrapPanels and blog posts on how to implement your own codeVirtualizationPanel, but I can't seem to find any simpler solutions.Is it possible to arrange virtualized databound items in a grid-style view (fixed number of rows) with standard WPF components?",Not-TD-related,Other,,2,,0,0.962,0.038,0.1901
5223240,Rails Model Naming: Fix or Leave As-Is,"This is more of a philosophical question than a technical one.I'm about 40 hours into working on a new Rails app. It's retail-related, and early on I chose the name item to describe a single available product for sale.As time has gone on it's become obvious to me this was a mistake - the word item is too generic, and product perhaps would have been a better choice.So the decision I'm faced with now is, do I refactor / rename my models, ERB code and tables before I build more with this somewhat poorly chosen name, or do I just leave it as-is, save some time and move on? I worry that it's choosing the latter repeatedly that results in the ridiculous technical debt I've seen on other projects, but I also think this might be a form of premature optimization.Thoughts?",Not-TD-related,Other,,,,0.065,0.904,0.031,-0.3736
5332695,TFS Check-in Policy - Best Practices,"Are there any best practices for enforcing a TFS check-in policy? Are there any good guides on how to implement various types of policies as well as their pros and cons?Things I'd particularly like to do are ensure that code compiles (note that compilation can take up to five minutes) and that obvious bits of the coding standards are followed (summary tags must exist, naming conventions are followed, etc).",Not-TD-related,Other,,,,0,0.808,0.192,0.9319
5475676,"When your scrum team has finished the sprint's work early, what are the official rules/guidelines for accepting more work?","Specifically, should you only accept new work you know the team can finish in the given iteration? Is it ok to start the next highest priority backlog item even if you know the team doesn't have time to finish it? Thanks!",Not-TD-related,Other,,,,0,0.82,0.18,0.8101
6261342,Why do big sites use 'bad practices'?,"I often see articles, posts and comments something like:ulliglobals are bad in javascriptliscript tags should be at bottom of pageliCSS should be in external files and at the top of pageliscripts should be in external files, not plain script-tags.lietc.I've looked up the HTML source of some big sites and have noticed that they have a lot of plain javascript and CSS inside HTML markup. JavaScript and HTML are note always obfuscated, and so on.",Not-TD-related,Other,,,,0.046,0.93,0.024,-0.4019
6300704,How can I zip multiple folders individually with ant?,"If I have a folder with multiple subfolders (e.g. foo, bar, baz), how can I use ant to zip them individually into foo.zip, bar.zip and baz.zip, without doing them one by one?Ideally there should also be a way to specify which files/subfolders to zip rather than ""every single one"".",Not-TD-related,Other,,,,0,1,0,0
6788205,Why isn't database version control considered as important as application version control?,"I've recently started using Kiln Source Control for all my projects VB.NET code, and I don't know how I managed without it!I've been looking for a database source control, for all my stored procedures, UDFs etc. However, I've found that there is not as much available for database version control as there is for my web files.Why is database version control not considered as important as my web files? Surely all the programming in my database is just as important as the code in my code-behind and .aspx files?",Not-TD-related,Other,,,,0.042,0.927,0.032,0.3331
7065404,Does having a bad table and column naming convention is a good protection against Sql injection,An hacker have much more chance to try to inject this query:  ') DELETE FROM Users --rethen this one: ') DELETE From Blargblarbglbglab--reDoes having a bad table and column naming convention is a good additional protection against Sql injection.,Not-TD-related,Other,,,,0.082,0.796,0.122,0.1761
7747328,Choosing a vagrant provisioner,"QuestionCan anyone explain why it would be better to choose the puppet or chef vagrant provisioners, rather than the shell provisioner?BackgroundI'm in the process of getting started with Vagrant. One of the things I'm having trouble with is deciding which provisioner to use. So far, I've had some success using the shell provisioner, but it has been more work than I expected to get it to run reliably.At the moment, I'm not familar with ruby, puppet or chef, but I'm happy to learn any or all of them if I have to. My early experience playing with puppet and chef is that if someone else has a recipe that does exactly what you want, it works really well, but doing something non-standard means falling back coding up solution in ruby.I'm aware of articles comparing puppet and chef, and I'm less worried about which of them to use, rather than knowing when and why I should use them at all.",Not-TD-related,Other,,,,0.035,0.856,0.109,0.9174
7952972,Which of these rails 3.1 validations are better?,(A) Like this:  <code>OR-(B) like this:  <code>.-OR-(C) Am I just too anal retentive about how my code reads and looks?,Not-TD-related,Other,,,,0,0.773,0.227,0.6124
9929887,Automating eclipse console input with values from a file,I currently have a problem where I need to test thousands of console inputs in order to create a log for another team on the project. The project is being developed in eclipse (java)Basically the process looks like this:1)Program loads and outputs some text on the console2)User input of text (sometimes depending on what the program has printed before)3)Program outputs more text ready to take input again.basically I need to write/use a script that will allow me to put all the inputs into some kind of file and let it run to create this log file. Can this be done and do you have any tips?,Not-TD-related,Other,,,,0.025,0.87,0.105,0.7703
10386261,What are some .NET methods for creating a generic SQL Server query?,"I'm just looking to write a generic function in C# .NET 4.0 where I can send it a database string, a query string, and get my results back.Not being that well versed in C# and it's various different objects, I'm not really sure what the best options might be for returning this information.I know there is DataTable, DataSet, and that's really about it. What I'm looking for is an object that is fairly efficient and something where I can easily access it's data members. I'm sure it wouldn't be a problem writing my own, but I know there has to be some other object in .NET 4.0 that I can access.",Not-TD-related,Other,,,,0.042,0.887,0.072,0.5012
10692182,Agile estimation with tech-debt,"When estimating (story points) a story that consists on extending a current functionality with a known tech-debt, should we consider the effort that will be spent to refactor the current code or should we estimate independently of this tech-debt?",Not-TD-related,Other,,,,0,1,0,0
11206791,Skip test for sonar analysis,"What happens if I run following command :mvn clean install sonar:sonar -Dmaven.test.skip=true I have set Up sonar locally and its running on port 9000.What would be impact of skipping test on sonar report?",Not-TD-related,Other,,,,0,0.92,0.08,0.4019
11894333,Testing memory usage of python frameworks in Virtualenv,"I'm creating an app in several different python web frameworks to see which has the better balance of being comfortable for me to program in and performance. Is there a way of reporting the memory usage of a particular app that is being run in virtualenv?If not, how can I find the average, maximum and minimum memory usage of my web framework apps?",Not-TD-related,Other,,,,0,0.869,0.131,0.8299
12169496,Find and replace text in a string using C,"Anyone know how I would find   replace text in a string? Basically I have two strings: string firstS = /9j/4AAQSkZJRgABAQEAYABgAAD/2wBDABQODxIPDRQSERIXFhQYHzMhHxwcHz8tLyUzSkFOTUlBSEZSXHZkUldvWEZIZoxob3p9hIWET2ORm4+AmnaBhH//2wBDARYXFx8bHzwhITx/VEhUf39/f39/f39/f39/f39/f39/f39/f39/f39/f39/f39/f39/f39/f39/f39/f39/f3//;string secondS = abcdefg2wBDABQODxIPDRQSERIXFh/f39/f39/f39/f39/f39/f39/f39/f39/f39/f39/f39/f39/f39/f39/f39/abcdefg;reI want to search codefirstS to see if it contains any sequence of characters that's in codesecondS and then replace it. It also needs to be replaced with the number of replaced characters in squared brackets: block e [NUMBER-OF-CHARACTERS-REPLACED]/block eFor example, because codefirstS and codesecondS both contain 2wBDABQODxIPDRQSERIXFh and /f39/f39/f39/f39/f39/f39/f39/f39/f39/f39/f39/f39/f39/f39/f39/ they would need to be replaced. So then codefirstS becomes: string firstS = /9j/4AAQSkZJRgABAQEAYABgAAD/[22]QYHzMhHxwcHz8tLyUzSkFOTUlBSEZSXHZkUldvWEZIZoxob3p9hIWET2ORm4+AmnaBhH//2wBDARYXFx8bHzwhITx/VEhUf39[61]f3//;reHope that makes sense. I think I could do this with Regex, but I don't like the inefficiency of it. Does anyone know of another, faster way?",Not-TD-related,Other,,,,0.047,0.931,0.022,-0.5683
13936058,Problems using C++ community plugin in sonar. Cppcheck doesn't work,"sonar doesn't launch cppcheck when I use sonar-runner.I'm using the last version off all (sonar, c++ community pluguin and sonar-runner) in ubuntu 12.04.If someone has sonar working correctly with cppcheck (and the other plugins too, but now I only need cppcheck), tell me how please.In the sonar dashboard of the project appears the number of lines of code, comments, quality index, technical debt,... and the rules compliance appears at 100% and it's not true, because the project has cppcheck errors.I'm sure that sonar doesn't launch cppcheck because running cppcheck takes 1-2 minutes, and sonar-runner shows 0ms in cppcheck section.Thank you!",Not-TD-related,Other,,,,0.029,0.925,0.046,0.1764
14817467,Generic way of exception handling, catch(Exception ex)re/ being sent to database table to log is - block e ex.ToString()/block eThe parameters are not being sent. private int GetAge (int ID){}private string GetName (int ID){}reHow do i write in a generic way so that all the methods can have parameters concatenated with exception(ex.ToString)? Is there any generic approach(for winforms)?,Not-TD-related,Other,,,,0.064,0.936,0,-0.504
14909853,Is SortedDictionary a red-black tree?,I saw several  es about this on the Internet but no official documentation? Can anyone tell me where I can get information about this?,Not-TD-related,Other,,,,0.131,0.869,0,-0.4871
15247247,What is the most efficient loop in c,"There are a number of different way to accomplish the same simple loop though the items of an object in c. This has made me wonder if there is any reason be it performance or ease of use, as to use on over the other. Or is it just down to personal preference. Take a simple object  var myList = List  MyObject  ; reLets assume the object is filled and we want to iterate over the items. Method 1. foreach(var item in myList) { //Do stuff}reMethod 2  myList.Foreach(ml =   { //Do stuff});reMethod 3  while (myList.MoveNext()) { //Do stuff}reMethod 4  for (int i = 0; i    myList.Count; i++){ //Do stuff }reWhat I was wondering is do each of these compiled down to the same thing? is there a clear performance advantage for using one over the others?or is this just down to personal preference when coding?Have I missed any?",Not-TD-related,Other,,,,0.016,0.888,0.096,0.8504
15392247,Display HTML table in center of screen,"Having problems with elegantly showing this table in the center of the screen. Please advice?The web link is pasted below:a href=http://www.technicaldebt.co.uk/fyprototype/databasetest.php rel=nofollowhttp://www.technicaldebt.co.uk/fyprototype/databasetest.php/aAny help is greatly appreciated.   table border=5 cellspacing=2 cellpadding=2    tr    td    font face=Arial, Helvetica, sans-serif  Title  /font    /td    td    font face=Arial, Helvetica, sans-serif  First Name  /font    /td     td    font face=Arial, Helvetica, sans-serif  Last Name  /font    /td    td    font face=Arial, Helvetica, sans-serif  E-mail Address  /font    /td    td    font face=Arial, Helvetica, sans-serif  Project Title  /font    /td    /tr    ?php$i=0;while ($i    $num) {$f1=mysql_result($result,$i,Titles);$f2=mysql_result($result,$i,FirstName);$f3=mysql_result($result,$i,LastName);$f4=mysql_result($result,$i,Email);$f5=mysql_result($result,$i,ProjectRoles);?    tr    td    font face=Arial, Helvetica, sans-serif    ?php echo $f1; ?    /font    /td    td    font face=Arial, Helvetica, sans-serif    ?php echo $f2; ?    /font    /td    td    font face=Arial, Helvetica, sans-serif    ?php echo $f3; ?    /font    /td    td    font face=Arial, Helvetica, sans-serif    ?php echo $f4; ?    /font    /td    td    font face=Arial, Helvetica, sans-serif    ?php echo $f5; ?    /font    /td    /tr    ?php$i++;}?  re",Not-TD-related,Other,,,,0.019,0.895,0.086,0.8675
15802337,Scaling to support a massive amount of traffic in a short period of time,"Until now, our site has had a modest amount of traffic. None of our developers are big ops guys, but we've stayed ahead of it and keep the site up and running pretty quick. That said, our dev team is stretched, we've accumulated some technical debt, and there's plenty of opportunity to optimize.Without getting into specifics, we just found out that we'll be expecting a massive amount of traffic in the near future in a very short period time. On the order of several million hits in a few hours. Scaling is one thing, but this is several orders of magnitude greater than what we're seeing now.We're a Rails app hosted on S3 using ELB, and Postgresql.I wanted to field some recommendations for broad starting points for scaling and load testing given this situation.ulliUpdate: Sorry, EC2, late night :)",Not-TD-related,Other,,,,0.032,0.865,0.103,0.9109
16712503,Is it possible to get the technical debt per file in Sonar?,Is it possible to get the technical debt per file in Sonar and preferably export it so it is possible to put in a chart?,Not-TD-related,Other,,,,0.098,0.902,0,-0.3612
16871600,Is ViewBag and ViewData also part of state management in asp.net mvc?,Can somebody please tell me that whether ViewData and ViewBag are also part of asp.net mvc state management or not? Thanks,Not-TD-related,Other,,,,0.101,0.801,0.097,-0.0274
17727289,How to calculate the technical debt?,"We try to use Sonar to manage the software quality, like this page, we can get the technical debt. a href=http://www.sonarqube.org/sqale-the-ultimate-quality-model-to-assess-technical-debt/ rel=nofollowhttp://www.sonarqube.org/sqale-the-ultimate-quality-model-to-assess-technical-debt//aMy question is, how to define the debt to fix a violation, remove some duplicated code or a new test case. Is there any calculate algorithm?",Not-TD-related,Other,,,,0.162,0.789,0.049,-0.6908
17762744,Error deserializing a php soap webservice with a .NET WCF Client,I am having an issue in deserializing the soap XML from a php web serviceThe XML that is coming back from the web service has a tag code  item xsi:type=xsd:  Basically its saying codetype= which throws an error:block e The specified type was not recognized: name=':'/block eis the attribute codexsi:type=xsd: valid?I've asked out client to remove it but they are saying they cannot.,Not-TD-related,Other,,,,0,1,0,0
17771512,Implementing scrum-but for first time: how to deal with technical pre-requisites?,"After working Scrum(ish) in a previous workplace, I am trying to implement it in my new place of work for a brand new project (I am no scrum expert). We have some pre-requisites to code before we can begin working on the stories (which are being groomed in the mean time). Things like database design, api design, etc. We plan to use two week iterations and it's just not clear to me how the first one (or two) can provide something useful to the customer and ""potentially shippable"" if we first have to ""lay down some groundwork"" ? Any ideas on how to treat this?",Not-TD-related,Other,,,,0.04,0.882,0.078,0.6219
19263645,what is core purpose of IDE refractor option?,To change name of folder or file NET-BEANS and ECLIPSE IDE both offer an option i.e. REFRACTOR What actually is the core purpose of this option? or other way around how can we get benefit from this option while developmentPLEASE explain it with some hello word type example.,Not-TD-related,Other,,,,0,0.94,0.06,0.4588
19421526,How to use Facebook SDK with android.app.Fragment,"I'm trying to follow the samples of Facebook SDK from developers.facebook.com site.However, what I know is it's Facebook SDK is working with Activity and android.support.v4.app.Fragment only.Now in my application I'm using android.app.Fragment with all Fragments in my project and I don't really care about support to older version of Android.Question is (in case I really need to use Facebook SDK with Fragment (means I don't use it with Activity) ulliHow can I use it with android.app.Fragment? if there's no possible way for first questionulliHow can I make android.support.v4.app.Fragment works with other android.app.Fragment?Thank you",Not-TD-related,Other,,,,0.059,0.909,0.032,-0.3487
20182049,Can I dynamically calculate technical debt?,"I have a large number of individual, unrelated Java programs in a Programs folder, and I'd really like to be able to calculate a technical debt score automatically for each individual program. I understand that SonarQube can allow you to do this (kind of) with a href=http://docs.codehaus.org/display/SONAR/Analyzing+with+SonarQube+RunnerSonar-Runner/a, however I would really like a way to do this dynamically, so I can have a script analyze and write technical debt scores of all the programs within the Programs folder into a csv. I am perfectly willing and happy to try any other sort of technical debt software (or quality for that matter) if it can do this for me. I would just really appreciate any input, or thoughts about if this would even be possible?",Not-TD-related,Other,,,,0.058,0.769,0.173,0.9332
20746316,Business Aspect of Agile,"As I understand Agile is more or less like an open/flexible process. Meaning I anticipate and expect stakeholders' rapid changes.But how about the business aspect of this? What if the stakeholder has a specific budget for a product?What if their changes go beyond the specified budget?Is there a term as an ""agile contract""?",Not-TD-related,Other,,,,0,0.949,0.051,0.401
22540066,Why does SonarQ say 'Using' block does not dispose?,"Here is what Sonar is saying:  EnsureLocalDisposalRule Open Updated: 6 days Technical debt: 1 hours Local 'da' of type 'SqlDataAdapter' is not guaranteed to be disposed of. reHere is the code:  conn1.Open() Using da As New SqlDataAdapter(qry, conn1) 'fill data set 1 for combobox da.Fill(ds1) End Using ds1.Dispose() With CompanyCbx 'what the user sees .DisplayMember = CMPNY_NM 'value behind each display member .ValueMember = CMPNY_SEQ_ID .DataSource = ds1.Tables(0) .SelectedIndex = 0 End With 'close connection conn1.Close() 'Dispose connection conn1.Dispose()reThe documentation regarding the codeUsing block states that it disposes of whatever it is 'using,' so I don't understand the error.Here is Sonar's documentation: EnsureLocalDisposalRuleThis rule checks that disposable locals are always disposed of before the method returns. Use a 'using' statement (or a try/finally block) to guarantee local disposal even in the event an unhandled exception occurs. Link to the official Mono Gendarme documentation",Not-TD-related,Other,,,,0.039,0.929,0.032,-0.25
23421864,Can a task done for next sprint be classified as a spike?,"If all the user stories for the current sprint are completed and we work on a task that will be for the next sprint, then how can we classify it?Can it be called as ""Spike""?",Not-TD-related,Other,,,,0,1,0,0
23423347,SonarQube with remote database is too slow,"I'm new to SonarQube. I'm trying to analyze my project sources with SonarQube 4.2 with Maven3.SonarQube is installed on my local PC and it's database(i.e MySQL) is installed on a remote host.I executed sonar:sonar goarl by maven, then some process between Index files and Quality profile was too slow(about 7min). Why is it such a slow? When MySQL was installed on same host with SonarQube, it's not so slow.Does anybody knows how to fix this problem?<code>Thanks,",Not-TD-related,Other,,,,0,1,0,0
24291048,How to enable RCI in SonarQube 4.3?,"I am doing code anaylysis using SonarQube version 4.3 with Sonar Runner 2.4. But I don't see RCI (Rules compliance index) which was there in version 3.7.Question:olliis RCI replaced by Technical Debts ? (as in a href=https://jira.codehaus.org/browse/SONAR-4820 rel=nofollowSONAR-4820/a)liis it possible to view RCI in SonarQube version 4.3, if so how ?",Not-TD-related,Other,,,,0,1,0,0
24953951,Eclipse / Sonar Analysis - java.lang.OutOfMemoryError: PermGen space,"Good morning,i am trying to syncronize my Eclipse project with the Sonar server we have in our Company. I tried with 2 completely different computers/environments but cannot find a solution, even if I tried to apply every suggested tip found here (stackOverflow) or elsewhere.It seems (as clearly explained by the stacktrace) that I may have a memory lack and, since the project is really huge, it may be obvious, but pheraps I cannot (or I don't know) how to launch eclipse with more memory.I modified the eclipse.ini as below: <code>Any other suggestions?ThanksAlessandro",Not-TD-related,Other,,,,0.058,0.847,0.095,0.5418
25025178,What is the best approach for control version branching in Scrum?,"Having multiple teams working on a single product with a single Product Backlog, is it a good idea for each member of those teams to frequently commit their code to the trunk, rather than having branches for each team?So they would be working separately on Sprints, synchronize the trunk and their branches frequently after code reviews and add their working code within to their branch(es) first?Or What could be the approach we can use, is there any standard model for it?",Not-TD-related,Other,,,,0,0.931,0.069,0.6848
25205171,How do I ignore files/folders in SonarQube 4.4's Technical Debt calulation?,"I have a project that I am using SonarQube 4.4 to track code quality on. The Technical Debt section (no longer a plug-in as they have merged it into the main project I believe) picks up several open source libraries in my project that I would like to ignore. Other sections in SonarQube allow for exclusions (i.e. Jacoco and/or Cobertura honor the exclusions in the exclusions tab) but the Technical Debt calculator does not seem to honor them. Is it possible to exclude files from Technical Debt analysis? If so, how?",Not-TD-related,Other,,,,0.129,0.773,0.098,-0.4784
25627617,Analysing with SonarQube causes 0 files indexed and no reports (Maven Project),"I have some trouble using SonarQube on an extern server. I'm working with SonarQube just for a couple days now and when I analyze my Maven project local everything is working fine. We are using a Postgresql database.But there are some problems when I try to analyze a project on an extern SonarQube server.The Environment:/I'm using SonarQube 4.4 and Maven 3.3. Please find my Maven settings.xml down below.    <code>.Just to make this clear, the project is not on the same mashine as sonarqube. Does this matter for indexing files?Please consider that I'm a complete newbie to SonarQubeBest regardsChristian",Not-TD-related,Other,,,,0.055,0.862,0.083,0.2083
25734090,Polymer core-submenu styling in Firefox?,"This may be a more general purpose question than how I stated it, but I wanted to be specific as possible. I'm not sure how to use jsFiddle with Polymer, with all of the imports, but I hope some code samples will suffice.I have a core-menu that looks like this:<core-menu><core-submenu label=""First submenu""><core-item label=""Test submenu item 1""><core-item label=""Test submenu item 2""><core-item label=""Test submenu item 3""><core-item label=""Test submenu item 4""></core-submenu><core-submenu label=""Second submenu""></core-submenu></core-menu>What I'm trying to do is style the core-items in the submenu differently from the core-submenu itself. The core-submenu core-item selector works in Chrome, but in Firefox it is selecting the text ""First submenu"" and ""Second submenu"" as well.I looked into the firefox dev tools, and it looks like Polymer is creating this sort of DOM tree:<core-menu><core-submenu><core-item><div id=""label"">First submenu</div></core-item><core-menu id=""submenu""><core-item>Test submenu item 1</core-item>...So, I tried #submenu core-item which works, but now I have the opposite problem! Chrome is now not finding the items, since the polyfill doesn't add the submenu id to the core-submenu tag. I've been trying for an hour to find a selector (or set of selectors) that will work across both browsers. Any help?",Not-TD-related,Other,,,,0.028,0.88,0.092,0.928
26214365,Sonarqube with gallio openCover - how to?,"I am trying to get the C unit test coverage.br /Below is my sonar setup, but when I run sonar runner I don't see any thing related tounite test coverage and the result on browser it does not show any unit testcoverage.br /My question is: the sonar c a <code>",Not-TD-related,Other,,,,0,1,0,0
26775613,Not able to execute java-custom-rules plugin in SonarQube,I am a newbie to SonarQube and I am working on creating a new Metrics for SOnarQube.As a part of learning am trying the examples in the SonarQube site.I was trying the example given a href=https://github.com/SonarSource/sonar-examples/tree/masterlugins/java-custom-rules rel=nofollowhere/a I used maven clean and maven build in eclipse and created the jar file. I placed the jar file in the extensionlugins directory in the SonarQube server (I have locally installed the server in my Win 7 machine).Then I used SonarQube Runner to link my project with SonarQube. How ever am getting this error: C:\xxx\Desktop\Workspace\sonar-test  sonar-runner -eC:\sonar-runner-2.4SonarQube Runner 2.4Java 1.6.0_21 Sun Microsystems Inc. (32-bit)Windows 7 6.1 x86INFO: <code>But when I execute with the SonarQube Runner am getting the above error.Kindly help me with this.,Not-TD-related,Other,,,,0.026,0.862,0.112,0.851
27614985,Sonar runner codenarc sensor ignore violation from Codenarc,I have grails project with a href=http://grails.orgluginnarc rel=nofollow noreferrerCodeNarc Plugin/a installed and generated xml report. Installed and configured SonarQube with following configurations and versions:<code>I have installed all necessary plugins in SonarQube Serverimg src=https://i.stack.imgur.com/WCjCs.png alt=Installed Plugin for SonarQube ServerAfter all configuration why these rules are getting ignored and zero issues generated for project ?,Not-TD-related,Other,,,,0.045,0.955,0,-0.3182
27653261,Javascript Closure Within a For Loop (2 closures involved - an $http.get call and a $scope.$watch) using angular.js,"I'm creating an angular app using a href=https://angular-ui.github.io/angular-google-maps/!/api rel=nofollowangular-google-maps/a. What I'm trying to do is loop through an array of locations in order to place a marker at each location's latitude and longitude. However, because I'm using a couple of closures within my for-loop, a marker is only showing up at the last entry of the array. Here's the code: $scope.petMarkers = [];$http.get('/apiets').success(function(foundPets){ $scope.foundPets = foundPets; var listOfPets = $scope.foundPets; var markerCreator = function(arrayOfPets){ for (var i = 0; i    arrayOfPets.length; i++){ var singlePet = arrayOfPets[i]; var petName = arrayOfPets[i].name; var identity = singlePet._id; var location = singlePet.addressFound; var split = location.split(' '); var joined = split.join('+'); var httpAddress = 'http://maps.google.com/maps/api/geocode/json?address=' + joined + ' sensor=false'; // anonymous function keeps reference to i, and when console.log is called, for loop has already finished and value of i is set to 4 $http.get(httpAddress).success(function(mapDataAgain){ var ladder = mapDataAgain.results[0].geometry.location.lat; var longer = mapDataAgain.results[0].geometry.location.lng; var obj = { latitude: ladder, longitude: longer, title: petName, id: i }; $scope.$watch(function(){ console.log('we are in scope.watch'); return $scope.map.bounds; }, function(){ var markers = []; //markers.push(obj); $scope.petMarkers.push(obj); //$scope.petMarkers = markers; console.log('markers = ', $scope.petMarkers); }, true); }); }; }; markerCreator(listOfPets);});rehrAny ideas as to how to use an immediately invoked function expression(IIFE) with this code? I'm having trouble figuring out whether I need two IIFEs (one for the anonymous function called upon success of the $http call and one for the anonymous function called as the argument to $scope.$watch). I'm kind of lost here, so any explanation/help/suggestions would be helpful.",Not-TD-related,Other,,,,0.034,0.915,0.051,0.6071
27914683,point to point vs web services integration,There were times when organizations used point to point methods to integrate applications which the middle-ware tools helped to avoid by allowing applications to focus on their core area instead of each one of them writing integration logic. Now the applications are saying that they are using web services for integration and not really need a middle-ware. How can i convince applications that middle-ware can still help in this situation ? According to me web services is just an advanced point to point solution. Is SOA Governance the only selling point here ?,Not-TD-related,Other,,,,0.023,0.879,0.098,0.7319
28198854,Analyze SonarQube Eclipse - Caused by: org.apache.bcel.classfile.ClassFormatException: Invalid byte tag in constant pool: 15,"I'm using Eclipse Luna (codeBuild id: 20150109-0600, 64 bits) on Windows with SonarQube plugin (codeSonarQube Java Analyser 3.4.0.20140404-0949-RELEASE)When I try to Run Analyze, the plugin can connect with the server and download the issues of the last analyze (the problems are shown on SonarQube Issues view), but after that there is this error: java.lang.IllegalStateException: Error status [command: C:\Program Files\Java\jre8\bin\java.exe -cp D:\temp\sonar-runner-impl1326048247551966004.jar org.sonar.runner.impl.BatchLauncherMain D:\temp\sonar-project7307491695046280128.properties]: 1at org.sonar.runner.api.ForkedRunner.fork(ForkedRunner.java:199)at org.sonar.runner.api.ForkedRunner.doExecute(ForkedRunner.java:144)at org.sonar.runner.api.Runner.execute(Runner.java:90)at org.sonar.ide.eclipse.core.internal.jobs.AnalyseProjectJob.run(AnalyseProjectJob.java:343)at org.sonar.ide.eclipse.core.internal.jobs.AnalyseProjectJob.run(AnalyseProjectJob.java:130)at org.eclipse.core.internal.jobs.Worker.run(Worker.java:54)reThe strange thing is that in codeD:\temp there is no file codesonar-runner-implXXX.jar or codesonar-projectXXX.properties but there emare/em files codesonar-runner-batchXXX.jar (like codesonar-runner-batc316679692029245803.jar)Another strange thing, the command line is using a JRE 8, but my JAVA_HOME is a JDK 7, the projet where I'm running the Analyze is configured to use a JDK 7 and all my Installed Jres on Eclipse are acctually JDKs.Can someone help me?========================================================================Hi1 - About the temp files, they are really created and then deleted (I made a test monitoring the temp file while running the Analyze)2 - And I could even copy the files and run the command line by hand, in this case i could se the real stack trace: C:\  c:\Progra~1\Java\jdk1.8.0\jre\bin\java.exe -cp D:\temp\sonar-runner-impl5987517469765765781.jar org.sonar.runner.impl.BatchLauncherMain D:\temp\sonar-project5904228863019510021.propertiesINFO: SonarQube Server 4.3.214:01:54.841 INFO - Preview mode14:01:54.851 INFO - Load batch settings14:01:55.338 INFO - User cache: C:\Users\fred\.sonar\cache14:01:55.353 INFO - Install plugins14:01:55.391 INFO - Include plugins:14:01:55.391 INFO - Exclude plugins: devcockpit, buildstability, pdfreport, report, buildbreaker, scmactivity, views, jiraException in thread main org.sonar.runner.impl.RunnerException: Unable to execute Sonar at org.sonar.runner.impl.BatchLauncher$1.delegateExecution(BatchLauncher.java:91) at org.sonar.runner.impl.BatchLauncher$1.run(BatchLauncher.java:75) at java.security.AccessController.doPrivileged(Native Method) at org.sonar.runner.impl.BatchLauncher.doExecute(BatchLauncher.java:69) at org.sonar.runner.impl.BatchLauncher.execute(BatchLauncher.java:50) at org.sonar.runner.impl.BatchLauncherMain.execute(BatchLauncherMain.java:41) at org.sonar.runner.impl.BatchLauncherMain.main(BatchLauncherMain.java:59)Caused by: org.sonar.api.utils.SonarException: You're not authorized to execute a dry run analysis. Please contact your SonarQube administrator. at org.sonar.batch.bootstrap.ServerClient.handleHttpException(ServerClient.java:120) at org.sonar.batch.bootstrap.ServerClient.download(ServerClient.java:71) at org.sonar.batch.bootstrap.PreviewDatabase.downloadDatabase(PreviewDatabase.java:85) at org.sonar.batch.bootstrap.PreviewDatabase.start(PreviewDatabase.java:67) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:483) at org.picocontainer.lifecycle.ReflectionLifecycleStrategy.invokeMethod(ReflectionLifecycleStrategy.java:110) at org.picocontainer.lifecycle.ReflectionLifecycleStrategy.start(ReflectionLifecycleStrategy.java:89) at org.picocontainer.injectors.AbstractInjectionFactory$LifecycleAdapter.start(AbstractInjectionFactory.java:84) at org.picocontainer.behaviors.AbstractBehavior.start(AbstractBehavior.java:169) at org.picocontainer.behaviors.Stored$RealComponentLifecycle.start(Stored.java:132) at org.picocontainer.behaviors.Stored.start(Stored.java:110) at org.picocontainer.DefaultPicoContainer.potentiallyStartAdapter(DefaultPicoContainer.java:1015) at org.picocontainer.DefaultPicoContainer.startAdapters(DefaultPicoContainer.java:1008) at org.picocontainer.DefaultPicoContainer.start(DefaultPicoContainer.java:766) at org.sonar.api.platform.ComponentContainer.startComponents(ComponentContainer.java:91) at org.sonar.api.platform.ComponentContainer.execute(ComponentContainer.java:77) at org.sonar.batch.bootstrapper.Batch.startBatch(Batch.java:92) at org.sonar.batch.bootstrapper.Batch.execute(Batch.java:74) at org.sonar.runner.batch.IsolatedLauncher.execute(IsolatedLauncher.java:45) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:483) at org.sonar.runner.impl.BatchLauncher$1.delegateExecution(BatchLauncher.java:87) ... 6 moreC:\  re3 - The real problem seems to be a lack of a permission...But how can I give permission to dry run analysis to an user?========================================================================3 - I could solve the permission problem adding Execute Preview Analysis permission to the users.4 - Now other error happened: Caused by: org.apache.bcel.classfile.ClassFormatException: Invalid byte tag in constant pool: 15And i have no clue about it... C:\  c:\Progra~1\Java\jdk1.8.0\jre\bin\java.exe -cp D:\temp\sonar-runner-impl5987517469765765781.jar org.sonar.runner.impl.BatchLauncherMain D:\temp\sonar-project5904228863019510021.propertiesINFO: SonarQube Server 4.3.214:53:18.370 INFO - Preview mode14:53:18.389 INFO - Load batch settings14:53:18.794 INFO - User cache: C:\Users\fred\.sonar\cache14:53:18.814 INFO - Install plugins14:53:18.854 INFO - Include plugins:14:53:18.854 INFO - Exclude plugins: devcockpit, buildstability, pdfreport, report, buildbreaker, scmactivity, views, jira14:53:19.550 INFO - Create JDBC datasource for jdbc::D:\workspaces\workspace-fred\.metadata\.plugins\org.eclipse.core.resources\.projects\sgl\org.sonar.ide.eclipse.core\.sonartmp\preview1422550399090-014:53:23.617 INFO - Initializing Hibernate14:53:26.543 INFO - Load project settings14:53:26.634 INFO - Apply project exclusions14:53:26.862 INFO - ------------- Scan sgl14:53:26.873 INFO - Load module settings14:53:27.828 INFO - Loading technical debt model...14:53:27.842 INFO - Loading technical debt model done: 14 ms14:53:27.842 INFO - Loading rules...14:53:28.111 INFO - Loading rules done: 269 ms14:53:28.152 INFO - Configure Maven plugins14:53:28.356 INFO - Compare to previous analysis (2015-01-29)14:53:28.366 INFO - Compare over 30 days (2014-12-30, analysis of 2015-01-01 02:44:35.053)14:53:28.376 INFO - Compare to previous version (2015-01-29)14:53:28.376 INFO - No quality gate is configured.14:53:28.485 INFO - Base dir: D:\workspaces\workspace-fred\sgl14:53:28.485 INFO - Working dir: D:\workspaces\workspace-fred\.metadata\.plugins\org.eclipse.core.resources\.projects\sgl\org.sonar.ide.eclipse.core14:53:28.485 INFO - Source dirs: D:\workspaces\workspace-fred\sgl\webApplication, D:\workspaces\workspace-fred\sgl\clientconf, D:\workspaces\workspace-fred\sgl\src\java, D:\workspaces\workspace-fred\sgl\src\conf, D:\workspaces\workspace-fred\sgl\conf14:53:28.485 INFO - Test dirs: D:\workspaces\workspace-fred\sgl\src\test14:53:28.485 INFO - Binary dirs: D:\workspaces\workspace-fred\sgl\webApplication\WEB-INF\classes14:53:28.485 INFO - Source encoding: UTF-8, default locale: en_US14:53:28.485 INFO - Index files14:53:46.434 INFO - 959 files indexed14:53:50.916 INFO - Quality profile for java: Minds Java Profile14:53:51.088 INFO - Sensor JavaSquidSensor...14:53:51.223 INFO - Java Main Files AST scan...14:53:51.227 INFO - 946 source files to be analyzed14:54:01.229 INFO - 127/946 files analyzed, current is D:\workspaces\workspace-fred\sgl\src\java\br\com\mindsatwork\sgl\model\DatabaseVersion.java14:54:11.240 INFO - 176/946 files analyzed, current is D:\workspaces\workspace-fred\sgl\src\java\br\com\mindsatwork\sgl\model\MaterialReservationStatus.java14:54:21.269 INFO - 240/946 files analyzed, current is D:\workspaces\workspace-fred\sgl\src\java\br\com\mindsatwork\sgl\model\strategy\AbstractTicketChangeRequestStatusStrategy.java14:54:31.299 INFO - 321/946 files analyzed, current is D:\workspaces\workspace-fred\sgl\src\java\br\com\mindsatwork\sgl\permission\ApplicationModuleStrategyCourse.java14:54:36.119 ERROR - Class not found: org.slf4j.Logger14:54:41.320 INFO - 455/946 files analyzed, current is D:\workspaces\workspace-fred\sgl\src\java\br\com\mindsatwork\sgl\web\action\ActionInitSaveCorrectiveMaintenance.java14:54:51.324 INFO - 541/946 files analyzed, current is D:\workspaces\workspace-fred\sgl\src\java\br\com\mindsatwork\sgl\web\action\ActionListProvider.java14:55:01.370 INFO - 614/946 files analyzed, current is D:\workspaces\workspace-fred\sgl\src\java\br\com\mindsatwork\sgl\web\action\ActionSearch.java14:55:11.395 INFO - 674/946 files analyzed, current is D:\workspaces\workspace-fred\sgl\src\java\br\com\mindsatwork\sgl\web\dwr\MessageManager.java14:55:21.398 INFO - 748/946 files analyzed, current is D:\workspaces\workspace-fred\sgl\src\java\br\com\mindsatwork\sgl\web\service\model\xstream\WsPackageTrackingMainData.java14:55:23.288 ERROR - Class not found: javax.el.ELContext14:55:23.650 ERROR - Class not found: javax.el.ELContext14:55:23.781 ERROR - Class not found: javax.el.ELContext14:55:23.890 ERROR - Class not found: javax.el.ELContext14:55:24.429 ERROR - Class not found: javax.el.ELContext14:55:24.531 ERROR - Class not found: javax.el.ELContext14:55:24.657 ERROR - Class not found: javax.el.ELContext14:55:24.757 ERROR - Class not found: javax.el.ELContext14:55:24.877 ERROR - Class not found: javax.el.ELContext14:55:24.982 ERROR - Class not found: javax.el.ELContext14:55:25.102 ERROR - Class not found: javax.el.ELContext14:55:25.212 ERROR - Class not found: javax.el.ELContext14:55:25.332 ERROR - Class not found: javax.el.ELContext14:55:25.437 ERROR - Class not found: javax.el.ELContext14:55:25.537 ERROR - Class not found: javax.el.ELContext14:55:25.639 ERROR - Class not found: javax.el.ELContext14:55:25.731 ERROR - Class not found: javax.el.ELContext14:55:25.931 ERROR - Class not found: javax.el.ELContext14:55:26.022 ERROR - Class not found: javax.el.ELContext14:55:26.127 ERROR - Class not found: javax.el.ELContext14:55:26.295 ERROR - Class not found: javax.el.ELContext14:55:26.398 ERROR - Class not found: javax.el.ELContext14:55:26.479 ERROR - Class not found: javax.el.ELContext14:55:26.560 ERROR - Class not found: javax.el.ELContext14:55:26.665 ERROR - Class not found: javax.el.ELContext14:55:26.786 ERROR - Class not found: javax.el.ELContext14:55:26.878 ERROR - Class not found: javax.el.ELContext14:55:27.438 ERROR - Class not found: javax.el.ELContext14:55:27.741 ERROR - Class not found: javax.el.ELContext14:55:28.152 ERROR - Class not found: javax.el.ELContext14:55:28.366 ERROR - Class not found: javax.el.ELContext14:55:28.457 ERROR - Class not found: javax.el.ELContext14:55:28.556 ERROR - Class not found: javax.el.ELContext14:55:28.631 ERROR - Class not found: javax.el.ELContext14:55:28.709 ERROR - Class not found: javax.el.ELContext14:55:28.801 ERROR - Class not found: javax.el.ELContext14:55:28.873 ERROR - Class not found: javax.el.ELContext14:55:28.953 ERROR - Class not found: javax.el.ELContext14:55:29.026 ERROR - Class not found: javax.el.ELContext14:55:29.355 ERROR - Class not found: javax.el.ELContext14:55:29.435 ERROR - Class not found: javax.el.ELContext14:55:29.624 ERROR - Class not found: javax.el.ELContext14:55:29.694 ERROR - Class not found: javax.el.ELContext14:55:31.380 INFO - 848/946 files analyzed, current is D:\workspaces\workspace-fred\sgl\src\java\br\com\mindsatwork\sgl\web\taglib\display\export\ReportExcelHssfView.java14:55:31.436 ERROR - Class not found: javax.el.ELContext14:55:31.536 ERROR - Class not found: javax.el.ELContext14:55:39.628 INFO - 946/946 source files analyzed14:55:39.791 INFO - Java Main Files AST scan done: 108568 ms14:55:39.880 INFO - Java bytecode scan...14:55:41.734 INFO - Java bytecode scan done: 1854 ms14:55:41.734 INFO - Java Test Files AST scan...14:55:41.735 INFO - 13 source files to be analyzed14:55:41.964 INFO - Java Test Files AST scan done: 230 ms14:55:41.964 INFO - 13/13 source files analyzed14:55:42.290 INFO - Package design analysis...14:55:43.038 INFO - Package design analysis done: 748 ms14:55:43.509 INFO - Sensor JavaSquidSensor done: 112421 ms14:55:43.509 INFO - Sensor QProfileSensor...14:55:43.512 INFO - Sensor QProfileSensor done: 3 ms14:55:43.512 INFO - Sensor PmdSensor...14:55:43.515 INFO - Execute PMD 5.1.1...14:55:43.546 INFO - Java version: 1.714:55:43.593 INFO - PMD configuration: D:\workspaces\workspace-fred\.metadata\.plugins\org.eclipse.core.resources\.projects\sgl\org.sonar.ide.eclipse.core\pmd.xml14:55:52.299 INFO - PMD configuration: D:\workspaces\workspace-fred\.metadata\.plugins\org.eclipse.core.resources\.projects\sgl\org.sonar.ide.eclipse.core\pmd-unit-tests.xml14:55:52.300 INFO - Execute PMD 5.1.1 done: 8785 ms14:55:52.328 INFO - Sensor PmdSensor done: 8816 ms14:55:52.328 INFO - Sensor SurefireSensor...14:55:52.330 INFO - parsing D:\workspaces\workspace-fred\.metadata\.plugins\org.eclipse.core.resources\.projects\sgl\org.sonar.ide.eclipse.core\build\surefire-reports14:55:52.330 WARN - Reports path not found: D:\workspaces\workspace-fred\.metadata\.plugins\org.eclipse.core.resources\.projects\sgl\org.sonar.ide.eclipse.core\build\surefire-reports14:55:52.330 INFO - Sensor SurefireSensor done: 2 ms14:55:52.330 INFO - Sensor InitialOpenIssuesSensor...14:55:52.373 INFO - Sensor InitialOpenIssuesSensor done: 43 ms14:55:52.374 INFO - Sensor ProfileEventsSensor...14:55:52.396 INFO - Sensor ProfileEventsSensor done: 22 ms14:55:52.396 INFO - Sensor ProjectLinksSensor...14:55:52.409 INFO - Sensor ProjectLinksSensor done: 13 ms14:55:52.410 INFO - Sensor FindbugsSensor...14:55:52.412 INFO - Execute Findbugs 2.0.3...14:55:53.888 INFO - Findbugs output report: D:\workspaces\workspace-fred\.metadata\.plugins\org.eclipse.core.resources\.projects\sgl\org.sonar.ide.eclipse.core\findbugs-result.xmlException in thread main org.sonar.runner.impl.RunnerException: Unable to execute Sonar at org.sonar.runner.impl.BatchLauncher$1.delegateExecution(BatchLauncher.java:91) at org.sonar.runner.impl.BatchLauncher$1.run(BatchLauncher.java:75) at java.security.AccessController.doPrivileged(Native Method) at org.sonar.runner.impl.BatchLauncher.doExecute(BatchLauncher.java:69) at org.sonar.runner.impl.BatchLauncher.execute(BatchLauncher.java:50) at org.sonar.runner.impl.BatchLauncherMain.execute(BatchLauncherMain.java:41) at org.sonar.runner.impl.BatchLauncherMain.main(BatchLauncherMain.java:59)Caused by: org.sonar.api.utils.SonarException: Can not execute Findbugs at org.sonar.plugins.findbugs.FindbugsExecutor.execute(FindbugsExecutor.java:154) at org.sonar.plugins.findbugs.FindbugsSensor.analyse(FindbugsSensor.java:59) at org.sonar.batch.phases.SensorsExecutor.executeSensor(SensorsExecutor.java:79) at org.sonar.batch.phases.SensorsExecutor.execute(SensorsExecutor.java:70) at org.sonar.batch.phases.PhaseExecutor.execute(PhaseExecutor.java:131) at org.sonar.batch.scan.ModuleScanContainer.doAfterStart(ModuleScanContainer.java:178) at org.sonar.api.platform.ComponentContainer.startComponents(ComponentContainer.java:92) at org.sonar.api.platform.ComponentContainer.execute(ComponentContainer.java:77) at org.sonar.batch.scan.ProjectScanContainer.scan(ProjectScanContainer.java:199) at org.sonar.batch.scan.ProjectScanContainer.scanRecursively(ProjectScanContainer.java:194) at org.sonar.batch.scan.ProjectScanContainer.doAfterStart(ProjectScanContainer.java:187) at org.sonar.api.platform.ComponentContainer.startComponents(ComponentContainer.java:92) at org.sonar.api.platform.ComponentContainer.execute(ComponentContainer.java:77) at org.sonar.batch.scan.ScanTask.scan(ScanTask.java:56) at org.sonar.batch.scan.ScanTask.execute(ScanTask.java:44) at org.sonar.batch.bootstrap.TaskContainer.doAfterStart(TaskContainer.java:82) at org.sonar.api.platform.ComponentContainer.startComponents(ComponentContainer.java:92) at org.sonar.api.platform.ComponentContainer.execute(ComponentContainer.java:77) at org.sonar.batch.bootstrap.BootstrapContainer.executeTask(BootstrapContainer.java:175) at org.sonar.batch.bootstrap.BootstrapContainer.doAfterStart(BootstrapContainer.java:163) at org.sonar.api.platform.ComponentContainer.startComponents(ComponentContainer.java:92) at org.sonar.api.platform.ComponentContainer.execute(ComponentContainer.java:77) at org.sonar.batch.bootstrapper.Batch.startBatch(Batch.java:92) at org.sonar.batch.bootstrapper.Batch.execute(Batch.java:74) at org.sonar.runner.batch.IsolatedLauncher.execute(IsolatedLauncher.java:45) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:483) at org.sonar.runner.impl.BatchLauncher$1.delegateExecution(BatchLauncher.java:87) ... 6 moreCaused by: java.util.concurrent.ExecutionException: java.lang.ExceptionInInitializerError at java.util.concurrent.FutureTask.report(FutureTask.java:122) at java.util.concurrent.FutureTask.get(FutureTask.java:206) at org.sonar.plugins.findbugs.FindbugsExecutor.execute(FindbugsExecutor.java:146) ... 35 moreCaused by: java.lang.ExceptionInInitializerError at edu.umd.cs.findbugs.detect.SerializableIdiom.visit(SerializableIdiom.java:609) at edu.umd.cs.findbugs.visitclass.BetterVisitor.visitField(BetterVisitor.java:286) at org.apache.bcel.classfile.Field.accept(Field.java:92) at edu.umd.cs.findbugs.visitclass.PreorderVisitor.doVisitField(PreorderVisitor.java:266) at edu.umd.cs.findbugs.visitclass.PreorderVisitor.visitJavaClass(PreorderVisitor.java:349) at org.apache.bcel.classfile.JavaClass.accept(JavaClass.java:214) at edu.umd.cs.findbugs.detect.SerializableIdiom.visitClassContext(SerializableIdiom.java:133) at edu.umd.cs.findbugs.DetectorToDetector2Adapter.visitClass(DetectorToDetector2Adapter.java:74) at edu.umd.cs.findbugs.FindBugs2.analyzeApplication(FindBugs2.java:1209) at edu.umd.cs.findbugs.FindBugs2.execute(FindBugs2.java:282) at org.sonar.plugins.findbugs.FindbugsExecutor$FindbugsTask.call(FindbugsExecutor.java:201) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745)Caused by: org.apache.bcel.classfile.ClassFormatException: Invalid byte tag in constant pool: 15 at org.apache.bcel.classfile.Constant.readConstant(Constant.java:147) at org.apache.bcel.classfile.ConstantPool.  init  (ConstantPool.java:68) at org.apache.bcel.classfile.ClassParser.readConstantPool(ClassParser.java:237) at org.apache.bcel.classfile.ClassParser.parse(ClassParser.java:143) at org.apache.bcel.util.SyntheticRepository.loadClass(SyntheticRepository.java:179) at org.apache.bcel.util.SyntheticRepository.loadClass(SyntheticRepository.java:127) at edu.umd.cs.findbugs.ba.AnalysisContext.lookupSystemClass(AnalysisContext.java:501) at edu.umd.cs.findbugs.DeepSubtypeAnalysis.  clinit  (DeepSubtypeAnalysis.java:39) ... 15 moreC:\  re========================================================================HiFind a link that report the same error on tomcat and tells that it only happens with JDK 7.So I change de JDK version used by the Analyze (the project is compiled with JDK 7 64 bits)I tried:ulliJDK 6 32 bits: no error (but a lot of warnings java.lang.UnsupportedClassVersionError as project is compiled to java 7)liJDK 7 32 bits: no errorliJDK 7 64 bits: no errorliJDK 8 64 bits: Caused by: org.apache.bcel.classfile.ClassFormatException: Invalid byte tag in constant pool: 15It seems that Sonar only support JDK 8 on recent versions, since 4.3.But my Sonar server is 4.3.2, so it should support....hrOBS: If I compile the project with JDK 8 and then do an Anylize I receive a different error:... Caused by: java.lang.ArrayIndexOutOfBoundsException: 7352 at org.objectweb.asm.ClassReader.readClass(Unknown Source) at org.objectweb.asm.ClassReader.accept(Unknown Source) at edu.umd.cs.findbugs.asm.FBClassReader.accept(FBClassReader.java:44) at org.objectweb.asm.ClassReader.accept(Unknown Source) at edu.umd.cs.findbugs.classfile.engine.ClassParserUsingASM.parse(ClassParserUsingASM.java:110) at edu.umd.cs.findbugs.classfile.engine.ClassParserUsingASM.parse(ClassParserUsingASM.java:587) at edu.umd.cs.findbugs.classfile.engine.ClassInfoAnalysisEngine.analyze(ClassInfoAnalysisEngine.java:76) at edu.umd.cs.findbugs.classfile.engine.ClassInfoAnalysisEngine.analyze(ClassInfoAnalysisEngine.java:38) at edu.umd.cs.findbugs.classfile.impl.AnalysisCache.getClassAnalysis(AnalysisCache.java:268) at edu.umd.cs.findbugs.ba.XFactory.getXClass(XFactory.java:652) at edu.umd.cs.findbugs.ba.AnalysisContext.setAppClassList(AnalysisContext.java:932) at edu.umd.cs.findbugs.FindBugs2.setAppClassList(FindBugs2.java:997) at edu.umd.cs.findbugs.FindBugs2.execute(FindBugs2.java:225) at org.sonar.plugins.findbugs.FindbugsExecutor$FindbugsTask.call(FindbugsExecutor.java:201) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745)re",Not-TD-related,Other,,,,0.184,0.802,0.014,-0.9998
28712446,sonarqube 5.0 giving Error getting generated key or setting result to parameter object message,"I am trying to use SonarQube 5.0 with Hudson 3.2.1.Sonar runner version 2.4.Once Hudson invokes a sonar analysis, it ends with a build failure. SonarQube is configured with Oracle 12c database using ojdbc7.jar driver.The log output -  [workspace] $ /opt/sonar-runner-2.4/bin/sonar-runner -Dsonar.jdbc.driver=oracle.jdbc.xa.client.OracleXADataSource -Dsonar.jdbc.url=jdbc:oracle:thin:@//host:port/URL id pass -Dsonar.host.url=http://host:port id pass -Dsonar.projectBaseDir=/basedir -Dsonar.projectName=prjName -Dsonar.projectVersion=1.0 -Dsonar.projectKey=org:prj -Dsonar.sources=.SonarQube Runner 2.4Java 1.7.0_75 Oracle Corporation (64-bit)Linux 2.6.18-308.el5 amd64INFO: Runner configuration file: /opt/sonar-runner-2.4/conf/sonar-runner.propertiesINFO: Project configuration file: NONEINFO: Default locale: en_US, source code encoding: UTF-8 (analysis is platform dependent)INFO: Work directory: /basedirINFO: SonarQube Server 5.004:04:54.792 INFO - Load global referentials...04:04:55.100 INFO - Load global referentials done: 311 ms04:04:55.105 INFO - User cache: /varb/hudson/.sonar/cache04:04:55.116 INFO - Install plugins04:04:55.196 INFO - Install JDBC driver04:04:55.205 INFO - Create JDBC datasource for jdbcURL04:04:59.095 INFO - Initializing Hibernate04:05:01.906 INFO - Load project referentials...04:05:02.242 INFO - Load project referentials done: 336 ms04:05:02.242 INFO - Load project settings04:05:02.594 INFO - Loading technical debt model...04:05:02.616 INFO - Loading technical debt model done: 21 ms04:05:02.622 INFO - Apply project exclusionsINFO: ------------------------------------------------------------------------INFO: EXECUTION FAILUREINFO: ------------------------------------------------------------------------Total time: 9.050sFinal Memory: 16M/242MINFO: ------------------------------------------------------------------------ERROR: Error during Sonar runner executionERROR: Unable to execute SonarERROR: Caused by: Error getting generated key or setting result to parameter object. Cause: java.lang.NullPointerExceptionERROR: ERROR: To see the full stack trace of the errors, re-run SonarQube Runner with the -e switch.ERROR: Re-run SonarQube Runner using the -X switch to enable full debug logging.Finished: FAILUREreI have replaced the actual parameters like host,port, jdbcurl with placeholders.",Not-TD-related,Other,,,,0.085,0.895,0.02,-0.9317
30323763,How to set technical debt for rules which SQALE remediation function is linear?,"I'm trying to set the technical debt issues against rules which SQALE remediation function is linear. I replaced a href=https://github.com/SonarCommunity/sonar-css/blame/master/css-checks/src/main/java/org/sonar/css/checks/ImportNumberThreshold.javaL71 rel=nofollowhttps://github.com/SonarCommunity/sonar-css/blame/master/css-checks/src/main/java/org/sonar/css/checks/ImportNumberThreshold.javaL71/a by  CheckMessage checkMessage = new CheckMessage(this, Reduce the number of @import. This sheet imports {0,number,integer} other sheets, + {1,number,integer} more than the {2,number,integer} maximum., currentImportCount, currentImportCount - DEFAULT_THRESHOLD, DEFAULT_THRESHOLD); checkMessage.setCost(1000.0); getContext().log(checkMessage);rebut it does not set the technical debt to 1,000 minutes. The technical debt remains 10 minutes for each issue whatever the number of imports beyond the limit.In my test file though, the following assertion is green:   CheckMessagesVerifier.verify(file.getCheckMessages()).next() .withMessage(Reduce the number of @import. This sheet imports 32 other sheets, 1 more than the 31 maximum.) .withCost(Double.valueOf(1000.0)) .noMore();reWhat am I missing?Thanks for your help!",Not-TD-related,Other,,,,0.068,0.874,0.058,-0.4926
30406828,CSS and Javascript inside single HTML file. Pro's & Cons?,What are the pro's and cons of putting css   javascript code in your html file. I'm teaching students who are just getting started and not sure if starting with external files would be the best way to start and if just having them add everything in a single file is more beneficial for the early learning stage. What are the pro's and cons?,Not-TD-related,Other,,,,0.029,0.863,0.108,0.7529
31069799,Sonarqube Javascript Coverage doesn't show source files,"I tried to display the coverage from a javascript project with Sonarqube. The value of the code coverage is correct but I can't see the source files.img src=https://i.stack.imgur.com/QRO4q.jpg alt=ScreenshotCurrently I have the following project structure: angular-playground+- app| +- scripts| | +- app.js+- build| +- coverage| | +- lcov.inforeThis is my codesonar-project.properties-File:  metadatasonar.projectKey=angular-playgroundsonar.projectName=angular-playgroundsonar.projectVersion=1.0.0 source folderssonar.language=jssonar.sourceEncoding=UTF-8sonar.sources=appsonar.tests=test coverage reportingsonar.javascript.lcov.reportPath=build/coverage/lcov.infosonar.surefire.reportsPath=build/reports/sonar.dynamicAnalysis=reuseReportsreThis is my codelcov.info-File: TN:SF:app/scripts/app.jsFNF:0FNH:0DA:11,1LF:1LH:1BRF:0BRH:0end_of_recordreand the debug log: SonarQube Runner 2.4Java 1.8.0_40 Oracle Corporation (64-bit)Windows 8.1 6.3 amd64INFO: Error stacktraces are turned on.INFO: Default locale: de_CH, source code encoding: UTF-8INFO: SonarQube Server 5.1.121:43:29.687 INFO - Load global repositories21:43:29.734 DEBUG - Download: http://  domain  /batch/global (no proxy)21:43:30.273 INFO - Load global repositories (done) | time=586ms21:43:30.289 INFO - Server id: 2015062316083621:43:30.320 INFO - Install plugins21:43:30.320 DEBUG - Download index of plugins21:43:30.320 DEBUG - Download: http://  domain  /deploylugins/index.txt (no proxy)21:43:30.945 DEBUG - Loaded 3329 properties from l10n bundles21:43:30.945 INFO - Install JDBC driver21:43:30.945 DEBUG - Download index of jdbc-driver21:43:30.945 DEBUG - Download: http://  domain  /deploy/jdbc-driver.txt (no proxy)21:43:31.070 INFO - Create JDBC datasource for jdbc:postgresql://  domain  /sonarqube?useUnicode=true characterEncoding=utf821:43:32.750 DEBUG - Testing JDBC connection21:43:35.255 DEBUG - Download: http://  domain  /api/server (no proxy)21:43:35.529 INFO - Initializing Hibernate21:43:35.529 DEBUG - hibernate.generate_statistics: false21:43:35.529 DEBUG - hibernate.dialect: org.sonar.core.persistence.dialect.PostgreSql$PostgreSQLWithDecimalDialect21:43:35.529 DEBUG - hibernate.connection.provider_class: org.sonar.jpa.session.CustomHibernateConnectionProvider21:43:39.321 INFO - Load project repositories21:43:39.321 DEBUG - Download: http://  domain  /batchroject?key=angular-playground preview=false (no proxy)21:43:41.045 INFO - Load project repositories (done) | time=1724ms21:43:41.045 INFO - Load project settings21:43:41.730 INFO - Load technical debt model21:43:41.871 DEBUG - Load technical debt model (done) | time=141ms21:43:41.885 INFO - Apply project exclusions21:43:43.195 WARN - 'sonar.dynamicAnalysis' is deprecated since version 4.3 and should no longer be used.21:43:43.242 DEBUG - Acquire semaphore on project : org.sonar.api.resources.Project@f94fc29[id=  null  ,key=angular-playground,qualifier=TRK], with key batch-angular-playground21:43:43.383 INFO - ------------- Scan angular-playground21:43:43.398 INFO - Load module settings21:43:43.892 DEBUG - Available languages:21:43:43.894 DEBUG - * Java =   java21:43:43.894 DEBUG - * JavaScript =   js21:43:44.161 INFO - Language is forced to js21:43:44.177 INFO - Load rules21:43:53.327 DEBUG - Load rules (done) | time=9150ms21:43:53.403 DEBUG - Updating semaphore batch-angular-playground21:43:53.533 DEBUG - Code colorizer, supported languages: 21:43:53.557 DEBUG - Initializers : 21:43:53.557 INFO - Base dir: C:\  cwd  \angular-playground21:43:53.558 INFO - Working dir: C:\  cwd  \angular-playground\.sonar21:43:53.560 INFO - Source paths: app21:43:53.561 INFO - Test paths: test21:43:53.562 INFO - Source encoding: UTF-8, default locale: de_CH21:43:53.563 INFO - Index files21:43:53.573 DEBUG - Declared extensions of language org.sonar.batch.repository.language.Language@566140d4 were converted to sonar.lang.patterns.java : **/*.java,**/*.jav21:43:53.573 DEBUG - Declared extensions of language org.sonar.batch.repository.language.Language@60a8d8d6 were converted to sonar.lang.patterns.js : **/*.js21:43:53.601 DEBUG - Language of file 'app/scripts/app.js' is detected to be 'js'21:43:53.614 DEBUG - Language of file 'app/scripts/controllers/main.js' is detected to be 'js'21:43:53.635 DEBUG - Language of file 'test/karma.ci.conf.js' is detected to be 'js'21:43:53.642 DEBUG - Language of file 'test/spec/controllers/main.js' is detected to be 'js'21:43:53.642 DEBUG - Language of file 'test/karma.conf.js' is detected to be 'js'21:43:53.658 INFO - 5 files indexed21:43:56.516 INFO - Quality profile for js: Sonar way21:43:57.456 INFO - JIRA issues sensor will not run as some parameters are missing.21:43:57.476 DEBUG - Sensors : Lines Sensor (wrapped) -   QProfileSensor -   InitialOpenIssuesSensor -   ProjectLinksSensor -   VersionEventsSensor -   JavaScriptSquidSensor -   SCM Sensor (wrapped) -   org.sonar.plugins.javascript.lcov.UTCoverageSensor@b39a3bf -   org.sonar.plugins.javascript.lcov.ITCoverageSensor@4da6546a -   CPD Sensor (wrapped)21:43:57.476 INFO - Sensor Lines Sensor (wrapped)21:43:57.533 INFO - Sensor Lines Sensor (wrapped) (done) | time=57ms21:43:57.534 INFO - Sensor QProfileSensor21:43:57.549 INFO - Sensor QProfileSensor (done) | time=15ms21:43:57.550 INFO - Sensor InitialOpenIssuesSensor21:43:57.655 INFO - Sensor InitialOpenIssuesSensor (done) | time=105ms21:43:57.655 INFO - Sensor ProjectLinksSensor21:43:57.733 INFO - Sensor ProjectLinksSensor (done) | time=78ms21:43:57.733 INFO - Sensor VersionEventsSensor21:43:57.920 INFO - Sensor VersionEventsSensor (done) | time=187ms21:43:57.921 INFO - Sensor JavaScriptSquidSensor21:43:58.952 INFO - 2 source files to be analyzed21:43:59.338 INFO - 2/2 source files analyzed21:43:59.370 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.21:43:59.385 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.21:43:59.448 INFO - Sensor JavaScriptSquidSensor (done) | time=1527ms21:43:59.448 INFO - Sensor SCM Sensor (wrapped)21:43:59.479 INFO - Sensor SCM Sensor (wrapped) (done) | time=31ms21:43:59.479 INFO - Sensor org.sonar.plugins.javascript.lcov.UTCoverageSensor@b39a3bf21:43:59.479 INFO - Analysing C:\  cwd  \angular-playground\build\coverage\lcov.info21:43:59.495 INFO - Sensor org.sonar.plugins.javascript.lcov.UTCoverageSensor@b39a3bf (done) | time=16ms21:43:59.495 INFO - Sensor org.sonar.plugins.javascript.lcov.ITCoverageSensor@4da6546a21:43:59.495 INFO - Sensor org.sonar.plugins.javascript.lcov.ITCoverageSensor@4da6546a (done) | time=0ms21:43:59.495 INFO - Sensor CPD Sensor (wrapped)21:43:59.495 INFO - DefaultCpdEngine is used for js21:43:59.495 INFO - Cross-project analysis disabled21:43:59.510 DEBUG - Populating index from [moduleKey=angular-playground, relative=app/scripts/app.js, basedir=C:\  cwd  \angular-playground]21:43:59.526 DEBUG - Populating index from [moduleKey=angular-playground, relative=app/scripts/controllers/main.js, basedir=C:\  cwd  \angular-playground]21:43:59.526 DEBUG - Detection of duplications for [moduleKey=angular-playground, relative=app/scripts/app.js, basedir=C:\  cwd  \angular-playground]21:43:59.542 DEBUG - Detection of duplications for [moduleKey=angular-playground, relative=app/scripts/controllers/main.js, basedir=C:\  cwd  \angular-playground]21:43:59.542 INFO - Sensor CPD Sensor (wrapped) (done) | time=47ms21:43:59.542 INFO - No quality gate is configured.21:44:00.019 INFO - Compare to previous analysis (2015-06-29)21:44:00.066 INFO - Compare over 30 days (2015-05-30, analysis of Fri Jun 26 11:04:54 CEST 2015)21:44:00.636 INFO - Execute decorators...21:44:00.638 DEBUG - Decorators: ManualMeasureDecorator -   org.sonar.batch.issue.tracking.IssueTrackingDecorator@39e05056 -   QProfileEventsDecorator -   org.sonar.batch.design.ProjectDsmDecorator@5eef49f2 -   org.sonar.batch.design.SubProjectDsmDecorator@1376ea26 -   org.sonar.batch.design.DirectoryDsmDecorator@28af6afe -   FileTangleIndexDecorator -   SumDuplicationsDecorator -   UnitTestDecorator -   org.sonar.plugins.core.security.ApplyProjectRolesDecorator@3b5c7033 -   org.sonar.plugins.core.sensors.DirectoriesDecorator@4183a26f -   org.sonar.plugins.core.sensors.FilesDecorator@5bebff4b -   org.sonar.plugins.core.timemachine.TimeMachineConfigurationPersister@4ba148fb -   org.sonar.plugins.core.timemachine.NewCoverageFileAnalyzer@5811502e -   org.sonar.plugins.core.timemachine.NewItCoverageFileAnalyzer@6ed80c52 -   org.sonar.plugins.core.timemachine.NewOverallCoverageFileAnalyzer@32144b3c -   org.sonar.plugins.core.timemachine.NewCoverageAggregator@3601fb92 -   f(lines) -   f(generated_lines) -   f(ncloc) -   f(generated_ncloc) -   f(classes) -   f(packages) -   f(functions) -   f(accessors) -   f(statements) -   f(public_api) -   f(comment_lines) -   f(public_undocumented_api) -   f(commented_out_code_lines) -   f(complexity) -   f(complexity_in_classes) -   f(complexity_in_functions) -   f(class_complexity_distribution) -   f(function_complexity_distribution) -   f(file_complexity_distribution) -   f(lines_to_cover) -   f(uncovered_lines) -   f(conditions_to_cover) -   f(uncovered_conditions) -   f(it_lines_to_cover) -   f(it_uncovered_lines) -   f(it_conditions_to_cover) -   f(it_uncovered_conditions) -   f(overall_lines_to_cover) -   f(overall_uncovered_lines) -   f(overall_conditions_to_cover) -   f(overall_uncovered_conditions) -   f(rfc) -   f(rfc_distribution) -   f(lcom4_distribution) -   f(package_cycles) -   f(package_tangles) -   f(package_feedback_edges) -   f(package_edges_weight) -   f(new_lines_to_cover) -   f(new_uncovered_lines) -   f(new_conditions_to_cover) -   f(new_uncovered_conditions) -   f(new_it_lines_to_cover) -   f(new_it_uncovered_lines) -   f(new_it_conditions_to_cover) -   f(new_it_uncovered_conditions) -   f(new_overall_lines_to_cover) -   f(new_overall_uncovered_lines) -   f(new_overall_conditions_to_cover) -   f(new_overall_uncovered_conditions) -   org.sonar.batch.language.LanguageDistributionDecorator@454009a0 -   org.sonar.batch.debt.DebtDecorator@483740d5 -   org.sonar.batch.debt.NewDebtDecorator@24e25991 -   DirectoryTangleIndexDecorator -   org.sonar.batch.cpd.decorators.DuplicationDensityDecorator@4d763525 -   CountUnresolvedIssuesDecorator -   CountFalsePositivesDecorator -   CommentDensityDecorator -   f(file_complexity) -   f(class_complexity) -   f(function_complexity) -   org.sonar.plugins.core.sensors.LineCoverageDecorator@78751d07 -   org.sonar.plugins.core.sensors.CoverageDecorator@2d34798d -   org.sonar.plugins.core.sensors.BranchCoverageDecorator@53f92771 -   org.sonar.plugins.core.sensors.ItLineCoverageDecorator@6160714c -   org.sonar.plugins.core.sensors.ItCoverageDecorator@31add542 -   org.sonar.plugins.core.sensors.ItBranchCoverageDecorator@3f5b2aeb -   org.sonar.plugins.core.sensors.OverallLineCoverageDecorator@258350de -   org.sonar.plugins.core.sensors.OverallCoverageDecorator@478bbf33 -   org.sonar.plugins.core.sensors.OverallBranchCoverageDecorator@18537545 -   org.sonar.batch.debt.SqaleRatingDecorator@79f40cc5 -   org.sonar.plugins.core.timemachine.TendencyDecorator@4cf4fb3b -   VariationDecorator21:44:03.511 DEBUG - Updating semaphore batch-angular-playground21:44:04.137 DEBUG - Decorator time: ManualMeasureDecorator: 289ms org.sonar.batch.issue.tracking.IssueTrackingDecorator@39e05056: 13ms QProfileEventsDecorator: 173ms org.sonar.batch.design.ProjectDsmDecorator@5eef49f2: 1ms org.sonar.batch.design.SubProjectDsmDecorator@1376ea26: 1ms org.sonar.batch.design.DirectoryDsmDecorator@28af6afe: 16ms FileTangleIndexDecorator: 9ms SumDuplicationsDecorator: 1ms UnitTestDecorator: 1ms org.sonar.plugins.core.security.ApplyProjectRolesDecorator@3b5c7033: 127ms org.sonar.plugins.core.sensors.DirectoriesDecorator@4183a26f: 0ms org.sonar.plugins.core.sensors.FilesDecorator@5bebff4b: 1ms org.sonar.plugins.core.timemachine.TimeMachineConfigurationPersister@4ba148fb: 606ms org.sonar.plugins.core.timemachine.NewCoverageFileAnalyzer@5811502e: 34ms org.sonar.plugins.core.timemachine.NewItCoverageFileAnalyzer@6ed80c52: 0ms org.sonar.plugins.core.timemachine.NewOverallCoverageFileAnalyzer@32144b3c: 0ms org.sonar.plugins.core.timemachine.NewCoverageAggregator@3601fb92: 1ms f(lines): 1ms f(generated_lines): 2ms f(ncloc): 0ms f(generated_ncloc): 1ms f(classes): 0ms f(packages): 0ms f(functions): 0ms f(accessors): 0ms f(statements): 0ms f(public_api): 0ms f(comment_lines): 0ms f(public_undocumented_api): 0ms f(commented_out_code_lines): 0ms f(complexity): 0ms f(complexity_in_classes): 0ms f(complexity_in_functions): 0ms f(class_complexity_distribution): 0ms f(function_complexity_distribution): 1ms f(file_complexity_distribution): 1ms f(lines_to_cover): 1ms f(uncovered_lines): 0ms f(conditions_to_cover): 0ms f(uncovered_conditions): 0ms f(it_lines_to_cover): 1ms f(it_uncovered_lines): 0ms f(it_conditions_to_cover): 0ms f(it_uncovered_conditions): 0ms f(overall_lines_to_cover): 0ms f(overall_uncovered_lines): 0ms f(overall_conditions_to_cover): 0ms f(overall_uncovered_conditions): 0ms f(rfc): 0ms f(rfc_distribution): 0ms f(lcom4_distribution): 0ms f(package_cycles): 0ms f(package_tangles): 0ms f(package_feedback_edges): 0ms f(package_edges_weight): 0ms f(new_lines_to_cover): 0ms f(new_uncovered_lines): 0ms f(new_conditions_to_cover): 0ms f(new_uncovered_conditions): 0ms f(new_it_lines_to_cover): 0ms f(new_it_uncovered_lines): 0ms f(new_it_conditions_to_cover): 0ms f(new_it_uncovered_conditions): 0ms f(new_overall_lines_to_cover): 0ms f(new_overall_uncovered_lines): 0ms f(new_overall_conditions_to_cover): 1ms f(new_overall_uncovered_conditions): 0ms org.sonar.batch.language.LanguageDistributionDecorator@454009a0: 2ms org.sonar.batch.debt.DebtDecorator@483740d5: 11ms org.sonar.batch.debt.NewDebtDecorator@24e25991: 5ms DirectoryTangleIndexDecorator: 0ms org.sonar.batch.cpd.decorators.DuplicationDensityDecorator@4d763525: 0ms CountUnresolvedIssuesDecorator: 55ms CountFalsePositivesDecorator: 2ms CommentDensityDecorator: 0ms f(file_complexity): 0ms f(class_complexity): 0ms f(function_complexity): 0ms org.sonar.plugins.core.sensors.LineCoverageDecorator@78751d07: 8ms org.sonar.plugins.core.sensors.CoverageDecorator@2d34798d: 0ms org.sonar.plugins.core.sensors.BranchCoverageDecorator@53f92771: 1ms org.sonar.plugins.core.sensors.ItLineCoverageDecorator@6160714c: 0ms org.sonar.plugins.core.sensors.ItCoverageDecorator@31add542: 0ms org.sonar.plugins.core.sensors.ItBranchCoverageDecorator@3f5b2aeb: 0ms org.sonar.plugins.core.sensors.OverallLineCoverageDecorator@258350de: 0ms org.sonar.plugins.core.sensors.OverallCoverageDecorator@478bbf33: 1ms org.sonar.plugins.core.sensors.OverallBranchCoverageDecorator@18537545: 0ms org.sonar.batch.debt.SqaleRatingDecorator@79f40cc5: 5ms org.sonar.plugins.core.timemachine.TendencyDecorator@4cf4fb3b: 1032ms VariationDecorator: 941ms21:44:04.138 INFO - Store results in database21:44:04.140 DEBUG - Execute org.sonar.batch.phases.GraphPersister21:44:04.165 DEBUG - Execute org.sonar.batch.index.SourcePersister21:44:04.494 DEBUG - Execute org.sonar.batch.index.ResourcePersister21:44:04.494 DEBUG - Execute org.sonar.batch.index.MeasurePersister21:44:06.450 DEBUG - Execute org.sonar.batch.index.DuplicationPersister21:44:06.600 INFO - Analysis reports generated in 135ms, dir size=767 bytes21:44:06.678 INFO - Analysis reports compressed in 63ms, zip size=3 KB21:44:06.678 DEBUG - Publish results21:44:06.945 INFO - Analysis reports sent to server in 266ms21:44:06.945 INFO - ANALYSIS SUCCESSFUL, you can browse http://  domain  /dashboard/index/angular-playground21:44:06.945 INFO - Note that you will be able to access the updated dashboard once the server has processed the submitted analysis report.21:44:06.947 DEBUG - Post-jobs : 21:44:06.948 DEBUG - Release semaphore on project : org.sonar.api.resources.Project@f94fc29[id=75,key=angular-playground,qualifier=TRK], with key batch-angular-playgroundINFO: ------------------------------------------------------------------------INFO: EXECUTION SUCCESSINFO: ------------------------------------------------------------------------Total time: 39.758sFinal Memory: 20M/469MINFO: ------------------------------------------------------------------------reWhen the path to the source file is incorrect code./app/scripts/app.js then I see the source file but not the correct coverage value. I use Sonar 5.1.1 and the javascript plugin 2.6.Is this a bug with the javascript plugin or a configuration fault?",Not-TD-related,Other,,,,0.024,0.954,0.021,-0.5484
31157780,"Sonar plugin, set Technical Debt for a rule in xml","I have a plugin that creates a repository and defines rules within it using a xml file with rules defined for example:   rules     rule     key  KEY  /key     name  RULE_NAME  /name     severity  BLOCKER  /severity     description  DESCRIPTION  /description     /rule    /rules  reI want to add technical debt information for each rule as this is currently undefined. After some googling I've seen how it can be done when the rule is defined with in java: @Rule( key = KEY, name = RULE_NAME, priority = Priority.MAJOR) @SqaleSubCharacteristic(RulesDefinition.SubCharacteristics.UNDERSTANDABILITY)@SqaleConstantRemediation(5min)reso I want to add the @SqaleConstantRemediation(5min) to my xml, can I do this and what tag do I use?Cheers",Not-TD-related,Other,,,,0.027,0.924,0.05,0.0516
31520963,SonarQube 5.1.1 - Analysis very Slow with Oracle DB,"We want to use SonarQube 5.1.1 for analysing a Java-project with about 25.000 files. But the Step Apply project exclusions is very slow and takes 2.5 hours. Meanwhile the CPU-activity on the AIX-DB-Server is very high - 60% CPU.When starting SonarQube-Analysis (ANT-Task) in TRACE-Mode, we can see, that the following SQLs are executed very slow. Every SQL needs approximately 0.5 seconds. It seems, that this SQL is executed for each of the 25.000 files.I'm no Oracle-expert but it seems that the problem will be a full tablescan on the table project_measures for each of the 25.000 files.Any ideas on work arounds or solutions?I'm not sure if this is the same problem: a href=https://stackoverflow.com/questions/31029254/sonarqube-apply-project-exclusions-very-slowsonarqube-apply-project-exclusions-very-slow/aLog from ANT-Analyzer (TRACE-Level): [sonar:sonar] 10:59:29.342 DEBUG - Opening JDBC Connection[sonar:sonar] 10:59:29.358 DEBUG - Resetting autocommit to true on JDBC Connection [jdbc:oracle:thin:@XXX:XXX:XXX, UserName=SONAR, Oracle JDBC driver][sonar:sonar] 10:59:29.358 DEBUG - Closing JDBC Connection [jdbc:oracle:thin:@XXX:XXX:XXX, UserName=SONAR, Oracle JDBC driver][sonar:sonar] 10:59:29.358 DEBUG - Load technical debt model (done) | time=16ms[sonar:sonar] 10:59:29.374 INFO - Apply project exclusions[sonar:sonar] 10:59:29.374 DEBUG - Opening JDBC Connection[sonar:sonar] 10:59:29.389 DEBUG - Resetting autocommit to true on JDBC Connection [jdbc:oracle:thin:@XXX:XXX:XXX, UserName=SONAR, Oracle JDBC driver][sonar:sonar] 10:59:29.389 DEBUG - Closing JDBC Connection [jdbc:oracle:thin:@XXX:XXX:XXX, UserName=SONAR, Oracle JDBC driver][sonar:sonar] 10:59:29.592 DEBUG - select metric1_.name as col_0_0_, measuremod0_.id as col_1_0_, measuremod0_.id as id5_, measuremod0_.alert_status as alert2_5_, measuremod0_.alert_text as alert3_5_, measuremod0_.characteristic_id as characte4_5_, measuremod0_.measure_data as measure5_5_, measuremod0_.description as descript6_5_, measuremod0_.metric_id as metric7_5_, measuremod0_.person_id as person8_5_, measuremod0_.project_id as project9_5_, measuremod0_.rule_id as rule10_5_, measuremod0_.rule_priority as rule11_5_, measuremod0_.snapshot_id as snapshot12_5_, measuremod0_.tendency as tendency5_, measuremod0_.text_value as text14_5_, measuremod0_.url as url5_, measuremod0_.value as value5_, measuremod0_.variation_value_1 as variation17_5_, measuremod0_.variation_value_2 as variation18_5_, measuremod0_.variation_value_3 as variation19_5_, measuremod0_.variation_value_4 as variation20_5_, measuremod0_.variation_value_5 as variation21_5_ from project_measures measuremod0_, metrics metric1_, projects resourcemo2_, snapshots snapshot3_ where metric1_.id=measuremod0_.metric_id and measuremod0_.snapshot_id=snapshot3_.id and snapshot3_.project_id=resourcemo2_.id and resourcemo2_.kee=? and snapshot3_.status=? and snapshot3_.qualifier    ? and (measuremod0_.characteristic_id is null) and (measuremod0_.person_id is null) and (measuremod0_.rule_id is null) and (measuremod0_.rule_priority is null) and (metric1_.name in (? , ? , ?)) and snapshot3_.islast=1 order by snapshot3_.created_at[sonar:sonar] 10:59:32.077 DEBUG - select metric1_.name as col_0_0_, measuremod0_.id as col_1_0_, measuremod0_.id as id5_, measuremod0_.alert_status as alert2_5_, measuremod0_.alert_text as alert3_5_, measuremod0_.characteristic_id as characte4_5_, measuremod0_.measure_data as measure5_5_, measuremod0_.description as descript6_5_, measuremod0_.metric_id as metric7_5_, measuremod0_.person_id as person8_5_, measuremod0_.project_id as project9_5_, measuremod0_.rule_id as rule10_5_, measuremod0_.rule_priority as rule11_5_, measuremod0_.snapshot_id as snapshot12_5_, measuremod0_.tendency as tendency5_, measuremod0_.text_value as text14_5_, measuremod0_.url as url5_, measuremod0_.value as value5_, measuremod0_.variation_value_1 as variation17_5_, measuremod0_.variation_value_2 as variation18_5_, measuremod0_.variation_value_3 as variation19_5_, measuremod0_.variation_value_4 as variation20_5_, measuremod0_.variation_value_5 as variation21_5_ from project_measures measuremod0_, metrics metric1_, projects resourcemo2_, snapshots snapshot3_ where metric1_.id=measuremod0_.metric_id and measuremod0_.snapshot_id=snapshot3_.id and snapshot3_.project_id=resourcemo2_.id and resourcemo2_.kee=? and snapshot3_.status=? and snapshot3_.qualifier    ? and (measuremod0_.characteristic_id is null) and (measuremod0_.person_id is null) and (measuremod0_.rule_id is null) and (measuremod0_.rule_priority is null) and (metric1_.name in (? , ? , ?)) and snapshot3_.islast=1 order by snapshot3_.created_at[sonar:sonar] 10:59:33.295 DEBUG - select metric1_.name as col_0_0_, measuremod0_.id as col_1_0_, measuremod0_.id as id5_, measuremod0_.alert_status as alert2_5_, measuremod0_.alert_text as alert3_5_, measuremod0_.characteristic_id as characte4_5_, measuremod0_.measure_data as measure5_5_, measuremod0_.description as descript6_5_, measuremod0_.metric_id as metric7_5_, measuremod0_.person_id as person8_5_, measuremod0_.project_id as project9_5_, measuremod0_.rule_id as rule10_5_, measuremod0_.rule_priority as rule11_5_, measuremod0_.snapshot_id as snapshot12_5_, measuremod0_.tendency as tendency5_, measuremod0_.text_value as text14_5_, measuremod0_.url as url5_, measuremod0_.value as value5_, measuremod0_.variation_value_1 as variation17_5_, measuremod0_.variation_value_2 as variation18_5_, measuremod0_.variation_value_3 as variation19_5_, measuremod0_.variation_value_4 as variation20_5_, measuremod0_.variation_value_5 as variation21_5_ from project_measures measuremod0_, metrics metric1_, projects resourcemo2_, snapshots snapshot3_ where metric1_.id=measuremod0_.metric_id and measuremod0_.snapshot_id=snapshot3_.id and snapshot3_.project_id=resourcemo2_.id and resourcemo2_.kee=? and snapshot3_.status=? and snapshot3_.qualifier    ? and (measuremod0_.characteristic_id is null) and (measuremod0_.person_id is null) and (measuremod0_.rule_id is null) and (measuremod0_.rule_priority is null) and (metric1_.name in (? , ? , ?)) and snapshot3_.islast=1 order by snapshot3_.created_at[sonar:sonar] 10:59:34.405 DEBUG - select metric1_.name as col_0_0_, measuremod0_.id as col_1_0_, measuremod0_.id as id5_, measuremod0_.alert_status as alert2_5_, measuremod0_.alert_text as alert3_5_, measuremod0_.characteristic_id as characte4_5_, measuremod0_.measure_data as measure5_5_, measuremod0_.description as descript6_5_, measuremod0_.metric_id as metric7_5_, measuremod0_.person_id as person8_5_, measuremod0_.project_id as project9_5_, measuremod0_.rule_id as rule10_5_, measuremod0_.rule_priority as rule11_5_, measuremod0_.snapshot_id as snapshot12_5_, measuremod0_.tendency as tendency5_, measuremod0_.text_value as text14_5_, measuremod0_.url as url5_, measuremod0_.value as value5_, measuremod0_.variation_value_1 as variation17_5_, measuremod0_.variation_value_2 as variation18_5_, measuremod0_.variation_value_3 as variation19_5_, measuremod0_.variation_value_4 as variation20_5_, measuremod0_.variation_value_5 as variation21_5_ from project_measures measuremod0_, metrics metric1_, projects resourcemo2_, snapshots snapshot3_ where metric1_.id=measuremod0_.metric_id and measuremod0_.snapshot_id=snapshot3_.id and snapshot3_.project_id=resourcemo2_.id and resourcemo2_.kee=? and snapshot3_.status=? and snapshot3_.qualifier    ? and (measuremod0_.characteristic_id is null) and (measuremod0_.person_id is null) and (measuremod0_.rule_id is null) and (measuremod0_.rule_priority is null) and (metric1_.name in (? , ? , ?)) and snapshot3_.islast=1 order by snapshot3_.created_at[sonar:sonar] 10:59:35.108 DEBUG - select metric1_.name as col_0_0_, measuremod0_.id as col_1_0_, measuremod0_.id as id5_, measuremod0_.alert_status as alert2_5_, measuremod0_.alert_text as alert3_5_, measuremod0_.characteristic_id as characte4_5_, measuremod0_.measure_data as measure5_5_, measuremod0_.description as descript6_5_, measuremod0_.metric_id as metric7_5_, measuremod0_.person_id as person8_5_, measuremod0_.project_id as project9_5_, measuremod0_.rule_id as rule10_5_, measuremod0_.rule_priority as rule11_5_, measuremod0_.snapshot_id as snapshot12_5_, measuremod0_.tendency as tendency5_, measuremod0_.text_value as text14_5_, measuremod0_.url as url5_, measuremod0_.value as value5_, measuremod0_.variation_value_1 as variation17_5_, measuremod0_.variation_value_2 as variation18_5_, measuremod0_.variation_value_3 as variation19_5_, measuremod0_.variation_value_4 as variation20_5_, measuremod0_.variation_value_5 as variation21_5_ from project_measures measuremod0_, metrics metric1_, projects resourcemo2_, snapshots snapshot3_ where metric1_.id=measuremod0_.metric_id and measuremod0_.snapshot_id=snapshot3_.id and snapshot3_.project_id=resourcemo2_.id and resourcemo2_.kee=? and snapshot3_.status=? and snapshot3_.qualifier    ? and (measuremod0_.characteristic_id is null) and (measuremod0_.person_id is null) and (measuremod0_.rule_id is null) and (measuremod0_.rule_priority is null) and (metric1_.name in (? , ? , ?)) and snapshot3_.islast=1 order by snapshot3_.created_at[sonar:sonar] 10:59:35.733 DEBUG - select metric1_.name as col_0_0_, measuremod0_.id as col_1_0_, measuremod0_.id as id5_, measuremod0_.alert_status as alert2_5_, measuremod0_.alert_text as alert3_5_, measuremod0_.characteristic_id as characte4_5_, measuremod0_.measure_data as measure5_5_, measuremod0_.description as descript6_5_, measuremod0_.metric_id as metric7_5_, measuremod0_.person_id as person8_5_, measuremod0_.project_id as project9_5_, measuremod0_.rule_id as rule10_5_, measuremod0_.rule_priority as rule11_5_, measuremod0_.snapshot_id as snapshot12_5_, measuremod0_.tendency as tendency5_, measuremod0_.text_value as text14_5_, measuremod0_.url as url5_, measuremod0_.value as value5_, measuremod0_.variation_value_1 as variation17_5_, measuremod0_.variation_value_2 as variation18_5_, measuremod0_.variation_value_3 as variation19_5_, measuremod0_.variation_value_4 as variation20_5_, measuremod0_.variation_value_5 as variation21_5_ from project_measures measuremod0_, metrics metric1_, projects resourcemo2_, snapshots snapshot3_ where metric1_.id=measuremod0_.metric_id and measuremod0_.snapshot_id=snapshot3_.id and snapshot3_.project_id=resourcemo2_.id and resourcemo2_.kee=? and snapshot3_.status=? and snapshot3_.qualifier    ? and (measuremod0_.characteristic_id is null) and (measuremod0_.person_id is null) and (measuremod0_.rule_id is null) and (measuremod0_.rule_priority is null) and (metric1_.name in (? , ? , ?)) and snapshot3_.islast=1 order by snapshot3_.created_atreSQL which probably causes the problem: SELECT metric1_.name AS col_0_0_, measuremod0_.id AS col_1_0_, measuremod0_.id AS id5_, measuremod0_.alert_status AS alert2_5_, measuremod0_.alert_text AS alert3_5_, measuremod0_.characteristic_id AS characte4_5_, measuremod0_.measure_data AS measure5_5_, measuremod0_.description AS descript6_5_, measuremod0_.metric_id AS metric7_5_, measuremod0_.person_id AS person8_5_, measuremod0_.project_id AS project9_5_, measuremod0_.rule_id AS rule10_5_, measuremod0_.rule_priority AS rule11_5_, measuremod0_.snapshot_id AS snapshot12_5_, measuremod0_.tendency AS tendency5_, measuremod0_.text_value AS text14_5_, measuremod0_.url AS url5_, measuremod0_.VALUE AS value5_, measuremod0_.variation_value_1 AS variation17_5_, measuremod0_.variation_value_2 AS variation18_5_, measuremod0_.variation_value_3 AS variation19_5_, measuremod0_.variation_value_4 AS variation20_5_, measuremod0_.variation_value_5 AS variation21_5_ FROM project_measures measuremod0_, metrics metric1_, projects resourcemo2_, snapshots snapshot3_ WHERE metric1_.id = measuremod0_.metric_id AND measuremod0_.snapshot_id = snapshot3_.id AND snapshot3_.project_id = resourcemo2_.id AND resourcemo2_.kee = :1 AND snapshot3_.status = :2 AND snapshot3_.qualifier      :3 AND (measuremod0_.characteristic_id IS NULL) AND (measuremod0_.person_id IS NULL) AND (measuremod0_.rule_id IS NULL) AND (measuremod0_.rule_priority IS NULL) AND (metric1_.name IN ( :4, :5, :6)) AND snapshot3_.islast = 1ORDER BY snapshot3_.created_atre",Not-TD-related,Other,,,,0.019,0.968,0.012,-0.7966
31567939,Not deleting dynamically allocated memory and let it get free by the OS after programme termination,"I have read this question and answer a href=https://stackoverflow.com/questions/6727383/dynamically-allocated-memory-after-program-terminationdynamically allocated memory after program termination/a,and I want to know if it is okay to NOT delete dynamically allocated memory and let it get freed by the OS after programme termination.So, if I have allocated some memory for objects that I need thoughout the programme, is it ok to skip deleting them at the end of the programme, in order to make the code run faster?",Not-TD-related,Other,,,,0.028,0.862,0.109,0.6111
31936401,String Related Field in DjangoRest,"I have implemented Foreign key to fetch a list of genres for movies using StringRelatedField in DRF. This however does not work while POST. I get StringRelatedField.to_internal_value() must be implemented as error. Can anyone help me?models.pyclass Movies(models.Model):movie_id = models.AutoField(primary_key=True)movie_name = models.CharField(max_length =200)director = models.CharField(max_length = 100)popularity = models.FloatField(max_length = 3)imdb_score = models.FloatField(max_length = 10)def __unicode__(self): return '%s%s%d%d' % (self.movie_name,self.director,self.popularity,self.imdb_score)class Genre(models.Model):genre_id = models.AutoField(primary_key=True)movie_name =models.ForeignKey(Movies, blank=True, null=True, on_delete=models.SET_NULL,related_name='genres')genre = models.CharField(max_length =40)def __unicode__(self):return '%s%s' % (self.genre,self.movie_name)views.pyclass MovieList(viewsets.ViewSet):def list(self,request):try:movie_list = Movies.objects.all()serializer = MovieSerializer(movie_list, many=True)username = request.session['username']user_role = request.session['role']context = {'username': username, 'user_role': user_role, 'movie_list': serializer.data}return render(request, 'imdb/movie-list.html', context)except KeyError:passreturn HttpResponseRedirect(reverse('imdb:login'))class AddMovie(APIView):def post(self, request, format='json'):data = request.dataserializer = MovieSerializer(data =request.data)#print serializerif serializer.is_valid():serializer.save()return Response(serializer.data, status=status.HTTP_201_CREATED)else:return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)urls.pyurlpatterns = patterns('',url(r'^$', views.login, name='login'),url(r'^home/$', views.home, name='home'), url(r'^logout/$', views.logout, name='logout'),url(r'^movie-list/$', views.MovieList.as_view({'get':'list'}),name ='movie-list'),url(r'^add-movie/$', views.AddMovie.as_view(),name ='add-movie') )serializer.pyclass MovieSerializer(serializers.ModelSerializer):genres = serializers.StringRelatedField(many=True)class Meta:model = Moviesfields = ('movie_name','director','popularity','imdb_score','genres')",Not-TD-related,Other,,,,0.017,0.947,0.036,0.4767
32356181,sonarqube eclipse plugin Usage,"I Just figured out, there should be a project in sonar server before you can integrate sonarqube with your project in eclipse, I don't see much benefit as I already ran the sonarrunner to have that project on the sonar server and I have the analysis for that one on sonar application i.e. http://localhost:9000 (in my case). Is it just for the sake of having it in eclipse we install the plugin and see the results or am I missing some point or else Is there any way we can run analysis within eclipse without having the project on sonar server at the first place. Any help is appreciated. Thanks.",Not-TD-related,Other,,,,0.042,0.879,0.079,0.6393
32720048,Unable to open sonar in browser,"Installed sonarqube and started the sonar service. but sonar is not opening in the browser with port 9000. havent done any changes in sonar.properties file (all the contents are commented). but the log shows the web server is started, http connector enabled port on 9000. how it is possible when contents are commented?port status tcp 0 0 0.0.0.0:9000 0.0.0.0:* LISTEN -reSonar logs   -- Wrapper Stopped--   Wrapper Started as DaemonLaunching a JVM...Wrapper (Version 3.2.3) http://wrapper.tanukisoftware.org Copyright 1999-2006 Tanuki Software, Inc. All Rights Reserved.2015.09.22 10:09:31 INFO app[o.s.p.m.JavaProcessLauncher] Launch process[search]: /usrb/jvm/java-1.7.0-openjdk-1.7.0.85.x86_64/jre/bin/java -Djava.awt.headless=true -Xmx1G -Xms256m -Xss256k -Djava.net.preferIPv4Stack=true -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+HeapDumpOnOutOfMemoryError -Djava.io.tmpdir=/usr/local/sonarqube-5.1.2/temp -cp .b/common/*:.b/search/* org.sonar.search.SearchServer /tmp/sq-process7377450394324020959properties2015.09.22 10:09:32 INFO es[o.s.p.ProcessEntryPoint] Starting searc015.09.22 10:09:32 INFO es[o.s.s.SearchServer] Starting Elasticsearch[sonarqube] on port 90012015.09.22 10:09:32 INFO es[o.elasticsearch.node] [sonar-1442930970839] version[1.4.4], pid[27953], build[c88f77f/2015-02-19T13:05:36Z]2015.09.22 10:09:32 INFO es[o.elasticsearch.node] [sonar-1442930970839] initializing ...2015.09.22 10:09:32 INFO es[o.e.plugins] [sonar-1442930970839] loaded [], sites []2015.09.22 10:09:35 INFO es[o.elasticsearch.node] [sonar-1442930970839] initialized2015.09.22 10:09:35 INFO es[o.elasticsearch.node] [sonar-1442930970839] starting ...2015.09.22 10:09:35 INFO es[o.e.transport] [sonar-1442930970839] bound_address {inet[/0.0.0.0:9001]}, publish_address {inet[/10.246.236.55:9001]}2015.09.22 10:09:35 INFO es[o.e.discovery] [sonar-1442930970839] sonarqube/xTJRTzNESlunLbRSr4pkYA2015.09.22 10:09:38 INFO es[o.e.cluster.service] [sonar-1442930970839] new_master [sonar-1442930970839][xTJRTzNESlunLbRSr4pkYA][usboss-sdijenkins.aaitg.com][inet[/10.246.236.55:9001]]{rack_id=sonar-1442930970839}, reason: zen-disco-join (elected_as_master)2015.09.22 10:09:38 INFO es[o.elasticsearch.node] [sonar-1442930970839] started2015.09.22 10:09:40 INFO es[o.e.gateway] [sonar-1442930970839] recovered [6] indices into cluster_state2015.09.22 10:09:41 INFO app[o.s.p.m.Monitor] Process[search] is up2015.09.22 10:09:41 INFO app[o.s.p.m.JavaProcessLauncher] Launch process[web]: /usrb/jvm/java-1.7.0-openjdk-1.7.0.85.x86_64/jre/bin/java -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djruby.management.enabled=false -Djruby.compile.invokedynamic=false -Xmx768m -XX:MaxPermSize=160m -XX:+HeapDumpOnOutOfMemoryError -Djava.net.preferIPv4Stack=true -Djava.io.tmpdir=/usr/local/sonarqube-5.1.2/temp -cp .b/common/*:.b/server/*:/usr/local/sonarqube-5.1.2b/jdbc//-1.3.176.jar org.sonar.server.app.WebServer /tmp/sq-process4883903207582149281properties2015.09.22 10:09:42 INFO web[o.s.p.ProcessEntryPoint] Starting web2015.09.22 10:09:42 INFO web[o.s.s.app.Webapp] Webapp directory: /usr/local/sonarqube-5.1.2/web2015.09.22 10:09:43 INFO web[o.a.c.h.Http11NioProtocol] Initializing ProtocolHandler [http-nio-0.0.0.0-9000]2015.09.22 10:09:43 INFO web[o.a.t.u.n.NioSelectorPool] Using a shared selector for servlet write/read2015.09.22 10:09:44 INFO web[o.e.plugins] [sonar-1442930970839] loaded [], sites []2015.09.22 10:09:45 INFO web[o.s.s.p.ServerImpl] SonarQube Server / 5.1.2 / 2a52a7106b2bfbd659c591c2d6fc09ad0ab2db5c2015.09.22 10:09:46 INFO web[o.s.s.d.EmbeddedDatabase] Starting embedded database on port 9092 with url jdbc::tcp://localhost:9092/sonar2015.09.22 10:09:46 INFO web[o.s.s.d.EmbeddedDatabase] Embedded database started. Data stored in: /usr/local/sonarqube-5.1.2/data2015.09.22 10:09:46 INFO web[o.s.c.p.Database] Create JDBC datasource for jdbc::tcp://localhost:9092/sonar2015.09.22 10:09:47 WARN web[o.s.s.d.DatabaseChecker] H2 database should be used for evaluation purpose only2015.09.22 10:09:49 INFO web[o.s.s.p.DefaultServerFileSystem] SonarQube home: /usr/local/sonarqube-5.1.22015.09.22 10:09:49 INFO web[o.s.s.p.ServerPluginJarsInstaller] Install plugins2015.09.22 10:09:49 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin Git / 1.0 / 9ce9d330c313c296fab051317cc5ad4b26319e072015.09.22 10:09:49 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin SVN / 1.0 / 213fc8a8b582ff530b12dd4a59a6512be10712342015.09.22 10:09:49 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin Core / 5.1.2 / 2a52a7106b2bfbd659c591c2d6fc09ad0ab2db5c2015.09.22 10:09:49 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin Java / 3.0 / 65396a609ddface8b311a6a665aca92a7da694f12015.09.22 10:09:49 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin English Pack / 5.1.2 / 2a52a7106b2bfbd659c591c2d6fc09ad0ab2db5c2015.09.22 10:09:49 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin Email notifications / 5.1.2 / 2a52a7106b2bfbd659c591c2d6fc09ad0ab2db5c2015.09.22 10:09:49 INFO web[o.s.s.p.RailsAppsDeployer] Deploy Ruby on Rails applications2015.09.22 10:09:49 INFO web[o.s.j.s.AbstractDatabaseConnector] Initializing Hibernate2015.09.22 10:09:50 INFO web[o.s.s.p.UpdateCenterClient] Update center: http://update.sonarsource.org/update-center.properties (no proxy)2015.09.22 10:09:51 INFO web[o.s.s.n.NotificationService] Notification service started (delay 60 sec.)2015.09.22 10:09:52 INFO web[o.s.s.s.IndexSynchronizer] Index rules2015.09.22 10:09:52 INFO web[o.s.s.s.IndexSynchronizer] Index activeRules2015.09.22 10:09:52 INFO web[o.s.s.s.RegisterMetrics] Register metrics2015.09.22 10:09:53 INFO web[o.s.s.s.RegisterMetrics] Cleaning quality gate conditions2015.09.22 10:09:53 INFO web[o.s.s.s.RegisterDebtModel] Register technical debt model2015.09.22 10:09:53 INFO web[o.s.s.r.RegisterRules] Register rules2015.09.22 10:09:54 INFO web[o.s.s.q.RegisterQualityProfiles] Register quality profiles2015.09.22 10:09:55 INFO web[o.s.s.s.RegisterNewMeasureFilters] Register measure filters2015.09.22 10:09:55 INFO web[o.s.s.s.RegisterDashboards] Register dashboards2015.09.22 10:09:55 INFO web[o.s.s.s.RegisterPermissionTemplates] Register permission templates2015.09.22 10:09:55 INFO web[o.s.s.s.RenameDeprecatedPropertyKeys] Rename deprecated property keys2015.09.22 10:09:55 INFO web[o.s.s.s.IndexSynchronizer] Index activities2015.09.22 10:09:55 INFO web[o.s.s.s.IndexSynchronizer] Index issues2015.09.22 10:09:55 INFO web[o.s.s.s.IndexSynchronizer] Index source lines2015.09.22 10:09:55 INFO web[o.s.s.s.IndexSynchronizer] Index users2015.09.22 10:09:55 INFO web[o.s.s.s.IndexSynchronizer] Index views2015.09.22 10:09:55 INFO web[jruby.rack] jruby 1.7.9 (ruby-1.8.7p370) 2013-12-06 87b108a on OpenJDK 64-Bit Server VM 1.7.0_85-mockbuild_2015_07_25_13_10-b00 [linux-amd64]2015.09.22 10:09:55 INFO web[jruby.rack] using a shared (threadsafe!) runtime2015.09.22 10:10:26 INFO web[jruby.rack] keeping custom (config.logger) Rails logger instance2015.09.22 10:10:26 INFO web[o.a.c.h.Http11NioProtocol] Starting ProtocolHandler [http-nio-0.0.0.0-9000]2015.09.22 10:10:26 INFO web[o.s.s.a.TomcatAccessLog] Web server is started2015.09.22 10:10:26 INFO web[o.s.s.a.EmbeddedTomcat] HTTP connector enabled on port 90002015.09.22 10:10:27 INFO app[o.s.p.m.Monitor] Process[web] is upresonar.properties file  See http://docs.oracle.com/javase/1.5.0/docs/api/java/utilroperties.htmlload(java.io.InputStream) Property values can: - reference an environment variable, for example sonar.jdbc.url= ${env:SONAR_JDBC_URL} - be encrypted. See http://redirect.sonarsource.com/doc/settings-encryption.html-------------------------------------------------------------------------------------------------- DATABASE IMPORTANT: the embedded H2 database is used by default. It is recommended for tests but not for production use. Supported databases are MySQL, Oracle, PostgreSQL and Microsoft SQLServer. User credentials. Permissions to create tables, indices and triggers must be granted to JDBC user. The schema must be created first.sonar.jdbc.username=sonarsonar.jdbc.password=sonar----- Embedded Database (default) It does not accept connections from remote hosts, so the server and the analyzers must be executed on the same host.sonar.jdbc.url=jdbc::tcp://localhost:9092/sonar H2 embedded database server listening port, defaults to 9092sonar.embeddedDatabase.port=9092----- MySQL 5.x Only InnoDB storage engine is supported (not myISAM). Only the bundled driver is supported.sonar.jdbc.url=jdbc:mysql://localhost:3306/sonar?useUnicode=true characterEncoding=utf8 rewriteBatchedStatements=true useConfigs=maxPerformance----- Oracle 10g/11g - Only thin client is supported - Only versions 11.2.* of Oracle JDBC driver are supported, even if connecting to lower Oracle versions. - The JDBC driver must be copied into the directory extensions/jdbc-driver/oracle/ - If you need to set the schema, please refer to http://jira.codehaus.org/browse/SONAR-5000sonar.jdbc.url=jdbc:oracle:thin:@localhost/XE----- PostgreSQL 8.x/9.x If you don't use the schema named public, please refer to http://jira.codehaus.org/browse/SONAR-5000sonar.jdbc.url=jdbc:postgresql://localhost/sonar----- Microsoft SQLServer 2008/2012 Only the bundled jTDS driver is supported. Collation must be case-sensitive (CS) and accent-sensitive (AS).sonar.jdbc.url=jdbc:jtds:sqlserver://localhost/sonar;SelectMethod=Cursor----- Connection pool settings The maximum number of active connections that can be allocated at the same time, or negative for no limit.sonar.jdbc.maxActive=50 The maximum number of connections that can remain idle in the pool, without extra ones being released, or negative for no limit.sonar.jdbc.maxIdle=5 The minimum number of connections that can remain idle in the pool, without extra ones being created, or zero to create none.sonar.jdbc.minIdle=2 The maximum number of milliseconds that the pool will wait (when there are no available connections) for a connection to be returned before throwing an exception, or   = 0 to wait indefinitely.sonar.jdbc.maxWait=5000sonar.jdbc.minEvictableIdleTimeMillis=600000sonar.jdbc.timeBetweenEvictionRunsMillis=30000-------------------------------------------------------------------------------------------------- WEB SERVER Web server is executed in a dedicated Java process. By default heap size is 768Mb. Use the following property to customize JVM options. Recommendations: The HotSpot Server VM is recommended. The property -server should be added if server mode is not enabled by default on your environment: http://docs.oracle.com/javase/7/docs/technotes/guides/vm/server-class.html Set min and max memory (respectively -Xms and -Xmx) to the same value to prevent heap from resizing at runtime.sonar.web.javaOpts=-Xmx768m -XX:MaxPermSize=160m -XX:+HeapDumpOnOutOfMemoryError Same as previous property, but allows to not repeat all other settings like -Xmxsonar.web.javaAdditionalOpts= Binding IP address. For servers with more than one IP address, this property specifies which address will be used for listening on the specified ports. By default, ports will be used on all IP addresses associated with the server.sonar.web.host=0.0.0.0sonar.web.host=localhost Web context. When set, it must start with forward slash (for example /sonarqube). The default value is root context (empty value).sonar.web.context= TCP port for incoming HTTP connections. Disabled when value is -1.sonar.web.port=9000 Recommendation for HTTPS SonarQube natively supports HTTPS. However using a reverse proxy infrastructure is the recommended way to set up your SonarQube installation on production environments which need to be highly secured. This allows to fully master all the security parameters that you want. TCP port for incoming HTTPS connections. Disabled when value is -1 (default).sonar.web.https.port=-1 HTTPS - the alias used to for the server certificate in the keystore. If not specified the first key read in the keystore is used.sonar.web.https.keyAlias= HTTPS - the password used to access the server certificate from the specified keystore file. The default value is changeit.sonar.web.https.keyPass=changeit HTTPS - the pathname of the keystore file where is stored the server certificate. By default, the pathname is the file .keystore in the user home. If keystoreType doesn't need a file use empty value.sonar.web.https.keystoreFile= HTTPS - the password used to access the specified keystore file. The default value is the value of sonar.web.https.keyPass.sonar.web.https.keystorePass= HTTPS - the type of keystore file to be used for the server certificate. The default value is JKS (Java KeyStore).sonar.web.https.keystoreType=JKS HTTPS - the name of the keystore provider to be used for the server certificate. If not specified, the list of registered providers is traversed in preference order and the first provider that supports the keystore type is used (see sonar.web.https.keystoreType).sonar.web.https.keystoreProvider= HTTPS - the pathname of the truststore file which contains trusted certificate authorities. By default, this would be the cacerts file in your JRE. If truststoreFile doesn't need a file use empty value.sonar.web.https.truststoreFile= HTTPS - the password used to access the specified truststore file.sonar.web.https.truststorePass= HTTPS - the type of truststore file to be used. The default value is JKS (Java KeyStore).sonar.web.https.truststoreType=JKS HTTPS - the name of the truststore provider to be used for the server certificate. If not specified, the list of registered providers is traversed in preference order and the first provider that supports the truststore type is used (see sonar.web.https.truststoreType).sonar.web.https.truststoreProvider= HTTPS - whether to enable client certificate authentication. The default is false (client certificates disabled). Other possible values are 'want' (certificates will be requested, but not required), and 'true' (certificates are required).sonar.web.https.clientAuth=false HTTPS - comma separated list of encryption ciphers to support for HTTPS connections. If specified, only the ciphers that are listed and supported by the SSL implementation will be used. By default, the default ciphers for the JVM will be used. Note that this usually means that the weak export grade ciphers, for instance RC4, will be included in the list of available ciphers. The ciphers are specified using the JSSE cipher naming convention (see https://www.openssl.org/docs/apps/ciphers.html) Example: sonar.web.https.ciphers=TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384sonar.web.https.ciphers= The maximum number of connections that the server will accept and process at any given time. When this number has been reached, the server will not accept any more connections until the number of connections falls below this value. The operating system may still accept connections based on the sonar.web.connections.acceptCount property. The default value is 50 for each enabled connector.sonar.web.http.maxThreads=50sonar.web.https.maxThreads=50 The minimum number of threads always kept running. The default value is 5 for each enabled connector.sonar.web.http.minThreads=5sonar.web.https.minThreads=5 The maximum queue length for incoming connection requests when all possible request processing threads are in use. Any requests received when the queue is full will be refused. The default value is 25 for each enabled connector.sonar.web.http.acceptCount=25sonar.web.https.acceptCount=25 TCP port for incoming AJP connections. Disabled if value is -1. Disabled by default.sonar.ajp.port=-1-------------------------------------------------------------------------------------------------- ELASTICSEARCH Elasticsearch is used to facilitate fast and accurate information retrieval. It is executed in a dedicated Java process. JVM options of Elasticsearch process Recommendations: Use HotSpot Server VM. The property -server should be added if server mode is not enabled by default on your environment: http://docs.oracle.com/javase/7/docs/technotes/guides/vm/server-class.html Set min and max memory (respectively -Xms and -Xmx) to the same value to prevent heap from resizing at runtime.sonar.search.javaOpts=-Xmx1G -Xms256m -Xss256k -Djava.net.preferIPv4Stack=true \ -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 \ -XX:+UseCMSInitiatingOccupancyOnly -XX:+HeapDumpOnOutOfMemoryError Same as previous property, but allows to not repeat all other settings like -Xmxsonar.search.javaAdditionalOpts= Elasticsearch port. Default is 9001. Use 0 to get a free port. This port must be private and must not be exposed to the Internet.sonar.search.port=9001-------------------------------------------------------------------------------------------------- UPDATE CENTER Update Center requires an internet connection to request http://update.sonarsource.org It is enabled by default.sonar.updatecenter.activate=true HTTP proxy (default none)http.proxyHost=http.proxyPort= NT domain name if NTLM proxy is usedhttp.auth.ntlm.domain= SOCKS proxy (default none)socksProxyHost=socksProxyPort= proxy authentication. The 2 following properties are used for HTTP and SOCKS proxies.http.proxyUser=http.proxyPassword=-------------------------------------------------------------------------------------------------- LOGGING Level of logs. Supported values are INFO, DEBUG and TRACEsonar.log.level=INFO Path to log files. Can be absolute or relative to installation directory. Default is   installation home  /logssonar.path.logs=logs Rolling policy of log files - based on time if value starts with time:, for example by day (time:yyyy-MM-dd) or by month (time:yyyy-MM) - based on size if value starts with size:, for example size:10MB - disabled if value is none. That needs logs to be managed by an external system like logrotate.sonar.log.rollingPolicy=time:yyyy-MM-dd Maximum number of files to keep if a rolling policy is enabled. - maximum value is 20 on size rolling policy - unlimited on time rolling policy. Set to zero to disable old file purging.sonar.log.maxFiles=7 Access log is the list of all the HTTP requests received by server. If enabled, it is stored in the file {sonar.path.logs}/access.log. This file follows the same rolling policy as for sonar.log (see sonar.log.rollingPolicy and sonar.log.maxFiles).sonar.web.accessLogs.enable=true Format of access log. It is ignored if sonar.web.accessLogs.enable=false. Value is: - common is the Common Log Format (shortcut for: %h %l %u %user %date %r %s %b) - combined is another format widely recognized (shortcut for: %h %l %u [%t] %r %s %b %i{Referer} %i{User-Agent}) - else a custom pattern. See http://logback.qos.ch/manual/layouts.htmlAccessPatternLayoutsonar.web.accessLogs.pattern=combined-------------------------------------------------------------------------------------------------- OTHERS Delay in seconds between processing of notification queue. Default is 60 seconds.sonar.notifications.delay=60 Paths to persistent data files (embedded database and search index) and temporary files. Can be absolute or relative to installation directory. Defaults are respectively   installation home  /data and   installation home  /tempsonar.path.data=datasonar.path.temp=temp-------------------------------------------------------------------------------------------------- DEVELOPMENT - only for developers The following properties MUST NOT be used in production environments. Dev mode allows to reload web sources on changes and to restart server when new versions of plugins are deployed.sonar.web.dev=false Path to webapp sources for hot-reloading of Ruby on Rails, JS and CSS (only core, plugins not supported).sonar.web.dev.sources=ath/to/server/sonar-web/src/main/webapp Uncomment to enable the Elasticsearch HTTP connector, so that ES can be directly requested through http://lmenezes.com/elasticsearch-kopf/?location=http://localhost:9010sonar.search.httpPort=9010re",Not-TD-related,Other,,,,0.027,0.878,0.095,0.9991
33392576,Caused by: java.lang.IllegalStateException: The folder 'test' does not exist for,"I will need your help please.This is the context, I'm trying to set up a Continous Integration plateform, for specifc needs, and this is my Configuration, all in the same machine(Windows 7 ):ulliSonarQube 5.1 (I tried both internal and external databases)liSonarQube runner 2.4liPHP plugin for SonarliJenkins 1.6liSonarQube plugin for Jenkins (I'have already done all of the Sonarqube config in Jenkins)liI created a specific Job for PHP (Which is a local folder in my file system)(I configured the build section of Jenkins bu adding Standalone SonarQube Analysis, with the specific Path to projeetc proporties which point to my sonar-project.properties behind ) sonar.projectKey=my:projectsonar.projectName=PHP project analyzed with the SonarQube Runner reusing PHPUnit reportssonar.projectVersion=1.0 sonar.sources=userthing,test sonar.tests=test sonar.language=php sonar.sourceEncoding=UTF-8 Reusing PHPUnit reports sonar.php.coverage.reportPath=reportshpunit.coverage.xml sonar.php.tests.reportPath=reportshpunit.xmlreWhen I launch a build from Jenkins I have this error : NFO: Work directory: C:\Users\user\.jenkins\jobs\test projet\workspace\.sonarINFO: SonarQube Server 5.1.214:13:10.295 INFO - Load global repositories14:13:10.372 INFO - Load global repositories (done) | time=78ms14:13:10.374 INFO - Server id: 2015102813351214:13:10.374 INFO - User cache: C:\Users\user\.sonar\cache14:13:10.379 INFO - Install plugins14:13:10.706 INFO - Install JDBC driver14:13:10.710 INFO - Create JDBC datasource for jdbc::tcp://localhost/sonar14:13:11.247 INFO - Initializing Hibernate14:13:12.106 ERROR - Invalid value of sonar.tests for my:projectINFO: ------------------------------------------------------------------------INFO: EXECUTION FAILUREINFO: ------------------------------------------------------------------------Total time: 2.131sFinal Memory: 6M/20MINFO: ------------------------------------------------------------------------ERROR: Error during Sonar runner executionorg.sonar.runner.impl.RunnerException: Unable to execute Sonar at org.sonar.runner.impl.BatchLauncher$1.delegateExecution(BatchLauncher.java:91) at org.sonar.runner.impl.BatchLauncher$1.run(BatchLauncher.java:75) at java.security.AccessController.doPrivileged(Native Method) at org.sonar.runner.impl.BatchLauncher.doExecute(BatchLauncher.java:69) at org.sonar.runner.impl.BatchLauncher.execute(BatchLauncher.java:50) at org.sonar.runner.api.EmbeddedRunner.doExecute(EmbeddedRunner.java:102) at org.sonar.runner.api.Runner.execute(Runner.java:100) at org.sonar.runner.Main.executeTask(Main.java:70) at org.sonar.runner.Main.execute(Main.java:59) at org.sonar.runner.Main.main(Main.java:53)Caused by: java.lang.IllegalStateException: The folder 'test' does not exist for 'my:project' (base directory = C:\Users\user\.jenkins\jobs\test projet\workspace) at org.sonar.batch.scan.ProjectReactorBuilder.checkExistenceOfPaths(ProjectReactorBuilder.java:427) at org.sonar.batch.scan.ProjectReactorBuilder.validateDirectories(ProjectReactorBuilder.java:334) at org.sonar.batch.scan.ProjectReactorBuilder.defineRootProject(ProjectReactorBuilder.java:163) at org.sonar.batch.scan.ProjectReactorBuilder.execute(ProjectReactorBuilder.java:116) at org.sonar.batch.scan.ProjectScanContainer.projectBootstrap(ProjectScanContainer.java:110) at org.sonar.batch.scan.ProjectScanContainer.doBeforeStart(ProjectScanContainer.java:86) at org.sonar.api.platform.ComponentContainer.startComponents(ComponentContainer.java:90) at org.sonar.api.platform.ComponentContainer.execute(ComponentContainer.java:77) at org.sonar.batch.scan.ScanTask.scan(ScanTask.java:57) at org.sonar.batch.scan.ScanTask.execute(ScanTask.java:45) at org.sonar.batch.bootstrap.TaskContainer.doAfterStart(TaskContainer.java:135) at org.sonar.api.platform.ComponentContainer.startComponents(ComponentContainer.java:92) at org.sonar.api.platform.ComponentContainer.execute(ComponentContainer.java:77) at org.sonar.batch.bootstrap.GlobalContainer.executeTask(GlobalContainer.java:158) at org.sonar.batch.bootstrapper.Batch.executeTask(Batch.java:95) at org.sonar.batch.bootstrapper.Batch.execute(Batch.java:67) at org.sonar.runner.batch.IsolatedLauncher.execute(IsolatedLauncher.java:48) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.sonar.runner.impl.BatchLauncher$1.delegateExecution(BatchLauncher.java:87) ... 9 moreERROR: ERROR: Re-run SonarQube Runner using the -X switch to enable full debug logging.Build step 'Lancer une analyse SonarQube autonome' marked build as failureFinished: FAILUREreI follow those steps to identify the root concern:olliI created manually sonar-project.properties.liLunch sonar-runner.bat directly from my php folder, = then it works perfectly I have all the metric.liI'm sure that the root cause is Jenkins, but I don't know exactly what I'm missing.Even if some times everything seems to work fine, I got this message from stacktrace block e 0 file indexed/block e:a href=https://i.stack.imgur.com/55gzf.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/55gzf.png alt=enter image description here/a  INFO: Error stacktraces are turned on.INFO: Runner configuration file: C:\DevTools\sonar-runner-2.4\conf\sonar-runner.propertiesINFO: Project configuration file: C:\Users\user\Desktop\Exemple de projet PHPUNIT\sonar-project.propertiesINFO: Default locale: fr_FR, source code encoding: UTF-8INFO: Work directory: C:\Users\user\.jenkins\jobs\projet\workspace\.sonarINFO: SonarQube Server 5.1.214:55:20.977 INFO - Load global repositories14:55:21.040 INFO - Load global repositories (done) | time=63ms14:55:21.040 INFO - Server id: 2015102813351214:55:21.040 INFO - User cache: C:\Users\user\.sonar\cache14:55:21.040 INFO - Install plugins14:55:21.390 INFO - Install JDBC driver14:55:21.390 INFO - Create JDBC datasource for jdbc::tcp://localhost/sonar14:55:21.918 INFO - Initializing Hibernate14:55:22.858 INFO - Load project repositories14:55:23.030 INFO - Load project repositories (done) | time=172ms14:55:23.030 INFO - Load project settings14:55:23.326 INFO - Load technical debt model14:55:23.358 INFO - Apply project exclusions14:55:23.498 WARN - SCM provider autodetection failed. No SCM provider claims to support this project. Please use sonar.scm.provider to define SCM of your project.14:55:23.498 INFO - ------------- Scan My Sonar Analyses for PHP project14:55:23.498 INFO - Load module settings14:55:23.576 INFO - Language is forced to php14:55:23.576 INFO - Load rules14:55:23.864 INFO - Base dir: C:\Users\user\.jenkins\jobs\projet\workspace14:55:23.864 INFO - Working dir: C:\Users\user\.jenkins\jobs\projet\workspace\.sonar14:55:23.864 INFO - Source paths: .14:55:23.864 INFO - Source encoding: UTF-8, default locale: fr_FR14:55:23.864 INFO - Index files14:55:23.866 INFO - **0 files indexed******************************14:55:23.866 INFO - Quality profile for php: Sonar way14:55:24.095 INFO - Sensor Lines Sensor14:55:24.095 INFO - Sensor Lines Sensor (done) | time=0ms14:55:24.095 INFO - Sensor QProfileSensor14:55:24.105 INFO - Sensor QProfileSensor (done) | time=10ms14:55:24.105 INFO - Sensor InitialOpenIssuesSensor14:55:24.120 INFO - Sensor InitialOpenIssuesSensor (done) | time=15ms14:55:24.120 INFO - Sensor ProjectLinksSensor14:55:24.128 INFO - Sensor ProjectLinksSensor (done) | time=8ms14:55:24.128 INFO - Sensor VersionEventsSensor14:55:24.133 INFO - Sensor VersionEventsSensor (done) | time=5ms14:55:24.133 INFO - Sensor SCM Sensor14:55:24.133 INFO - No SCM system was detected. You can use the 'sonar.scm.provider' property to explicitly specify it.14:55:24.133 INFO - Sensor SCM Sensor (done) | time=0ms14:55:24.133 INFO - Sensor CPD Sensor14:55:24.133 INFO - DefaultCpdEngine is used for php14:55:24.133 INFO - Sensor CPD Sensor (done) | time=0ms14:55:24.133 INFO - No quality gate is configured.14:55:24.163 INFO - Compare to previous analysis (2015-10-28)14:55:24.165 INFO - Compare over 30 days (2015-09-28, analysis of Wed Oct 28 14:39:55 CET 2015)14:55:24.267 INFO - Execute decorators...14:55:24.372 INFO - Store results in database14:55:24.425 INFO - Analysis reports generated in 35ms, dir size=2 KB14:55:24.435 INFO - Analysis reports compressed in 10ms, zip size=2 KB14:55:24.459 INFO - Analysis reports sent to server in 23ms14:55:24.460 INFO - ANALYSIS SUCCESSFUL, you can browse http://localhost:9000/dashboard/indexrojet14:55:24.460 INFO - Note that you will be able to access the updated dashboard once the server has processed the submitted analysis report.INFO: ------------------------------------------------------------------------INFO: EXECUTION SUCCESSINFO: ------------------------------------------------------------------------Total time: 3.851sFinal Memory: 13M/113MINFO: ------------------------------------------------------------------------Finished: SUCCESSreIt seems like his enable to index files that I have in my php folder.Thanks in advance for your help!",Not-TD-related,Other,,,,0.05,0.902,0.048,-0.6171
33843378,Sonar fails to connect to mysql on mac EI Caption,"I have a sonar configuration that looks like this: sonar.jdbc.username=sonarsonar.jdbc.password=sonarsonar.jdbc.url=jdbc:mysql://localhost:3306/sonar?useUnicode=true characterEncod$sonar.jdbc.driverClassName=com.mysql.jdbc.Driversonar.jdbc.validationQuery=select 1reMysql server is successfully running.I have started sonar like: ./sonar.sh startreConsole looks like: Starting SonarQube...Started SonarQube.reBut codehttp://localhost:9000 give me error like the one in fig:a href=https://i.stack.imgur.com/7PvDz.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/7PvDz.png alt=enter image description here/aIs there any thing missing to connect sonar with mysql ?Here are my logs from sonar.logs: --   Wrapper Started as DaemonLaunching a JVM...Wrapper (Version 3.2.3) http://wrapper.tanukisoftware.org Copyright 1999-2006 Tanuki Software, Inc. All Rights Reserved.2015.11.21 17:03:21 INFO app[o.s.p.m.JavaProcessLauncher] Launch process[search]: /Library/Java/JavaVirtualMachines/jdk1.8.0_65.jdk/Contents/Home/jre/bin/java -Djava.awt.headless=true -Xmx1G -Xms256m -Xss256k -Djava.net.preferIPv4Stack=true -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+HeapDumpOnOutOfMemoryError -Djava.io.tmpdir=/usr/local/Cellar/sonar/5.2bexec/temp -cp .b/common/*:.b/search/* org.sonar.search.SearchServer /var/folders/cg/fg6j4gpd2jvg76y22fhnr_f00000gn/T/sq-process4013461511666170063properties2015.11.21 17:03:21 INFO es[o.s.p.ProcessEntryPoint] Starting searc015.11.21 17:03:21 INFO es[o.s.s.SearchSettings] Elasticsearch listening on 127.0.0.1:90012015.11.21 17:03:22 INFO es[o.elasticsearch.node] [sonar-1448107401111] version[1.7.2], pid[1741], build[e43676b/2015-09-14T09:49:53Z]2015.11.21 17:03:22 INFO es[o.elasticsearch.node] [sonar-1448107401111] initializing ...2015.11.21 17:03:22 INFO es[o.e.plugins] [sonar-1448107401111] loaded [], sites []2015.11.21 17:03:22 INFO es[o.elasticsearch.env] [sonar-1448107401111] using [1] data paths, mounts [[/ (/dev/disk0s2)]], net usable_space [278.3gb], net total_space [371.8gb], types [hfs]2015.11.21 17:03:23 WARN es[o.e.bootstrap] JNA not found. native methods will be disabled.2015.11.21 17:03:23 INFO es[o.elasticsearch.node] [sonar-1448107401111] initialized2015.11.21 17:03:23 INFO es[o.elasticsearch.node] [sonar-1448107401111] starting ...2015.11.21 17:03:23 INFO es[o.e.transport] [sonar-1448107401111] bound_address {inet[/127.0.0.1:9001]}, publish_address {inet[/127.0.0.1:9001]}2015.11.21 17:03:23 INFO es[o.e.discovery] [sonar-1448107401111] sonarqube/wE-3adbvTRKj14FKn6iMIA2015.11.21 17:03:26 INFO es[o.e.cluster.service] [sonar-1448107401111] new_master [sonar-1448107401111][wE-3adbvTRKj14FKn6iMIA][Muhammads-MBP][inet[/127.0.0.1:9001]]{rack_id=sonar-1448107401111}, reason: zen-disco-join (elected_as_master)2015.11.21 17:03:26 INFO es[o.elasticsearch.node] [sonar-1448107401111] started2015.11.21 17:03:26 INFO es[o.e.gateway] [sonar-1448107401111] recovered [0] indices into cluster_stateJava HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=160m; support was removed in 8.02015.11.21 17:03:27 INFO app[o.s.p.m.Monitor] Process[search] is up2015.11.21 17:03:27 INFO app[o.s.p.m.JavaProcessLauncher] Launch process[web]: /Library/Java/JavaVirtualMachines/jdk1.8.0_65.jdk/Contents/Home/jre/bin/java -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djruby.management.enabled=false -Djruby.compile.invokedynamic=false -Xmx768m -Xms256m -XX:MaxPermSize=160m -XX:+HeapDumpOnOutOfMemoryError -Djava.net.preferIPv4Stack=true -Djava.io.tmpdir=/usr/local/Cellar/sonar/5.2bexec/temp -cp .b/common/*:.b/server/*:/usr/local/Cellar/sonar/5.2bexecb/jdbc//-1.3.176.jar org.sonar.server.app.WebServer /var/folders/cg/fg6j4gpd2jvg76y22fhnr_f00000gn/T/sq-process4839778306314254109properties2015.11.21 17:03:27 INFO web[o.s.p.ProcessEntryPoint] Starting web2015.11.21 17:03:28 INFO web[o.s.s.app.Webapp] Webapp directory: /usr/local/Cellar/sonar/5.2bexec/web2015.11.21 17:03:28 INFO web[o.a.c.h.Http11NioProtocol] Initializing ProtocolHandler [http-nio-0.0.0.0-9000]2015.11.21 17:03:28 INFO web[o.a.t.u.n.NioSelectorPool] Using a shared selector for servlet write/read2015.11.21 17:03:29 INFO web[o.e.plugins] [sonar-1448107401111] loaded [], sites []2015.11.21 17:03:30 INFO web[o.s.s.p.ServerImpl] SonarQube Server / 5.2 / f045be98be3ba032b6b19d71574038eeeb91803b2015.11.21 17:03:30 INFO web[o.s.s.d.EmbeddedDatabase] Starting embedded database on port 9092 with url jdbc::tcp://localhost:9092/sonar2015.11.21 17:03:30 INFO web[o.s.s.d.EmbeddedDatabase] Embedded database started. Data stored in: /usr/local/Cellar/sonar/5.2bexec/data2015.11.21 17:03:30 INFO web[o.sonar.db.Database] Create JDBC data source for jdbc::tcp://localhost:9092/sonar2015.11.21 17:03:30 WARN web[o.s.d.DatabaseChecker] H2 database should be used for evaluation purpose only2015.11.21 17:03:32 INFO web[o.s.s.p.DefaultServerFileSystem] SonarQube home: /usr/local/Cellar/sonar/5.2bexec2015.11.21 17:03:32 INFO es[o.e.cluster.metadata] [sonar-1448107401111] [rules] creating index, cause [api], templates [], shards [1]/[0], mappings []2015.11.21 17:03:32 INFO es[o.e.cluster.metadata] [sonar-1448107401111] [rules] create_mapping [rule]2015.11.21 17:03:32 INFO es[o.e.cluster.metadata] [sonar-1448107401111] [rules] create_mapping [activeRule]2015.11.21 17:03:33 INFO web[o.s.s.p.ServerPluginRepository] Plugin Java [java] installed2015.11.21 17:03:33 INFO web[o.s.s.p.ServerPluginRepository] Plugin Git [scmgit] installed2015.11.21 17:03:33 INFO web[o.s.s.p.ServerPluginRepository] Plugin SVN [scmsvn] installed2015.11.21 17:03:33 INFO web[o.s.s.p.ServerPluginRepository] Deploy plugin Git / 1.0 / 9ce9d330c313c296fab051317cc5ad4b26319e072015.11.21 17:03:33 INFO web[o.s.s.p.ServerPluginRepository] Deploy plugin Java / 3.6 / 88ff47a7574edcc4472ff495c15b6f94d8dbd98f2015.11.21 17:03:33 INFO web[o.s.s.p.ServerPluginRepository] Deploy plugin SVN / 1.2 / d04c3cdb21f48905dd8300d1129ec90281aa6db22015.11.21 17:03:33 INFO web[o.s.s.d.m.DatabaseMigrator] Create database2015.11.21 17:03:34 INFO web[o.s.s.p.RailsAppsDeployer] Deploying Ruby on Rails applications2015.11.21 17:03:35 INFO web[o.s.s.p.UpdateCenterClient] Update center: http://update.sonarsource.org/update-center.properties (no proxy)2015.11.21 17:03:35 INFO web[o.s.s.e.IndexCreator] Create index tests2015.11.21 17:03:35 INFO es[o.e.cluster.metadata] [sonar-1448107401111] [tests] creating index, cause [api], templates [], shards [5]/[0], mappings []2015.11.21 17:03:35 INFO web[o.s.s.e.IndexCreator] Create type tests/test2015.11.21 17:03:35 INFO es[o.e.cluster.metadata] [sonar-1448107401111] [tests] create_mapping [test]2015.11.21 17:03:35 INFO web[o.s.s.e.IndexCreator] Create index activities2015.11.21 17:03:35 INFO es[o.e.cluster.metadata] [sonar-1448107401111] [activities] creating index, cause [api], templates [], shards [5]/[0], mappings []2015.11.21 17:03:35 INFO web[o.s.s.e.IndexCreator] Create type activities/activity2015.11.21 17:03:35 INFO es[o.e.cluster.metadata] [sonar-1448107401111] [activities] create_mapping [activity]2015.11.21 17:03:35 INFO web[o.s.s.e.IndexCreator] Create index issues2015.11.21 17:03:36 INFO es[o.e.cluster.metadata] [sonar-1448107401111] [issues] creating index, cause [api], templates [], shards [5]/[0], mappings []2015.11.21 17:03:36 INFO web[o.s.s.e.IndexCreator] Create type issues/authorization2015.11.21 17:03:36 INFO es[o.e.cluster.metadata] [sonar-1448107401111] [issues] create_mapping [authorization]2015.11.21 17:03:36 INFO web[o.s.s.e.IndexCreator] Create type issues/issue2015.11.21 17:03:36 INFO es[o.e.cluster.metadata] [sonar-1448107401111] [issues] create_mapping [issue]2015.11.21 17:03:36 INFO web[o.s.s.e.IndexCreator] Create index users2015.11.21 17:03:36 INFO es[o.e.cluster.metadata] [sonar-1448107401111] [users] creating index, cause [api], templates [], shards [5]/[0], mappings []2015.11.21 17:03:36 INFO web[o.s.s.e.IndexCreator] Create type users/user2015.11.21 17:03:36 INFO es[o.e.cluster.metadata] [sonar-1448107401111] [users] create_mapping [user]2015.11.21 17:03:36 INFO web[o.s.s.e.IndexCreator] Create index views2015.11.21 17:03:36 INFO es[o.e.cluster.metadata] [sonar-1448107401111] [views] creating index, cause [api], templates [], shards [5]/[0], mappings []2015.11.21 17:03:36 INFO web[o.s.s.e.IndexCreator] Create type views/view2015.11.21 17:03:36 INFO es[o.e.cluster.metadata] [sonar-1448107401111] [views] create_mapping [view]2015.11.21 17:03:36 INFO web[o.s.s.n.NotificationService] Notification service started (delay 60 sec.)2015.11.21 17:03:36 INFO web[o.s.s.s.IndexSynchronizer] Index rules2015.11.21 17:03:37 INFO web[o.s.s.s.IndexSynchronizer] Index activeRules2015.11.21 17:03:37 INFO web[o.s.s.s.RegisterMetrics] Register metrics2015.11.21 17:03:37 INFO web[o.s.s.s.RegisterDebtModel] Register technical debt model2015.11.21 17:03:37 INFO web[o.s.s.r.RegisterRules] Register rules2015.11.21 17:03:43 INFO web[o.s.s.q.RegisterQualityProfiles] Register quality profiles2015.11.21 17:03:44 INFO web[o.s.s.q.RegisterQualityProfiles] Register profile {lang=java, name=Sonar way}2015.11.21 17:03:46 INFO web[o.s.s.q.RegisterQualityProfiles] Set default java profile: Sonar way2015.11.21 17:03:46 INFO web[o.s.s.s.RegisterNewMeasureFilters] Register measure filters2015.11.21 17:03:46 INFO web[o.s.s.s.RegisterNewMeasureFilters] Register measure filter: Projects2015.11.21 17:03:46 INFO web[o.s.s.s.RegisterNewMeasureFilters] Register measure filter: My favourites2015.11.21 17:03:46 INFO web[o.s.s.s.RegisterDashboards] Register dashboards2015.11.21 17:03:46 INFO web[o.s.s.s.RegisterDashboards] Register dashboard: Dashboard2015.11.21 17:03:46 INFO web[o.s.s.s.RegisterDashboards] Register dashboard: Home2015.11.21 17:03:46 INFO web[o.s.s.s.RegisterDashboards] Register dashboard: Issues2015.11.21 17:03:46 INFO web[o.s.s.s.RegisterDashboards] Register dashboard: TimeMachine2015.11.21 17:03:46 INFO web[o.s.s.s.RegisterPermissionTemplates] Register permission templates2015.11.21 17:03:46 INFO web[o.s.s.s.RenameDeprecatedPropertyKeys] Rename deprecated property keys2015.11.21 17:03:46 INFO web[o.s.s.s.RenameIssueWidgets] Replacing issue related widgets with issue filter widgets2015.11.21 17:03:46 INFO web[o.s.s.s.IndexSynchronizer] Index activities2015.11.21 17:03:46 INFO es[o.e.cluster.metadata] [sonar-1448107401111] [activities] update_mapping [activity] (dynamic)2015.11.21 17:03:46 INFO web[o.s.s.s.IndexSynchronizer] Index issues2015.11.21 17:03:47 INFO web[o.s.s.s.IndexSynchronizer] Index tests2015.11.21 17:03:47 INFO web[o.s.s.s.IndexSynchronizer] Index users2015.11.21 17:03:47 INFO web[o.s.s.s.IndexSynchronizer] Index views2015.11.21 17:03:47 INFO web[o.s.s.c.q.PurgeCeActivities] Delete the Compute Engine tasks created before Mon May 25 17:03:47 PKT 20152015.11.21 17:03:47 INFO web[jruby.rack] jruby 1.7.9 (ruby-1.8.7p370) 2013-12-06 87b108a on Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17 [darwin-x86_64]2015.11.21 17:03:47 INFO web[jruby.rack] using a shared (threadsafe!) runtime2015.11.21 17:03:58 INFO web[jruby.rack] keeping custom (config.logger) Rails logger instance2015.11.21 17:03:58 INFO web[o.a.c.h.Http11NioProtocol] Starting ProtocolHandler [http-nio-0.0.0.0-9000]2015.11.21 17:03:58 INFO web[o.s.s.a.TomcatAccessLog] Web server is started2015.11.21 17:03:58 INFO web[o.s.s.a.EmbeddedTomcat] HTTP connector enabled on port 90002015.11.21 17:03:59 INFO app[o.s.p.m.Monitor] Process[web] is upWARNING: while creating new bindings for class org.jruby.rack.RackInput,found an existing binding; you may want to run a clean build.WARNING: while creating new bindings for class org.jruby.rack.RackInput,found an existing binding; you may want to run a clean build.2015.11.21 17:03:59 ERROR web[o.s.s.ui.JRubyFacade] Fail to render: http://localhost:9000/en-US is not a valid locale /Users/muhammadsoorage/.rvm/gems/ruby-2.2.1/gems/i18n-0.7.0b/i18n.rb:284:in `enforce_available_locales!' /Users/muhammadsoorage/.rvm/gems/ruby-2.2.1/gems/i18n-0.7.0b/i18n/config.rb:13:in `locale=' /Users/muhammadsoorage/.rvm/gems/ruby-2.2.1/gems/i18n-0.7.0b/i18n.rb:43:in `locale=' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/app/controllers/application_controller.rb:99:in `set_user_session' org/jruby/RubyKernel.java:2223:in `send' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/activesupport-2.3.15b/active_support/callbacks.rb:178:in `evaluate_method' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/activesupport-2.3.15b/active_support/callbacks.rb:166:in `call' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/actionpack-2.3.15b/action_controller/filters.rb:225:in `call' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/actionpack-2.3.15b/action_controller/filters.rb:629:in `run_before_filters' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/actionpack-2.3.15b/action_controller/filters.rb:615:in `call_filters' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/actionpack-2.3.15b/action_controller/filters.rb:610:in `perform_action_with_filters' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/actionpack-2.3.15b/action_controller/benchmarking.rb:68:in `perform_action_with_benchmark' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/activesupport-2.3.15b/active_support/core_ext/benchmark.rb:17:in `ms' jar:file:/usr/local/Cellar/sonar/5.2bexecb/server/jruby-complete-1.7.9.jar!/META-INF/jruby.homeb/ruby/1.8/benchmark.rb:308:in `realtime' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/activesupport-2.3.15b/active_support/core_ext/benchmark.rb:17:in `ms' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/actionpack-2.3.15b/action_controller/benchmarking.rb:68:in `perform_action_with_benchmark' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/actionpack-2.3.15b/action_controller/rescue.rb:160:in `perform_action_with_rescue' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/actionpack-2.3.15b/action_controller/flash.rb:151:in `perform_action_with_flash' org/jruby/RubyKernel.java:2223:in `send' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/actionpack-2.3.15b/action_controller/base.rb:532:in `process' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/actionpack-2.3.15b/action_controller/filters.rb:606:in `process_with_filters' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/actionpack-2.3.15b/action_controller/base.rb:391:in `process' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/actionpack-2.3.15b/action_controller/base.rb:386:in `call' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/actionpack-2.3.15b/action_controller/routing/route_set.rb:450:in `call' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/actionpack-2.3.15b/action_controller/dispatcher.rb:87:in `dispatch' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/actionpack-2.3.15b/action_controller/dispatcher.rb:121:in `_call' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/actionpack-2.3.15b/action_controller/dispatcher.rb:130:in `build_middleware_stack' org/jruby/RubyProc.java:290:in `call' org/jruby/RubyProc.java:224:in `call' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/activerecord-2.3.15b/active_record/query_cache.rb:29:in `call' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/activerecord-2.3.15b/active_record/connection_adapters/abstract/query_cache.rb:34:in `cache' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/activerecord-2.3.15b/active_record/query_cache.rb:9:in `cache' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/activerecord-2.3.15b/active_record/query_cache.rb:28:in `call' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/activerecord-2.3.15b/active_record/connection_adapters/abstract/connection_pool.rb:361:in `call' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/config/environment.rb:67:in `call' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/actionpack-2.3.15b/action_controller/string_coercion.rb:25:in `call' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/rack-1.1.6b/rack/head.rb:9:in `call' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/rack-1.1.6b/rack/methodoverride.rb:24:in `call' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/actionpack-2.3.15b/action_controllerarams_parser.rb:15:in `call' file:/usr/local/Cellar/sonar/5.2bexecb/server/jruby-rack-1.1.13.2.jar!/jruby/rack/session_store.rb:70:in `context' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/rack-1.1.6b/rack/session/abstract/id.rb:58:in `call' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/actionpack-2.3.15b/action_controller/failsafe.rb:26:in `call' /usr/local/Cellar/sonar/5.2bexec/web/WEB-INF/gems/gems/actionpack-2.3.15b/action_controller/dispatcher.rb:106:in `call' file:/usr/local/Cellar/sonar/5.2bexecb/server/jruby-rack-1.1.13.2.jar!/rack/adapter/rails.rb:34:in `serve_rails' file:/usr/local/Cellar/sonar/5.2bexecb/server/jruby-rack-1.1.13.2.jar!/rack/adapter/rails.rb:39:in `call' file:/usr/local/Cellar/sonar/5.2bexecb/server/jruby-rack-1.1.13.2.jar!/rack/handler/servlet.rb:22:in `call're",Not-TD-related,Other,,,,0.023,0.904,0.074,0.9908
33918733,SonarQube 5.1.1 LDAP authentication is not working,"I am using Sonar 5.1.1 version. I am trying to Link the Sonar with LDAP server.For this these are the properties i am givig. sonar.security.realm=LDAPsonar.security.savePassword=trueldap.url=ldap://***ldap.windows.auth=falseldap.user.baseDn=CN=Development,DC=abc,DC=comldap.user.request=( (objectClass=user)(sAMAccountName={login}))ldap.user.realNameAttribute=cnldap.user.emailAttribute=mailldap.group.baseDn=CN=Development,DC=abc,DC=comldap.group.request=( (objectClass=group)(member={dn}))reIn The sonar.log/ LdapGroupMapping{baseDn=CN=Development,DC=abc,DC=com, idAttribute=cn, requiredUserAttributes=[dn], request=( (objectClass=group)(**member={0}**))}2015.11.25 18:53:04 INFO web[o.s.p.l.LdapContextFactory] Test LDAP connection on ldap://****: OK2015.11.25 18:53:04 INFO web[org.sonar.INFO] Security realm started2015.11.25 18:53:04 INFO web[o.s.s.n.NotificationService] Notification service started (delay 60 sec.)2015.11.25 18:53:04 INFO web[o.s.s.s.IndexSynchronizer] Index rules2015.11.25 18:53:04 INFO web[o.s.s.s.IndexSynchronizer] Index activeRules2015.11.25 18:53:04 INFO web[o.s.s.s.RegisterMetrics] Register metrics2015.11.25 18:53:05 INFO web[o.s.s.s.RegisterMetrics] Cleaning quality gate conditions2015.11.25 18:53:05 INFO web[o.s.s.s.RegisterDebtModel] Register technical debt model2015.11.25 18:53:05 INFO web[o.s.s.r.RegisterRules] Register rulesreHere Above member is coming 0, and when i am trying to login from sonar web UI, I am getting this message in log. ERROR web[rails] Error from external users provider: exception Java::OrgSonarApiUtils::SonarException: Unable to retrieve details for user maruti in   default  re",Not-TD-related,Other,,,,0.063,0.919,0.018,-0.7378
34192201,Is onclick attribute redundant after href attribute?,"In the below code,   div id=content   Here is my   a href=javascript:(function(){ _my_script=document.createElement('SCRIPT'); _my_script.type='text/javascript'; _my_script.src='file:///D:/Access/bookmark/bmlet.js'; document.getElementsByTagName('head')[0].appendChild(_my_script);})();   bookmarklet  /a    /div  rein addition to bookmark functionality, codejavascript: URI scheme allows you to invoke the JavaScript code that can inspect/update DOM of current page on click event of anchor tag(codea),Another example, where, code  a href=JavaScript:void(0) onClick=alert('Hello');  Say Hello  /a  ?can be written as,code  a href=JavaScript:{alert('Hello');}void(0)  Say Hello  /a  ?So, What is the purpose of html attribute codeonclick?",Not-TD-related,Other,,,,0,1,0,0
34467473,Fade in on scroll doesn't work in mobile browser,"I am using this code to add class show to my images so when a person scrolls down, images show up. It works on desktop (tested in chrome, with mousescroll and with touch simulation) but it does not work in chrome on mobile device. Swipe(scroll with touch) is not detected. Page goes down but images dont get that .show. I am using this inside fullpage.js+iscroll.js page. You can try this at: a href=http://www.vinarijapantic.com/apps/onePageroject.html rel=nofollowhttp://www.vinarijapantic.com/apps/onePageroject.html/aAny ideas? jQuery(document).ready(function($) { function showImages(el) { var windowHeight = jQuery(window).height(); $(el).each(function() { var thisPos = $(this).offset().top; var topOfWindow = $(window).scrollTop(); if (topOfWindow + windowHeight - 250    thisPos) { $(this).addClass(show); } }); } /*full page library */ var SCROLLING_SPEED = 600; $('fullpage').fullpage({ scrollOverflow: true, css3: true, controlArrows: true, loopHorizontal: false, easing: 'easeInOutCubic', easingcss3: 'ease-out', autoScrolling: true, scrollingSpeed: SCROLLING_SPEED, //anchors:['s0', 's1', 's2', 's3'] afterLoad: function(anchorLink, index) { }, afterSlideLoad: function(anchorLink, index, slideAnchor, slideIndex) { if (slideIndex == 0) { $('.slide-' + index).addClass('show'); } else { $('.slide').removeClass('show'); } if ($('.bigScroll').hasClass('active')    $('.bigScroll').closest('.section').hasClass('active')) { console.log($(.bigScroll).height()); showImages('.bigScroll img'); $('.fp-scrollable').scroll(function() { showImages('.bigScroll img'); }); } } }); });re",Not-TD-related,Other,,,,0,0.892,0.108,0.9538
34493713,Step definitions library for Meteor-cucumber/chimp,Hi I am looking for predefined (common) step definitions for Meteor-cucumber\chimp.I used PHP's Behat (BDD cucumber framework). There is this a href=https://github.com/Behat/MinkExtension rel=nofollow noreferrerextensions/a and this a href=https://github.com/Behat/MinkExtension/blob/master/src/Behat/MinkExtension/Context/MinkContext.php rel=nofollow noreferrerclass/a. Which allows you to have a common step definitions out of the box. You don't need to write those step definitions by yourself. Down below it is the list of step definitions you got from Behat. a href=https://i.stack.imgur.comMrfF.png rel=nofollow noreferrerimg src=https://i.stack.imgur.comMrfF.png alt=behat -dl/a,Not-TD-related,Other,,,,0,1,0,0
34950922,VSSonarExtention - why connect to the server?,"Just installed and started using VSSonarExtension, but already have a couple of questions that I am unable to answer myself:ulliWhy does the extension need to connect to the server if it scans local code with local tools, such as FxCop and StyleCop?liAfter looking through roughly 15 files, I get an error saying that I need a license to scan more than 15 files in one session - isn't the extension open source?liI want to make sure that the rules specified on the server match the rules locally, so that I get the same output with regards to technical debt - how can I achieve it?liSeems like the extension does not use FxCop, according to the logs; moreover, sometimes logs indicate that some code has been skipped because some rules were not present or defined in StyleCop. What does that mean?Looking forward to your replies, thanks for help.",Not-TD-related,Other,,,,0.044,0.852,0.104,0.8485
35224937,Sonar CeWorkerRunnableImpl - Failed to execute task AVKxZzs3XOSwYL28ZL1g,"Facing nullpointerexception while integrating jenkins(1.646) and sonar(5.2).I am trigerring jenkins job for sonar scan, which is completing sucessfully.INFO] Analysis reports generated in 17987ms, dir size=9 MB[INFO] Analysis reports compressed in 21186ms, zip size=3 MB[INFO] Analysis reports sent to server in 1029ms[INFO] ANALYSIS SUCCESSFUL, you can browse http://10.72.118.177:9000/dashboard/index/com.barclaycard.bpay.core:bPay_Core[INFO] Note that you will be able to access the updated dashboard once the server has processed the submitted analysis report.[INFO] More about the report processing at http://10.72.118.177:9000/api/ce/task?id=AVKxZzs3XOSwYL28ZL1gHowever when I look at the status on sonar it I'm getting the below error -016.02.05 12:28:52 ERROR [o.s.s.c.t.CeWorkerRunnableImpl] Failed to execute task AVKxZzs3XOSwYL28ZL1gjava.lang.NullPointerException: null key in entry: null=org.sonar.server.computation.sqale.SqaleRatingSettings$LanguageSpecificConfiguration@1a17df9at com.google.common.collect.CollectPreconditions.checkEntryNotNull(CollectPreconditions.java:31) ~[guava-17.0.jar:na]at com.google.common.collect.ImmutableMap.entryOf(ImmutableMap.java:135) ~[guava-17.0.jar:na]at com.google.common.collect.ImmutableMap$Builder.put(ImmutableMap.java:206) ~[guava-17.0.jar:na]at org.sonar.server.computation.sqale.SqaleRatingSettings.buildLanguageSpecificConfigurationByLanguageKey(SqaleRatingSettings.java:54) ~[sonar-server-5.2.jar:na]at org.sonar.server.computation.sqale.SqaleRatingSettings.<init>(SqaleRatingSettings.java:46) ~[sonar-server-5.2.jar:na]at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[na:1.8.0_60]at sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source) ~[na:1.8.0_60]at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source) ~[na:1.8.0_60]at java.lang.reflect.Constructor.newInstance(Unknown Source) ~[na:1.8.0_60]at org.picocontainer.injectors.AbstractInjector.newInstance(AbstractInjector.java:145) ~[picocontainer-2.15.jar:na]at org.picocontainer.injectors.ConstructorInjector$1.run(ConstructorInjector.java:342) ~[picocontainer-2.15.jar:na]at org.picocontainer.injectors.AbstractInjector$ThreadLocalCyclicDependencyGuard.observe(AbstractInjector.java:270) ~[picocontainer-2.15.jar:na]at org.picocontainer.injectors.ConstructorInjector.getComponentInstance(ConstructorInjector.java:364) ~[picocontainer-2.15.jar:na]at org.picocontainer.injectors.AbstractInjectionFactory$LifecycleAdapter.getComponentInstance(AbstractInjectionFactory.java:56) ~[picocontainer-2.15.jar:na]at org.picocontainer.behaviors.AbstractBehavior.getComponentInstance(AbstractBehavior.java:64) ~[picocontainer-2.15.jar:na]at org.picocontainer.behaviors.Stored.getComponentInstance(Stored.java:91) ~[picocontainer-2.15.jar:na]at org.picocontainer.DefaultPicoContainer.getInstance(DefaultPicoContainer.java:699) ~[picocontainer-2.15.jar:na]at org.picocontainer.DefaultPicoContainer.getComponent(DefaultPicoContainer.java:647) ~[picocontainer-2.15.jar:na]at org.picocontainer.DefaultPicoContainer.getComponent(DefaultPicoContainer.java:632) ~[",Not-TD-related,Other,,,,0.052,0.922,0.025,-0.5994
35703780,Technical Debt decreased after migration,"We just migrate from SQ-4.2 to the last LTS 4.5.6.And we noticed a strange behaviour:ulliOn 4.5.6 de technical debt cost get drastically reduced, while the number of issues get increased (please see attached)a href=http://i.stack.imgur.com/gwD76.jpg rel=nofollowenter image description here/aWe didn't find any answer to this behaviour (change in formulas? in each violation remediation cost?)Before migration (on 4.2): sonar-java-plugin-2.5.jarAfter (on 4.5.6): sonar-java-plugin-3.9.jarThank you in advance for any clarification,Issam",Not-TD-related,Other,,,,0.107,0.802,0.091,-0.2794
36091852,SonarQube - Is there an API to grab a part of analysis for all projects you have?,"I want to be able to extract, for example, just the Technical Debt numbers out of my sonar instance for all the projects I have, and display them on a page.Does Sonar provide an api that I can utilize and achieve this?",Not-TD-related,Other,,,,0.063,0.905,0.033,-0.296
36396710,Calculate technical debt on manual rules,"I am trying to import code and static code check results for APL language (there is no plugin for SonarQube). I have imported all files as txt, created manual rules and manual issue. Installed SQALE plugin and defined measures for my rules, but technical debt is not calculated.I assume that this is because my rules are not in QualityProfile for my project (I used standart SonarWay C, Project has C as language), but I just can not add them there :(Here is what I get when I try to activate them - 0 rule(s) changed, 50 rule(s) ignored in profile Sonar way - C",Not-TD-related,Other,,,,0.079,0.906,0.015,-0.743
36586659,ServerLog : sonarQube server doesn't show analysis,"Well I screw'd up my classpath while I was working on log4j library on a project, (i'm pretty new to coding), I now have fix'd it or almost, but my problem is i have no data on sonarqube serveur @localhost:9000when i run sonar-runner, i success :INFO: EXECUTION SUCCESSINFO: ------------------------------------------------------------------------INFO: Total time: 7.892sINFO: Final Memory: 51M/367M but I have no data when I reach localhost:90000Before I touch'd to classpath stuff it was working well, my sonar-project.properties is a copyaste of the default one on sonarqube websiteI checked the errorLog, but I can't figure out how to fix the error, here is the log :  --   Wrapper Started as ConsoleLaunching a JVM...Wrapper (Version 3.2.3) http://wrapper.tanukisoftware.org Copyright 1999-2006 Tanuki Software, Inc. All Rights Reserved.2016.04.13 02:30:01 INFO app[o.s.a.AppFileSystem] Cleaning or creating temp directory /usr/local/Cellar/sonar/5.4bexec/temp2016.04.13 02:30:01 INFO app[o.s.p.m.JavaProcessLauncher] Launch process[search]: /Library/Java/JavaVirtualMachines/jdk1.8.0_65.jdk/Contents/Home/jre/bin/java -Djava.awt.headless=true -Xmx1G -Xms256m -Xss256k -Djava.net.preferIPv4Stack=true -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+HeapDumpOnOutOfMemoryError -Djava.io.tmpdir=/usr/local/Cellar/sonar/5.4bexec/temp -cp .b/common/*:.b/search/* org.sonar.search.SearchServer /var/folders/zb/hstkh53d32d1yqxmyhbjrg3c0000gq/T/sq-process7171255290909270089properties2016.04.13 02:30:02 INFO es[o.s.p.ProcessEntryPoint] Starting searc016.04.13 02:30:02 INFO es[o.s.s.SearchSettings] Elasticsearch listening on 127.0.0.1:9001log4j:WARN No appenders could be found for logger (org.elasticsearch.node).log4j:WARN Please initialize the log4j system properly.log4j:WARN See http://logging.apache.org/log4j/1.2/faq.htmlnoconfig for more info.2016.04.13 02:30:07 INFO app[o.s.p.m.Monitor] Process[search] is up2016.04.13 02:30:07 INFO app[o.s.p.m.JavaProcessLauncher] Launch process[web]: /Library/Java/JavaVirtualMachines/jdk1.8.0_65.jdk/Contents/Home/jre/bin/java -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djruby.management.enabled=false -Djruby.compile.invokedynamic=false -Xmx768m -Xms256m -XX:MaxPermSize=160m -XX:+HeapDumpOnOutOfMemoryError -Djava.net.preferIPv4Stack=true -Djava.io.tmpdir=/usr/local/Cellar/sonar/5.4bexec/temp -cp .b/common/*:.b/server/*:/usr/local/Cellar/sonar/5.4bexecb/jdbc//-1.3.176.jar org.sonar.server.app.WebServer /var/folders/zb/hstkh53d32d1yqxmyhbjrg3c0000gq/T/sq-process8184838493579271569propertiesJava HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=160m; support was removed in 8.02016.04.13 02:30:07 INFO web[o.s.p.ProcessEntryPoint] Starting web2016.04.13 02:30:07 INFO web[o.s.s.a.TomcatContexts] Webapp directory: /usr/local/Cellar/sonar/5.4bexec/web2016.04.13 02:30:08 INFO web[o.a.c.h.Http11NioProtocol] Initializing ProtocolHandler [http-nio-0.0.0.0-9000]2016.04.13 02:30:08 INFO web[o.a.t.u.n.NioSelectorPool] Using a shared selector for servlet write/read2016.04.13 02:30:08 INFO web[o.s.s.p.ServerImpl] SonarQube Server / 5.4 / 7b02df9be3cd9448699b5857586e1c6e2b28c0072016.04.13 02:30:08 INFO web[o.s.s.d.EmbeddedDatabase] Starting embedded database on port 9092 with url jdbc::tcp://localhost:9092/sonar2016.04.13 02:30:08 INFO web[o.s.s.d.EmbeddedDatabase] Embedded database started. Data stored in: /usr/local/Cellar/sonar/5.4bexec/data2016.04.13 02:30:08 INFO web[o.sonar.db.Database] Create JDBC data source for jdbc::tcp://localhost:9092/sonar2016.04.13 02:30:08 WARN web[o.s.d.DatabaseChecker] H2 database should be used for evaluation purpose only2016.04.13 02:30:09 INFO web[o.e.plugins] [sonar-1460507401119] loaded [], sites []2016.04.13 02:30:10 INFO web[o.s.s.p.DefaultServerFileSystem] SonarQube home: /usr/local/Cellar/sonar/5.4bexec2016.04.13 02:30:11 INFO web[o.s.s.p.ServerPluginRepository] Plugin C [csharp] installed2016.04.13 02:30:11 INFO web[o.s.s.p.ServerPluginRepository] Plugin Java [java] installed2016.04.13 02:30:11 INFO web[o.s.s.p.ServerPluginRepository] Plugin JavaScript [javascript] installed2016.04.13 02:30:11 INFO web[o.s.s.p.ServerPluginRepository] Plugin Git [scmgit] installed2016.04.13 02:30:11 INFO web[o.s.s.p.ServerPluginRepository] Plugin SVN [scmsvn] installed2016.04.13 02:30:11 INFO web[o.s.s.p.ServerPluginRepository] Deploy plugin C / 4.4 / 5b9adce1c37c4ef907b316ea4500ed5d7c4629c42016.04.13 02:30:11 INFO web[o.s.s.p.ServerPluginRepository] Deploy plugin Git / 1.0 / 9ce9d330c313c296fab051317cc5ad4b26319e072016.04.13 02:30:11 INFO web[o.s.s.p.ServerPluginRepository] Deploy plugin Java / 3.10 / e55d43e814fd68587a7a9e0f37089492b34445cc2016.04.13 02:30:11 INFO web[o.s.s.p.ServerPluginRepository] Deploy plugin JavaScript / 2.10 / 88475229068f817583013a08facf2b45d03578292016.04.13 02:30:11 INFO web[o.s.s.p.ServerPluginRepository] Deploy plugin SVN / 1.2 / d04c3cdb21f48905dd8300d1129ec90281aa6db22016.04.13 02:30:11 INFO web[o.s.s.d.m.DatabaseMigrator] Create database2016.04.13 02:30:11 INFO web[o.s.s.p.RailsAppsDeployer] Deploying Ruby on Rails applications2016.04.13 02:30:12 INFO web[o.s.s.p.UpdateCenterClient] Update center: http://update.sonarsource.org/update-center.properties (no proxy)2016.04.13 02:30:12 INFO web[o.s.s.e.IndexCreator] Create index tests2016.04.13 02:30:12 INFO web[o.s.s.e.IndexCreator] Create type tests/test2016.04.13 02:30:12 INFO web[o.s.s.e.IndexCreator] Create index activities2016.04.13 02:30:13 INFO web[o.s.s.e.IndexCreator] Create type activities/activity2016.04.13 02:30:13 INFO web[o.s.s.e.IndexCreator] Create index issues2016.04.13 02:30:13 INFO web[o.s.s.e.IndexCreator] Create type issues/authorization2016.04.13 02:30:13 INFO web[o.s.s.e.IndexCreator] Create type issues/issue2016.04.13 02:30:13 INFO web[o.s.s.e.IndexCreator] Create index users2016.04.13 02:30:13 INFO web[o.s.s.e.IndexCreator] Create type users/user2016.04.13 02:30:13 INFO web[o.s.s.e.IndexCreator] Create index views2016.04.13 02:30:13 INFO web[o.s.s.e.IndexCreator] Create type views/view2016.04.13 02:30:13 INFO web[o.s.s.n.NotificationService] Notification service started (delay 60 sec.)2016.04.13 02:30:13 INFO web[o.s.s.s.IndexSynchronizer] Index rules2016.04.13 02:30:13 INFO web[o.s.s.s.IndexSynchronizer] Index activeRules2016.04.13 02:30:13 INFO web[o.s.s.s.RegisterMetrics] Register metrics2016.04.13 02:30:14 INFO web[o.s.s.s.RegisterDebtModel] Register technical debt model2016.04.13 02:30:14 INFO web[o.s.s.r.RegisterRules] Register rules2016.04.13 02:30:22 INFO web[o.s.s.q.RegisterQualityProfiles] Register quality profiles2016.04.13 02:30:23 INFO web[o.s.s.q.RegisterQualityProfiles] Register profile {lang=cs, name=Sonar way}2016.04.13 02:30:24 INFO web[o.s.s.q.RegisterQualityProfiles] Set default cs profile: Sonar way2016.04.13 02:30:24 INFO web[o.s.s.q.RegisterQualityProfiles] Register profile {lang=java, name=Sonar way}2016.04.13 02:30:25 INFO web[o.s.s.q.RegisterQualityProfiles] Set default java profile: Sonar way2016.04.13 02:30:25 INFO web[o.s.s.q.RegisterQualityProfiles] Register profile {lang=js, name=Sonar way}2016.04.13 02:30:26 INFO web[o.s.s.q.RegisterQualityProfiles] Register profile {lang=js, name=Sonar Security Way}2016.04.13 02:30:26 INFO web[o.s.s.q.RegisterQualityProfiles] Set default js profile: Sonar way2016.04.13 02:30:26 INFO web[o.s.s.s.RegisterNewMeasureFilters] Register measure filters2016.04.13 02:30:26 INFO web[o.s.s.s.RegisterNewMeasureFilters] Register measure filter: Projects2016.04.13 02:30:26 INFO web[o.s.s.s.RegisterNewMeasureFilters] Register measure filter: My favourites2016.04.13 02:30:26 INFO web[o.s.s.s.RegisterDashboards] Register dashboards2016.04.13 02:30:26 INFO web[o.s.s.s.RegisterDashboards] Register dashboard: Custom2016.04.13 02:30:26 INFO web[o.s.s.s.RegisterDashboards] Register dashboard: Home2016.04.13 02:30:26 INFO web[o.s.s.s.RegisterPermissionTemplates] Register permission templates2016.04.13 02:30:26 INFO web[o.s.s.s.RenameDeprecatedPropertyKeys] Rename deprecated property keys2016.04.13 02:30:26 INFO web[o.s.s.s.RenameIssueWidgets] Replacing issue related widgets with issue filter widgets2016.04.13 02:30:27 INFO web[o.s.s.s.IndexSynchronizer] Index activities2016.04.13 02:30:27 INFO web[o.s.s.s.IndexSynchronizer] Index issues2016.04.13 02:30:27 INFO web[o.s.s.s.IndexSynchronizer] Index tests2016.04.13 02:30:27 INFO web[o.s.s.s.IndexSynchronizer] Index users2016.04.13 02:30:27 INFO web[o.s.s.s.IndexSynchronizer] Index views2016.04.13 02:30:27 INFO web[o.s.s.c.q.PurgeCeActivities] Delete the Compute Engine tasks created before Fri Oct 16 02:30:27 CEST 20152016.04.13 02:30:28 INFO web[jruby.rack] jruby 1.7.9 (ruby-1.8.7p370) 2013-12-06 87b108a on Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17 [darwin-x86_64]2016.04.13 02:30:28 INFO web[jruby.rack] using a shared (threadsafe!) runtime2016.04.13 02:30:36 INFO web[jruby.rack] keeping custom (config.logger) Rails logger instance2016.04.13 02:30:36 INFO web[o.s.s.p.MasterServletFilter] Initializing servlet filter org.sonar.server.authentication.InitFilter@904e9a6 [pattern=/sessions/init/*]2016.04.13 02:30:36 INFO web[o.s.s.p.MasterServletFilter] Initializing servlet filter org.sonar.server.authentication.OAutCallbackFilter@73903d0f [pattern=/oaut/callback/*]2016.04.13 02:30:36 INFO web[o.a.c.h.Http11NioProtocol] Starting ProtocolHandler [http-nio-0.0.0.0-9000]2016.04.13 02:30:36 INFO web[o.s.s.a.TomcatAccessLog] Web server is started2016.04.13 02:30:36 INFO web[o.s.s.a.EmbeddedTomcat] HTTP connector enabled on port 90002016.04.13 02:30:37 INFO app[o.s.p.m.Monitor] Process[web] is up2016.04.13 02:31:22 INFO web[o.s.s.c.t.CeWorkerCallableImpl] Execute task | project=my:project | id=AVQNB5aeBQmoeuaHE_RF2016.04.13 02:31:22 ERROR web[o.s.s.c.t.CeProcessingSchedulerImpl] Compute Engine execution failed. Scheduled processing interrupted.java.lang.NoSuchMethodError: org.apache.log4j.MDC.put(Ljava/lang/String;Ljava/lang/String;)V at org.sonar.server.computation.log.CeLogging.initForTask(CeLogging.java:107) ~[sonar-server-5.4.jar:na] at org.sonar.server.computation.taskprocessor.CeWorkerCallableImpl.executeTask(CeWorkerCallableImpl.java:71) ~[sonar-server-5.4.jar:na] at org.sonar.server.computation.taskprocessor.CeWorkerCallableImpl.call(CeWorkerCallableImpl.java:55) ~[sonar-server-5.4.jar:na] at org.sonar.server.computation.taskprocessor.CeWorkerCallableImpl.call(CeWorkerCallableImpl.java:34) ~[sonar-server-5.4.jar:na] at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_65] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_65] at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_65] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) [na:1.8.0_65] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) [na:1.8.0_65] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_65] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_65] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_65] reif anyone has an idea ! :)",Not-TD-related,Other,,,,0.042,0.874,0.083,0.9832
36877945,Sonarqube not generating Technical debt data (Debt and Issues) when connecting to Oracle,I can run SonarQube without any database and works fine.When i configure below properties in file sonar.properties to use Oracledatabase then the scan is not generating Technical debt data (Debt and Issues).Duplications and Structure information is coming up correctly. sonar.jdbc.username= sonar.jdbc.password= sonar.jdbc.url=reIs there any config which I need to enable when using external database?I am using SonarQube 5.4 and SonarQube Scanner 2.6. Using ojdbc6_g.jar for Oracle drivers.Thanks in advance for any help.,Not-TD-related,Other,,,,0,0.933,0.067,0.5873
37310373,sonarqube how to access to default technical debt pyramid values from web service api?,"Im trying to access to default technical debt pyramid values, the chart that appears on dashboard, using the web service api that sonarqube provide.I don't have SQALE plugin installed, i just need those default values.there is any way to access to these values using the web service api?.Thanks.",Not-TD-related,Other,,,,0.048,0.848,0.104,0.4404
37478806,Technical Debt Pyramid Widget in Sonarqube 5.5?,"as we all know, the Technical Debt Pyramid Widget was moved into SonarQube core in version 4.0. br/But now in Sonarqube5.5, I'm not able to find it? Is it still exists? Is it plan to be introduced in Sonarqube 5.x one day?br/Thanx !",Not-TD-related,Other,,,,0.075,0.925,0,-0.5158
37746794,Automatically Resolve as Won't Fix issues that are suppressed inline,"I have the convention for FxCop / Code Analysis errors:ulliSuppressed Inline Won't FixliGlobal Suppressed Genuine Technical Debt, should fixWhen generating reports with SonarQube, the supressed inline ones are being flagged as Technical Debt:a href=https://i.stack.imgur.com/U3fNE.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/U3fNE.png alt=SonarQube/aI can go through these and select Resolve as Won't Fix. Is there a way to do this automatically for a project?Update 20/06:brI have updated the plugin to C 5.3, which is now ignoring any supressed files, but emincluding/em the ones in global suppressions. a href=https://stackoverflow.com/questions/37841029/how-do-i-get-sonarqube-to-ignore-the-globalsuppressions-cs-fileI've tried to stop SonarQube from processing the global suppression file, but with no luck/a.Current Versions:ulliSonarQube: Version 5.2 liC Pugin: 5.3",Not-TD-related,Other,,,,0.089,0.893,0.017,-0.7506
37882133,TypeScript and d3 domain type,"I have a problem, when I want to use domain.So, I try to use next part of my codevar x = d3.time.scale().domain([new Date('2016-06-10'), new Date('2016-06-25')]).rangeRound([0, 1000]);And I get error about error types for domain...Argument of type 'Scale' is not assignable to parameter of type 'Scale'.Types of property 'domain' are incompatible.Type '{ (): Date[]; (dates: number[]): Scale; (dates: Date[]): Scale; }' is not assignable to type '{ (): number[]; (values: number[]): Scale; }'.Type 'Date[]' is not assignable to type 'number[]'. Type 'Date' is not assignable to type 'number'.But If we look d3 typingsdomain(): Date[];domain(dates: number[]): Scale<Range, Output>;domain(dates: Date[]): Scale<Range, Output>;domain can take Date array!If we disable types, then all works fine.And I have similar problem with another part of my code:var drag = d3.behavior.drag().on('drag', function (d) {d3.event.sourceEvent.stopPropagation();}).on('dragstart', function () {//});I get error about:Property 'sourceEvent' does not exist on type 'Event | BaseEvent'.But If we look in typesexport var event: Event | BaseEvent;andinterface BaseEvent {type: string;sourceEvent?: Event;}I use typings:""d3"": ""registry:dt/d3#0.0.0+20160614091820""and awesome-typescript-loader for webpackSo, what's wrong with me?",Not-TD-related,Other,,,,0.11,0.873,0.017,-0.956
38058238,TeamCity/Sonar: Fail build if some metric increases,"We're using TeamCity with the Sonar plugin. Is there a way to fail the TeamCity build if some metric (i.e. number of Blocker issues, amount of technical debt, etc.) increases within Sonar, or if it just fails the Quality Gate? I haven't found any documentation regarding this.",Not-TD-related,Other,,,,0.172,0.802,0.025,-0.8176
38117439,eval Remote Code From My Server,"I am building a site platform similar to Wordpress that allows my users to download a code.zip file, upload it onto their server, and be good to go.I know everyone says codeeval() is evil - but the code will not include any user or variable input.The benefit here is that updates will occur automatically. I can just change the code being grabbed on my server.My clients using the code will have pretty low traffic sites - so I'm not worried about overloading their server. Most of the heavy lifting will be done by us.Here's the basic code concept: $code=file_get_contents(http://myserver.com.txt);eval($code);reIs this a realistic option? What security holes do I need to worry about?",Not-TD-related,Other,,,,0.076,0.789,0.135,0.804
38317836,Sonar parsing test-results,"I'm working on a groovy project. I'm trying to generate cobertura-reports on Sonar.But I'm having an issue with test-results.It's giving an error, saying that Sensor GroovySurefireSensor...**parsing** /home/jenkins/workspace/myproject/build/test-resultsWARN - Resource not found: xxx.xxx.myproject.xxx.xxxWARN - Resource not found: xxx.xxx.myproject.xxx.xxxWARN - Resource not found: xxx.xxx.myproject.xxx.xxxWARN - Resource not found: xxx.xxx.myproject.xxx.xxxWARN - Resource not found: xxx.xxx.myproject.xxx.xxxWARN - Resource not found: xxx.xxx.myproject.xxx.xxxWARN - Resource not found: xxx.xxx.myproject.xxx.xxxINFO - Sensor GroovySurefireSensor done: 12 msreFYI: I am able to generate Cobertura reports and test-reports on SonarQube but Technical debt and issues showing zerohrHere is my sonar-project properties: sonar.projectKey=myprojectsonar.projectName=myprojectsonar.projectVersion=1.0sonar.sources=src/maingroovy.sonar.tests=src/testsonar.language=grvysonar.sourceEncoding=UTF-8sonar.surefire.reportsPath=build/test-resultssonar.junit.reportsPath=build/test-resultssonar.groovy.cobertura.reportPath=build/reports/cobertura/coverage.xmlrehrAny suggestions?",Not-TD-related,Other,,,,0.059,0.921,0.02,-0.5267
38539382,Change drupal module directory,"Hello at the installation I want to change the modules directory on drupal 7 so i want to know if it possible or impossible.i want to change ../modules to ../mods/init and site/all/modules to ../mods/globali tried changing the install.core.inc the line require_once DRUPAL_ROOT . '/modules/ but i did get this message: Fatal error: Call to undefined function field_attach_load() in F:\xamp\htdocs\cms\php\dp7_1\includes\entity.inc on line 354",Not-TD-related,Other,,,,0.13,0.816,0.054,-0.8338
38702024,"Rails, Is there a way to generate Unit Tests from Existing Controllers and methods defined in them?",I was wondering if there is a script that can take existing codebase and generate unit tests for each method in controllers. By default all would be passing since they would be empty and i can remove tests i for methods i dont feel important. This would save huge time and increase testing. Since i'd have to define only what each method should output and not boilerplate that needs to be written.,Not-TD-related,Other,,,,0.046,0.847,0.107,0.6606
38717330,Accessing member function of super class,"How can I access a super class' method from a child class' method?Here is an example that illustrates the problem:Lets say, we have two classes class parent definition.public section. methods f.endclass.class child definition inheriting from parent.public section. methods f redefinition. methods g.endclass.reNow, in the implementation of codeg we want to call the super class' implementation of codef similar to the following syntactically wrong snippet class child implementation. method g. super-  f( ). forbidden: super-   can only be used to call the previous implementation of the same method endmethod.endclass.reAs stated in the comment, it is not possible to use codesuper-  . Can you help?hrAfter some googling, it was suggested to copy the implementation of codeparent-  f into codechild-  g is this really the only way to do it?hrThe actual use case@vwegert asked why codef is redefined in the first place. In my real use case, codeparent is a view, and codechild its extension. codechild-  f is an event handler which is supposed to trigger a popup. codechild receives a callback when the popup closes in form of a call to codeg. If codeg is called, the original implementation codeparent-  f should be called.",Not-TD-related,Other,,,,0.03,0.87,0.1,0.9305
38767612,How to retrieve data from multiple daily tables in SQL Server,"I am new to Microsoft SQL Server 2008. I need some help in retrieving data from multiple tables which have same columns with same datatype.Currently I have multiple tables in my database, each table contains data for a single day. For example, I have the following tables:ulliTable_20160820liTable_20160821liTable_20160822liTable_20160823liTable_20160824liTable_20160825All the tables have same columns with same datatype say:ullicolumn_1licolumn_2licolumn_3licolumn_4Now, is it possible to retrieve the columns from all the tables using a single query. What I am exactly looking for is to get the count of column_3 which will be grouped by column_1 for all the tables. I want to avoid writing multiple queries as I need to fetch the data for an entire month i.e. from 30 tables.",Not-TD-related,Other,,,,0.02,0.944,0.036,0.2023
38918830,Jenkins error: Authorization failed to svn in sonarqube.,"I am using Jenkins 2.8 with Sonarqube Plugin 2.2.1. A week ago we had a problem with the sonar server and we get this a href=https://stackoverflow.com/questions/3320400/to-prevent-a-memory-leak-the-jdbc-driver-has-been-forcibly-unregisterederror/a. To solve the problem we decided to create a new mysql schema and link it with sonar server. We did something like this:  mysql u root -plinux;create database sonarqube2 character set utf8;grant all privileges on sonarqube2.* to 'sonarsuer'@'localhost' identified by 'linux';grant all privileges sonarqube2.* to 'sonaruser'@'%' identified by 'linux';flush privileges;reNote: We used the same user we had in the old database After update sonar.jdbc.url with the new data in sonar.properties and in Jenkins configuration we manage to deploy sonarqube again. Then, we tried to launch a SONAR job that we have already created before and we get this error:   [ERROR] Failed to execute goal org.codehaus.mojo:sonar-maven-plugin:2.6:sonar (default-cli) on project cas: The svn blame command [svn blame --xml --non-interactive -x -w src/main/java/net/mycompany/cas/CookieRetrievingCookieGeneratorPatch.java] failed: svn: OPTIONS of 'https://my_svn_server/svn/mycompanyxf/cas/trunk/src/main/java/net/mycompany/cas/CookieRetrievingCookieGeneratorPatch.java': authorization failed: Could not authenticate to server: rejected Basic challenge (https://my_svn_server) -   [Help 1]org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.codehaus.mojo:sonar-maven-plugin:2.6:sonar (default-cli) on project cas: The svn blame command [svn blame --xml --non-interactive -x -w src/main/java/net/mycompany/cas/CookieRetrievingCookieGeneratorPatch.java] failed: svn: OPTIONS of 'https://my_svn_server/svn/mycompanyxf/cas/trunk/src/main/java/net/mycompany/cas/CookieRetrievingCookieGeneratorPatch.java': authorization failed: Could not authenticate to server: rejected Basic challenge (https://my_svn_server)reThis is the whole stacktrace:  [INFO] --- sonar-maven-plugin:2.6:sonar (default-cli) @ cas ---[INFO] SonarQube version: 5.0.1[WARNING] Invalid POM for org.samba.jcifs:jcifs-ext:jar:0.9.4, transitive dependencies (if any) will not be available, enable debug logging for more detailsINFO: Default locale: es_ES, source code encoding: UTF-8 (analysis is platform dependent)INFO: Work directory: /u01/jenkins_home/jobs/SONAR - MC - Cas/workspace/trunk/target/sonarINFO: SonarQube Server 5.0.1[INFO] [13:47:05.297] Load global referentials...[INFO] [13:47:05.751] Load global referentials done: 458 ms[INFO] [13:47:05.771] User cache: /home/tomcat/.sonar/cache[INFO] [13:47:05.801] Install plugins[INFO] [13:47:07.792] Install JDBC driver[INFO] [13:47:07.802] Create JDBC datasource for jdbc:mysql://myserver:3306/sonarqube2?useUnicode=true characterEncoding=utf8[INFO] [13:47:11.353] Initializing Hibernate[ERROR] [13:47:15.591] No license for plugin views[INFO] [13:47:16.958] Load project referentials...[INFO] [13:47:18.003] Load project referentials done: 1045 ms[INFO] [13:47:18.003] Load project settings[INFO] [13:47:19.038] Loading technical debt model...[INFO] [13:47:19.097] Loading technical debt model done: 59 ms[INFO] [13:47:19.115] Apply project exclusions[INFO] [13:47:19.336] ------------- Scan CAS (Central Authentication Service)[INFO] [13:47:19.339] Load module settings[INFO] [13:47:21.334] Loading rules...[INFO] [13:47:23.049] Loading rules done: 1715 ms[INFO] [13:47:23.115] Configure Maven plugins[INFO] [13:47:23.367] No quality gate is configured.[INFO] [13:47:29.435] Initializer FindbugsMavenInitializer...[INFO] [13:47:29.437] Initializer FindbugsMavenInitializer done: 2 ms[INFO] [13:47:29.437] Base dir: /u01/jenkins_home/jobs/SONAR - MC - Cas/workspace/trunk[INFO] [13:47:29.437] Working dir: /u01/jenkins_home/jobs/SONAR - MC - Cas/workspace/trunk/target/sonar[INFO] [13:47:29.438] Source paths: src/main/webapp, pom.xml, src/main/java[INFO] [13:47:29.438] Test paths: src/test/java[INFO] [13:47:29.439] Binary dirs: target/classes[INFO] [13:47:29.439] Source encoding: UTF-8, default locale: es_ES[INFO] [13:47:29.439] Index files[INFO] [13:47:30.480] 36 files indexed[INFO] [13:47:31.213] Quality profile for java: Sonar way[INFO] [13:47:31.213] Quality profile for js: Sonar way[INFO] [13:47:31.300] JIRA issues sensor will not run as some parameters are missing.[INFO] [13:47:31.392] Sensor JavaSquidSensor...[INFO] [13:47:32.089] Java Main Files AST scan...[INFO] [13:47:32.094] 25 source files to be analyzed[INFO] [13:47:36.733] Java Main Files AST scan done: 4643 ms[INFO] [13:47:36.733] 25/25 source files analyzed[INFO] [13:47:36.746] Java bytecode scan...[INFO] [13:47:37.302] Java bytecode scan done: 556 ms[INFO] [13:47:37.305] Java Test Files AST scan...[INFO] [13:47:37.306] 5 source files to be analyzed[INFO] [13:47:37.626] 5/5 source files analyzed[INFO] [13:47:37.627] Java Test Files AST scan done: 321 ms[INFO] [13:47:37.633] Package design analysis...[INFO] [13:47:37.684] Package design analysis done: 51 ms[INFO] [13:47:37.801] Sensor JavaSquidSensor done: 6409 ms[INFO] [13:47:37.813] Sensor QProfileSensor...[INFO] [13:47:37.819] Sensor QProfileSensor done: 6 ms[INFO] [13:47:37.819] Sensor Maven dependencies...[INFO] [13:47:40.023] Sensor Maven dependencies done: 2204 ms[INFO] [13:47:40.026] Sensor JavaScriptSquidSensor...[INFO] [13:47:40.205] 6 source files to be analyzed[INFO] [13:47:45.590] 6/6 source files analyzed[INFO] [13:47:48.499] Sensor JavaScriptSquidSensor done: 8473 ms[INFO] [13:47:48.506] Sensor CoverageSensor...[INFO] [13:47:48.507] Sensor CoverageSensor done: 1 ms[INFO] [13:47:48.507] Sensor InitialOpenIssuesSensor...[INFO] [13:47:48.525] Sensor InitialOpenIssuesSensor done: 18 ms[INFO] [13:47:48.525] Sensor ProjectLinksSensor...[INFO] [13:47:48.557] Sensor ProjectLinksSensor done: 32 ms[INFO] [13:47:48.558] Sensor VersionEventsSensor...[INFO] [13:47:48.600] Sensor VersionEventsSensor done: 42 ms[INFO] [13:47:48.600] Sensor FileHashSensor...[INFO] [13:47:48.608] Sensor FileHashSensor done: 8 ms[INFO] [13:47:48.610] Sensor CoberturaSensor...[INFO] [13:47:48.616] parsing /u01/jenkins_home/jobs/SONAR - MC - Cas/workspace/trunk/target/site/cobertura/coverage.xml[INFO] [13:47:49.078] Sensor CoberturaSensor done: 468 ms[INFO] [13:47:49.078] Sensor SCM Sensor...[INFO] [13:47:49.089] SCM provider for this project is: svn[INFO] [13:47:49.089] Retrieve SCM blame information...[INFO] [13:47:49.218] 36 files to be analyzed[INFO] ------------------------------------------------------------------------[INFO] BUILD FAILURE[INFO] ------------------------------------------------------------------------[INFO] Total time: 1:04.240s[INFO] Finished at: Fri Aug 12 13:47:54 CEST 2016[INFO] Final Memory: 58M/955M[INFO] ------------------------------------------------------------------------[ERROR] Failed to execute goal org.codehaus.mojo:sonar-maven-plugin:2.6:sonar (default-cli) on project cas: The svn blame command [svn blame --xml --non-interactive -x -w src/main/java/net/mycompany/cas/CookieRetrievingCookieGeneratorPatch.java] failed: svn: OPTIONS of 'https://my_svn_server/svn/mycompanyxf/cas/trunk/src/main/java/net/mycompany/cas/CookieRetrievingCookieGeneratorPatch.java': authorization failed: Could not authenticate to server: rejected Basic challenge (https://my_svn_server) -   [Help 1]org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.codehaus.mojo:sonar-maven-plugin:2.6:sonar (default-cli) on project cas: The svn blame command [svn blame --xml --non-interactive -x -w src/main/java/net/mycompany/cas/CookieRetrievingCookieGeneratorPatch.java] failed: svn: OPTIONS of 'https://my_svn_server/svn/mycompanyxf/cas/trunk/src/main/java/net/mycompany/cas/CookieRetrievingCookieGeneratorPatch.java': authorization failed: Could not authenticate to server: rejected Basic challenge (https://my_svn_server)reShould I change aditional credential in Jenkins? Any help would be appreciated.",Not-TD-related,Other,,,,0.116,0.85,0.034,-0.9966
38923149,How does SonarQube calculate its Maintainability Rating?,"I believe it uses Technical Debt, Added Technical Debt, Technical Debt Ration, and Technical Debt Ration on New Code.Or does it just use Code Smells?Does anyone understand how this rating is produced? It only provides a rating, not how that rating came to be.",Not-TD-related,Other,,,,0.214,0.786,0,-0.8541
38995643,Limit number of calls to RESTful service,"we have a RESTful service deployed on multiple nodes and we want to limit the number of calls coming to our service from each client with different  a for each client per minute.our stack : Jboss application server, Java/Spring RESTful service.What cloud be the possible technique to implement this?",Not-TD-related,Other,,,,0,0.847,0.153,0.6808
39203571,Should return 0; be avoided in main()?,"I know that the current C++ standard special cases codemain so that falling off the end has the same effect as codereturn 0; rather than undefined behavior.I was recently surprised to see a href=https:/review.stackexchange.com/questions/139896/determining-if-the-kangaroos-will-land-in-the-same-positionan example at codereview/a where the responses not only pointed out that including the final codereturn 0; is optional, but actually went so far as to emremove/em it from the original code.Thus prompts my question  mdash; is it really considered bad style to make the codereturn 0; explicit at the end of main? What is the rationale for or against?",Not-TD-related,Other,,,,0.07,0.867,0.063,-0.4052
39255644,Relationship between overwall SQALE Rating calculation and the technical debts?,"Sorry if this is a simple question...We noticed that we are getting SQALE rating = A for most of our projects, whichraise concerns from the dev team.For some projects, we noticed that most modules are given technical debts = B, or C but not B, but the SQALE rating would be = A.We are wondering if this makes sense because shouldn't the average at most B?",Not-TD-related,Other,,,,0.019,0.981,0,-0.0387
39265188,sonarqube 6.0 and motion chart plugin,"Since I updated sonarqube to version 6.0, I can't get motionchart plugin to work ... All I get is a blank widget and a red top band with a [hide] button. Besides, I have found errors like this in the server log:2016.08.26 14:23:19 ERROR web[rails] undefined method `snapshot' for #MeasureFilter::Row:0x641ff8d3Has someone got the motion chart plugin 1.7 to work with sonarqube version 6.0?",Not-TD-related,Other,,,,0.091,0.842,0.067,-0.368
40186532,sonarqube missing project dashboard,"I have SonarQube 6.1. When I click on a project entry from the main dashboards projects widget, I get to a project home page where it says quality gate passed and where some issues are listed ('Bugs', 'Vulnerabilities', 'Code smells' and 'Duplications').On the left side, close to the top, below the project name, there is a home icon and to the right it says 'Issuses', 'Measures', 'Code' and 'Administration'.When I tried to get to a project dashboard - similar to the main dashboard, but specific to the project - I found this page a href=http://docs.sonarqube.org/display/SONARQUBE56roject+Dashboards rel=noreferrerhttp://docs.sonarqube.org/display/SONARQUBE56roject+Dashboards/a. It shows in part a project home page that looks very different from my installations projects home pages. Instead of 'Issuses', 'Measures', 'Code' and 'Administration', like in my case, it has 'Technical Debt', 'Coverage' and so on and also 'Dashboards'. I guess thats where I should go looking for a project dashboard. But that menu item is just missing (along with others) from what my SonarQube shows me!What can I do?",Not-TD-related,Other,,,,0.018,0.95,0.032,0.2828
40934543,SonarQube analysis failed,"I'm working with SonarQube 6.1 and I'm on a Symfony 2.8 project.When I run an analyse with sonar-scanner, I get an ANALYSIS SUCCESSFUL but the result is failed with in my logs :  Error Detailsorg.sonar.server.computation.task.projectanalysis.component.VisitException: Visit of Component {key=ThisIsMyFuckingProjectKeyFor:XXXXXX:src/AdminBundle/AdminBundle.php,type=FILE} failed at org.sonar.server.computation.task.projectanalysis.component.VisitException.rethrowOrWrap(VisitException.java:44) at org.sonar.server.computation.task.projectanalysis.component.VisitorsCrawler.visit(VisitorsCrawler.java:74) at org.sonar.server.computation.task.projectanalysis.component.VisitorsCrawler.visitChildren(VisitorsCrawler.java:110) at org.sonar.server.computation.task.projectanalysis.component.VisitorsCrawler.visitImpl(VisitorsCrawler.java:97) at org.sonar.server.computation.task.projectanalysis.component.VisitorsCrawler.visit(VisitorsCrawler.java:72) at org.sonar.server.computation.task.projectanalysis.component.VisitorsCrawler.visitChildren(VisitorsCrawler.java:110) at org.sonar.server.computation.task.projectanalysis.component.VisitorsCrawler.visitImpl(VisitorsCrawler.java:97) at org.sonar.server.computation.task.projectanalysis.component.VisitorsCrawler.visit(VisitorsCrawler.java:72) at org.sonar.server.computation.task.projectanalysis.step.ExecuteVisitorsStep.execute(ExecuteVisitorsStep.java:51) at org.sonar.server.computation.task.step.ComputationStepExecutor.executeSteps(ComputationStepExecutor.java:64) at org.sonar.server.computation.task.step.ComputationStepExecutor.execute(ComputationStepExecutor.java:52) at org.sonar.server.computation.task.projectanalysis.taskprocessor.ReportTaskProcessor.process(ReportTaskProcessor.java:75) at org.sonar.server.computation.taskprocessor.CeWorkerCallableImpl.executeTask(CeWorkerCallableImpl.java:84) at org.sonar.server.computation.taskprocessor.CeWorkerCallableImpl.call(CeWorkerCallableImpl.java:57) at org.sonar.server.computation.taskprocessor.CeWorkerCallableImpl.call(CeWorkerCallableImpl.java:35) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.IllegalArgumentException: The manDays for language php is not a valid long number at org.sonar.server.computation.task.projectanalysis.qualitymodel.RatingSettings.getDevCost(RatingSettings.java:87) at org.sonar.server.computation.task.projectanalysis.qualitymodel.QualityModelMeasuresVisitor.computeDevelopmentCost(QualityModelMeasuresVisitor.java:126) at org.sonar.server.computation.task.projectanalysis.qualitymodel.QualityModelMeasuresVisitor.visitFile(QualityModelMeasuresVisitor.java:119) at org.sonar.server.computation.task.projectanalysis.component.PathAwareVisitorWrapper.visitFile(PathAwareVisitorWrapper.java:66) at org.sonar.server.computation.task.projectanalysis.component.VisitorsCrawler.visitNode(VisitorsCrawler.java:129) at org.sonar.server.computation.task.projectanalysis.component.VisitorsCrawler.visitImpl(VisitorsCrawler.java:100) at org.sonar.server.computation.task.projectanalysis.component.VisitorsCrawler.visit(VisitorsCrawler.java:72) ... 21 moreCaused by: java.lang.NumberFormatException: For input string: at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) at java.lang.Long.parseLong(Long.java:601) at java.lang.Long.parseLong(Long.java:631) at org.sonar.server.computation.task.projectanalysis.qualitymodel.RatingSettings.getDevCost(RatingSettings.java:84) ... 27 morereDo you have an idea for this error ?",Not-TD-related,Other,,,,0.121,0.861,0.019,-0.9451
41180132,"ASP.Net Web API vs WCF, which one should I choose in my project","I have read many articles in the web so far, about the differences between WCF and ASP.Net web API. Unfortunately I could not come up to a clear idea about what will serve my purpose. Most of the Articles I have read highlighted on the design point of view of the two web services. But I am confused what will work best for my project and why? Here is my brief description of the project.I need to create a communication channel between two servers (both are written in C). The servers will communicate using messages (certain type of commands). The messages sometimes can be only acknowledgements, and sometimes the messages may contain instructions to do some computation. For example, one message can be draw something, or send an SMS etc. And not necessarily the messages will involve any database transactions. But the messages can sometimes send large text files as payload (around 1-5 MB maxm). What I believe WCF is very will surely do this, but can I do the same with ASP.net web API. Because so far all the example I have seen for ASP.Net web api: they are good for RESTful services that manipulate some kind of DB store (GET, PUT, DELETE). But in my case I will need to expose service points that will block e do some kind of processing such as return the value of a computation, sending and acknowledging messages, etc. /block eNot just manipulating a DB-store.So, what should be the best and simplest way to do so? It is needed to be mentioned that I did not find any straight forward example of achieving this using ASP.Net web API.",Not-TD-related,Other,,,,0.053,0.842,0.105,0.9597
41652842,SonarQube: How many hours in a day of technical debt?,"If SonarQube says I have 1 day of technical debt in a project, does that translate to 24 hours of technical debt or 8 hours of technical debt?",Not-TD-related,Other,,,,0.263,0.737,0,-0.7579
41705392,Changing value of a specific key in TypeScript,I need to change a value from a object. In javascript I would do something like data = {};this.data.password = this.password;reWhat can I do to change ou maybe to add a new key/value to this object?,Not-TD-related,Other,,,,0,0.841,0.159,0.5994
41923519,What is the best way to perform custom result sets using JPA or HQL with Spring?,"I develop a little Web Service using Spring REST API. I just wanted to know what is the best way to build a custom data result set from a query using HQL or Criterias.Let's assume we need to handle these 2 entities to perform the following HQL request: SELECT m.idMission, m.driver, m.dateMission FROM MissionEntity mreThe Mission entity (simplified form): @Entitypublic class Mission{ Integer idMission; //id of the mission String dateMission; //date of the mission [...] //Other fields not needed for my request @ManyToOne @JoinColumn(name = driver, referencedColumnName = id_user) User driver; //the driver (user) associated to the mission [...] //Accessors};reAnd the User entity (the driver) (simplified form): @Entitypublic class User{ Integer idUser; //id of the user [...] //Others fields not needed for my request @OneToMany List  Mission   missionList; //the missions associated to the user [...] //Accessors};reJSON output (first result): [ [ //Mission: depth = 0 (root) 1, { //Driver: depth = 1 (mission child -   User) idUser: 29, shortId: Adr_Adr, lastname: ADRIAN, firstname: null, status: Driver, active: 1 }, 05/03/2015 ], [...]]reAs you can see, I have a custom Mission entity result set (List) which the pattern for each Mission entity is the following: + Object - missionId (Integer) + driver (User) - idUser - shortId - lastname - firstname - status - active - dateMission (String)reBut for the purpose of my request I only need for the User entity its firstname and its lastname.So I need a result set like the following one: + Mission (Mission) - missionId (Integer) + driver (User) - lastname - firstname - dateMission (String)reAs you can see, I want to keep the same JSON tree structure: a mission entity own a child User entity but this time with a partial set of attributes (only the firstname and the lastname is needed in the set).For the moment, the only way to solve my problem is to use 2 additionnal POJO classes:The UserProj class: public class UserProj{ private String firstname, lastname; public UserProj(String firstname, String lastname) { this.firstname = firstname; this.lastname = lastname; } [...] //Accessors};reThe MissionProj class: public class MissionProj{ private Integer missionId; private UserProj driver; private String dateMission; public MissionProj(Integer missionId, String driverFirstname, String driverLastname, String dateMission) { this.missionId = missionId; { this.driver = new UserProj(driverFirstname, driverLastname); } this.dateMission = dateMission; } [...] //Accessors};reHere's now the request I use to get the wished JSON output result set: [ { missionId: 1, driver: { firstname: null, lastname: ADRIAN }, dateMission: 05/03/2015 }, [...]]reAs you can see, the result set is the one I was looking for! But my problem with that solution is that solution is not scalable. In fact, if I want to perform another custom result set for the User or the Mission entity with one additional field, I will have to create another POJO for this other custom result set. So for me this solution is not really a solution.I think it should exist a way to do this properly using HQL or Criteria directly but I couldn't find it! Do you have an idea ?Thanks a lot in advance for your help!",Not-TD-related,Other,,,,0.015,0.916,0.069,0.9662
42034381,Handle different user types with Hibernate,"I'm starting a web app project with Spring framework + Hibernate. I want to model two different types of users in the application: doctors and patients. They have some common attributes like name, email, telephone number etc, but the doctors have more specific attributes like collegiate number, specialities, studies etc.This is an E-R model (Hibernate approach) simplified without attributes.a href=https://i.stack.imgur.com/c2A3G.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/c2A3G.png alt=enter image description here/aAs you can see, the relationships will become 1 to 1, but one of them will always be null. I've also though about using inheritance but I've never worked with it in Hibernate so I don't know which is the best approach and why. Which is the simplest and efficient way to go here?Thanks!",Not-TD-related,Other,,,,0,0.853,0.147,0.948
42660067,Is it performative to use criteria.list () to determine the number of rows returned?,"I have a Criteria object that I use to get a common list. But in a specific case, I'd like to use this same Criteria object to know only the amount of rows returned.My question is if i use: Integer count = criteria.list().size();reIt is the same perfomatically as: criteria.setProjection(Projections.rowCount());Integet count = (Integer)criteria.uniqueResult()re",Not-TD-related,Other,,,,0,0.93,0.07,0.5023
42741424,Calculating sum of List in scala,I am new to scala. Currently I am trying to develop a calculator as scala project.But while trying to find the sum I am getting problem. The following code doesn't compile. def add [T](values :List[T]) : Option[T]={ if (values.isInstanceOf[String]) { None } else if(values.isInstanceOf[Int] || values.isInstanceOf[Long] || values.isInstanceOf[Double]) { Some(values.sum) } }re,Not-TD-related,Other,,,,0.06,0.94,0,-0.4019
42768263,The different between Browser native css display: grid and bootstrap grid system?,"I just read the a href=https://developers.google.com/web/updates/2017/03/nic57 rel=nofollow noreferrerChrome 57 release log/a and noticed start from version 57, Chrome native support css style - a href=https://developer.mozilla.org/en-US/docs/Learn/CSS/CSS_layout/Grids rel=nofollow noreferrerdisplay: grid/a, it seems late to come because bootstrap having grid system since version 2 and on the a href=https://developers.google.com/web/updates/2014/03/Get-on-the-CSS-Grid rel=nofollow noreferrerearly of 2014/a, Chrome team already aware the grid system and can be enable by flags panel.I have read the article above but it doesn't turn out the PROS over some css framework like bootstrap/foundation etc.So I curious is it any advantage using native grid css?",Not-TD-related,Other,,,,0,0.886,0.114,0.8608
43256484,Sonarqube(5.4 / 5.2.1) is not getting started with JDK 7 & mysql 5.2.1,"I HAVE ATTACHED SOME IMAGES RELATED TO mY ProblemHardware:JDK-7 (Its my requirement) MySQL 5.7.17 sonarqube5.4 or 5.2.1Process i am following to start sonar:1.After downloading sonarqube, i did below configuration sonar.propertiessonar.jdbc.username=rootsonar.jdbc.password=rootsonar.jdbc.url=jdbc:mysql://localhost:3306/sonar?useUnicode=true&characterEncoding=utf8&rewriteBatchedStatements=true&useConfigs=maxPerformancesonar.jdbc.driverClassName=com.mysql.jdbc.Driversonar.jdbc.maxWait=10000sonar.web.host=localhostsonar.web.context=/sonar.web.port=9092wrapper.confwrapper.java.command=javawrapper.java.additional.1=-Djava.awt.headless=truewrapper.java.mainclass=org.tanukisoftware.wrapper.WrapperSimpleAppwrapper.java.classpath.1=../../lib/jsw/*.jarwrapper.java.classpath.2=../../lib/*.jarwrapper.java.library.path.1=./libwrapper.app.parameter.1=org.sonar.application.Appwrapper.java.initmemory=3wrapper.java.maxmemory=32wrapper.console.format=PMwrapper.console.loglevel=INFOwrapper.logfile=../../logs/sonar.logwrapper.logfile.format=Mwrapper.logfile.loglevel=INFOwrapper.syslog.loglevel=NONEwrapper.console.title=SonarQubewrapper.single_invocation=truewrapper.ntservice.name=SonarQubewrapper.ntservice.displayname=SonarQubewrapper.ntservice.description=SonarQubewrapper.ntservice.dependency.1=[getting response on cmd in admin mode[![\]\[1\][1]][1]wrapper.ntservice.starttype=AUTO_STARTwrapper.ntservice.interactive=falsewrapper.disable_restarts=TRUEwrapper.ping.timeout=0wrapper.shutdown.timeout=3000wrapper.jvm_exit.timeout=3000LOG fileCreateService failed - The specified service already exists. (0x431)Starting the SonarQube service...The SonarQube service was launched, but failed to start.--> Wrapper Started as ConsoleLaunching a JVM...Wrapper (Version 3.2.3) http://wrapper.tanukisoftware.orgCopyright 1999-2006 Tanuki Software, Inc. All Rights Reserved.2017.04.06 17:50:53 INFO app[o.s.a.AppFileSystem] Cleaning or creating temp directory C:\sonar\sonarqube-5.4\temp2017.04.06 17:50:53 INFO app[o.s.p.m.JavaProcessLauncher] Launch process[search]: C:\Program Files\Java\jre7\bin\java -Djava.awt.headless=true -Xmx1G -Xms256m -Xss256k -Djava.net.preferIPv4Stack=true -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+HeapDumpOnOutOfMemoryError -Djava.io.tmpdir=C:\sonar\sonarqube-5.4\temp -cp ./lib/common/*;./lib/search/* org.sonar.search.SearchServer C:\Users\LOKESH~1.KUM\AppData\Local\Temp\sq-process7155234219752233605properties2017.04.06 17:50:54 INFO es[o.s.p.ProcessEntryPoint] Starting search2017.04.06 17:50:54 INFO es[o.s.s.SearchSettings] Elasticsearch listening on 127.0.0.1:90012017.04.06 17:50:54 INFO es[o.elasticsearch.node] [sonar-1491481253018] version[1.7.2], pid[9596], build[e43676b/2015-09-14T09:49:53Z]2017.04.06 17:50:54 INFO es[o.elasticsearch.node] [sonar-1491481253018] initializing ...2017.04.06 17:50:54 INFO es[o.e.plugins] [sonar-1491481253018] loaded [], sites []2017.04.06 17:50:55 INFO es[o.elasticsearch.env] [sonar-1491481253018] using [1] data paths, mounts [[(C:)]], net usable_space [162.2gb], net total_space [221.2gb], types [NTFS]2017.04.06 17:50:57 WARN es[o.e.bootstrap] JNA not found. native methods will be disabled.2017.04.06 17:50:58 INFO es[o.elasticsearch.node] [sonar-1491481253018] initialized2017.04.06 17:50:58 INFO es[o.elasticsearch.node] [sonar-1491481253018] starting ...2017.04.06 17:50:58 INFO es[o.e.transport] [sonar-1491481253018] bound_address {inet[/127.0.0.1:9001]}, publish_address {inet[/127.0.0.1:9001]}2017.04.06 17:50:58 INFO es[o.e.discovery] [sonar-1491481253018] sonarqube/tREKX7ZHS3yCEME6KEmqtg2017.04.06 17:51:01 INFO es[o.e.cluster.service] [sonar-1491481253018] new_master [sonar-1491481253018][tREKX7ZHS3yCEME6KEmqtg][ntpc01401][inet[/127.0.0.1:9001]]{rack_id=sonar-1491481253018}, reason: zen-disco-join (elected_as_master)2017.04.06 17:51:01 INFO es[o.elasticsearch.node] [sonar-1491481253018] started2017.04.06 17:51:01 INFO es[o.e.gateway] [sonar-1491481253018] recovered [6] indices into cluster_state2017.04.06 17:51:05 INFO app[o.s.p.m.Monitor] Process[search] is up2017.04.06 17:51:05 INFO app[o.s.p.m.JavaProcessLauncher] Launch process[web]: C:\Program Files\Java\jre7\bin\java -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djruby.management.enabled=false -Djruby.compile.invokedynamic=false -Xmx768m -Xms256m -XX:MaxPermSize=160m -XX:+HeapDumpOnOutOfMemoryError -Djava.net.preferIPv4Stack=true -Djava.io.tmpdir=C:\sonar\sonarqube-5.4\temp -cp ./lib/common/*;./lib/server/*;C:\sonar\sonarqube-5.4\lib\jdbc\mysql\mysql-connector-java-5.1.35.jar org.sonar.server.app.WebServer C:\Users\LOKESH~1.KUM\AppData\Local\Temp\sq-process1860280482306293638properties2017.04.06 17:51:06 INFO web[o.s.p.ProcessEntryPoint] Starting web2017.04.06 17:51:07 INFO web[o.s.s.a.TomcatContexts] Webapp directory: C:\sonar\sonarqube-5.4\web2017.04.06 17:51:07 INFO web[o.a.c.h.Http11NioProtocol] Initializing ProtocolHandler [""http-nio-127.0.0.1-9092""]2017.04.06 17:51:07 INFO web[o.a.t.u.n.NioSelectorPool] Using a shared selector for servlet write/read2017.04.06 17:51:10 INFO web[o.s.s.p.ServerImpl] SonarQube Server / 5.4 / 7b02df9be3cd9448699b5857586e1c6e2b28c0072017.04.06 17:51:10 INFO web[o.sonar.db.Database] Create JDBC data source for jdbc:mysql://localhost:3306/sonar?useUnicode=true&characterEncoding=utf8&rewriteBatchedStatements=true&useConfigs=maxPerformance2017.04.06 17:51:10 INFO web[o.e.plugins] [sonar-1491481253018] loaded [], sites []2017.04.06 17:51:12 INFO web[o.s.s.p.DefaultServerFileSystem] SonarQube home: C:\sonar\sonarqube-5.42017.04.06 17:51:13 INFO web[o.s.s.p.ServerPluginRepository] Deploy plugin C# / 4.4 / 5b9adce1c37c4ef907b316ea4500ed5d7c4629c42017.04.06 17:51:13 INFO web[o.s.s.p.ServerPluginRepository] Deploy plugin Git / 1.0 / 9ce9d330c313c296fab051317cc5ad4b26319e072017.04.06 17:51:13 INFO web[o.s.s.p.ServerPluginRepository] Deploy plugin Java / 3.10 / e55d43e814fd68587a7a9e0f37089492b34445cc2017.04.06 17:51:13 INFO web[o.s.s.p.ServerPluginRepository] Deploy plugin JavaScript / 2.10 / 88475229068f817583013a08facf2b45d03578292017.04.06 17:51:13 INFO web[o.s.s.p.ServerPluginRepository] Deploy plugin SVN / 1.2 / d04c3cdb21f48905dd8300d1129ec90281aa6db22017.04.06 17:51:14 INFO web[o.s.s.p.RailsAppsDeployer] Deploying Ruby on Rails applications2017.04.06 17:51:14 INFO web[o.s.s.p.Platform] DB needs migration, entering safe mode2017.04.06 17:51:15 INFO web[jruby.rack] jruby 1.7.9 (ruby-1.8.7p370) 2013-12-06 87b108a on Java HotSpot(TM) 64-Bit Server VM 1.7.0-b147 [Windows 7-amd64]2017.04.06 17:51:15 INFO web[jruby.rack] using a shared (threadsafe!) runtime2017.04.06 17:51:37 INFO web[DbMigration] == InitialSchema: migrating ==================================================2017.04.06 17:51:37 INFO web[DbMigration] -- create_table(:projects, {})2017.04.06 17:51:37 INFO web[DbMigration] -> 0.2160s2017.04.06 17:51:37 INFO web[DbMigration] -> 0 rows017.04.06 17:54:47 INFO web[DbMigration] == IncreaseProjectsNameColumnsSize: migrating ================================2017.04.06 17:54:47 INFO web[DbMigration] == IncreaseProjectsNameColumnsSize: migrated (0.1080s) =======================2017.04.06 17:54:47 INFO web[DbMigration] 2017.04.06 17:54:53 INFO web[o.s.s.p.UpdateCenterClient] Update center: http://update.sonarsource.org/update-center.properties (no proxy)2017.04.06 17:54:55 INFO web[o.s.s.n.NotificationService] Notification service started (delay 60 sec.)2017.04.06 17:54:56 INFO web[o.s.s.s.IndexSynchronizer] Index rules2017.04.06 17:54:56 INFO web[o.s.s.s.IndexSynchronizer] Index activeRules2017.04.06 17:54:56 INFO web[o.s.s.s.RegisterMetrics] Register metrics2017.04.06 17:54:57 INFO web[o.s.s.s.RegisterDebtModel] Register technical debt model2017.04.06 17:54:57 INFO web[o.s.s.r.RegisterRules] Register rulesA fatal error has been detected by the Java Runtime Environment:EXCEPTION_ACCESS_VIOLATION (0xc0000005) at pc=0x000000000252fbd9, pid=9596, tid=8112JRE version: 7.0-b147 Java VM: Java HotSpot(TM) 64-Bit Server VM (21.0-b17 mixed mode windows-amd64 compressed oops) Problematic frame: J org.apache.lucene.analysis.en.PorterStemFilter.incrementToken()ZFailed to write core dump. Minidumps are not enabled by default on client versions of WindowsAn error report file with more information is saved as: C:\sonar\sonarqube-5.4\hs_err_pid9596.logIf you would like to submit a bug report, please visit: http://bugreport.sun.com/bugreport/crash.jsp2017.04.06 17:55:01 INFO app[o.s.p.m.Monitor] Process[web] is stopping2017.04.06 17:55:01 ERROR web[jruby.rack] initialization failedorg.jruby.rack.RackInitializationException: org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes were available: [[sonar-1491481253018][tREKX7ZHS3yCEME6KEmqtg][ntpc01401][inet[/127.0.0.1:9001]]{rack_id=sonar-1491481253018}]at org.jruby.rack.RackInitializationException.wrap(RackInitializationException.java:31) ~[jruby-rack-1.1.13.2.jar:na]at org.jruby.rack.RackApplicationFactoryDecorator.init(RackApplicationFactoryDecorator.java:98) ~[jruby-rack-1.1.13.2.jar:na]at org.jruby.rack.RackServletContextListener.contextInitialized(RackServletContextListener.java:50) ~[jruby-rack-1.1.13.2.jar:na]at org.sonar.server.platform.RubyRailsContextListener.contextInitialized(RubyRailsContextListener.java:35) [sonar-server-5.4.jar:na]at org.apache.catalina.core.StandardContext.listenerStart(StandardContext.java:4812) [tomcat-embed-core-8.0.30.jar:8.0.30]at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5255) [tomcat-embed-core-8.0.30.jar:8.0.30]at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [tomcat-embed-core-8.0.30.jar:8.0.30]at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1408) [tomcat-embed-core-8.0.30.jar:8.0.30]at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1398) [tomcat-embed-core-8.0.30.jar:8.0.30]at java.util.concurrent.FutureTask$Sync.innerRun(Unknown Source) [na:1.7.0]at java.util.concurrent.FutureTask.run(Unknown Source) [na:1.7.0]at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [na:1.7.0]at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [na:1.7.0]at java.lang.Thread.run(Unknown Source) [na:1.7.0]Caused by: org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes were available: [[sonar-1491481253018][tREKX7ZHS3yCEME6KEmqtg][ntpc01401][inet[/127.0.0.1:9001]]{rack_id=sonar-1491481253018}]at org.elasticsearch.client.transport.TransportClientNodesService$RetryListener.onFailure(TransportClientNodesService.java:242) ~[elasticsearch-1.7.2.jar:na]at org.elasticsearch.action.TransportActionNodeProxy$1.handleException(TransportActionNodeProxy.java:78) ~[elasticsearch-1.7.2.jar:na]at org.elasticsearch.transport.TransportService$Adapter$3.run(TransportService.java:468) ~[elasticsearch-1.7.2.jar:na]... 3 common frames omittedCaused by: org.elasticsearch.transport.NodeDisconnectedException: [sonar-1491481253018][inet[/127.0.0.1:9001]][indices:data/write/bulk] disconnected2017.04.06 17:55:01 INFO web[o.s.p.StopWatcher] Stopping process2017.04.06 17:55:02 INFO web[o.a.c.h.Http11NioProtocol] Starting ProtocolHandler [""http-nio-127.0.0.1-9092""]2017.04.06 17:55:02 INFO web[o.s.s.a.TomcatAccessLog] Web server is started2017.04.06 17:55:02 INFO web[o.a.c.h.Http11NioProtocol] Pausing ProtocolHandler [""http-nio-127.0.0.1-9092""]2017.04.06 17:55:02 INFO web[o.s.s.a.EmbeddedTomcat] HTTP connector enabled on port 90922017.04.06 17:55:02 INFO web[o.s.s.n.NotificationService] Notification service stopped2017.04.06 17:55:02 WARN web[o.a.c.l.WebappClassLoaderBase] The web application [ROOT] appears to have started a thread named [Abandoned connection cleanup thread] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:java.lang.Object.wait(Native Method)java.lang.ref.ReferenceQueue.remove(Unknown Source)com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43)2017.04.06 17:55:02 WARN web[o.a.c.l.WebappClassLoaderBase] The web application [ROOT] appears to have started a thread named [JRubyJIT-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:sun.misc.Unsafe.park(Native Method)java.util.concurrent.locks.LockSupport.park(Unknown Source)java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(Unknown Source)java.util.concurrent.LinkedBlockingQueue.take(Unknown Source)java.util.concurrent.ThreadPoolExecutor.getTask(Unknown Source)java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)java.lang.Thread.run(Unknown Source)2017.04.06 17:55:02 WARN web[o.a.c.l.WebappClassLoaderBase] The web application [ROOT] appears to have started a thread named [JRubyJIT-2] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:sun.misc.Unsafe.park(Native Method)java.util.concurrent.locks.LockSupport.park(Unknown Source)java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(Unknown Source)java.util.concurrent.LinkedBlockingQueue.take(Unknown Source)java.util.concurrent.ThreadPoolExecutor.getTask(Unknown Source)java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)java.lang.Thread.run(Unknown Source)2017.04.06 17:55:02 INFO web[o.a.c.h.Http11NioProtocol] Stopping ProtocolHandler [""http-nio-127.0.0.1-9092""]2017.04.06 17:55:02 INFO web[o.a.c.h.Http11NioProtocol] Destroying ProtocolHandler [""http-nio-127.0.0.1-9092""]2017.04.06 17:55:02 INFO web[o.s.s.a.TomcatAccessLog] Web server is stoppedStrategy I have tried:Created/Deleted Temp folder in C:\Windows\System32\config\systemprofile\AppData\Local & then starting service & start sonar => SAME iSSUEclean/delete temp from sonarqube & then run => SAME iSSUEmy need is JDK-7 so changed 5.4 / 5.2.1 both => => SAME iSSUEwrapper.java.command=Gave my jdk/bin/java path => SAME iSSUERestarted & Reinstall from scratch => SAME iSSUEPLEASE HELP ME, THANKS IN ADVANCE",Not-TD-related,Other,,,,0.094,0.861,0.045,-0.9945
43474197,How to retrieve SQALE rating and Technical debt information?,I was looking at the web service API V5.5 documentation for SonarQube and would like to retrieve two things at the project level:olliSQALE rating liTechnical DebtWhich API can I exactly use to get these values directly?,Not-TD-related,Other,,,,0,0.86,0.14,0.6369
44804182,Reports path not found or is not a directory-Jacoco+Maven+Jenkins+Sonar,"I have followed below link to get code coverage for a multi module project.a href=https://www.petrikainulainen.netrogramming/maven/creating-code-coverage-reports-for-unit-and-integration-tests-with-the-jacoco-maven-plugin/ rel=nofollow noreferrerhttps://www.petrikainulainen.netrogramming/maven/creating-code-coverage-reports-for-unit-and-integration-tests-with-the-jacoco-maven-plugin//aJenkins ver. 1.631Sonar ver. 5.1.1Jacoco ver. 0.7.9Java ver. 1.8Maven ver. 3.3.9Main Pom file-    ?xml version=1.0 encoding=UTF-8?    project xmlns=http://maven.apache.orgOM/4.0.0 xmlns:xsi=http://www.w3.org/2001/XMLSchema-instance xsi:schemaLocation=http://maven.apache.orgOM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd     modelVersion  4.0.0  /modelVersion     groupId  com.test  /groupId     artifactId  test  /artifactId     version  0.0.1-SNAPSHOT  /version     packaging  pom  ackaging     name  test  /name     properties     project.build.sourceEncoding  UTF-8  roject.build.sourceEncoding     project.reporting.outputEncoding  UTF-8  roject.reporting.outputEncoding     org.springframework.version  4.3.4.RELEASE  /org.springframework.version     commons.lang.version  2.5  /commons.lang.version     log4j.version  1.2.15  /log4j.version     org.jboss.hibernate.version  5.2.5.Final  /org.jboss.hibernate.version     jaxb.version  2.1  /jaxb.version     guava.version  19.0  /guava.version     jersey.version  2.24.1  /jersey.version     jackson.version  2.8.5  /jackson.version     jackson.databind.version  2.8.1  /jackson.databind.version     cxf.version  3.1.4  /cxf.version     tomcat.version  7.0.47  /tomcat.version     tomcat.port  18080  /tomcat.port     tomcat.client.port  28080  /tomcat.client.port     server.version  1.0.0  /server.version     maven.build.timestamp.format  yyyy-MM-dd'T'HH:mm:ss.SSS z  /maven.build.timestamp.format     olingo.version  2.0.6  ingo.version     felix.version  5.4.0  /felix.version     roperties     dependencies     dependency     groupId  org.testng  /groupId     artifactId  testng  /artifactId     version  6.9.10  /version     type  jar  /type     scope  test  /scope     /dependency     dependency     groupId  org.apache.httpcomponents  /groupId     artifactId  httpclient  /artifactId     version  4.5.2  /version     type  jar  /type     scope  compile  /scope     /dependency     !--   dependency     groupId  mysql  /groupId     artifactId  mysql-connector-java  /artifactId     version  5.1.13  /version     type  jar  /type     scope  compile  /scope     /dependency   --     dependency     groupId  org.postgresql  /groupId     artifactId  postgresql  /artifactId     version  9.3-1102-jdbc41  /version     !-- 9.2-1002-jdbc4 --     type  jar  /type     scope  compile  /scope     /dependency     dependency     groupId  mysql  /groupId     artifactId  mysql-connector-java  /artifactId     version  5.1.28  /version     type  jar  /type     scope  compile  /scope     /dependency     dependency     groupId  net.sourceforge.jtds  /groupId     artifactId  jtds  /artifactId     version  1.3.1  /version     type  jar  /type     scope  compile  /scope     /dependency     dependency     groupId  com.mchange  /groupId     artifactId  c3p0  /artifactId     version  0.9.5.2  /version     type  jar  /type     scope  compile  /scope     /dependency     dependency     groupId  org.springframework  /groupId     artifactId  spring-aop  /artifactId     version  ${org.springframework.version}  /version     /dependency     dependency     groupId  org.springframework  /groupId     artifactId  spring-orm  /artifactId     version  ${org.springframework.version}  /version     /dependency     dependency     groupId  org.springframework  /groupId     artifactId  spring-test  /artifactId     version  ${org.springframework.version}  /version     scope  test  /scope     /dependency     dependency     groupId  org.springframework  /groupId     artifactId  spring-core  /artifactId     version  ${org.springframework.version}  /version     type  jar  /type     scope  compile  /scope     /dependency     dependency     groupId  org.springframework  /groupId     artifactId  spring-context  /artifactId     version  ${org.springframework.version}  /version     /dependency     dependency     groupId  org.springframework  /groupId     artifactId  spring-expression  /artifactId     version  ${org.springframework.version}  /version     type  jar  /type     scope  compile  /scope     /dependency     dependency     groupId  org.springframework  /groupId     artifactId  spring-aspects  /artifactId     version  ${org.springframework.version}  /version     type  jar  /type     scope  compile  /scope     /dependency     dependency     groupId  org.hibernate  /groupId     artifactId  hibernate-entitymanager  /artifactId     version  ${org.jboss.hibernate.version}  /version     type  jar  /type     scope  compile  /scope     /dependency     dependency     groupId  commons-codec  /groupId     artifactId  commons-codec  /artifactId     version  1.4  /version     /dependency     dependency     groupId  log4j  /groupId     artifactId  log4j  /artifactId     version  ${log4j.version}  /version     exclusions     exclusion     groupId  javax.jms  /groupId     artifactId  jms  /artifactId     /exclusion     exclusion     groupId  com.sun.jdmk  /groupId     artifactId  jmxtools  /artifactId     /exclusion     exclusion     groupId  com.sun.jmx  /groupId     artifactId  jmxri  /artifactId     /exclusion     exclusion     groupId  javax.mail  /groupId     artifactId  mail  /artifactId     /exclusion     /exclusions     /dependency     dependency     groupId  joda-time  /groupId     artifactId  joda-time  /artifactId     version  2.9.2  /version     /dependency     dependency     groupId  opensymphony  /groupId     artifactId  quartz  /artifactId     version  1.6.3  /version     type  jar  /type     scope  compile  /scope     /dependency     dependency     groupId  com.fasterxml.jackson.core  /groupId     artifactId  jackson-databind  /artifactId     version  ${jackson.databind.version}  /version     type  jar  /type     scope  compile  /scope     exclusions     exclusion     artifactId  jackson-annotations  /artifactId     groupId  com.fasterxml.jackson.core  /groupId     /exclusion     /exclusions    /dependency     !-- https://mvnrepository.com/artifact/com.fasterxml.jackson.core/jackson-annotations --     dependency     groupId  com.fasterxml.jackson.core  /groupId     artifactId  jackson-annotations  /artifactId     version  ${jackson.version}  /version     /dependency     dependency     groupId  com.google.guava  /groupId     artifactId  guava  /artifactId     version  ${guava.version}  /version     type  jar  /type     scope  compile  /scope     /dependency     dependency     groupId  org.glassfish.jersey.core  /groupId     artifactId  jersey-common  /artifactId     version  ${jersey.version}  /version     type  jar  /type     scope  compile  /scope     /dependency     dependency     groupId  org.aspectj  /groupId     artifactId  aspectjweaver  /artifactId     version  1.7.4  /version     /dependency     !-- https://mvnrepository.com/artifact/org.apache.felix/org.apache.felix.framework --     dependency     groupId  org.apache.felix  /groupId     artifactId  org.apache.felix.framework  /artifactId     version  ${felix.version}  /version     /dependency     /dependencies     modules     module  module1  /module     module  module2  /module     module  module3  /module     module  module4  /module     module  module5  /module     module  module6  /module     module  module7  /module     module  module8  /module     /modules     profiles     !-- Default profile excludes connectors netsuite and salesforce in module1 and module2 and skips all module3 tests. --     profile     id  no-connector  /id     modules     module  module1  /module     module  module2  /module     module  module3  /module     module  module4  /module     module  module5  /module     module  module6  /module     /modules     build     pluginManagement     plugins     plugin     groupId  org.apache.maven.plugins  /groupId     artifactId  maven-failsafe-plugin  /artifactId     configuration     argLine  ${failsafeArgLine}  /argLine     excludedGroups  salesforce, netsuite, netsuitesso, GoogleDirectoryProvider,hybris4,hybris,hybris5, ftp  /excludedGroups     /configuration     lugin     plugin     groupId  org.apache.maven.plugins  /groupId     artifactId  maven-surefire-plugin  /artifactId     configuration     argLine  ${surefireArgLine}  /argLine     excludedGroups  salesforce, netsuite, netsuitesso, netsuite_min, GoogleDirectoryProvider, hybris4, hybris, hybris5, ftp  /excludedGroups     /configuration     lugin     lugins     luginManagement     /build     rofile     rofiles     reporting     plugins     plugin     groupId  org.apache.maven.plugins  /groupId     artifactId  maven-surefire-report-plugin  /artifactId     version  2.17  /version     reportSets     reportSet     reports     report  report-only  /report     /reports     /reportSet     /reportSets     lugin     !--   plugin     groupId  org.apache.maven.plugins  /groupId     artifactId  maven-pmd-plugin  /artifactId     version  2.4  /version     configuration     linkXref  true  nkXref     sourceEncoding  utf-8  /sourceEncoding     minimumTokens  100  /minimumTokens     targetJdk  1.7  /targetJdk     rulesets     ruleset  /rulesets/basic.xml  /ruleset     ruleset  /rulesets/imports.xml  /ruleset     ruleset  /rulesets/unusedcode.xml  /ruleset     ruleset  /rulesets/controversial.xml  /ruleset     ruleset  /rulesets/coupling.xml  /ruleset     ruleset  /rulesets/optimizations.xml  /ruleset     ruleset  /rulesets/design.xml  /ruleset     ruleset  /rulesets/migrating.xml  /ruleset     ruleset  /rulesets/typeresolution.xml  /ruleset     /rulesets     /configuration     lugin     plugin     groupId  org.codehaus.mojo  /groupId     artifactId  findbugs-maven-plugin  /artifactId     version  2.3.2  /version     configuration     findbugsXmlOutput  true  /findbugsXmlOutput     findbugsXmlOutputDirectory  target/site  /findbugsXmlOutputDirectory     xmlOutput  true  /xmlOutput     /configuration     lugin   --     lugins     /reporting     build     pluginManagement     plugins     plugin     groupId  org.apache.maven.plugins  /groupId     artifactId  maven-compiler-plugin  /artifactId     version  3.1  /version     configuration     source  1.8  /source     target  1.8  /target     /configuration     lugin     lugins     luginManagement     /build    roject  reI have added below plugin configuration in my Module1 and Module2 Pom xml where I have my Integration tests.   plugin     groupId  org.jacoco  /groupId     artifactId  jacoco-maven-plugin  /artifactId     version  0.7.9  /version     executions     execution     id  prepare-agent  /id     goals     goal  prepare-agent  /goal     /goals     /execution     execution     id  report  /id     phase  prepare-package  hase     goals     goal  report  /goal     /goals     /execution     execution     id  post-unit-test  /id     phase  test  hase     goals     goal  report  /goal     /goals     configuration     !-- Sets the path to the file which contains the execution data. --     dataFile  target/jacoco.exec  /dataFile     !-- Sets the output directory for the code coverage report. --     outputDirectory  target/jacoco-ut  /outputDirectory     /configuration     /execution     /executions     configuration     systemPropertyVariables     jacoco-agent.destfile  target/jacoco.exec  /jacoco-agent.destfile     /systemPropertyVariables     /configuration     lugin  reMaven Build Command- -DargLine=-DDB_SERVER=localhost -DDB_PORT=1234 -DDB_NAME=test -DDB_USER=tester -DDB_PASSWORD=testerpwd -DDB_MAX_POOL=10 -Dcom.tester.redis=false clean verifyreI am getting below error while I execute this using Jenkins. [Checking] $ /Users/test-test/.jenkins/tools/hudson.plugins.sonar.SonarRunnerInstallation/Sonar_Runner/bin/sonar-runner -Dsonar.jdbc.url=jdbc:mysql://123.45.65/sonar?autoReconnect=true useUnicode=true characterEncoding=utf8 -Dsonar.jdbc.username=abcd -Dsonar.jdbc.password=abcd@123 -e -Dsonar.host.url=http://123.45.65:9000 ******** ******** -Dsonar.projectName=test-Test -Dsonar.projectVersion=28-06-2017-23 -Dsonar.jacoco.reportPath=reports/jacoco/jacoco-ut.exec -Dsonar.projectKey=test-Test -Dsonar.jacoco.itReportPath=reports/jacoco/jacoco-it.exec -Dsonar.java.coveragePlugin=jacoco -Dsonar.sources=. -Dsonar.modules=module1,module2,module3,module4,module5 -Dsonar.projectBaseDir=/Users/test-test/.jenkins/test/test/CheckingSonarQube Runner 2.3Java 1.8.0_60 Oracle Corporation (64-bit)Mac OS X 10.11.6 x86_64INFO: Error stacktraces are turned on.INFO: Runner configuration file: /Users/test-test/.jenkins/tools/hudson.plugins.sonar.SonarRunnerInstallation/Sonar_Runner/conf/sonar-runner.propertiesINFO: Project configuration file: NONEINFO: Default locale: en_US, source code encoding: UTF-8 (analysis is platform dependent)INFO: Work directory: /Users/test-test/.jenkins/test/test/Checking/.sonarINFO: SonarQube Server 5.1.118:16:25.065 INFO - Load global repositories18:16:25.337 INFO - Load global repositories (done) | time=283ms18:16:25.339 INFO - Server id: 2017061609395918:16:25.344 INFO - User cache: /Users/test-test/.sonar/cache18:16:25.354 INFO - Install plugins18:16:27.168 INFO - Install JDBC driver18:16:27.187 INFO - Create JDBC datasource for jdbc:mysql://172.26.72.76/sonar?autoReconnect=true useUnicode=true characterEncoding=utf818:16:28.882 INFO - Initializing Hibernate18:16:30.622 WARN - /!\ A multi-module project can't have source folders, so '/Users/test-test/.jenkins/test/test/Checking' won't be used for the analysis. If you want to analyse files of this folder, you should create another sub-module and move them inside it.18:16:31.095 INFO - Load project repositories18:16:31.323 INFO - Load project repositories (done) | time=228ms18:16:31.323 INFO - Load project settings18:16:31.801 INFO - Load technical debt model18:16:31.852 INFO - Apply project exclusions18:16:34.302 WARN - SCM provider autodetection failed. No SCM provider claims to support this project. Please use sonar.scm.provider to define SCM of your project.18:16:34.304 INFO - ------------- Scan module118:16:34.314 INFO - Load module settings18:16:34.707 INFO - Load rules18:16:35.242 INFO - Base dir: /Users/test-test/.jenkins/test/test/Checking/module118:16:35.242 INFO - Working dir: /Users/test-test/.jenkins/test/test/Checking/.sonar/test-Test_admin18:16:35.242 INFO - Source paths: .18:16:35.243 INFO - Source encoding: UTF-8, default locale: en_US18:16:35.243 INFO - Index files18:16:35.948 INFO - 78 files indexed18:16:39.945 INFO - Quality profile for java: QPtest18:16:40.081 INFO - Trying to guess scm provider from project layout...18:16:40.113 INFO - Didn't find which SCM provider is used. Fallback on configuration18:16:40.113 WARN - SCM URL must not be blank. SCM Stats Plugin will not run.Please check the parameter SCM URL or the   scm   section of Maven pom.18:16:40.149 INFO - Sensor JavaSquidSensor18:16:40.456 INFO - Configured Java source version: none18:16:40.841 INFO - Java Main Files AST scan...18:16:40.844 INFO - 78 source files to be analyzed18:16:50.845 INFO - 13/78 files analyzed, current file: /Users/test-test/.jenkins/test/test/Checking/module1/src/main/java/com/test/services/impl/ApplicationService.java18:17:00.849 INFO - 25/78 files analyzed, current file: /Users/test-test/.jenkins/test/test/Checking/module1/src/main/java/com/test/services/impl/exampleServiceService.java18:17:10.849 INFO - 37/78 files analyzed, current file: /Users/test-test/.jenkins/test/test/Checking/module1/src/main/java/com/test/services/impl/StarterProject.java18:17:20.851 INFO - 74/78 files analyzed, current file: /Users/test-test/.jenkins/test/test/Checking/module1/src/main/java/com/test/test/client/ServiceProviderIT.java18:17:21.904 INFO - 78/78 source files have been analyzed18:17:21.904 INFO - Java Main Files AST scan done: 41063 ms18:17:21.904 WARN - Java bytecode has not been made available to the analyzer. The org.sonar.java.bytecode.visitor.DependenciesVisitor@585fa2fb, org.sonar.java.checks.UnusedPrivateMethodCheck@2434f548, org.sonar.java.checks.UnusedProtectedMethodCheck@72bdb6d3, CycleBetweenPackages rule are disabled.18:17:21.904 INFO - Java Test Files AST scan...18:17:21.904 INFO - 0 source files to be analyzed18:17:21.904 INFO - Java Test Files AST scan done: 0 ms18:17:21.905 INFO - 0/0 source files have been analyzed18:17:21.905 INFO - Sensor JavaSquidSensor (done) | time=41756ms18:17:21.906 INFO - Sensor Lines Sensor18:17:21.911 INFO - Sensor Lines Sensor (done) | time=5ms18:17:21.911 INFO - Sensor QProfileSensor18:17:21.915 INFO - Sensor QProfileSensor (done) | time=4ms18:17:21.915 INFO - Sensor InitialOpenIssuesSensor18:17:23.303 INFO - Sensor InitialOpenIssuesSensor (done) | time=1388ms18:17:23.303 INFO - Sensor ProjectLinksSensor18:17:23.339 INFO - Sensor ProjectLinksSensor (done) | time=36ms18:17:23.339 INFO - Sensor VersionEventsSensor18:17:23.420 INFO - Sensor VersionEventsSensor (done) | time=81ms18:17:23.420 INFO - Sensor CoberturaSensor18:17:23.420 WARN - Cobertura report not found at /Users/test-test/.jenkins/test/test/Checking/module1/target/site/cobertura/coverage.xml18:17:23.420 INFO - Sensor CoberturaSensor (done) | time=0ms18:17:23.420 INFO - Sensor org.sonar.plugins.findbugs.FindbugsSensor@5bebff4b18:17:23.451 WARN - Findbugs needs sources to be compiled. Please build project before executing sonar or check the location of compiled classes to make it possible for Findbugs to analyse your project.18:17:23.451 INFO - Sensor org.sonar.plugins.findbugs.FindbugsSensor@5bebff4b (done) | time=31ms18:17:23.451 INFO - Sensor SurefireSensor18:17:23.451 INFO - parsing /Users/test-test/.jenkins/test/test/Checking/module1/target/surefire-reports18:17:23.451 ERROR - Reports path not found or is not a directory: /Users/test-test/.jenkins/test/test/Checking/module1/target/surefire-reportsreMy sonar.properties are as below- sonar.projectKey=test-Testsonar.projectName=test-Testsonar.projectVersion=$PipelineIdsonar.modules=module1,module2,module3,module4,module5sonar.java.coveragePlugin=jacocosonar.jacoco.reportPath=reports/jacoco/jacoco-ut.execsonar.jacoco.itReportPath=reports/jacoco/jacoco-it.execsonar.sources=.reSonar IMG shows null as Unit Coverage.a href=https://i.stack.imgur.com/8FpJQ.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/8FpJQ.png alt=enter image description here/aHow to include UT ans IT to get good no of code coverage.",Not-TD-related,Other,,,,0.03,0.951,0.018,-0.9447
44985983,How to get coverage on new code displayed on the SonarQube dashboard?,"I'm using SonarQube 5.6 for analysing c legacy application code. I'm able to see data for latest check-in in terms of added LOC, new defects, added technical debt etc. But the coverage on new code section shows nothing but dash. I'm using SVN Source control.How can I enable the coverage on new code metric? I'm using dotcover.exe to create coverage.html and this HTML report is getting sent to SonarQube via additional parameters in TeamCity build step.",Not-TD-related,Other,,,,0.047,0.919,0.034,0.0129
45043813,Using OpenGL Compatibility Profile with Intel HD GPU + Mesa,"I was given an OpenGL application written by another team and I've been struggling to get it to work for nearly a week now. My set-up has a core profile of 3.3 (GLSL 3.3, Mesa 11.2)and compatibility profile of 3.0 (GLSL 1.3, Mesa 11.2). I tried running some test applications using the core profile on my set up and was successful. However, I know for a fact that this application uses the 3.0 compatibility profile (uses ARB functions in the glext.h) but it keeps throwing INVALID_OPERATION errors (1282) whenever functions like glUseProgramObjectARB, glActiveTextureARB, glUniform1iARB get executed.Any help in solving this issue is much appreciated.",Not-TD-related,Other,,,,0.044,0.809,0.147,0.9144
45073289,Query SQL Server to get count data with populate string id another table,"I have two tables, master and transaction. When in table codetransaction I get populate id with string. And I have a question, how to get count id in table codemaster from table codetransaction. I will display sample table and table when I want display.Table codeMaster: IdReferensi Referensi----------------------- 1 Alfa 2 Beta 3 Charlie 4 Delta 5 Echo 6 Fanta 7 GorillareTable codeTransaction: IdCPAR NoCPAR IdReferensi----------------------------- 1 NC001 2,5 2 NC002 1,2,3 3 NC003 2,3,5reReturn Table like this IdReferensi Referensi Total-------------------------------- 1 Alfa 1 2 Beta 3 3 Charlie 2 4 Delta 0 5 Echo 2 6 Fanta 0 7 Gorilla 0reSo, in SQL Server I hope you to help me to create query to display for returning the table from my example. Thanks",Not-TD-related,Other,,,,0,0.858,0.142,0.9081
45221362,How to Moq Mock a LoggerFactory in C AspNet Core,"I am trying to write some unit tests for controller actions. To do that, I am using XUnit and Moq. The controllers have an ILoggerFactory injected in the constructor. How does one Moq this up for testing?I have tried mocking a Logger for the controller class, and then mocking up CreateLogger to return the mock Logger, but I keep getting various test runtime NullReferenceExceptions when the LogInformation() function is called.// Logger that yields only disappointment... var mockLogger = new Mock<ILogger<JwtController>>();mockLogger.Setup(ml => ml.Log(It.IsAny<LogLevel>(), It.IsAny<EventId>(), It.IsAny<object>(), It.IsAny<Exception>(), It.IsAny<Func<object, Exception, string>>()));var mockLoggerFactory = new Mock<ILoggerFactory>();mockLoggerFactory.Setup(mlf => mlf.CreateLogger(""JwtController"")).Returns(mockLogger.Object);I assume the problem is that LogInformation is being called, and this is an extension method, so how to moq that?",Not-TD-related,Other,,,,0.081,0.919,0,-0.8181
45305749,Best plugins for sonarqube for analysisng Java code,"I am Looking for best plugins for sonarqube to analyze Java code. I found sonar-java plugin, cobertura plugin and is there any other plugins that I can use for analyszing java. My criteria is Timeline, Takeout useless code, SIG maintainability,Technical debt, and quality index.I tried to find but SIG plugin is deprecated.Sonarqube version-5.6.6Thanks.....",Not-TD-related,Other,,,,0.069,0.883,0.049,-0.0129
45307633,"maven equivalent for gradle `compile fileTree(dir: 'libs', include: '*.jar')`","What is maven equivalent for gradle's one-liner to include all jars from lib(s) folder? i.e. : dependencies { compile fileTree(dir: 'libs', include: '*.jar')}reI have a set of project to mavenize, and for a average project with ~50 jar in codelib folder, it takes at least half a day for thorough searching on a href=http://mvnrepository.com/ rel=nofollow noreferrerhttp://mvnrepository.com//a , guessing versions and jar dependencies looking inside jar etc work to solve technical debt of jar hell.The problem is old, and as of July 2017, one can findbr- a href=https://stackoverflow.com/questions/19065666/how-to-include-system-dependencies-in-war-built-using-mavenHow to include system dependencies in war built using maven/abr- a href=https://stackoverflow.com/questions/4955635/how-to-add-local-jar-files-in-maven-projectHow to add local jar files in maven project?/abrlisting similar answers with their limitations.New for me were pluginsbr- codeaddjars-maven-plugin, now dead at a href=https://github.com/kahing/addjars-maven-plugin rel=nofollow noreferrerhttps://github.com/kahing/addjars-maven-plugin/abr- codenon-maven-jar-maven-plugin at a href=https://github.com/stephenc/non-maven-jar-maven-plugin rel=nofollow noreferrerhttps://github.com/stephenc/non-maven-jar-maven-plugin/aThinking over again, the first step to mavenize a project should be to let compiler use existing jars an focus on code, not on dependencies (that often has jar put there just for a case, or copied in bulk)    !-- THIS DOES NOT WORK --     plugin     groupId  org.apache.maven.plugins  /groupId     artifactId  maven-compiler-plugin  /artifactId     configuration     includes     include  lib/*.jar  /include     /includes     /configuration     lugin  re",Not-TD-related,Other,,,,0.075,0.915,0.01,-0.9224
45389512,The anti-forgery cookie token and form field token do not match when using WebApi,"I have a single-page app (user loads a bunch of HTML/JS and then makes AJAX requests without another call to MVC - only via WebAPI). In WebAPI I have the following:public sealed class WebApiValidateAntiForgeryTokenAttribute : ActionFilterAttribute{public override void OnActionExecuting(System.Web.Http.Controllers.HttpActionContext actionContext){if (actionContext == null){throw new ArgumentNullException(nameof(actionContext));}if (actionContext.Request.Method.Method == ""POST""){string requestUri = actionContext.Request.RequestUri.AbsoluteUri.ToLower();if (uriExclusions.All(s => !requestUri.Contains(s, StringComparison.OrdinalIgnoreCase))) // place some exclusions here if needed{HttpRequestHeaders headers = actionContext.Request.Headers;CookieState tokenCookie = headers.GetCookies().Select(c => c[AntiForgeryConfig.CookieName]) // __RequestVerificationToken.FirstOrDefault();string tokenHeader = string.Empty;if (headers.Contains(""X-XSRF-Token"")){tokenHeader = headers.GetValues(""X-XSRF-Token"").FirstOrDefault();}AntiForgery.Validate(!string.IsNullOrEmpty(tokenCookie?.Value) ? tokenCookie.Value : null, tokenHeader);}}base.OnActionExecuting(actionContext); // this is where it throws}}Registered in Global.asax:private static void RegisterWebApiFilters(HttpFilterCollection filters){filters.Add(new WebApiValidateAntiForgeryTokenAttribute());filters.Add(new AddCustomHeaderFilter());}Occasionally, I see the The anti-forgery cookie token and form field token do not match error in my logs. When this is happening, both tokenCookie.value and tokenHeader are not null.Clientside, all of my AJAX requests use the following:beforeSend: function (request) {request.setRequestHeader(""X-XSRF-Token"", $('input[name=""__RequestVerificationToken""]').attr(""value""););},With Razor generating the token once on my SPA page:@Html.AntiForgeryToken()I have my machine key set in Web.config.What could be causing this?Update I just checked logs and I'm seeing this sometimes as well:The provided anti-forgery token was meant for user """", but the current user is ""someuser@domain.com"". a few seconds agoThis occurs when a user refreshes their instance of the SPA while logged in. The SPA then drops them into the landing page instead of the inner page for some reason (User.Identity.IsAuthenticated is true) - then they can't log in because of this error. Refreshing pulls them back inside. Not sure what this means, but I figured more info can't hurt.Appendix https://security.stackexchange.com/questions/167064/is-csrf-protection-useless-with-ajax/167076#167076",Not-TD-related,Other,,,,,,,
45492209,Which approach is better and why? Select statements or functions in PL/SQL?,"Which approach is better and why? Select statements or functions in PL/SQL?I came across some articles on PL/SQL where it was mentioned that select statements should be replaced by the functions. Whether this really improves the performance?",Not-TD-related,Other,,,,0,0.843,0.157,0.7603
46173132,How to define time/efforts in sonarqube quality gates,I am using Sonar server 5.6 version.I want to set a quality gates such that efforts required to resolve all major issue should be less than or equal to 5 days (say). How can I specify such criteria as quality gates?I can see similar condition for Reliability Remediation Effort,Not-TD-related,Other,,,,0,0.917,0.083,0.4404
46251649,How to get the values of different rows into single row in Oracle,I need to select data from different rows returning one row.I have table like this: SNO USEFUL COUNTER PINCODE SUBSNO DATA REFERENCE--- ------ ------- ------- ------ ----------------------------- --------- 1 Y null 504293 null 504293 Sl.No 2 null null 504293 null 1 null 3 null null 504293 null iciseva00031 null 4 null null 504293 null SANTHOSH KUMAR null 5 null null 504293 null SANTHOSH MANTHENA null 6 null null 504293 null 12-52 BRAHMAN WADA null 7 null null 504293 null ASIFABAD null 8 null null 504293 null Andhra Pradesh null 9 null null 504293 null 9248859222 null10 null null 504293 null 2 null11 null null 504293 null WSGLDPL12415 null12 null null 504293 null SIDDHARTHA COMMUNICATIONS null13 null null 504293 null MASADE SATISH null14 null null 504293 null HNO10-143POSTOFFICEROADBAPUNAGAR null ASIFABADDISTKUMRAMBHEEMASIFABAD 15 null null 504293 null ADILABAD null16 null null 504293 null ANDHRA PRADESH null17 null null 504293 null 9059187009 nullreAnd I have to return output like this: PINCODE SUBSNO USER COMPANY AGENT ADDRESS CITY STATE PHONE------- ------ ---- ------- ----- ------- ---- ----- -----504293 1 iciseva00031 SANTHOSHKUMAR SANTHOSHMANTHENA 12-52 BRAHMAN WADA ASIFABAD Andhra Pradesh 9248859222rePlease help me.,Not-TD-related,Other,,,,0,0.936,0.064,0.8842
46283656,Static assert that source code does not change in C++,"Say I have a method that must not change. Is there a way in C++ to create a compile time error (or runtime if compile time is impossible) if such a method changes?There are many uses of such a method (consider ficky threading or security issues that you don't want a novice co-worker changing). My particular use case is in maintaining backwards compatibility where some old methods such as persistent data deserializers must not change.I'm imagining something like the following: static_assert(chechsumOfBelowFunction() != 0x123, You changed the method! We can't do this because...)std::string getRelaseDateForVersion3(){ // This should never change because Version 3 was // only released once! return 2014-Jan-01;}reWhere codechecksumOfBelowFunction() computes a checksum or some other unique representation of the function (preferably cross platform) at compile time and code0x123 is the known reference checksum of what the function must stay as. Note that I've taken quite a bit or liberty with pseudo code but I hope I convey what I'm trying to do.",Not-TD-related,Other,,,,0.019,0.905,0.076,0.8441
46461030,Best datatype for column indicating the enumerated type,"I need to add column to a table, which represent the origin of value in another column. I.e. it's an enumerated value of known origins.What is the best datatype to represent the value? Should I use an integer or string? I realize best design would store both columns in another table, but it's not possible at the moment.Also, would it be better to represent unknown origin with some fixed value or null?",Not-TD-related,Other,,,,0,0.774,0.226,0.9412
46906515,Sonar dashboard not showing the score for code smells,"Looking at the sonar dashboard I thought everything is fine because I have 'A' ratings for Bugs, Vulnerabilities and Debt.a href=https://i.stack.imgur.com/hahuR.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/hahuR.png alt=Sonarqube dashboard with different ratings/aHowever then I checked the Code Smells in the issues view, and there are lots of unresolved issues in there, some with high severities:a href=https://i.stack.imgur.com/OH71A.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/OH71A.png alt=number of issues with severities/aI looked at the a href=https://docs.sonarqube.org/display/SONAR/Metric+Definitions rel=nofollow noreferrerdefinition/a of the Debt, but didn't find the Technical Debt Ratio anywhere in sonar. I would have expected the following view - including a rating on Code Smells:a href=https://i.stack.imgur.com/eWXOv.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/eWXOv.png alt=Image of how the sonarqube dashboard should look like/aSo why is the rating missing for Code smells? Is that configurable? Where can I see the Technical Debt Ratio in sonar?UpdateSome clarification what I meant with the question:For Bugs and Vulnerabilities the rating 1:1 reflects the issue situation: If there is only one Blocker (E) the rating for both categories jums to E (red) in the dashboard. For Debt category this is different. However as a product owner/manager the dashboard is an important instrument where people want to quickly view the state of the application. So in our project the developers must fix all issues above Info level (B,C,D,E). Two aspects:olliIn the project there are currently over 4314 issues which are not represented in the dashboard. liSince our project has a huge amount of DTO/Entity/Java Beans/Enum etc. classes which, due to their triviality contain less issues, dilute and distort the result of the debt rating.So is it possible to activate a Code Smell rating in the dashboard (which has the behavior of Bugs and Vulnerabilities)? (cp. last image)?",Not-TD-related,Other,,,,0.093,0.879,0.028,-0.9546
47176711,Changes since last version in SonarQube LTS 5.6.6,"We recently got SonarQube into our organisation as one of the main draws was that we would be able to track changes in technical debt over time. However, the core settings and default installation don't seem to provide for this. What do we need to do to be able to see changes in issues/coverage/etc. since our last build/a month ago/etc?On others' dashboards I've seen it available as a convenient dropdown!",Not-TD-related,Other,,,,0.039,0.961,0,-0.4199
47628680,Performance of java if-else with return statement, private String getString1(int n){ if (n == 0) { return ZERO; } if (n == 1) { return ONE; } if(n == 2) { return TWO; } return -NA-;}private String getString2(int n){ if (n == 0) { return ZERO; } else if (n == 1) { return ONE; } else if(n == 2) { return TWO; } else return -NA-;}reI have the above methods getString1(int) and getString2(int). Both will give the same o. But which one is the most efficient way of using? In there any difference in term of performance?,Not-TD-related,Other,,,,0,0.945,0.055,0.6704
47817252,Sonarqube Quality gate condition using 'Severity',"I would like to setup a Quality gate that checks: - No Vulnarabilities - No Bugs with severity >= MajorCan I, and if so how, add that severity into the condition?Regards!",Not-TD-related,Other,,,,0.141,0.783,0.075,-0.2942
48018400,"What are the restapis to get Coverage,technical debt,unit test success density and unit test failure density json data for SonarQube 6.3.1 in Postman?","The rest apis for Sonarqube 6.0 version is:- block e 1.(SonarqubeUrl)/api/issues/search=For Technical Debt.br 2.(SonarqubeUrl)/api/resources?metrics=ncloc,coverage=For Code Coverage.br 3.(SonarqubeUrl)/api/resources?metrics=ncloc,test_success_density=For Unit Test Success.br 4.(SonarqubeUrl)//api/resources?metrics=ncloc,test_failure_density=For Unit Test Failure. Sources.br a.a href=https://docs.sonarqube.orgages/viewpage.action?pageId=2752802 rel=nofollow noreferrerhttps://docs.sonarqube.orgages/viewpage.action?pageId=2752802/abr b.a href=https://docs.sonarqube.orgages/viewpage.action?pageId=2392181 rel=nofollow noreferrerhttps://docs.sonarqube.orgages/viewpage.action?pageId=2392181/a/block e",Not-TD-related,Other,,,,0.193,0.807,0,-0.7998
48057340,Get fix time for Sonar issue,When we select sonar issue in SonarQube it gives estimated fix time based on the project rules ( for example 45 mins in the uploaded image)a href=https://i.stack.imgur.com/iggN9.jpg rel=nofollow noreferrerimg src=https://i.stack.imgur.com/iggN9.jpg alt=enter image description here/aIs there a method of getting this value from SonarApi. There is a way to get Technical Debt for whole project.,Not-TD-related,Other,,,,0.046,0.903,0.051,0.0644
48519609,Updating project status under a change in quality gate,"I recently used sonarqube api to create a dynamic quality gate, it increases or decreases the acceptable number for the project, according to the number of lines of code, but I'm having some problems ...It works like this, after the analysis I use the number of lines and calculate the quality gate to increase or lower the acceptable limitI use the sonar line count itself to avoid mismatching information, but whenever I update a quality gate, the project status is not updated.For example, if a project was with the quality gate with the status Passed, after I update the quality gate, it should change the status to Failed, but it remains Passed because I did not perform a new analysis.How can I request pro sonar to re-execute the project status according to the quality gate change?I'm using sonarqube 6.0Thanks",Not-TD-related,Other,,,,0.092,0.786,0.121,-0.1779
48531345,Hide/show a table row when clicking on a link in Angular2,"Please don't mark it as a duplicate- I have tried the below links already:1) a href=https://stackoverflow.com/questions/36873900/hide-show-individual-items-inside-ngfor/4202764742027647Hide/show individual items inside ngFor/a2) a href=https://stackoverflow.com/questions/46423989/angular-2-expand-collapse-table-rowAngular 2 - expand collapse table row/a3) a href=https://stackoverflow.com/questions/44412377/hide-show-individual-items-inside-ngfor-in-angular-2?noredirect=1 lq=1Hide/show individual items inside ngFor in angular 2/aProblem:br/I am trying to hide/show a table row when clicking on a link in the previous row like below: component.html    div class=table-responsive *ngFor=let total of totals; let i=index    table class=table     ng-container *ngIf=total     h4 class=productName  Product: {{total.projectGroup}}  /h4     tr     th  Total LOC  /th     th  Total Test Coverage  /th     th  Total Coverage on New Code  /th     th  Total Technical Debt  /th     th  Total Issues  /th     /tr     tr     td  {{total.totalLOC}}  /td     td  {{total.totalCoverage}}  /td     td  {{total.totalNewCoverage}}  /td     td  {{total.totalTechDebtDays}}  /td     td    span *ngIf=total.totalCriticalIssues   = 0  Critical:   /span  {{total.totalCriticalIssues}}   br/     span *ngIf=total.totalNonCriticalIssues   = 0  Non-critical:   /span  {{total.totalNonCriticalIssues}}  /td     /tr     tr     td    a id={{i}} class =a_link (click)=toggle[total.projectGroup]=!toggle[total.projectGroup]; expand(total.projectGroup)   Expand/Collapse  /a    /td     /tr     tr [hidden]=!toggle[total.projectGroup]     div class=table-responsive     table class=table     tr class=table-header     th  Project Key  /th     th  Quality Gate  /th     th  LOC  /th     th  Test Coverage  /th     th  Coverage on New Code  /th     th  Technical Debt  /th     th  Issues  /th     /tr     tr *ngFor=let pjt of indProjects class=table-condensed     td  {{pjt.projectKey}}  /td     td  {{pjt.qualityGate}}  /td     td  {{pjt.loc}}  /td     td  {{pjt.coverage}}  /td     td  {{pjt.newCoverage}}  /td     td  {{pjt.techDebtDays}}  /td     td    span *ngIf=pjt.criticalIssues   = 0  Critical:   /span  {{pjt.criticalIssues}}   br/     span *ngIf=pjt.nonCriticalIssues   = 0  Non-critical:   /span  {{pjt.nonCriticalIssues}}  /td     /tr     /table     /div     /tr     /ng-container    /table  reIts working if I click on the same Expand/Collapse link 2 times - first it shows and then it hides. But if I click on a link once(it shows) and then click on another link, both of the expansions will show the same data in the inner table( which is the data of the last expansion). What I need is the first expansion should show the data related to that link and second expansion should show the data related to the second one. brlease, any pointers would be helpful. Please let me know if I am not clear in describing the issue.",Not-TD-related,Other,,,,0.043,0.92,0.037,0.3089
49249988,Sonar scanner not honoring the quality gates for code smells,"I want to have a quality gates defined such that efforts required to fix all code smells is not more than 5days(say). I defined the criteria as Technical Debt is greater than 7000 (in mins). Currently I have around 7days of code smell its quality gates pass. Following are screenshots,a href=https://i.stack.imgur.com/KpEk6.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/KpEk6.png alt=enter image description here/aI am using Sonar Server 6.7.1Can anybody please tell me what is wrong here ? Atul Sureka",Not-TD-related,Other,,,,0.074,0.845,0.081,-0.128
49529658,Prevent SonarQube from failing Pull Request checks,"I've set up an automatic pull request check via jenkins/github/sonarqube integration.brThe workflow is as follows:brGithub pull request created by user  Github Webhook triggers, and calls Jenkins API to execute sonarqube scanner  reports to sonarqube server  sonarqube server calls github API(create commit statuses : ref a href=https://developer.github.com/v3/repos/statuses/ rel=nofollow noreferrerhttps://developer.github.com/v3/repos/statuses//a) and posts a comment about the PR. The issue is that it marks the PR as check failed just because it didn't pass its code health checks. The build passed, but the code is dirty - and that causes the PR to be marked as unacceptable. I'd like to find a way to prevent code quality checks from appearing as an actual status of the commit, and only allow commenting. Additional images to provide some context: SonarQube uses a techuser account token to post its analysis summary as a comment on the PR thread. (Sorry for the black boxes, corporate stuff..)brThis functionality is everything we need, nothing more.a href=https://i.stack.imgur.com/5dd1F.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/5dd1F.png alt=enter image description here/aHowever... the plugin does one more thing, which is marking the commit as a failure. Note that we're already using something else to check for actual build failures. Although it didn't fail, sonarqube marking the commit as failure because of code quality makes the whole commit display as a failure. I'd like to prevent sonarqube from setting branch check statuses, while letting it comment on the issue. I couldn't find an option for anything like that neither in jenkins plugin configuration nor sonarqube admin page nor sonarqube scanner script documentation.a href=https://i.stack.imgur.com/srcK4.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/srcK4.png alt=enter image description here/aThanks in advance.",Not-TD-related,Other,,,,0.093,0.796,0.111,-0.2204
49923165,Tensorflow: training on JSON data to generate similar output,"Assume one has JSON data containining instructions for generating the following 10x5 cell patterns, and that each cell can contain one of the following characters: code_ 0 x y zAlso assume that each character can be displayed in various colors.pattern 1: _yx_0zzyxx_0__yz_0y_x0_0x000yx_y__x000zxzyyzx_z_0yrepattern 2: xx0z00yy_zzzx_0000_x_yxy0y__yx_xz0z__0_yy__x0_0_y_repattern 3: yx0x_xz0_zxz_x0_xxxz_yy0x_0z00zyy0__0zyxz_xy0_0xz0reThese were randomly generated, and are all black, but assume they were devised according to some set of rules, and in color.The JSON for the first pattern would look something like: { width: 10, height: 5, cells: [ { value: '_', color: 'red' }, { value: 'y', color: 'blue' }, ... ]}reIf one wanted to train on this data in order to generate new yet similar patterns (again, assuming these were not randomly generated), what is the recommended approach for:ullireading the data in (I'd imagine putting the JSON into an codeExample protobuf, serializing the buffer to string with tf.parse_example, and then writing that to TFRecord files)litraining on that dataligenerating new patterns based on the trained modellisupplying seed data for the generated patterns, e.g. first cell is the character x' with the color blue.I want to achieve something similar to what I've seen in style transfer with arthotos, and with music/MIDI data (see: Google Magenta). In those cases, here the model is trained an a distinctive set of artwork or melodic style, and a seed in the form of a photograph or primer melody is supplied in order to generate content similar to the data used in training.Thanks!",Not-TD-related,Other,,,,0,0.944,0.056,0.908
49938302,Increment a string value,How can I increment a string value? For example: string RECONCILIATION_COUNT;if (thing happens) { RECONCILIATION_COUNT++;}reThis is normally wont work since it is not possible to increment a string variable in the same way used for int values.codeRECONCILIATION_COUNT is always a number from 0-5.I chose to declare it as a string since I am getting this value from database and i am not finding a way how to get an int value from sql. RECONCILIATION_COUNT = Rows[RECONCILIATION_COUNT].toString();reThis is what I am using for the moment.,Not-TD-related,Other,,,,0,0.89,0.11,0.7579
51379526,How does SonarQube calculate the total amount of Technical Debt?,"I have a Multi Module Maven Project which I have analyzed with SonarQube Scanner for Maven. I query the table codeissues of the database and I retrieve all the open issues codeSELECT * FROM public.issues WHERE project_uuid = {project_uuid} AND status = 'OPEN';. Although, when I sum the codeeffort of all the open issues the amount of TD is different than the one the API codeapi/measures/component?component={project_uuid} metricKeys=sqale_index returns.I am wondering i) why this is happening ii) which of the two numbers is the correct (probably the one the API returns is the correct) and iii) how could I get same number by querying the database.",Not-TD-related,Other,,,,0,0.986,0.014,0.0772
52202108,Technical Debt measured by GET api/measures/component VS GET api/issues/search,I am using SonarQube Version 7.2.1 and I have analyzed a Multi Module Maven Project.In order to retrieve all the project's open issues I call code/api/issues/search?componentKeys=COMPONENT_KEY ps=500 resolved=false. Then I sum-up either the emeffort/em or the emdebt/em property in order to calculate the amount of debt of the open issues. I get a total of: 3704 mins.Later I realized that there is another endpoint namely: GET codeapi/measures/component when I call it code/api/measures/component?component=COMPONENT_KEY metricKeys=sqale_index the amount of TD is different: 3449 mins.Which of the above numbers is correct and why is there a difference?,Not-TD-related,Other,,,,0.036,0.964,0,-0.466
52363258,Materialize Common Table Expression in HANA,"Is there a way to force HANA to materialize a subquery in a WITH clause like what MATERIALIZE and INLINE optimizer hints do as below in Oracle?WITH dept_count AS (SELECT /*+ MATERIALIZE */ deptno, COUNT(*) AS dept_countFROM empGROUP BY deptno)SELECT ...I find no such hint in hana. Any help?",Not-TD-related,Other,,,,0.039,0.818,0.143,0.7059
52513336,Is there a way to expose a docker container port bound to 127.0.0.1 to host?,"I run a service inside a container that binds to 127.0.0.1:8888.I want to expose this port to the host.Does docker-compose support this?I tried the following in docker-compose.yml but did not work.expose: - ""8888""ports:- ""8888:8888""P.S. Binding the service to 0.0.0.0 inside the container is not possible in my case.UPDATE: Providing a simple example:docker-compose.ymlversion: '3'services: myservice:expose: - ""8888""ports:- ""8888:8888""build: .DockerfileFROM centos:7RUN yum install -y nmap-ncatCMD [""nc"", ""-l"", ""-k"", ""localhost"", ""8888""]Commands:$> docker-compose up --build$> # Starting test1_myservice_1 ... done$> # Attaching to test1_myservice_1$> nc -v -v localhost 8888$> # Connection to localhost 8888 port [tcp/*] succeeded!TEST$>After inputing TEST in the console the connection is closed, which means the port is not really exposed, despite the initial success message. The same issue occurs with with my real service.But If I bind to 0.0.0.0 (instead of localhost) inside the container everything works fine.",Not-TD-related,Other,,,,0.056,0.878,0.067,0.1909
52759667,Properly getting blobs from mysql database with mysql connector in python,"When executing the following code:import mysql.connectorconnection = mysql.connector.connect(...) # connection params herecursor = connection.cursor()cursor.execute('create table test_table(value blob)')cursor.execute('insert into test_table values (_binary %s)', (np.random.sample(10000).astype('float').tobytes(),))cursor.execute('select * from test_table')cursor.fetchall()I get the following error:UnicodeDecodeError: 'utf-8' codec can't decode byte 0xf7 in position 1: invalid start byte(...and then a stack trace which I don't think is useful here)It seems that mysql connector converts my blob to string (and fails to do so). How can I fetch this data as bytes without any conversion?",Not-TD-related,Other,,,,0.09,0.879,0.031,-0.6377
53284561,How to use web api sonarcloud,"Recently I started using sonarcloud and I was asked for a university project to extract the technical debt of a project. I'm trying to use the web API exposed by sonarcloud but with little success. This is the python code I wrote import requestsimport jsonr = requests.get ('https://sonarcloud.io/component_measures?id=Huginn87_jabref/api/metrics/component?component= metricKeys=sqale_index',auth= (' usr ',' pwd '))code = r.status_codeprint Status code:, codeprint r.json ()reand this is the result I get Status code: 200Traceback (most recent call last): File test.py, line 7, in   module   print r.json () File /home/usr/.localbython2.7/site-packages/requests/models.py, line 897, in json return complexjson.loads (self.text, ** kwargs) File /usrbython2.7/json/__init__.py, line 339, in loads return _default_decoder.decode (s) File /usrbython2.7/json/decoder.py, line 364, in decode obj, end = self.raw_decode (s, idx = _w (s, 0) .end ()) File /usrbython2.7/json/decoder.py, line 382, in raw_decode raise ValueError (No JSON object could be decoded)ValueError: No JSON object could be decodedreAccording to the documentation, you should give me a json format, but it does not. Would anyone be kind enough to tell me where I'm wrong, please? Many thanks in advance. Greetings.",Not-TD-related,Other,,,,0.054,0.835,0.111,0.9246
53633092,Relation between Sonarqube and build tools,"This might be a basic question to most people that have experience with these tools, but I recently went to an interview where the interviewer asked me What's Sonaqube, What's Maven which I basically just defined based on various Google searches prior to the interview, but then the killer questions, What's the relation between Sonarqube and Build automation tools? How does Sonarqube work with Maven, Why do we use Sonarqube with build automation tools..... And I literally froze and couldn't answer them and died a bit inside on my career ambitions as a Junior dev!So here I am, for anyone to enlighten me on these killer questions for any other interviews to come.",Not-TD-related,Other,,,,0.138,0.826,0.036,-0.9397
54204342,node-fetch: why is `signal` recommended over `timeout`?,"The node-fetch documentation suggests that using signal is recommended over timeout, but doesn't offer any hints as to why:{// These properties are part of the Fetch Standard...signal: null, // pass an instance of AbortSignal to optionally abort requests// The following properties are node-fetch extensions...timeout: 0, // req/res timeout in ms, it resets on redirect. 0 to disable (OS limit applies). Signal is recommended instead....}(source: https://www.npmjs.comackage/node-fetch)Why is that? In what situations would it be a problem to use timeout?",Not-TD-related,Other,,,,0.04,0.916,0.044,-0.3204
54290127,SonarQube web API for Code smells - Technical Debt Count,"SonarQube Version: 6.7 Is there any REST API for getting Code smells (Technical Debt) from SonarQube, I have searched many forums but I couldn't able to find.I need rest API where we can pass the project key to get the days count of code smells.",Not-TD-related,Other,,,,0,1,0,0
54852626,SonarQube Analysis in the Azure DevOps release pipeline,Refer a href=https://www.azuredevopslabs.com/labs/vstsextend/sonarqube/ rel=nofollow noreferrerthis/a guide to setup SonarQube and fire up to manage technical debt.,Not-TD-related,Other,,,,0.274,0.726,0,-0.5994
54921391,Load post from Followers in Nodejs and Mongoose,"I have a schema for post like below, but am having problem fetching post from my followers. i have also tried using but all to no avail. please help I have a schema for post like below, but am having problem fetching post from my followers. i have also tried using but all to no avail. please help I have a schema for post like below, but am having problem fetching post from my followers. i have also tried using but all to no avail. please help
const mongoose = require('mongoose');
const Schema = mongoose.Schema;
const PostSchema =new Schema({
user: {
type: Schema.Types.ObjectId,
ref:'users'
},
text:{
type:String,
required: true
},
name:{
type:String
},
avatar:{
type:String
},
likes:[
{
user:{
type: Schema.Types.ObjectId,
ref: 'users'
}
}
],
comments:[
{
user:{
type: Schema.Types.ObjectId,
ref: 'users'
},
text:{
type:String,
required: true
},
name: {
type: String
},
avatar: {
type: String
},
date:{
type:Date,
default: Date.now
},
likes: [
{
user: {
type: Schema.Types.ObjectId,
ref: 'users'
}
}
],
}
],
reposter: [
{
user: { type: mongoose.Schema.Types.ObjectId, ref: ""User"" },
date: {
type: Date,
default: Date.now
}
}
],
numberOfRepost: { type: Number, default: 0 },
date: {
type: Date,
default: Date.now
}
});
module.exports = Post = mongoose.model('post', PostSchema);",Not-TD-related,Other,,,,0.09,0.721,0.19,0.965
54977712,Should I lock the table when creating user?,I want to create a user into User table.These are my process.ollicontinue when email and nickname are not existlicreates a user I think if I didn't lock the User table while creating a user then email and nickname can be duplicated. Any ideas?,Not-TD-related,Other,,,,0,0.859,0.141,0.5574
55064293,How to eliminate com.sun.jndi.ldap references from my Java project?,"I am refactoring here an Ldap tool using intensively codecom.sun.jndi.ldap.* classes.As it is expected, I get warnings likeblock e [...] is internal proprietary API and may be removed in a future release/block efrom the Java compiler. I would like to eliminate these warnings on a clean way.Can I somehow do it? I suspect, maybe same maven package should be available, containing the same or very similar API calls, but in a better package path (like codeorg.something.jndi.ldap.*).",Not-TD-related,Other,,,,0.066,0.833,0.102,0.5647
55512849,How to switch virtualenv in shell script?,"For my personal project, I'm trying to analyze the technical debt of various python libraries. For this, I made python script which downloads the library, checks out to each merged commit and runs the analysis. One part of the analysis is to get the test coverage.The easiest way I found to get it is to run codecoverage run --source={library}/ setup.py testHowever, I want to have this automated so I'm trying to run this command in a shell script from the python script mentioned above.The script shall change the dir to the library, switch to virtualenv (automatically created in the previous steps of the analysis) and run the codecoverage. However, it fails on codeRequirement error which indicates that it does not actually switch the virtualenv and stays in the virtualenv of the analysis project.The shell script looks like this: !/usr/bin/env bash Args $1 proj_path $2 proj_name $3 venv_namecd $1source `which virtualenvwrapper.sh`workon $3coverage run --source=$2/ setup.py testcoverage reportreAnd it's called from the python script like this: subprocess.call([analyzer/run_coverage.sh, self.repo_path, self.repo_name, self.venv_name])reCould you please help me how to switch the venv in the shell script? Thanks!",Not-TD-related,Other,,,,0.041,0.848,0.111,0.8953
55850870,Sidebar Functionality,"I have continued to develop a sidebar capability within my google sheet.I have am looking for some assistance in creating a flow within the sidebar and using links or buttons to create some output messages.Problem 1) - I have created a sidebar with forward and back arrows which I want to link other html files to when they are clicked within the sidebar, therefore creating a flow or dialog that can be moved back or forth in the same sequence. i.e.. I click next and the function openTheSidebar2() runs I have have a search dropdown feature which in the code below gives Primary risk categories. Problem 2) - I would like these to have the ability to provide a simple paragraph (explanation of each category) when they are selected. Would I need to create a different html file for each category? I'm hoping I can add the each message for each category in the same html file.Is hyperlinks the wrong way to go about this altogether?Any help is much appreciatedcode.gspre class=lang-js prettyprint-overridecodefunction onOpen() { menu();}function menu() { SpreadsheetApp.getUi().createMenu('Risk Menu') .addItem('Generate Risk Waiver', 'createNewCase') .addSubMenu(SpreadsheetApp.getUi().createMenu('Risk Help') .addItem('Risk Guidance', 'openTheSidebar') .addItem('Risk Title', 'openTheSidebar2')) .addToUi();}function openTheSidebar() { var userInterface=HtmlService.createTemplateFromFile('example3').evaluate() .setTitle('Risk Rating'); SpreadsheetApp.getUi().showSidebar(userInterface);}function openTheSidebar2() { var userInterface2=HtmlService.createTemplateFromFile('example4').evaluate() .setTitle('Primary Risk Category'); SpreadsheetApp.getUi().showSidebar(userInterface2);}function openTheSidebar3() { var userInterface3=HtmlService.createTemplateFromFile('example').evaluate() .setTitle('Cause'); SpreadsheetApp.getUi().showSidebar(userInterface3);}function include(filename) { return HtmlService.createHtmlOutputFromFile(filename).getContent();}function getRowColumn() { var ss=SpreadsheetApp.getActive(); var sh=ss.getActiveSheet(); var rg=sh.getActiveCell(); var rObj={row:rg.getColumn() ,column:rg.getRow()}; return rObj;}function getCellA1() { var ss=SpreadsheetApp.getActive(); var sh=ss.getActiveSheet(); var rg=sh.getActiveCell(); var rObj={A1:rg.getA1Notation()}; return rObj;}function onCheckOpenSideBar(e) { if(e.range.getSheet().getName()!='Option 1')return; if(e.range.rowStart==2    e.range.columnStart==24) { if(e.value=='TRUE') { openTheSidebar(); e.range.getSheet().getRange(e.range.rowStart,e.range.columnStart).setValue(FALSE); } } if(e.range.getSheet().getName()!='Option 1')return; if(e.range.rowStart==2    e.range.columnStart==8) { if(e.value=='TRUE') { openTheSidebar2(); e.range.getSheet().getRange(e.range.rowStart,e.range.columnStart).setValue(FALSE); } } if(e.range.getSheet().getName()!='Option 1')return; if(e.range.rowStart==2    e.range.columnStart==1) { if(e.value=='TRUE') { openTheSidebar3(); e.range.getSheet().getRange(e.range.rowStart,e.range.columnStart).setValue(FALSE); } }}function createOnEditTrigger() { ScriptApp.newTrigger('onCheckOpenSideBar').forSpreadsheet(SpreadsheetApp.getActive()).onEdit().create();}reexample4.htmlpre class=lang-html prettyprint-overridecode  !DOCTYPE html    html    head    meta name=viewport content=width=device-width, initial-scale=1    style  .dropbtn { background-color: 4CAF50; color: white; padding: 16px; font-size: 16px; border: none; cursor: pointer;}.dropbtn:hover, .dropbtn:focus { background-color: 3e8e41;}myInput { border-box: box-sizing; background-image: url('searchicon.png'); background-position: 14px 12px; background-repeat: no-repeat; font-size: 16px; padding: 14px 20px 12px 45px; border: none; border-bottom: 1px solid ddd;}myInput:focus {outline: 3px solid ddd;}.dropdown { position: relative; display: inline-block;}.dropdown-content { display: none; position: absolute; background-color: f6f6f6; min-width: 230px; overflow: auto; border: 1px solid ddd; z-index: 1;}.dropdown-content a { color: black; padding: 12px 16px; text-decoration: none; display: block;}.dropdown a:hover {background-color: ddd;}.show {display: block;}a { text-decoration: none; display: inline-block; padding: 8px 16px;}a:hover { background-color: ddd; color: black;}.previous { background-color: f1f1f1; color: black;}.next { background-color: 4CAF50; color: white;}.round { border-radius: 50%;}  /style    /head    body    p  Click on the button to open the dropdown menu, and use the input field to search for a specific dropdown link.      div class=dropdown     button onclick=myFunction() class=dropbtn  Categories  /button     a href= class=previous round   8249;  /a    a href= class=next round   8250  /a     div id=myDropdown class=dropdown-content     input type=text placeholder=Search.. id=myInput onkeyup=filterFunction()    a href=IT Security   Vulnerability  IT Security   Vulnerability  /a    a href=Information Security - Data Only  Information Security - Data Only  /a    a href=Technical Debt or Decommission  Technical Debt or Decommission  /a    a href=Availability (SLA)  Availability (SLA)  /a    a href=Service Continuity   Resilience  Service Continuity   Resilience  /a    a href=Capacity   Performance  Capacity   Performance  /a    a href=Licencing   Asset Management, Contracts, Maintenance,  Licencing   Asset Management, Contracts, Maintenance,  /a    a href=Legal   Regulatory Compliance  Legal   Regulatory Compliance  /a    a href=Supplier   Vendor Management  Supplier   Vendor Management  /a    a href=Shadow IT  Shadow IT  /a    a href=Resource  Resource  /a    a href=Knowledge / Skills / Tooling)  Knowledge / Skills / Tooling)  /a    a href=Procedure   Process  Procedure   Process  /a    a href=Service Ownership  Service Ownership  /a    a href=Project  Project  /a    a href=Environmental (includes facilities)  Environmental (includes facilities)  /a    a href=Architecture and Strategic  Architecture and Strategic  /a     /div    /div    script  /* When the user clicks on the button,toggle between hiding and showing the dropdown content */function myFunction() { document.getElementById(myDropdown).classList.toggle(show);}function filterFunction() { var input, filter, ul, li, a, i; input = document.getElementById(myInput); filter = input.value.toUpperCase(); div = document.getElementById(myDropdown); a = div.getElementsByTagName(a); for (i = 0; i    a.length; i++) { txtValue = a[i].textContent || a[i].innerText; if (txtValue.toUpperCase().indexOf(filter)    -1) { a[i].style.display = ; } else { a[i].style.display = none; } }}  /script    /body    /html  re",Not-TD-related,Other,,,,0.046,0.888,0.066,0.908
56350348,DbContext not updating database,"When I save changes to DbContext, it doesn't update my database. No errors either.Yes, the incoming form data is filled. Yes, the connection string is correct, I know this because I'm able to retrieve data from the database perfectly fine. If it's of relevance, it's a many-to-many relationship.A roadmap is like an article as far as you're concerned which can be associated with many tags.  public static class RoadmapService { static ConkerDbEntities dbContext; public static void createDbContext(ConkerDbEntities _dbContext) { dbContext = _dbContext; } public static void addToDatabase(Form form) { Roadmaps roadmap = new Roadmaps { RoadmapTitle = form.title, RoadmapSummary = form.summary, RoadmapBody = form.body }; var tags = new Tags[form.tags.Length]; for(int i = 0; i    tags.Length; i++) { tags[i] = new Tags(); tags[i].TagId = form.tags[i]; } var roadmapTags = new RoadmapTags[form.tags.Length]; for(int i = 0; i    tags.Length; i++) { roadmapTags[i] = new RoadmapTags{Roadmap = roadmap, Tag = tags[i]}; } dbContext.AddRange(roadmapTags); dbContext.SaveChangesAsync(); } }}reWhere dbcontext is created, this is the constructor of Startup.cs  public static SearchEngine engine; public static ConkerDbEntities dbContext; public Startup(IConfiguration configuration) { Configuration = configuration; dbContext = new ConkerDbEntities(); RoadmapService.createDbContext(dbContext); engine = new SearchEngine(dbContext); }reI get no errors, and there's nothing added to the database. I'm probably doing something fundamentally wrong here. Thanks in advance.",Not-TD-related,Other,,,,0.064,0.835,0.101,0.7906
56421037,Unable to Zip a File in Buffer,"i Want to Zip the CSV File in (Buffer) Using codezipFile in PythonBelow is My Code Which I Have Tried And Error Log Attached I Dont want to use the compression in df.to_csv due to Version issue re import pandas as pdimport numpy as npimport ioimport zipfiledf = pd.DataFrame(np.random.randn(100, 4), columns=list('ABCD'))s_buf = io.StringIO()df.to_csv(s_buf,index=False)s_buf.seek(0)s_buf.name = 'my_filename.csv'localfile= io.BytesIO()localzip = io.BytesIO()zf = zipfile.ZipFile(localzip, mode=w,compression=zipfile.ZIP_DEFLATED)zf.writestr(localfile, s_buf.read())zf.close()with open(D:/my_zip.zip, wb) as f: f.write(zf.getvalue())reError I am Getting Traceback (most recent call last): File C:/Users/WindowycharmProjects/dfZip/dfZiptest.py, line 25, in   module   zf.writestr(localfile, s_buf.read()) File C:\Python\Python37\lib\zipfile.py, line 1758, in writestr date_time=time.localtime(time.time())[:6]) File C:\Python\Python37\lib\zipfile.py, line 345, in __init__ null_byte = filename.find(chr(0))AttributeError: '_io.BytesIO' object has no attribute 'find're",Not-TD-related,Other,,,,0.062,0.925,0.013,-0.5889
56437875,"How do I define setter, getter for dynamically added attributes","I have a class as follows: class A: def __init__(self): pass def add_attr(self, name): setattr(self, name, 'something')reHow do I define custom setter, getter for codeself.name? I cannot use code__setattr__, code__getattribute__ because that will change the behaviour of codeadd_attr too.EDIT: the users of this class will add arbitrary number of attributes with arbitrary names: a = A()a.add_attr('attr1')a.add_attr('attr2')reI want custom behavior for only these user added attributes.",Not-TD-related,Other,,,,0,0.956,0.044,0.1531
56473896,Is there a way to disable the nested field name feature in react final form?,"Please see react final form's docs href=https://github.com/final-form/final-form#field-namesI'm working on a form which obviously is powered by react final form. In the form component, I'm fetching data from an API server and the response body includes something like the following:{""configs"": {""name"": ""abc"",""display.name"": ""Abc"",""value"": 12,""read.only"": true}}As we can see that there are four different key/value pairs in the configs. react final form can display values like name and value just fine but not values like display.name and read.only since they have a dot -> . in their key.I know I can change these dots (.) with something like underscores and it will work. But the problem is that our backend devs are saying that using dots (.) to separate key names is very common in the backend so replacing dots with other separators won't be an option.I'm currently replacing these separators with underscores in the frontend but that logic is everywhere and I think there should a better way to solve this. Thanks!",Not-TD-related,Other,,,,0.019,0.802,0.179,0.9761
56522808,"In SonarQube, Newcode is shown for bugs without enabling SCM blame information? is it the right behaviour?","We are using SonarQube version - 6.7.4 and we were not getting the coverage under new code, so followed below links and as suggested by ANN came to a conclusion that new-code will be available only after enabling SCM blame information because SonarQube relies on blame data from SCM repository for new code. We have enabled SCM blame (our source code is in SVN) and we started getting coverage under new-code.Now my doubt is in the below links as ANN suggested that if SCM blame is not enabled nothing is recorded under new-code like - bugs, duplications, coverage and technical debt etc. However, apart from Coverage Im able to see bugs and other things as shown in the attached image without enabling the SCM blame information. Could you please explain this behavior?URLs:a href=https://groups.google.com/forum/!topic/sonarqube/VCV77hLwsNE rel=nofollow noreferrerhttps://groups.google.com/forum/!topic/sonarqube/VCV77hLwsNE/aa href=https://docs.sonarqube.org/latest/user-guide/fixing-the-water-leak/header-2 rel=nofollow noreferrerhttps://docs.sonarqube.org/latest/user-guide/fixing-the-water-leak/header-2/a",Not-TD-related,Other,,,,0.119,0.849,0.032,-0.8953
56727872,Always presenting presenting modally,"No matter what I do, the segue kind is always present modally (one vc on top an other). This is even when it is not set to it. At the moment my segue is set to Show but even still, the bar at the top of the view controller is still there and when I run the app it does the present modally over the top animation.I don't know where to go from here!!Reseting my computer.Reinstalling Xcode.Different ways of showing the vc.a href=https://i.stack.imgur.com/LokRJ.png rel=nofollow noreferrerThis is what I mean by white bar at top/a",Not-TD-related,Other,,,,0.017,0.883,0.1,0.7214
57023486,Angular 8: Unit Test Error: Can't resolve all parameters for ApplicationModule: (?),"I am attempting to run a Jasmine test on an Angular service that uses http:pre class=lang-js prettyprint-overridecodeimport { PostService } from '.ost.service';import { Post } from '../_modelost';import { TestBed } from '@angular/core/testing';import { HttpClientTestingModule, HttpTestingController } from '@angular/common/http/testing';import { BrowserDynamicTestingModule, platformBrowserDynamicTesting } from '@angularlatform-browser-dynamic/testing';describe('PostService', () =   { let httpTestingController: HttpTestingController; let service: PostService; beforeEach(() =   { TestBed.resetTestEnvironment(); TestBed.initTestEnvironment(BrowserDynamicTestingModule, platformBrowserDynamicTesting()); TestBed.configureTestingModule({ providers: [PostService], imports: [HttpClientTestingModule] }); httpTestingController = TestBed.get(HttpTestingController); service = TestBed.get(PostService); // setting up mock localStorage let store = {}; const mockLocalStorage = { getItem: (key: string): string =   { return key in store ? store[key] : null; }, setItem: (key: string, value: string) =   { store[key] = `${value}`; }, removeItem: (key: string) =   { delete store[key]; }, clear: () =   { store = {}; } }; spyOn(localStorage, 'getItem') .and.callFake(mockLocalStorage.getItem); spyOn(localStorage, 'setItem') .and.callFake(mockLocalStorage.setItem); spyOn(localStorage, 'removeItem') .and.callFake(mockLocalStorage.removeItem); spyOn(localStorage, 'clear') .and.callFake(mockLocalStorage.clear); }); afterEach(() =   { httpTestingController.verify(); }); describe('getAll', () =   { it('should return an observable of Posts', () =   { const postData: Post[] = [ {id: '6aba8f8f-cd43-4b1c-b3a4-21aba97ab620', title: 'CSS Layouts: Justified Elements', created: '2018-3-20', content: 'css-layouts-justified-elements'}, {id: 'c49439a4-a24a-4e1b-bc92-ebad6caf5e74', title: 'The 4 Constraints of Project Management', created: '2018-02-05', content: 'the-4-constraints-of-project-management'}, {id: '23723e52-9f0d-4a5d-94e6-196382456258', title: 'Want a Project to Succeed? Gather Good Estimates', created: '2018-1-26', content: 'want-a-project-to-succeed-gather-good-estimates'}, {id: '69870c97-6736-4956-9826-8af4b2216a79', title: 'Measuring Technical Debt', created: '2019-7-7', content: 'measuring-technical-debt'}, {id: 'd05ee0b1-ade2-406c-a9ae-d22ba0229341', title: 'Estimations: Coping with Uncertainty', created: '2018-02-08', content: 'estimations-coping-with-uncertainty'} ]; service.getAll().subscribe(posts =   { expect(posts.length).toEqual(5); }); const req = httpTestingController.expectOne('http://localhost:8089osts'); expect(req.request.method).toEqual('GET'); req.flush(postData); // get the Observable to resolve 'flush' with the PostData }); it('should be created', () =   { expect(service).toBeTruthy(); }); });});reMuch of the test isn't there yet, I'm just trying to get things working.Basically, the test fails near to launch with the error: Failed: Can't resolve all parameters for ApplicationModule: (?).Error: Can't resolve all parameters for ApplicationModule: (?). at syntaxError (/Users/mikecoxon/dev/ws-otherackages/compiler/src/util.ts:100:17) at CompileMetadataResolver._getDependenciesMetadata (/Users/mikecoxon/dev/ws-otherackages/compiler/src/metadata_resolver.ts:957:27) at CompileMetadataResolver._getTypeMetadata (/Users/mikecoxon/dev/ws-otherackages/compiler/src/metadata_resolver.ts:836:20) at CompileMetadataResolver.getNgModuleMetadata (/Users/mikecoxon/dev/ws-otherackages/compiler/src/metadata_resolver.ts:680:18) at CompileMetadataResolver.getNgModuleSummary (/Users/mikecoxon/dev/ws-otherackages/compiler/src/metadata_resolver.ts:450:31) at /Users/mikecoxon/dev/ws-otherackages/compiler/src/metadata_resolver.ts:586:44 at Array.forEach (  anonymous  ) at CompileMetadataResolver.getNgModuleMetadata (/Users/mikecoxon/dev/ws-otherackages/compiler/src/metadata_resolver.ts:569:43) at CompileMetadataResolver.getNgModuleSummary (/Users/mikecoxon/dev/ws-otherackages/compiler/src/metadata_resolver.ts:450:31) at /Users/mikecoxon/dev/ws-otherackages/compiler/src/metadata_resolver.ts:586:44From: Task: Run beforeEach in control flow at UserContext.  anonymous   (/Users/mikecoxon/dev/ws-other/blog/node_modules/jasminewd2/index.js:94:19) at attempt (/Users/mikecoxon/dev/ws-other/blog/node_modules/jasmine/node_modules/jasmine-coreb/jasmine-core/jasmine.js:4297:26) at QueueRunner.run (/Users/mikecoxon/dev/ws-other/blog/node_modules/jasmine/node_modules/jasmine-coreb/jasmine-core/jasmine.js:4217:20) at runNext (/Users/mikecoxon/dev/ws-other/blog/node_modules/jasmine/node_modules/jasmine-coreb/jasmine-core/jasmine.js:4257:20) at /Users/mikecoxon/dev/ws-other/blog/node_modules/jasmine/node_modules/jasmine-coreb/jasmine-core/jasmine.js:4264:13 at /Users/mikecoxon/dev/ws-other/blog/node_modules/jasmine/node_modules/jasmine-coreb/jasmine-core/jasmine.js:4172:9 at /Users/mikecoxon/dev/ws-other/blog/node_modules/jasminewd2/index.js:64:48 at ControlFlow.emit (/Users/mikecoxon/dev/ws-other/blog/node_modules/selenium-webdriverb/events.js:62:21) at ControlFlow.shutdown_ (/Users/mikecoxon/dev/ws-other/blog/node_modules/selenium-webdriverbromise.js:2674:10) at shutdownTask_.MicroTask (/Users/mikecoxon/dev/ws-other/blog/node_modules/selenium-webdriverbromise.js:2599:53)From asynchronous test: Error: at Suite.  anonymous   (/Users/mikecoxon/dev/ws-other/blog/src/app/_servicesost.service.spec.ts:20:3) at addSpecsToSuite (/Users/mikecoxon/dev/ws-other/blog/node_modules/jasmine/node_modules/jasmine-coreb/jasmine-core/jasmine.js:1107:25) at Env.describe (/Users/mikecoxon/dev/ws-other/blog/node_modules/jasmine/node_modules/jasmine-coreb/jasmine-core/jasmine.js:1074:7) at describe (/Users/mikecoxon/dev/ws-other/blog/node_modules/jasmine/node_modules/jasmine-coreb/jasmine-core/jasmine.js:4399:18) at Object.  anonymous   (/Users/mikecoxon/dev/ws-other/blog/src/app/_servicesost.service.spec.ts:16:1) at Module._compile (internal/modules/cjs/loader.js:701:30) at Module.m._compile (/Users/mikecoxon/dev/ws-other/blog/node_modules/ts-node/src/index.ts:473:23) at Module._extensions..js (internal/modules/cjs/loader.js:712:10) at Object.require.extensions.(anonymous function) [as .ts] (/Users/mikecoxon/dev/ws-other/blog/node_modules/ts-node/src/index.ts:476:12)reThe tested service itself is a pretty stock-standard http service with nothing fancy in it. I'm fairly sure the problem isn't in there, rather it looks like my package dependencies (I think). I'm not sure how I ended up with a very new version of typescript, but I had to run the following commands to get everything to compile again:pre class=lang-sh prettyprint-overridecode$ npm i -g npm-check-updates$ npm install -g npm$ npm installreAnd finally downgrade typescript from 3.5.4 with:pre class=lang-sh prettyprint-overridecode$ npm i typescript@3.4.5 --save-dev --save-exactreand now codepackage.json looks like this: { name: blog, version: 0.0.0, scripts: { ng: ng, start: ng serve, build: ng build, test: ng test, lint: ng lint, e2e: ng e2e }, private: true, dependencies: { @angular/animations: ~8.1.1, @angular/common: ~8.1.1, @angular/compiler: ~8.1.1, @angular/core: ~8.1.1, @angular/forms: ~8.1.1, @angularlatform-browser: ~8.1.1, @angularlatform-browser-dynamic: ~8.1.1, @angular/router: ~8.1.1, ngx-markdown: ^8.1.0, ngx-markdown-editor: ^1.2.0, rxjs: ~6.5.2, tslib: ^1.10.0 }, devDependencies: { @angular-devkit/build-angular: ~0.801.1, @angular/cli: ~8.1.1, @angular/compiler-cli: ~8.1.1, @angular/language-service: ~8.1.1, @types/jasmine: ~3.3.13, @types/jasminewd2: ~2.0.6, @types/node: ~12.6.2, codelyzer: ^5.1.0, jasmine-core: ~3.4.0, jasmine-spec-reporter: ~4.2.1, karma: ~4.2.0, karma-chrome-launcher: ~3.0.0, karma-coverage-istanbul-reporter: ~2.0.5, karma-jasmine: ~2.0.1, karma-jasmine-html-reporter: ^1.4.2, protractor: ~5.4.2, ts-node: ~8.3.0, tslint: ~5.18.0, typescript: 3.5.3, zone.js: ^0.9.1 }}reI put the tested service and app.component.ts in codepens fro reference:a href=https:en.io/mikecoxonen/jjoyPm rel=nofollow noreferrerapp.component.ts/a, a href=https:en.io/mikecoxonen/wLbgMz rel=nofollow noreferrerpost.service.ts/a.So does anyone know why this is happening? In fact what does codeFailed: Can't resolve all parameters for ApplicationModule: (?). mean exactly?UPDATE:I have completely rebuilt the project from scratch using Angular 8.1 cli, and the issue remains. It seems clear to me that the problem is coming out of the test somewhere, because the rest of the project works as in the routing, the services, the components etc.I'm going to start stripping down the test to see where it breaks.UPDATE 2:OK, so even on the following minimal test, it breaks with the same error:pre class=lang-js prettyprint-overridecodeimport { TestBed } from '@angular/core/testing';import { PostContentService } from '.ost.content.service';import {BrowserDynamicTestingModule, platformBrowserDynamicTesting} from '@angularlatform-browser-dynamic/testing';import {AppComponent} from '../app.component';describe('PostContentService', () =   { beforeEach(() =   { TestBed.resetTestEnvironment(); TestBed.initTestEnvironment(BrowserDynamicTestingModule, platformBrowserDynamicTesting()); TestBed.configureTestingModule({ declarations: [ AppComponent ], }); }); it('should be created', () =   { const service: PostContentService = TestBed.get(PostContentService); expect(service).toBeTruthy(); });});reSo I'm thinking now that there's some basic issue with Angular 8 and jasmine testing, perhaps there's a circular dependency somewhere, or some other reason that we get this rather inscrutable error. I'd be very interested to know if others are getting this error. My next move is to try all of this with Jest, and see if I get any further.",Not-TD-related,Other,,,,0.029,0.906,0.065,0.9593
57260348,Is it possible to run an On premise SonarQube Server on azure devops deploy pipeline?,"I'm deploying my application to an on promise IIS server and I would like to run a sonarQube Analytics at the same time, using a self-hosted agent, but the sonarQube server is in another server. I was thinking to run a command using cmd to start the analytics, but I'm not sure how to do this because sonarQube is in another server.",Not-TD-related,Other,,,,0.041,0.902,0.057,-0.0111
57775109,Filter one table based on collection of values and one-to-many relation,"I have Web Application where allow to filter codePerson by collection of codeName. This should return all codePerson whose codeNames have all sended values (extended when: for all codevalue in codevalues exists one codeName which contain that codevalue)Model was defined as two tables: codePerson and codeName (and matching C classes) (other columnsroperties omitted for clarity): CREATE TABLE [dbo].[Person]( [Id] [int] IDENTITY(1,1) NOT NULL, CONSTRAINT [PK_Person] PRIMARY KEY CLUSTERED ( [Id] ASC ))CREATE TABLE [dbo].[Name]( [Id] [int] IDENTITY(1,1) NOT NULL, [PersonId] [int] NOT NULL, [Name] [nvarchar](max) NULL, CONSTRAINT [PK_Name] PRIMARY KEY CLUSTERED ( [Id] ASC ), CONSTRAINT [FK_Name_Person] FOREIGN KEY([PersonId]) REFERENCES [dbo].[Person]([Id]) ON DELETE CASCADE)reI wrote simple EF Core query // basic_context.Set  Person  ().Where(p =   values.All(value =   p.Names.Contains(value))); // extended_context.Set  Person  ().Where(p =   values.All(value =   p.Names.Any(n =   n.Contains(value)))); rebut none of them were translated to SQL and filtering were performed in memory. So I try to write SQL query (and maybe translate it back if possible), but I cannot find out how to do it correctly.One of idea was: select * from Personwhere Id in ( select distinct PersonId from PersonName where CHARINDEX('value1', Name, 0)    0)andId in ( select distinct PersonId from PersonName where CHARINDEX('value2', Name, 0)    0)re(and add new codein clause for each codevalue in codevalues)but isn't it inefficient?I also read a href=https://blog.marcgravell.com/2014/04/technical-debt-case-study-tags.html rel=nofollow noreferrerhttps://blog.marcgravell.com/2014/04/technical-debt-case-study-tags.html/a as study case, but firstly I want to achieve it without changing model------------------------- SAMPLE DATA -------------------------  Person Name------ ---------------------------| Id | | Id | PersonId | Name |------ ---------------------------| 1 | | 1 | 1 | James |------ ---------------------------| 2 | | 2 | 1 | Jacob |------ ---------------------------| 3 | | 3 | 2 | Jacob |------ --------------------------- | 4 | 2 | Michael | --------------------------- | 5 | 3 | Mike | ---------------------------re // basic (exact matching)-------------------| Input | Result |-------------------| Jacob | 1, 2 | Both 1 and 2 has Jacob in Name-------------------| Mike | 3 | Only 3 has Mike in Name-------------------// extended (any contains)-------------------| Input | Result |-------------------| j, m | 1, 2 | 1: james (both j and m), 2: jacob, michael -------------------| m | 1, 2, 3 | All persons have name containing m-------------------| mi | 2, 3 | 2: michael, 3: mike-------------------re",Not-TD-related,Other,,,,0,0.977,0.023,0.5671
57836964,How to convert Django source installation to package like installation,"OS : CentOS, RedhatNew to Django and python, we basically built a monitoring tool using python and Django framework. Below is the project folder structure. |-- Makefile|-- monitor-pycodes`-- web |-- content |-- __init__.py |-- manage.py |-- monitor_templ | |-- __init__.py | |-- templates | |-- templatetags | |-- urls.py | `-- views.py |-- packmonitor.wsgi |-- settings.py `-- urls.pyreDidnt mentioned the certain folders content to simplify the view.We used Makefile to copy our codes to system folders as belowAll python codes in monitor-pycodes -- /usrbython2.7/site-packagesackmonitor/ and compile itDjango templates in web -- /var/wwwackmonitor for web UI.scritps such as packmontior   packmonitord to -- /usr/binWhen run make install inside the project directory, above copying process take place and application started.My employer doesnt want this tool to be install from source.How to convert this install from source to package installation ?Thanks,Mohan",Not-TD-related,Other,,,,0.009,0.975,0.016,0.2211
57944583,Google App Engine Modular Project Structure,"There is much talk about the microservices architecture in Google App Engine. In fact, the documentation seems to compel the developer to lean towards building apps in microservices. The perspective of a project seems to be either a 'monolithic' mess or a well-organised microservices project. However, it is a href=http://www.ptone.com/dablog/2015/07/microservices-may-be-the-new-premature-optimization/ rel=nofollow noreferrerdebatable/a that perhaps microservices is not the suitable approach during early phases of a project.With this said, is there a recommended approach to project structure for building a AE project in a modular way? Assuming that we would want to organise our project to consist of the following characteristics:ulliA service is organised as a moduleliModules can easily access shared resources (datastore, task queue, memcache)liModules provide their own APIliModules can be testableliModules conform to the session / authentication servicesMy assumed solution is the following: project/ app.yaml main.py requirements.txt libs/ module1/ datastore/ endpoints/ tests/ module2/ datastore/ endpoints/ tests/ module3/ datastore/ endpoints/ tests/ auth_module/ tests/ endpoints/ sessions_module/ tests/ endpoints/ datastore_module/ tests/ endpoints/ taskqueue_module/ tests/ endpoints/re",Not-TD-related,Other,,,,0.016,0.92,0.064,0.6908
58312166,How to include current row in PARTITION BY of Postgresql's window function,"I'm trying to do the following; let's say I want to partition a table in two partition given a set condition: SELECT userid, ARRAY_AGG(userid) OVER ( PARTITION BY userid    100 ) arr, AVG(userid) OVER ( PARTITION BY userid    100 ) avgFROM users;reI'll get this:  userid | arr | avg --------+-----------------------------------------------------------+---------------------- 46 | {46,23,69,92} | 57.5000000000000000 23 | {46,23,69,92} | 57.5000000000000000 69 | {46,23,69,92} | 57.5000000000000000 92 | {46,23,69,92} | 57.5000000000000000 552 | {552,506,575,621,644,667,690,759,713,782,828,460,483,529} | 629.2142857142857143 ... | ... | ... 529 | {552,506,575,621,644,667,690,759,713,782,828,460,483,529} | 629.2142857142857143reAll good, but what if instead, for the userids    100, I wanted to include each userid with the ones 100: SELECT userid, CASE WHEN userid    100 THEN ARRAY_AGG(userid) OVER ( PARTITION BY userid    100 ) ELSE ARRAY_AGG(userid) OVER ( PARTITION BY userid -- OR userid    100 -- PARTITION BY userid    100 OR CURRENT_ROW -- PARTITION BY userid    100 OR userid = LAG(userid, 0) OVER () ) END arr CASE WHEN userid    100 THEN AVG(userid) OVER ( PARTITION BY userid    100 ) ELSE AVG(userid) OVER ( PARTITION BY userid -- OR userid    100 -- PARTITION BY userid    100 OR CURRENT_ROW -- PARTITION BY userid    100 OR userid = LAG(userid, 0) OVER () ) END avgFROM users;reAll the commented code above is the various tries I've been doing.The best I've got is either just the userid without the ones 100 or all userids:  userid | arr | avg --------+-----------------------------------------------------------+---------------------- 23 | {23} | 23.0000000000000000 46 | {46} | 46.0000000000000000 69 | {69} | 69.0000000000000000 92 | {92} | 92.0000000000000000 552 | {552,506,575,621,644,667,690,759,713,782,828,460,483,529} | 629.2142857142857143 ... | ... | ... 529 | {552,506,575,621,644,667,690,759,713,782,828,460,483,529} | 629.2142857142857143reIs there any way to do what I'm looking for? I'm also trying not to use CTE as much as possible, because the actual code as so much technical debt that it will takes a pretty lengthy time to just adapt it with a WITH.To be clear, here is the expected result:  userid | arr | avg--------+--------------------------------------------------------------|---------------------- 23 | {23,552,506,575,621,644,667,690,759,713,782,828,460,483,529} | 588.6000000000000000 46 | {46,552,506,575,621,644,667,690,759,713,782,828,460,483,529} | 590.1333333333333334 69 | {69,552,506,575,621,644,667,690,759,713,782,828,460,483,529} | 591.6666666666666667 92 | {92,552,506,575,621,644,667,690,759,713,782,828,460,483,529} | 593.2000000000000000 552 | {552,506,575,621,644,667,690,759,713,782,828,460,483,529} | 629.2142857142857143 ... | ... | ... 529 | {552,506,575,621,644,667,690,759,713,782,828,460,483,529} | 629.2142857142857143reHere's the reference for potential future stuff that I've been looking at: a href=https://sqlperformance.com/2019/07/sql-performance/nested-window-functions-in-sql rel=nofollow noreferrernested window functions/a (but isn't implemented at the moment, as of Postgresql-11)EDIT: Last but not least, the condition is a placeholder! it may or may not be tied to userids, it is just used here for the sake of the example, it could have been CUME_DIST() OVER ( PARTITION BY x -- OR CURRENT_USERID)re",Not-TD-related,Other,,,,0.01,0.944,0.046,0.9224
58329279,Dynamically generate a select based on another select,"I am trying to generate a list of options in a select dynamically based on the selection in another select by referencing a value in an array of objects.   select id=radar     option value=15  City1  /option     option value=64  City2  /option    /select    select id=beam    /select  reObjects: var radars = { city1: { name: city1, maxBeams: 16 }, city2: { name: city2, maxBeams: 3 }}reWhen a radar option is selected for example City2, I would like to fill the beam select with an option for as many maxBeams that have thee option value and text to simply be that index number:   select id=beam     option value=1  1   /option     option value=2  2  /option     option value=3  3  /option    /select  reWhat is the simplest way to accomplish this and make it easy to update?",Not-TD-related,Other,,,,0,0.863,0.137,0.93
58651017,Should I use numpy.polyfit or numpy.polynomial.polyfit or numpy.polynomial.polynomial.Polynomial?,"What is the difference betweenhttps://docs.scipy.org/doc/numpy/reference/generated/numpy.polyfit.htmlandhttps://docs.scipy.org/doc/numpy/reference/generated/numpy.polynomial.polynomial.polyfit.htmland which one should I use when?I checked the code and however both use numpy.linalg.linalg.lstsq at their code, but are different otherwise.The documentation of numpy.polyfit also suggests to usehttps://docs.scipy.org/doc/numpy/reference/generated/numpy.polynomial.polynomial.Polynomial.fit.htmlWhat is the right choice?(Bonus: How would I use the class when the first thing I want to do is to fit to my data?)",Not-TD-related,Other,,,,0,0.92,0.08,0.6416
58704271,Why my contact form getting browser alert,"actually facing some problems with my php contact form. problem Number 1: After submit the contact form if the user reload the browser they get an message from browser alertConfirm Form ResubmissionThe page that you're looking for used information that you entered. Returning to that page might cause any action you took to be repeated. Do you want to continue?Continue button and Cancel buttonProblem Number 2: after submit the form i'm getting mails on my mailbox but i'm getting it via hostinguser@webserver.com so is that any problem?here is my all code please make me currect if i'm doing wrong or something like that. thanks<head><title>Form submission</title></head><body><form method=""post"">First Name: <input type=""text"" name=""client_name""><br>Last Name: <input type=""text"" name=""client_phone""><br>Email: <input type=""text"" name=""email""><br>Message:<br><textarea rows=""5"" name=""message"" cols=""30""></textarea><br><input type=""submit"" name=""submit"" value=""Submit""></form><?php if(isset($_POST['submit'])){$to = ""mailmenow23@gmail.com""; // this is your Email address$from = $_POST['email']; // this is the sender's Email address$client_name = $_POST['client_name'];$client_phone = $_POST['client_phone'];$subject = ""Form Submission by""."" "" $client_name ;$message = ""Client Name : "". $client_name .""\n\n"". ""Client Phone : "" . $client_phone .""\n\n""."" wrote the following:"" . ""\n\n"" . $_POST['message'];$headers = ""From:"" . $from;mail($to,$subject,$message,$headers);echo ""Mail Sent. Thank you "" . $client_name . "", we will contact you shortly."";}?></body></html>```",Not-TD-related,Other,,,,0.067,0.846,0.087,0.5514
58954054,Scrum Board: Confusion with Product Backlog Item Column,"I am doing an assignment on Scrum. But I am not sure whether my scrum board is correct or not. Here is my scrum table during the first week of sprint:enter image description hereHere is my scrum table during the second and final week of sprint: enter image description hereAt the end of the second week, all of my tasks are finished. That's why, there's no item in ""To Do"" and ""In Progress"" column.Now here is the confusing part. Do I have to move all the items from the column entitled Product Backlog Item? Or they will stay just like they are now in the table? I mean, am I supposed to move the things of Product Backlog Items column to Done column?",Not-TD-related,Other,,,,0.057,0.867,0.076,0.5495
34304174,MSBuild Sonar Runner - FxCop issues are not shown in sonarqube dashboard,"I'm using SonarQube v5.0 with MS Build Sonar Runner, C plugin v4.3 and OpenCover for Code Coverage.I have two QualityProfiles. 1. With only SonarQube rules. 2. With only FxCop rules.Using SonarQube rules QualityProfile, everything works fine. Issues are get posted in the dashboard. But when I use FxCop rules only QualityProfile, no issues are get posted in dashboard.It shows Technical Debt - 0 and Issues- 0.I have referred toa href=https://stackoverflow.com/questions/33239912/msbuildsonar-runner-fxcop-no-fxcop-issues-are-posted-to-server-sonardashboardMsbuildSonar Runner +Fxcop - No fxcop issues are posted to server.SonarDashBoard shows 0 technical debt/awhere this user faced same issue. But after changing his database Collation with CS_AS, his issue got resolved.But this is not happened for me. Even after recreating my database with Collation CS_AS (Latin1_General_CS_AS), FxCop issues are not get posted in Dashboard.NOTE: I can see the CodeAnalsisLog.xml in output directory having 163 warnings.Also in ProjectInfo.xml, there is an entry for AnalysisResult with ID - FxCop.Don't have any idea that why FxCop rules are not get posted in dashboard.",Not-TD-related,Other ,,,,0.056,0.935,0.009,-0.8151
5880,Are there any negative reasons to use an N-Tier solution?,"I'm pretty new to my company (2 weeks) and we're starting a new platform for our system using .NET 3.5 Team Foundation from DotNetNuke. Our architect is suggesting we use one class project. Of course, I chime back with a 3-tier architecture (Business, Data, Web class projects). Is there any disadvantages to using this architecture? Pro's would be separation of code from data, keeping class objects away from your code, etc.",TD-related,requirements,pattern,1,71,0.038,0.918,0.045,0.128
55421,Do you actively manage technical debt?,"Do you actively manage a technical debt on your software development projects and if so, how do you do it?",TD-related,requirements,management,1,20,0.115,0.78,0.106,-0.0516
60888,"How do you avoid Technical Debt while still keep true to Agile, i.e.: avoiding violation of YAGNI and avoiding BDUF?","Technical Debt a href=http://www.martinfowler.com/bliki/TechnicalDebt.html rel=noreferrervia Martin Fowler/a, a href=http://forums.construx.com/blogs/stevemcc/archive/2007/11/01/technical-debt-2.aspx rel=noreferrervia Steve McConnell/aYAGNI (You Ain't Gonna Need It) a href=http://en.wikipedia.org/wiki/You_Ain%27t_Gonna_Need_It rel=noreferrervia Wikipedia/aBDUF (Big Design Up Front) a href=http://en.wikipedia.org/wiki/BDUF rel=noreferrervia Wikipedia/aUPDATE: To clarify the question, I think I can also state it this way and keep my meaning:emIn what ways do you, as an Agile practioner, find the right balance between quick and dirty (unintentionally risking Technical Debt while attempting to adhere to YAGNI) and over-engineering (BDUF) within each iteration?/em",TD-related,requirements,"management, software_methodology",2,78,0.13,0.87,0,-0.8481
167904,How do you stop interim solutions from lasting forever?,"Say there are two possible solutions to a problem: the first is quick but hacky; the second is preferable but would take longer to implement. You need to solve the problem fast, so you decide to get the hack in place as quickly as you can, planning to start work on the better solution afterwards. The trouble is, as soon as the problem is alleviated, it plummets down the to-do list. You're still planning to put in the better solution at some point, but it's hard to justify implementing it right now. Suddenly you find you've spent five years using the less-than-perfect solution, cursing it the while.Does this sound familiar? I know it's happened more than once where I work. One colleague describes deliberately making a bad GUI so that it wouldn't be accidentally adopted long-term. Do you have a better strategy?",TD-related,requirements,"management, td_resolution, td_communication",3,142,0.112,0.727,0.16,0.7914
305579,How do you effectively track technical debt?,"In your practice, how do you effectively track and manage technical debt? Is there a specific metric, like a href=http://jamesshore.com/Blog/An-Approximate-Measure-of-Technical-Debt.html rel=nofollow noreferrerSLOC/a, that you use?How do you visually display your results to stakeholders and management? What benefits have you seen in the process?",TD-related,requirements,"td_documentation, management",2,43,0.052,0.764,0.185,0.755
310010,Are there specific technical debts that are not worth incurring?,"There are (at least) two ways that technical debts make their way into projects. The first is by conscious decision. Some problems just are not worth tackling up front, so they are consciously allowed to accumulate as technical debt. The second is by ignorance. The people working on the project don't know or don't realize that they are incurring a technical debt. This question deals with the second. Are there technical debts that you let into your project that would have been trivial to keep out (If I had only known...) but once they were embedded in the project, they became dramatically more costly?",TD-related,requirements,management,3,104,0.108,0.892,0,-0.7595
454732,How do you tell a client that their project or a portion of needs a rewrite?,"I'm at the point with a project that most of it needs a rewrite, specifically one portion needs it very badly for a number of reasons:ulliit's no longer being used for it's original purposelithe code has been hacked so badly it's very hard to work withlithe changes they want will hack it to pieceslithe original design wasn't the greatest as we were trying a new techniqueThe unfortunate part is the piece of code that has been hacked so badly is run every minute and as the site gets used more, the longer it's taking.How do you tell your client that you need to take the time to think it through and rewrite it?",TD-related,requirements,"management, td_resolution, td_communication",4,113,0.2,0.742,0.058,-0.9605
498651,Goals of refactoring?,What are the goals of refactoring code? Is it only to enhance the code structure? Is it to pave the way for future changes?,TD-related,requirements,"management, td_resolution",1,24,0,1,0,0
532511,"How do you argue for the high notes, the true production class code?","This question has been addressed in a a href=https://stackoverflow.com/questions/362096/arguing-about-usability-and-prettynesssimilar post/a on a more specific level regarding UI.I would like to address the subject on a more general design level. I make descisions on design every day to ensure high quality. But every now and then I get into dicsussions with middle management and unexperienced developers about the gain of doing things the right way.Sometimes I just say trust me, I've seen where this leads to, we're doing it the other way, sometimes I make an attempt lay down a scenario where a particular set of choices introduce problems etc. Most of the time I feel I'm not reaching the person I'm talking to. I might as well have said trust me.I feel that one of my capabilities as a senior software guy should be to explain and motivate the technical choices we make as a company. I can do that on economical and user experience level.But I seem to fail to explain on technical and pseudo-technical levels why some design choices feels wrong and why others just feels more correct and benefitial, even though at first it might be harder to implement or seem unnecessarily complex.Luckily, I occasionally show good results, otherwise I probably would begin to doubt the whole concept of good vs. bad design.I would really find it interesting to read about what others here have to say about this.Thanks in advance!",TD-related,requirements,"management, td_resolution, td_communication",2,234,0.087,0.78,0.133,0.8971
600215,How to convince a manager to let you pay down technical debt?,"While the most recent a href=http://www.codinghorror.com/blog/archives/001230.html rel=noreferrerCoding Horror blog entry/a is not the first time I had heard of the concept, as I was reading it I couldn't help but apply the it in my mind to my own project. The code base I'm working on is an ongoing project at about the 3 year mark now, and large portions of the code in the early stages of the project were written by developers who were sub par with little oversight which lead to a lot of code duplication, poor performance, etc. In discussions with management I've tried to make the case that there are several key components that are dying to be refactored and doing so would save a lot of time and headaches in future iterations when adding new features and fixing bugs in these key areas. While they seem to trust me that refactoring these components would be nice, they don't want to give me the leeway to do it. Note that I'm not talking about a rewrite of the entire code base or anything dramatic, just a rewrite of a few core areas that would take on the order of 2-3 weeks.The questions then, is how to you as a developer sell to your manager that these areas need addressed and make a business case to get the time to address them now, rather than having to just incrementally improve here and there?",TD-related,requirements,"management, td_resolution, td_communication",2,237,0.039,0.892,0.069,0.8822
903573,Is too much focus on testing benefits a bad thing overall?,"What I mean by this, is that sometimes architects look to simplify and improve testability, at the expense of other important forces. For example, I'm reviewing a very complicated application, made so by extensive use of design patterns that overly favor testing, e.g. IoC, DI, AOP, etc...brNow, typically I like these things, but this system should have been much simpler - though not just a simple web frontend for CRUD on a db, it still not MUCH more complicated than that (even considering some internal workflows, processes, etc). On the other hand, just reviewing the code becomes a major pain in the heinie, barely readable (even though its well written), and coding it must have been a pain. The implemented complexity is a clear violator of KISS (the principle, NOT the band)... and the only benefit is improved testability, using testing frameworks and mocks and and... Now, before you TDD fans jump me, I'm not belittling the importance of testability, but I'm questioning the supremacy of consideration of this specific force (against all the others).brOr did I miss something?hrI'd like to add another point - it does seem to me that all this talk of testability is with regards specifically to unit testing, which differs from overall system testing, and can result in missed tests when the individual units are integrated together. At least, that seems the point of the IoC/DI for testing...brAlso, I'd point out that this system (and others I've seen preached) only have a single concrete object per interface, and the IoC/DI is only intended for - you guessed it - replacing the concrete objects with testing mockups for testing only. hrI felt the need to add this  e from a href=http://en.wikipedia.org/wiki/Inversion_of_ControlAdvantages_and_disadvantages_of_inversion_of_control rel=nofollow noreferrerWikipedia on IoC/a:block e Whereas the danger in procedural programming was to end with spaghetti code, the danger when using Inversion of Control is ending with macaroni code/block eYup, that expresses my feeling exactly :D",TD-related,requirements,"management, software_methodology",3,321,0.1,0.783,0.118,0.5321
971863,When do you refactor code?,"Do you do it when youre in the code doing something else?When your manager approves it? (Seems this never happens)I guess some of this depends on the impact of the changes. If I change the code and it affects nothing outside of the class, to me that is low impact.What does it become a design change? When it effect X object or X projects?Im just curious how others teams tackle this...",TD-related,requirements,"management, td_resolution, td_communication",3,71,0.029,0.888,0.083,0.594
1741578,what is the best way to visualize technical investment for the business,"we have a number of functional deliverable planned for 2010 but we also have a technology agenda (architectural refactorings, consolidation, upgrade a platform). any suggestions on the best way to include these in a roadmap to help the business understand why they are important.one option is just saying trust us as this is the right thing to do to keep everything healthy but i would like some better visualization if possible",TD-related,requirements,"td_documentation, td_communication, logging",3,71,0,0.697,0.303,0.979
1790431,How do you estimate a ROI for clearing technical debt?,"I'm currently working with a fairly old product that's been saddled with a lot of technical debt from poor programmers and poor development practices in the past. We are starting to get better and the creation of technical debt has slowed considerably.I've identified the areas of the application that are in bad shape and I can estimate the cost of fixing those areas, but I'm having a hard time estimating the return on investment (ROI). The code will be easier to maintain and will be easier to extend in the future but how can I go about putting a dollar figure on these? A good place to start looks like going back into our bug tracking system and estimating costs based on bugs and features relating to these bad areas. But that seems time consuming and may not be the best predictor of value.Has anyone performed such an analysis in the past and have any advice for me?",TD-related,requirements,"management, logging, td_documentation",4,158,0.119,0.768,0.113,0.1675
1815245,TDD with unclear requirements,"I know that TDD helps a lot and I like this method of development when you first create a test and then implement the functionality. It is very clear and correct way.But due to some flavour of my projects it often happens that when I start to develop some module I know very little about what I want and how it will look at the end. The requirements appear as I develop, there may be 2 or 3 iterations when I delete all or part of the old code and write new.I see two problems:1. I want to see the result as soon as possible to understand are my ideas right or wrong. Unit tests slow down this process. So it often happens that I write unit tests after the code is finished what is known to be a bad pattern.2. If I first write the tests I need to rewrite not only the code twice or more times but also the tests. It takes much time.Could someone please tell me how can TDD be applied in such situation?Thanks in advance!",TD-related,requirements,"software_methodology, management",5,181,0.025,0.904,0.071,0.6155
1892510,Agile development and architecture,"How does a formal architecture specification fit in with agile development - if at all? I'm thinking specifically of Scrum, which makes no mention of an architecture amongst the official artifacts. Do you just let the architecture evolve accidentally (so to speak), do you spec it informally, or is there room for doing something like a 4+1 spec up front, before assembling your first product backlog?",TD-related,requirements,software_methodology,2,66,0.067,0.856,0.078,0.1926
2489722,How to make freelance clients understand the costs of developing and maintaining mature products?,"I have a freelance web application project where the client requests new features every two weeks or so. I am unable to anticipate the requirements of upcoming features. So when the client requests a new feature, one of several things may happen:olliI implement the feature with easebecause it is compatible with theexisting platformliI implement the feature withdifficulty because I have to rewritea significant portion of theplatform's foundationliClient withdraws request because itcosts too much to implement againstexisting platformAt the beginning of the project, for about six months, all feature requests fell under category 1) because the system was small and agile. But for the past six months, most feature implementation fell under category 2). The system is mature, forcing me to refactor and test everytime I want to add new modules. Additionally, I find myself breaking things that use to work, and fixing it (I don't get paid for this).The client is starting to express frustration at the time and cost for me to implement new features. To them, many of the feature requests are of the same scale as the features they requested six months ago. For example, a client would ask, If it took you 1 week to build a ticketing system last year, why does it take you 1 month to build an event registration system today? An event registration system is much simpler than a ticketing system. It should only take you 1 week! Because of this scenario, I fear feature requests will soon land in category 3). In fact, I'm already eating a lot of the cost myself because I volunteer many hours to support the project.The client is often shocked when I tell him honestly the time it takes to do something. The client always compares my estimates against the early months of a project. I don't think they're prepared for what it really costs to develop, maintain and support a mature web application.When working on a salary for a full time company, managers were more receptive of my estimates and even encouraged me to pad my numbers to prepare for the unexpected. Is there a way to condition my clients to think the same way?Can anyone offer advice on how I can continue to work on this web project without eating too much of the cost myself?Additional info - I've only been freelancing full time for 1 year. I don't yet have the high end clients, but I'm slowly getting there. I'm getting better quality clients as time goes by.",TD-related,requirements,"software_methodology, td_communication",5,416,0.032,0.891,0.077,0.9523
2778772,Consistency vs Design Guidelines,"Lets say that you get involved in the development of a large project that is already in development for a long period ( more than one year ). The projects follows some of the current design guidelines, but also has a few different, that are currently discouraged ( mostly at naming guidelines ).Supposing that you can't/aren't allowed to change the whole project:What should be more important, consistency, follow the existing ones and defy current guidelines or the usage of the guidelines, creating differences between modules of the same project ? Thanks.",TD-related,requirements,"software_methodology, coding_standards",3,91,0.038,0.863,0.099,0.6946
4296362,What is worth spending time upfront when starting a new project,"Update:/Great answers so far everyone! Each one has been really helpful in getting to the root of the problem and helping to make sure both my partner and I are on the same page. I think a lot of it was that we hadn't talked about our actual intentions with release schedules and general work-flow.In doing this I have come to a number of related questions that I never thought about addressing and might make more posts later on (likely over in a href=https://softwareengineering.stackexchange.comrogrammers-stack-exchange/a)hrBackstory:/I'm working on web-app with a college friend of mine. We are developing our site using MySQL and PHP, and plan on using some jQuery for the front end. We are targeting cellphones and tablet-pc. It will eventually involve a lot of crowd-sourced data. I'd rather not say much about the specific project ideas. (Please comment on this if you think I should give more specifics.)We have a prototype, and have some GUI mock-ups. Our idea both scratches an itch, and seems to be something never attempted before.Our Issue:/We hope to follow principles from 37signals's book REWORK. A big part of the book is the idea of getting a product out early. It discusses why we should focus on the core of our product and that we should ignore all the extra stuff. Basically the idea of doing the minimal possible for a sellable product so we can ship and start getting feedback. We both have different views on what this means, and it is pulling us in different directions.I think the book is only talking about minimal features, but he feels it is about code design too. I think that some things are worth doing now to speed things up but he wants us to rush as fast as we can and skip those issues completely.I want to do some prep work because of the amount of time savings it would lead to later on. Like starting out with OO, Designing a thorough database schema, and spending time setting up stuff like a href=http://xcss.antpaw.org/ rel=nofollow noreferrerxCSS/a, and breaking down our problem into individual steps.[The way I understood him:] He wants to rush even emif it means writing horrible/sloppy code/em as long as it gets the design out the door. He doesn't want to get stuck spending time on basic code infrastructure or refactoring as we go or DRY principles. He doesn't want to spend the time to decide what needs to get done, he just wants to do it. He thinks that committing small changes to svn is just overhead, for example. I understand that he doesn't want us to get sucked into wasting time making a perfect system, but emI think this is going way too far, and isn't what 37signals is advocating./emIt's essentially a tortoise vs hare problem and I don't know how to explain to him that he will be shooting himself in the foot if he doesn't at least do some simple time saving code design choices, and break the problem down and work on it in small discrete chunks.He is a good developer otherwise, and is capable of doing it well.My Questions:liHow much prep is too much, how little is too little?liWhat high-payoff things should we be focusing on at the start of our project? liHow should we judge what is worth working on, code wise (not features), at this stage of development?liIs it worth spending the time implementing things like xCSS and other systems that would make it easier to write clean code from the start?liHow would you explain to him the value of fine-grain tasks and committing small atomic changes.liWhat things have you done with your code that havelead to a sooner ship time? Best Answers:/I will accept the answer that changes his/my mind the best. Feel free to answer any question I've listed, and bonus points for examples in our targeted languages. References to other 37signals' work might be helpful.",TD-related,requirements,"software_methodology, management",4,652,0.034,0.835,0.131,0.9963
4405132,"Which is more important: writing the code right, or writing the right code?","When we write code which helps the business, we create value for them, often in the form of profit, market share, etc.If we write the wrong code, we won't generate this value. We might generate some of it, but we'll be missing out on those big wins.a href=https://web.archive.org/web/1/http://blogs.techrepublic%2ecom%2ecom/hiner/?p=615 rel=nofollowA recent survey/a suggested that writing the right code - aligned to what the business want - may be less useful than writing the code right; oiling IT to produce anything, even if it's not well-aligned, to a higher quality.I've experienced projects which were technically amazing and never made it to production, projects which were buggy on release but helped the business to redefine their strategy, and everything between and vice-versa. What are your experiences, what balance would you recommend and why?",TD-related,requirements,management,2,130,0.034,0.8,0.167,0.9444
5522017,How to go about a large refactoring project?,"I am about to start planning a major refactoring of our codebase, and I would like to get some opinions and answers to some questions (I have seen quite a few discussions on similar topics, such as a href=https://stackoverflow.com/questions/108141/how-do-i-work-effectively-with-very-messy-legacy-codehttps://stackoverflow.com/questions/108141/how-do-i-work-effectively-with-very-messy-legacy-code/a, a href=https://stackoverflow.com/questions/330220/strategy-for-large-scale-refactoringStrategy for large scale refactoring/a, but I have some specific questions (at the bottom):We develop a complex application. There are some 25 developers working the codebase. Total man years put into the product to date are roughly 150.The current codebase is a single project, built with ant. The high level goal of the project I'm embarking on is to modularize the codebase into its various infrastructures and applicative components.There is currently no good separation between the various logical components, so it's clear that any modularization effort will need to include some API definitions and serious untangling to enable the separation.Quality standards are low - there are almost no tests, and definitely no tests running as part of the build process.Another very important point is that this project needs to take place in parallel to active product development and versions being shipped to customers.Goals of project:ulliallow reuse of components across different projectsliseparate application from infrastructure, and allow them to evolve independentlyliimprove testability (by creating APIs)lisimplify developers' dev env (less code checked out and compiled)My thoughts and questions:olliWhat are your thoughts regarding the project's goals? Anything you would change?lido you have experience with such projects? What would some recommendations?liI'm very concerned with the lack of tests - hence lack of control for me to know that the refactoring process is not breaking anything as i go. This is a catch 22, because one of the goals of this project is to make our code more testable...liI was very influenced by Michael Feathers' a href=https://rads.stackoverflow.com/amzn/click/com/0131177052 rel=noreferrer rel=nofollow noreferrerWorking Effectively With Legacy Code/a . According to it, a bottom up approach is the way to solve my problem - don't jump head first into the codebase and try to fix it, but rather start small by adding unit tests around new code for several months, and see how the code (and team) become much better, to an extent where abstractions will emerge, APIs will surface, etc, and essentially - the modularization will start happening by itself.Does anyone have experience with such a direction?As seen in many other questions on this topic - the main problem here is managerial disbelief. how is testing class by class (and spending a lot of time doing so) gonna bring us to a stable system? It's a nice theory which doesn't work in real life. Any tips on selling this?",TD-related,requirements,"td_resolution, management, software_methodology",4,431,0.056,0.852,0.092,0.9529
6280239,Understanding the scope of refactoring,"I've always thought of code refactoring as only improving implementation details. I want to make sure I have the appropriate understanding of the scope to which refactoring applies (Wikipedia didn't help me much to understand this).For example, I hear people talking about refactoring their designs, which seems paradox. When you modify the design of something (rename a public method in a class, remove a method, or other similar changes) this (to me) is called redesign, not refactoring.What is the common accepted scope of refactoring? Is it really possible to refactor designs? Knowing this will really help communication with co-workers when I'm trying to describe work I'm doing as refactoring or not.",TD-related,requirements,"software_methodology, td_communication, td_resolution",1,111,0.052,0.869,0.079,0.4486
8235551,Continuous Integration Strategy - Project Ref's vs Branching/Merging,"Say you have 7 core projects in a legacy code base (a enterprise API). The code base has roughly 50 applications that reference one or more of the core projects. Only a couple of the 50 applications still work after a vss to tfs migration that was manually don went pear shaped. To get the applications working again many have been taken out of the enterprise API and placed into there own TFS Project.I am trying to persuade colleagues that they should not make a branch of the core projects and put the copy in separate TFS Projects and only merge additions to the core project back into the enterprise API after a release to PROD. Obviously Continous Integration will be much harder when its less frequent.I am trying to convince colleagues it would be better to take the core projects out of enterprise API and put them in their own TFS Project and then referencing the bin/Debug.
Is it better to Branch, copy the branch(s) to seperate TFS Projects then Merge (and see conflicts at the end) or is it better to encapsulate core projects and force a team of 20 to use only one copy of each of the core projects?",TD-related,requirements,"legacy, management, td_communication",3,202,0.013,0.935,0.052,0.7964
16790004,Should a 'Refactoring' Product Backlog Item count towards velocity?,"I have seen this problem approached in several ways by different teams.1) Technical debt items (like refactoring) are added to the product backlog as stories, with the user type as 'developer', and business value expressed as direct costs or ROI.This has the advantage of making the technical debt items (and their business value/reason for existence) visible to everyone, including the customer. It also makes the velocity including necessary technical work be accounted for and visible.However, they may be too technical for everyone to understand and may waste time for explaining and negotiating these items. The business value may not be apparent or explainable to everyone, especially those who are feature-focused.2) Reserve one 'special' sprint for technical debt issues.These are tracked on a technical backlog that is completely separate from the product backlog. This eliminates the need for the team to make the case for them, to push for technical debt items to be added into a business-value based backlog, or for these issues to be forced into user story form.Disadvantages: there are some in the community who are against any kind of special iteration. It also requires the customer (and everyone) to accept the productivity hit of a 'dark' iteration, in which no visible progress (and velocity) is made.3) Roll up the time necessary for technical debt into the stories.This allows the team to only commit to those items that can be completed without incurring technical debt. Story points and velocity will thus include things like refactoring.The big disadvantage I see to this is that it implies that stories should be completed without technical debt...which seems to violate the principle of only doing enough to complete an item.",TD-related,requirements,"software_methodology, management",2,278,0.106,0.831,0.063,-0.9156
18618954,sql triggers and technical debt,"My boss asked me to create a easier system for finding points by having points associated with the user table in our mysql database. The old system just had events, there point values, then another table with events completed for a user, and then another table for just admin given points. So my job was to add these all together and put them in a column. Now he says the problem is that there is still all the queries running around adding points, but instead of changing them to simply add points to the users column upon task completion, they suggested i use a trigger to simply add points to the users column, when one of the other columns has points added to it.To me this sounds like using a work-around and creating technical debt. Am i wrong? Im new to the system, and i dont know exactly where all the queries are in the php pages, but if this is creating technical debt, what would be the appropriate way to fix this.Im new and am probably going to just use sql triggers as to not go against my boss's suggestions, I want to at least know the smart/best way to do things.Doing my best to provide not actual, but near actual db schemaEVENT: ID, point value, DescUser-Events: USERID, EVENTID, COMPLETION-STATUSGIVEN-POINTS:USERID, POINTS_GIVEN, DESC (Each time points are given, so its more of a log than updated points)I added a Points column to the basic USER TABLEthe trigger would be when user-Event completion-status =done, find point value, add to points in user, instead of changing queries to do that.",TD-related,requirements,"td_communication, td_resolution, database",3,268,0.044,0.858,0.097,0.9201
24682027,Refactoring Code To Psr standard and making the code testable in Laravel 4,"When i started making a mobile app (that uses laravel on the server) i decided to not dig into testing or coding standards as i thought it was better to actually get a working app first.A few months later i have a working app but my code doesn't follow any standards and nor have i written any tests. Current directory structure i'm using is: img src=https://i.stack.imgur.com/CV1Df.png alt=enter image description hereapp/controllers : Contains all the controllers the app uses. The controllers aren't exactly thin, they contain most of the logic and some of them even have multiple conditional statements (if/else). All the database interactions occur in the controllers.app/models : Define relationships with other models and contain certain functions relative to the particular model eg. A validate function.appbraries : contain custom helper functions. app/database : contains the migrations and seeds.My app is currently working and the reason for the slack is probably because i work alone on the app. My concerns:olliShould i go ahead and release the app and then see if its even worthmaking the effort to refactor or should i first refactor.liI do wish to refactor the code but i'm unsure on as to what approachi should take. Should i first get the standards right and then makemy code testable? Or should i not worry about standards( andcontinue using classmap to autoload) and just try and make my codetestable?liHow should i structure my files?liWhere should i place interfaces,abstract classes etc? Note: I am digging into testing and coding standards from whatever resources i can find, but if you guys could point me to some resource i would appreciate it.",TD-related,requirements,management,3,269,0.019,0.897,0.084,0.9525
27741583,How to best incorporate regression periods withint SCRUM agile approach?,"We are using Scrum framework in our project. However, the context is such that we cannot afford to release the product without massive regression testing. I know think what would be the best way to incorporate that into our Sprint. I can think of two options so far:olliDoing a regression after 5 sprints (sorta code freeze)liDedicate a sprint to regression   bug fixing.li...maybe something better?",TD-related,requirements,"software_methodology, management",3,64,0,0.889,0.111,0.7964
28772939,TFS 2013 Real world work item usage and workflow,"The team I manage has been using TFS for years, but we've used a 3rd party system for tracking bugs and features. I'm looking to upgrade our team into TFS 2013 and I've done tons of reading and research into how TFS manages work items, backlogs, iterations, tasks etc. And although I understand the principles of what 'can' be done, I'm having a hard time visualizing 'how' our team would work with these work items as tasks. If anyone knows of any best practice guides for actual sample based usage, or can answer any of these questions that'd be great1) Product backlog - Under the 'configure schedule and iterations' what is the concept for setting the current 'backlog iteration'? Our team uses short 2 week iterations with a build number, but setting the build iteration as the current backlog makes all new PBI's scoped to only that iteration. Any items not complete in that iteration would disappear once I set the current build to the next iteration number. On the other hand, if I set it to the parent root node, I could see the PBI list getting rather large over time. What is the best method for managing PBI's that are unassigned and working in a simple Parent-build1/build2 etc structure?2) Features - So I create a feature, perhaps it spans many work items and several tasks. They get completed over time, but I've noticed there's no 'auto' complete or status updates on parent items. So who/when is a Feature item supposed to get marked complete? If the product owner is supposed to use the features list to get an overview of work, they have no idea if all the dependent items have been complete and when to mark the feature Done.3) Work Items - Managing these, and in particular their 'state' or status seems like a royal pain. On the task board you can't change their state, only their tasks with drag-drop, which is nice. But you complete all the tasks, and the parent work item stays in status 'New'. Do you really have to micro-manage every work item, open it up, and set the state to Done?4) QA/testing - For every work item, each team member is responsible for testing each item, so every item is tested by multiple people, and logging any issues found. What's the best way to use work items or tasks for this? 5) Build Complete - Once every work item in the iteration is marked Done then I assume they are removed from the product backlog correct? The exception to this seems to be the features they were tied to, the feature item itself remains open. How do stakeholders view a list of features that were completed in the current build?",TD-related,requirements,"framework, outdated",3,458,0.029,0.882,0.088,0.985
35164334,SQALE SonarQube Rating,I'm using sonar to analyze a set of related projects. And I'm using SQALE Rating to justify the need for a refactoringMy question is what is the logic behind SQALE to Technical Debt ratio mapping?Why SQALE A rating is Tech Debt in range from 0% to 5%. But not 0% to 3% for instance?How should I define a SQALE rating limits?Why 5% Tech debt is good?Is there any methodology I can use?Or i have to come up with this standards by my own?And is there a way in SonarQube to change them?,TD-related,requirements,"td_documentation, metrics",2,92,0.087,0.913,0,-0.7724
35864712,View added or removed technical debt by developer or group of developers,"We are having a big team of developers which are working on multiple project in same code base, we want to see technical debt increased or decreased by each project team. I believe at present there are no such facility in sonar , do we have any such plugin or other way to achieve this.",TD-related,requirements,"software_methodology, td_documentation, td_resolution, metrics",3,55,0.084,0.856,0.061,-0.3182
35894899,"Should task, like refactoring needed be stored in product backlog?","In Scrum project, developers sometimes finish their work on product backlog item but they create also some kind of technical debt. Technical debt can be created because of some impediment at that time, or lack of time, sometimes also because of lack of knowledge.Now, when team member discovers technical debt, which should be fixed, what is the recommended way to track it? The work don't have necessarily be related to any particular feature. Should the team member just create new Product Backlog Item? Let's say there is enough trust bewteen the develoment team and product owner, so the is no reason to hide the technical debt from him.",TD-related,requirements,software_methodology,4,108,0.183,0.709,0.108,-0.8766
36542005,Difference between foo.bar and foo['bar'] in js,"I have to make sense of a codebase I was given on my new job. I can see many anti-patterns here, one of them is a god object, which contains a lot of things and different object access it all the time. That's a different problem, my question here is about the fact, that some objects access its members using '.', others do it via [], for example codeGOD.meow.woof() in one source file and codeGOD['meow'][woof]() in another. I know javascript deeply enough to realize that there is no difference whatsoever. Or is there? codegit blame shows me that both sources were written by the same person, so it has nothing to do with style. On the one hand, what can you expect from a person, who don't hesitate to create god objects, on the other hand maybe he was in a hustle and eventually didn't have time to repay this technical debt, we'll never know. Is it possible that using the latter method of access is safer in any way? Your opinions are welcome, fellows, before I launch my inner refactoring ninja.",TD-related,requirements,"antipatterns, coding_standards",4,182,0.061,0.84,0.098,0.7882
36944251,Estimating refactoring efforts,"Is there a way to estimate a refactoring effort? For instance, we know the lines of code that are duplicated across classesackages. Now how do we estimate the effort that is required?",TD-related,requirements,"software_methodology, td_documentation, td_resolution, metrics",2,32,0,1,0,0
37145103,SonarQube - how to specify last successfull analysis as Leak Period,"We are using SonarQube 5.5 (latest to date).Our project contains a lot of legacy code that wouldn't pass our desired Quality Gate, so we decided to ignore technical debt which is already there, but be strict about new changes.So we are enjoying a href=http://docs.sonarqube.org/display/HOME/Fixing+the+Water+Leak rel=noreferrerLeak/a concept and default Quality Gate that considers only new changes.We use Continuous Integration and Continuous Delivery, so we run SonarQube analysis for every CI build to be able to give immediate feedback to developers whether their changes fail the Quality Gate, so issues are not left till the end of sprint, or new technical debt accumulated.We set Leak Period to previous_version as we increment version number every run, but as far as I understand it could be set to previous_analysis in our case with the same effect.The problem with this approach is that next good commit will clear the state of the project (Green, was Red) as analysis for last only commit will pass the Quality Gate. Although the code already contains the issue introduced in previous commit.If Leak Period is set to a fixed date\version (A custom date or A version options), analysis will run for cumulative commits, and individual bad commits can squeeze through unnoticed, causing issues later in the cycle. So it doesn't satisfy immediate requirement.Imagine that after a fixed date\version there were 5 commits of the same size - 4 from good developers following TDD so with 100% coverage, and 1 from bad guy whose changes has 0% coverage. In average it will pass the default condition Coverage on new code is not less than 80%, but in reality we want to give feedback to such bad guys as soon as possible, so they improve their practices.If Leak Period is set to rolling Number of days before analysis, the state of the Gate will clear as soon as this number of days passes since the last bad commit, while issue could still be there in the code.We need to be able to analyze individual commits (similar to previous_version Leak Period option in SQ).But in case last commit passes QG and previous one failed, we should analyze them together to see if last commit actually fixes the problem from previous one, so that the project as a whole can be deemed as passed.So, in essence we should be analyzing all the commits since the last successful analysisThere is no such option for Leak Period.Is there any other way to achieve this?",TD-related,requirements,"software_methodology, td_documentation, td_resolution, metrics",1,409,0.137,0.75,0.113,-0.9599
37959397,Are there team leading problems at Google or other popular companies?,"I'm working as a software engineer for a company that is not very big, about 120 employers. I was head hunted and since the company was quite popular, I started working here. We offer coupons and discounts online and run our site in three different countries.When I first came here, I was shocked. The codebase was so bad and no unittests were written at all. There were half working acceptance tests that were also poorly designed and covered about 5 percent of all features. Not so long ago, the project was divided into pseudo microservices. The communication between them is not isolated; every service knows business processes of the others. We have our production sites down at least once a week. When I tell the team lead or CTO that we need to introduce at least 90 percent test coverage, they always answer that there is no time for that now. Hell.Are there such problems in your company? Did you overcome them and if so, how? What steps should our managers and developers take in order to change the situation?",TD-related,requirements,"software_methodology, td_communication",5,180,0.102,0.856,0.042,-0.9101
38839495,Using Sonar Qube to flag new issues,"I've just installed SonarQube and it's understandably found a lot of technical debt that we want to eventually fix. However at the moment, I want to make sure that any new code checked in is evaluated and issues flagged in that.I know I can mark issues as won't fix, but is there a way to flag issues that have arisen after a certain point in time and leave the existing technical debt as Will fix later?I know ideally I'd like to halt development and fix everything right now, but I've only just got buy in for a CI server and some of my senior colleagues don't even see the point of unit tests, let alone ensuring code quality.",TD-related,requirements,"td_documentation, metrics",2,118,0.07,0.802,0.129,0.7506
40305341,What influence the maintainability result for Sonarqube?,"I'm confronted to a huge spaghetti code with known lack of documentation, lack of test covering, high complexity, lack of design rules to be follow, etc. I let the code be analysed by a default sonar-scan, and surprisingly for me, the maintability has a really great score with a technical debt of 1,1% ! Reality shows that almost each change introduce new bugsI'm quite perplex, and wonder if some particularities in the implementation could explain this score... We have for example quite a lot of interfaces (feeling 4-5 Interfaces for 1 implementation), uses reflexion and service locator pattern.Are there other indicator that I could use that would be eventually more relevant for improving the quality?",TD-related,requirements,"antipatterns, td_documentation, metrics",3,115,0.093,0.805,0.102,0.4676
40536383,Can iOS and Android apps (who store user data locally) be updated without losing pre-existing data?,"I've seen a number of similar questions posed but for the sake of specificity  is possible to do an update to an existing app without losing the end users existing information?The scope of the existing app is:- Available on iOS and Android- Stores user data in the app, locally- The app does not require an internet connection at all The changes to this app would be:- Re-skinning- Fixing technical debt/bugs- Maybe adding some functionality (such as notifications) If it can be possible to do an update without losing local data, would the original source code be required? (I'm assuming the answer is DUH)Unfortunately I can't share the name of this exact (client request).Thanks!",TD-related,requirements,td_resolution,2,114,0.02,0.893,0.087,0.7889
45533485,What framework to use for development of a photoalbum app using pygobject,"I am planning to develop a photo album app in GTK3 using Python. It typically has multiple pages per album with multiple photos per page. These photo's can be arranges on the page, partly overlapping each other, rotated, resized, etc. Each photo can have a choice of borders. Each page can have a choice of background. It needs to be able to be printed as an album or exported as an web based album. You get the idea..Now, I am completely overwhelmed with the choices of libraries/frameworks that exist: Cairo and it's choice of canvases: a href=https://wiki.gnome.org/AtticrojectRidley/CanvasOverview/Canvases rel=nofollow noreferrerhttps://wiki.gnome.org/AtticrojectRidley/CanvasOverview/Canvases/a, GDK, GSK, GTK itself, clutter, and I probably forgot some.Starting fresh, with no technical debt involved, what is the best suited framework for this type of app in terms of features, stability and future? Btw, if needed, I would consider switching from Python to Vala.",TD-related,requirements,framework,2,144,0.033,0.912,0.056,0.5095
45678540,How should old resurfaced technical debt be handled within leak period?,"We have an on-premises installation of SonarQube, and after upgrading from version 6.0 to 6.5 I noticed that several bugs and code smells as old as 2012 have resurfaced. I wasnt expecting that to happen, as per a href=https://www.sonarsource.com/resourcesroduct-news/news.html2017-04-12-sonarqube-6.3-released rel=nofollow noreferrerSonarQube 6.3 release notes/a  see section emRemove noise on the Leak period for newly activated rules/em.Since they are old and we have no plans to handle them now, they are impacting our gate status  which is currently red  and I dont see how I can get rid of them in a proper way.I can think of two options:ulliShorten the leak period, which is not a good approach as existing valid smells in this leak period would be considered technical debt;liMark them as emfalse positive/em or emwont fix/em, which is also not a good idea as we would lose traceability of existing bugs and smells we could eventually plan to fix one day.In such cases, what's the best approach to be taken?",TD-related,requirements,"management, td_documentation, metrics",2,164,0.102,0.873,0.025,-0.8661
46647537,Database poorly designed,"I don't know if I can made this kind of question here so previously I apologize.I work with a system that has a lot of dependencies and a poorly designed database. Now I have to make a decision and would like to hear some cases of you people.That's the case: some part of the software was made without thinking in all cases of uses. Today I need to do severe changes like creating new relations on the database, refactoring all the classes and methods. That's what the theory says, but in pratice this will take a lot of days, will delay the version and the entire schedule. I have the option to keep the gambiarra (bad code that works) and make just the little changes that meets the new needs.I know that each case is different, so I want to hear what would you do and if have you been through something similar.",TD-related,requirements,database,4,153,0.032,0.919,0.049,0.1184
51523362,Static analysis using ESLint with snapshot,"We're using ESLint in our company in order to detect errors, that break the build and block the deploy, but we also have some other rules which trigger some warnings in our console.We want to see those warnings in a timeline, so we'll be able to check if we are improving our tech debts or not.I tried SonarEsLintPlugin in SonarQube but it does not work properly in version 7+Anyone knows other way to have ESLint timeline snapshots?",TD-related,requirements,"warnings, metrics",1,77,0.107,0.833,0.06,-0.4767
58741360,Refactor/Restructure Code Before Swapping Out UI Framework?,"The team I belong to at work is planning to swap out the UI framework we currently use, Om, with another one, re-frame. The main reason for the swap is that Om is no longer supported and we've built a simple proof-of-concept in re-frame that seems promising.In addition to the unsupported framework we currently use, our code is also in need of a refactor. Much of the UI code is in one large file (~3k lines).My preferred approach would be to first complete the refactoring on the existing Om code and split up the large file into many small files to make things more manageable and also restructure the files into a more intuitive file structure. After that, we would re-write the UI code using re-frame.My coworker would prefer to skip the refactor/restructure and write the UI code in re-frame.My thought process behind wanting to refactor first is that we would:ulliBe able to identify dead code and remove itliHave smaller, more organized files that would be easier to convert over to use the new frameworkliExtract common code that will be reused in the re-frame code so we have one copy of that common code that would be simultaneously used in Production by the Om code and by the re-frame code as it's being developedliDecrease the risk of project failure by doing one thing at a time (first the refactor and then UI framework swap)My coworker's thought process behind wanting to skip the refactor is that we would:ulliSave time and effort by not refactoring code that will be thrown outliTake advantage of the fact that we are in a lull period in between large projects to complete the UI framework swap, before we eventually get busy again and won't have time to address large technical debtI feel like my preferred approach is possibly slower but less risky. While my coworker's approach may be faster as long as things go smoothly, it seems riskier and would be more difficult to validate that we've fully reproduced the legacy functionality in the new code.Any advice?",TD-related,requirements,"td_communication, td_resolution, management, dead_code",2,341,0.052,0.918,0.03,-0.7848
11009755,F11key of IntelliJ idea equivalent in MyEclipse,"I used to use IntelliJ IDEA as my development environment and I have recently started to use MyEclipse. In IntelliJ, pressing the kbdF11/kbd key toggles a bookmark. IntelliJ creates a emtic/em or a emcorrect mark/em to the left side of the editor and a black icon in right side of editor to indicate that the line is bookmarked.Pressing kbdSHIFT/kbd kbdF11/kbd then presents a list of your bookmarks enabling another means of navigating around the codebase.Does codeMyEclipse have similar functionality and if it does how do I use it?",Not-TD-related,SonarQube,,,,0,0.974,0.026,0.2732
12980721,Magento - get results view HTML for a collection of products,"I get a list of magento ids from a web service. I load these into and array code$product_ids, so I have something like this: <code>Using my Magento inspector, I've seen that the category pages use the class a href=http://docs.magentocommerce.com/Mage_Core/Mage_Core_Block_Abstract.html rel=nofollowcodeMage_Catalog_Block_Product_List/a to display lists of products. I'd like to do something similar in my class. I've tried loading: $ProductList = new Mage_Catalog_Block_Product_List();$ProductList-  setCollection($collection);reAnd then I've tried to load the HTML of the results as follows: <code> is empty.How would I get the HTML of what you see in the list view (i.e. the generated output of frontend/base/default/template/catalogroductst.phtml, but given my collection)?",Not-TD-related,SonarQube,,,,0,0.96,0.04,0.4144
16531642,is it necessary to use Microsoft approach in every class for finding software maintainability?,"For finding software maintainability by using Microsoft approach, where normally we have to use following methodMI = MAX(0, (171  5.2 * ln(HV)  0.23 * CC  16.2 * ln(LoC)) * 100 / 171),Where,HV  Halstead Volume,CC  Cyclomatic Complexity;LoC  lines of code.In my program i have few different type of classes .as example For ""finding area ""__problem i have ----""circle"", ""triangle"",""quadrilateral"", ""abstract"",""choice"" classes .do i have to use the approach for every individual class for finding software maintainability ?",Not-TD-related,SonarQube,,,,0,1,0,0
17321583,How would PostgreSQL and Oracle behave for a query like SELECT * WHERE id='1blah'?,"On MySQL if I run a query  SELECT * FROM table WHERE id = '1blah'reand there is a record where the ID is 1, the query will actually return that record. I am executing the query via Workbench and PHP/Doctrine, and I get the same result.Why does MySQL does that? Is there a more general database concept involved here I am missing? Does the language/client play any role on this ?And finally, how would PostgreSQL and Oracle behave ?",Not-TD-related,SonarQube,,,,0.03,0.923,0.046,0.2869
19521956,recreate arraywithobjects as a plist,"i know its stupid but how do i recreate this array to a plist list
<code>
thanks for anyones help!",Not-TD-related,SonarQube,,,,0.092,0.586,0.322,0.7574
20764359,CSS File Structure,"Is there any best practices or very practical solutions to organizing mass amounts of css files.Firstly, how should you use css within a page, should you have a external style sheet for each individual page, and a include css file for 'css reset' and all common elements. Say you have a included header how would you style it, would you have another external style sheet.This just add up to mass amounts of style sheets, then secondly how to you organize them, do you have a folder for each external style sheet for each page?Lastly, is there any standard naming conventions, for example if the file was an include would it be 'filename.inc.css' or if it was for a specific page would it be 'filename.pagename.css'",Not-TD-related,SonarQube,,,,0,0.949,0.051,0.7334
20914171,Sonar with Groovy project always reports technical debt of 0.0 days,"I'm running Sonar 4.0 and the 0.6 Groovy plugin (latest version). I analyze the project with Sonar Runner 2.3, and the Sonar report gets generated. When I view the report in the Sonar web server, everything looks great, but the technical debt is always reported as 0.0 days, even though there are 2405 issues (including 2 critical and 587 minor). Is anyone else seeing this issue?",Not-TD-related,SonarQube,,,,0.09,0.873,0.037,-0.5647
21002503,Retrieve sonarqube rules by category,"How can I get a list (via webservice or sql query) of all the sonar rules with his category (Maintainability, Efficiency, Reliability...etc)Using xxxxx/api/rules?language=java plugin=pmd,findbugs :   rule    title  Unnecessary Local Before Return  /title    key  pmd:UnnecessaryLocalBeforeReturn  /key     config_key  rulesets/design.xml/UnnecessaryLocalBeforeReturn  /config_key     plugin  pmd  lugin     description  Avoid unnecessarily creating local variables  /description     priority  MAJOR  riority    /rule  reWhere is the category shown in the Technical Debt dashboard??Thanks!!!",Not-TD-related,SonarQube,,,,0.073,0.854,0.073,0
21017860,sonarqube analysis failed in eclipse throws error on local analysis due to the exception language cpp is not found,"I am running SonarQube 4.0 I'm using the SonarQube plugin for Eclipse, version 3.3.0,20131115 on Eclipse 3.7.2.On the server Sonarqube i have install the plugin Sonar C++ Community Plugin (0.9)The plugin is visible under General Settings -- Sonar C++ Community Plugin.I have associated my C++ projects with the SonarQube projects and am able to view issues from the server side great. However, if I switch to Local analysis, I get the following error Retrieve remote issues of project SonarCpp...Start SonarQube analysis on SonarCpp...INFO: <code>Any suggestions?",Not-TD-related,SonarQube,,,,0.031,0.921,0.048,0.34
21237225,how do JaCoCo and sonar work?,"I am trying to understand how JaCoCo and Sonar work together using the sonar ut-ant-jacoco-runTests example: <code>. One of the two will be used. Which one is undefined. Why I get this warning? is there something misconfigured? this creates:./target/jacoco.exec./target/reports/junit/TEST-OneTest.xml$ ant sonar this generates these two files, which are just a list of pmd rules (taken from the local sonar installation I guess). in any case, they are not a computation result..sonar/md-unit-tests.xml.sonar/md.xml and sends the results to sonar.with Unit tests success: 100% (1 tests), Unit Tests coverage: 60.0%reso, how do JaCoCo and Sonar work together?what does JaCoCo do exactly?what does this ./target/jacoco.exec file contain exactly?how does Sonar use this file, and what does Sonar do exactly?where is the 60.00% coverage result computed? during codeant test or during codeant sonar?Full log of codeant sonar: <code>",Not-TD-related,SonarQube,,,,0.021,0.944,0.035,0.4423
21484150,"Using SonarQube Quality profile All PHP CodeSniffer Rules results in 0 issue and 0,0 days of technical debt","I'm using SonarQube 4.0 and when I set a project to be analyzed with All PHP CodeSniffer Rules quality profile, the result is 0 issue and 0,0 days of technical debt. The project I analyze is a PHP Project.The other metrics work well like cyclomatic complexity, comments, duplications.When I use the default quality profile named SonarWay, everything work well but I want to use the other quality profile since it contains a lot more rules.At first glance there is no issues related to that problem in SonarQube PHP Plugin JIRA.",Not-TD-related,SonarQube,,,,0.091,0.839,0.07,-0.5859
21618953,the analysis result not being published with 4.1.1 using ANT Task,I have just upgraded to Sonar4.1.1 and the same project is not being published properly. I am not able to see the data on the dashboard. however when i tried to publish as a new project the project got created successfully with no data. Logs are here[sonar:sonar] 23:28:40.869 INFO - 0 files indexed[sonar:sonar] 23:28:40.893 INFO - Loading technical debt model.<code>,Not-TD-related,SonarQube,,,,0.08,0.832,0.088,0.128
21867892,Project coverage is set to 0%  JaCoCo and Sonar in Eclipse,"I'm having a hard time getting the unit test coverage in Eclipse 3.8.1 with the SonarQube plugin 3.3.0.I'm executing SonarQube on my Gradle project. Everything works fine except for JaCoCo's report.Here's the console output from a SonarQube analysis: Retrieve remote issues of project Utils...Start SonarQube analysis on Utils...INFO: SonarQube Server 4.1.123:52:07.236 INFO - Incremental mode23:52:07.247 INFO - Load batch settings23:52:07.471 INFO - User cache: /home/siberut/.sonar/cache23:52:07.517 INFO - Install plugins23:52:07.550 INFO - Exclude plugins: devcockpit, jira, pdfreport, views, report, scmactivity23:52:08.123 INFO - Create JDBC datasource for jdbc::/home/siberut/workspace/.metadata/.plugins/org.eclipse.core.resources/.projects/Utils/org.sonar.ide.eclipse.core/.sonartmpreview1392763927919-023:52:10.330 INFO - Initializing Hibernate23:52:14.497 INFO - Load project settings23:52:14.563 INFO - Apply project exclusions23:52:14.959 INFO - ------------- Scan Utils23:52:14.967 INFO - Load module settings23:52:15.686 INFO - Quality profile : [name=Sonar way,language=java]23:52:15.711 INFO - Excluded tests: 23:52:15.712 INFO - **ackage-info.java23:52:15.838 INFO - Index files23:52:16.008 INFO - 27 files indexed23:52:16.024 INFO - Loading technical debt model...23:52:16.600 INFO - Loading technical debt model done: 576 ms23:52:16.625 INFO - Configure Maven plugins23:52:16.908 INFO - Compare to previous analysis (2014-02-18)23:52:16.926 INFO - Compare over 30 days (2014-01-19, analysis of 2014-02-16 15:53:15.0)23:52:16.937 INFO - Compare to previous version (2014-02-18)23:52:17.297 INFO - Base dir: /home/siberut/workspace/Utils23:52:17.300 INFO - Working dir: /home/siberut/workspace/.metadata/.plugins/org.eclipse.core.resources/.projects/Utils/org.sonar.ide.eclipse.core23:52:17.301 INFO - Source dirs: /home/siberut/workspace/Utils/src/main/java, /home/siberut/workspace/Utils/src/main/resources23:52:17.302 INFO - Test dirs: /home/siberut/workspace/Utils/src/test/java, /home/siberut/workspace/Utils/src/test/resources23:52:17.304 INFO - Binary dirs: /home/siberut/workspace/Utils/bin23:52:17.305 INFO - Source encoding: UTF-8, default locale: en_US23:52:17.330 INFO - Sensor JavaSourceImporter...23:52:17.408 INFO - Sensor JavaSourceImporter done: 78 ms23:52:17.412 INFO - Sensor JavaSquidSensor...23:52:17.807 INFO - Java AST scan...23:52:17.825 INFO - 2 source files to be analyzed23:52:18.426 INFO - 2/2 source files analyzed23:52:18.437 INFO - Java AST scan done: 630 ms23:52:18.441 INFO - Java bytecode scan...23:52:18.937 INFO - Java bytecode scan done: 496 ms23:52:18.957 INFO - Package design analysis...23:52:18.970 INFO - Package design analysis done: 13 ms23:52:19.008 INFO - Sensor JavaSquidSensor done: 1596 ms23:52:19.008 INFO - Sensor SurefireSensor...23:52:19.012 INFO - parsing /home/siberut/workspace/Utils/build/test-results23:52:19.283 INFO - Sensor SurefireSensor done: 275 ms23:52:19.285 INFO - Sensor CpdSensor...23:52:19.286 INFO - SonarEngine is used23:52:19.288 INFO - Cross-project analysis disabled23:52:19.478 INFO - Sensor CpdSensor done: 193 ms23:52:19.478 INFO - Sensor PmdSensor...23:52:19.483 INFO - Execute PMD 4.3...23:52:19.500 INFO - Java version: 1.723:52:19.649 INFO - PMD configuration: /home/siberut/workspace/.metadata/.plugins/org.eclipse.core.resources/.projects/Utils/org.sonar.ide.eclipse.coremd.xml23:52:21.042 INFO - Execute PMD 4.3 done: 1559 ms23:52:21.045 INFO - Sensor PmdSensor done: 1567 ms23:52:21.046 INFO - Sensor InitialOpenIssuesSensor...23:52:21.129 INFO - Sensor InitialOpenIssuesSensor done: 83 ms23:52:21.136 INFO - Sensor ProfileSensor...23:52:21.377 INFO - Sensor ProfileSensor done: 241 ms23:52:21.378 INFO - Sensor ProfileEventsSensor...23:52:21.410 INFO - Sensor ProfileEventsSensor done: 32 ms23:52:21.411 INFO - Sensor ProjectLinksSensor...23:52:21.447 INFO - Sensor ProjectLinksSensor done: 36 ms23:52:21.450 INFO - Sensor JaCoCoSensor...23:52:21.468 INFO - Project coverage is set to 0% as no JaCoCo execution data has been dumped: /home/siberut/workspace/Utils/build/test-results/jacoco.exec23:52:21.767 INFO - Sensor JaCoCoSensor done: 317 ms23:52:22.306 INFO - Execute decorators...23:52:23.500 INFO - Export results to /home/siberut/workspace/.metadata/.plugins/org.eclipse.core.resources/.projects/Utils/org.sonar.ide.eclipse.core/sonar-report.json23:52:23.513 INFO - Store results in database23:52:23.795 INFO - ANALYSIS SUCCESSFULreThe part near the bottom bugs me: Project coverage is set to 0% as no JaCoCo execution data has been dumped: /home/siberut/workspace/Utils/build/test-results/jacoco.execreThese are the properties I've set for the analysis:img src=https://i.stack.imgur.com/DjcBz.png alt=sonar propertiesIt'd be great if someone could give me a hint on what's missing here.Thanks.",Not-TD-related,SonarQube,,,,0.052,0.93,0.018,-0.8934
21906671,Calculating Design Violations Technical Debt with SonarQube,"I was wondering if it is possible with the latest version of Sonar or through some plugin calculate the techical debt of an architectural violation (from a java project) like: em'X' class should be in com.domain.classes package/em or emthe class 'X' must extend the class 'Y' /em? Or emThe 'X' class must have a 'public static Y someAttribute' attribute/em?If there is no plugin for this, there is how to develop a plugin to automate this? I have read the documentation for the Java API, REST, how to develop a plugin and tried to code it, but have not found a way to do it.",Not-TD-related,SonarQube,,,,0.06,0.909,0.031,-0.4386
22306370,Sonar-runner execution failure causing cast exception,"After configure the sonar tools (SonarQube, MySql database and Sonar-runner) I perform an analysis over an Android project without any problem. But after install the Android Plugin for sonar and repeat the analysis, this one fails getting the next error: INFO - Preview modeLoad batch settingsUser cache: /home/user/.sonar/cacheINFO - Install pluginsINFO - Exclude plugins: devcockpit, jira, pdfreport, views, report, buildstability, scmactivity, buildbreakerINFO - Create JDBC datasource for jdbc::/home/user/workspace/myAndroidProject/.sonar/.sonartmpreview1394469024394-0INFO - Initializing HibernateINFO - Load project settingsINFO - Apply project exclusionsINFO - ------------- Scan myAndroidProjectINFO - Load module settingsINFO - Language is forced to javaINFO - Loading technical debt model...INFO - Loading technical debt model done: 424 msINFO - Configure Maven pluginsINFO - Base dir: /home/user/workspace/myAndroidProjectINFO - Working dir: /home/user/workspace/myAndroidProject/.sonarINFO - Source dirs: /home/user/workspace/myAdnroidProject/srcINFO - Source encoding: UTF-8, default locale: en_ENINFO - Index filesINFO - Included sources: INFO - src/**INFO - 116 files indexedWARN - Accessing the filesystem before the Sensor phase is deprecated and will not be supported in the future. Please update your plugin.INFO - Index filesINFO - Included sources: INFO - src/**INFO - 116 files indexedWARN - Accessing the filesystem before the Sensor phase is deprecated and will not be supported in the future. Please update your plugin.INFO - Index filesINFO - Included sources: INFO - src/**INFO - 116 files indexedINFO - Quality profile for java: Sonar wayINFO - Sensor JavaSourceImporter...INFO - Sensor JavaSourceImporter done: 49 msINFO - Sensor JavaSquidSensor...INFO - Java AST scan...INFO - 116 source files to be analyzedINFO - 116/116 source files analyzedINFO - Java AST scan done: 6693 msWARN - Java bytecode has not been made available to the analyzer. The Depth of Inheritance Tree (DIT) metric, Response for Class (RFC) metric, Number of Children (NOC) metric, Lack of Cohesion (LCOM4) metric, deperecated dependencies metrics, UnusedPrivateMethod rule, RedundantThrowsDeclarationCheck rule, S1160 rule, S1217 rule are disabled.INFO: ------------------------------------------------------------------------INFO: EXECUTION FAILUREINFO: ------------------------------------------------------------------------Total time: 18.440sFinal Memory: 12M/357MINFO: ------------------------------------------------------------------------ERROR: Error during Sonar runner executionERROR: Unable to execute SonarERROR: Caused by: org.sonar.api.resources.Directory cannot be cast to org.sonar.api.resources.JavaPackagereMy sonar-project.properties file is the enxt: Required metadatasonar.projectKey=mKeysonar.projectName=myAndroidProjectsonar.projectVersion=1.0 Paths to source directories. Paths are relative to the sonar-project.properties file. Replace \ by / on Windows. Do not put the sonar-project.properties file in the same directory with the source code. (i.e. never set the sonar.sources property to .)sonar.sources=src The value of the property must be the key of the language.sonar.language=java Encoding of the source codesonar.sourceEncoding=UTF-8 Analysis modesonar.analysis.mode=previewEnables the Lint profile to analyze the code using the Lint rules.sonar.profile=Android LintreI'm using the next environment:ulliSonarQube 4.2 RC1liSonar-runner 2.3liDatabase: MySQLliUbuntu 12.04 LTSliJava 1.7I tryed uninstalling the Android plugin but the problem persists. The unique way that I've found to solve it is deleting the database and the user and create them again.",Not-TD-related,SonarQube,,,,0.072,0.876,0.052,-0.9005
22653255,check document is opened by other user xpages,"I m working with xpages for following scenario. I have one agent that will update the value to one of the field of datasource from notesview. sometimes, while one user is opening the datasource via xpage and other user run the agent in the same time. at that time, agent can run and update the field of datasource. but from the xpages side, we can catch the exception for the document is modified by other user and cannot save the xpages. i would like to prevent this from agent side. i would like to know whether there is a way to know that document is opened by one of the user from agent side, so that agent wont update the value to that datasource. thank for your help.",Not-TD-related,SonarQube,,,,0.025,0.834,0.141,0.9301
22940671,sonarqube runs and stops after while for no apparent reason,"First of all: on my RHEL system I installed Sonarqube 4.2 with a MS SQL Server 2008R2 database.The service is started and running and then stopped after a while, so when i try to access the Sonarqube-service in my webbrowser the url is not accessible. In the logfile everything looks ok, but it is stopping. I installed the latest jTDS JDBC driver, but that didn't succeed too. I checked in the db if TCP/IP on port 1433 is enabled, but that's ok.This is the output in the sonar.log:<code>",Not-TD-related,SonarQube,,,,0.079,0.903,0.019,-0.636
23002368,SonarQube Analysis for Erlang,"I am trying to run sonar analysis for Erlang. I have downloaded the plug-ins and with 60+ rules, it is able to tell me which part of the source code is not compliant. However, I cannot get the SQALE rating to work correctly, in particular, the technical debt always shows 0.0 days. How do I configure this?",Not-TD-related,SonarQube,,,,0.046,0.954,0,-0.3612
23462769,Prevent MySQL JDBC drivers from converting DateTime to localtime,"I've found an number of posts here on Stack Overflow and mailing lists documenting the MySQL JDBC issue with timezones, datetimes, etc. But even with all that I still can't figure this out. I'm using a connection string like the following:
jdbc:mysql://localhost:3306/BigSense?useLegacyDatetimeCode=false&serverTimezone=UTC
I insert the date using the following:
stmt.setTimestamp(x, s, Calendar.getInstance(TimeZone.getTimeZone(""UTC"")))
And the date does correctly get stored in MySQL in a DateTime column in UTC time. I can do a SELECT from the console and see it in the time format I sent it to the server as. The trouble is when I do a <code>
It's old Scala code, so don't judge me. I realize I shouldn't be using a retval and there are more ""Scala"" ways to write this :)
Anyway, I've tried variation where I check to see if it's specifically the ""time"" column and use getTimestamp instead, both with and without the Calendar object option and I still get the time translated to local!
This is for the BigSense project where I'm trying to support multiple databases (currently have Postgres and MS SQL fully supported) and so I'm trying to keep the code as generic/agnostic as possible. The full source for my DB stuff can be found here:
https://github.com/sumdog/BigSense/blob/master/src/main/scala/io/bigsense/db/DataHandlerTrait.scala
Oh and I've also tried the following:
noTimezoneConversionForTimeType=true
and still get the same result. My local machine is setup as NZST, so it complains if I leave out the the ""serverTimezone=UTC"" from the JDBC URL. Inserts are working fine, it the SELECT that are coming back converted when they shouldn't.",Not-TD-related,SonarQube,,,,0.034,0.907,0.059,0.7597
23567128,Sonar-Runner doesn't index any files,I'm trying to run a sonar analysis on my playframework jave code. There are no files indexed:  <code>Any help is appreciated. Thanks!,Not-TD-related,SonarQube,,,,0.077,0.599,0.324,0.7901
23822513,Sonar displays no issues,"I have this weird situation while analyzing a java 1.7 project with SonarQube 4.2 through Jenkins plugin. Everything goes fine but sonar shows no issues after analysis.If I run the same project analysis on local sonarqube, I get the issues.I don't know where to look. Any ideas are welcome.Analysis log below: [INFO] --- sonar-maven-plugin<code>",Not-TD-related,SonarQube,,,,0.079,0.894,0.027,-0.4118
24193534,SonarQube 4.3 in Java 8 not showing any Issues,"I'm running SonarQube 4.3 in Java 8 and it's not showing any numbers in Issues, Technical Debt and not showing any numbers in Blocker, Critical, etc. I've a gradle project with jacoco plugin and codegradle sonarRunner runs fine and generates Unit Tests Coverage and Integration Tests Coverage. Also Java plugin is updated to 2.2.1. Thanks.",Not-TD-related,SonarQube,,,,0.082,0.838,0.08,-0.0258
24280389,SonarQube 4.3 - 0 files indexed,"I'm trying to run a sonar analysis on my jave code. There are no files indexed. INFO: Runner configuration file: <code>, but the web server is only the name of the project and no data about metrics and code coverage.Please help me!",Not-TD-related,SonarQube,,,,0.101,0.822,0.077,0.1134
24564410,How much should I care in my JS scripts for IE 8 and blew?,how much should I care about IE 8 and blew in ( JS and CSS ) code ?,Not-TD-related,SonarQube,,,,0,0.789,0.211,0.4939
24594523,Technical Debt and Issues' widget. How is issue trend calculated,"The 'Technical Debt and Issues' widget in a Sonarqube dashboard includes an issue list broken down by severity eme.g. Blocker, Critical, Major etc ./emThe widget display displays a trend arrow em(Up, down, no-change)/em against each issue category.A great feature, but I'd wanted to know how this is calculated for the default view.If you select a time-change category of 'emSince Previous Analysis/em' or 'emover 30 days/em', the answer is self-evident, its the delta in the selected periods. However not sure about the default where no period is selected.Reason for the question is that I have a current project where a couple of categories have downward trends over 'emprevious/em' and 'emover 30 days/em', but this isn't reflecting as a downward trend in the default view.",Not-TD-related,SonarQube,,,,0.087,0.893,0.021,-0.7305
24822125,SonarQube Technical Debt,"I've got a question about SonarQube and the technical debt.The official a href=http://www.sonarqube.org/sonarqube-4-3-in-screenshots/more-10185 rel=nofollowSonarQube 4.3 Release Notes/a says Now SonarQube displays debt not in fractional days but in days, hours and (where appropriate) minutes. But I wonder if there is a possibility to do the same for days and month or at least years.I would appreciate it very much if it would be possible to configure the time unit.As example: we have a helicopter view where a timeline, size metrics, issues and technical debt are shown. All projects are summarized to one project via the views plugin to do so.But here comes the problem: the technical debt is shown as 39,782 days. Years would come in handy here.Is there a possible to change the shown time unit or not?thanks to everyone who is posting an answer! :)",Not-TD-related,SonarQube,,,,0.084,0.863,0.053,-0.5487
25064211,How to open a new window from only one asp.net control,"I have the following codes which opens a PDF file in a new window from the current page:
<<code>
What is happening is when I click on the LinkButton it opens a new window from the current page, and everything is good.
But lets say I click on the following button (or any links) on the current page:
<asp:Button ID=""btnGeneratePDF"" ClientIDMode=""Static"" runat=""server"" Text=""Generate PDF"" CommandArgument='#SOMETHING GOES HERE' />
It keeps opening new window each time which I want to prevent. The only way it doesn't open new window, is if I don't open a new page and redirect on the same page and user comes back to the current page it doesn't open a new window each time.
How do I modify the code so that only LinkButton control will open a new window and any other controls will open on the same page and not in the new window?",Not-TD-related,SonarQube,,,,0,0.967,0.033,0.3716
25135589,Android: run sonarRunner from gradle,"I'm stuck trying to get sonar reporting to run with an gradle Android project. Because most of the important sonar properties are only applied by the a href=http://www.gradle.org/docs/current/userguide/sonar_runner_plugin.html rel=noreferrersonarRunner gradle plugin/a when the project is a codejava project I'm having trouble applying them for the codecom.android.application project.This is my sonarRunner config: sonarRunner { sonarProperties { property sonar.sourceEncoding, UTF-8 property sonar.profile, Android Lint property sonar.sources, android.sourceSets.main.java.srcDirs property sonar.binaries, file(${project.buildDir}/intermediates/classes/app) property sonar.libraries, // what to put here? }}reThe problem is, that sonar is complaining about classes not being found because the libraries could not be referenced. How can the dependencies + android libraries being referenced in my sonarRunner configuration?hrExample Error output: INFO - Load batch settingsINFO - User cache: C:\Users\mannaz\.sonar\cacheINFO - Install pluginsINFO - Install JDBC driverINFO - Create JDBC datasource for jdbc:postgresql://sonar.local/sonar?useUnicode=true characterEncoding=utf8INFO - Initializing HibernateINFO - Load project settingsINFO - Apply project exclusionsWARN - 'sonar.dynamicAnalysis' is deprecated since version 4.3 and should no longer be used.INFO - ------------- Scan appINFO - Load module settingsINFO - Loading technical debt model...INFO - Loading technical debt model done: 20 msINFO - Loading rules...INFO - Loading rules done: 584 msINFO - Configure Maven pluginsINFO - Compare to previous analysis (2014-08-05)INFO - Compare over 30 days (2014-07-06, analysis of 2014-07-07 11:33:19.0)INFO - Compare to previous version (2014-07-21)INFO - No quality gate is configured.INFO - Base dir: C:\Users\mannaz\workspace\project\appINFO - Working dir: C:\Users\mannaz\workspace\project\app\build\sonarINFO - Source dirs: C:\Users\mannaz\workspace\project\app\src\main\javaINFO - Binary dirs: C:\Users\mannaz\workspace\project\app\build\intermediates\classes\appINFO - Source encoding: UTF-8, default locale: de_ATINFO - Index filesINFO - 197 files indexedINFO - Quality profile for java: Android LintINFO - Sensor JavaSquidSensor...INFO - Java Main Files AST scan...INFO - 197 source files to be analyzedERROR - Class not found: android.widget.RelativeLayoutERROR - Class not found: android.os.HandlerERROR - Class not found: android.content.ContextERROR - Class not found: android.app.ActivityERROR - Class not found: android.util.AttributeSetERROR - Class not found: android.view.ViewERROR - Class not found: com.nostra13.universalimageloader.core.DisplayImageOptionsERROR - Class not found: com.google.gson.Gsonre",Not-TD-related,SonarQube,,,,0.077,0.908,0.015,-0.9401
25144655,"sonarRunner Anaylsis failed exception - Cannot analyze a .java file, NullPointerException sonar.sources","I'm running sonarRunner (Sonar Analysis) on Java project but getting the following error. I tried various options/settings as mentioned below but it's still failing. I even tried setting / passing -Dsonar.exclusions=emsrc/java/com/thc/ids/biz/SomePlansvcvt/costestimate/datavalidation/Validators.java/em, it's still not ignoring the file. <code>",Not-TD-related,SonarQube,,,,0.187,0.746,0.067,-0.728
25181800,Sonarqube - Getting Incorrect Technical Debt Measure in Plugin,"I am developing a plugin in Java for SonarQube (version 4.3.2) and need to make use of codeTECHNICAL_DEBT metrics present in codeCoreMetrics. I wrote below code to get this metrics from my codeDecorator.  Metric metric = metricFinder.findByKey(CoreMetrics.TECHNICAL_DEBT_KEY); data = context.getMeasure(metric);.getIntValue(); LOGGER.debug({}: {}, CoreMetrics.TECHNICAL_DEBT_KEY, data);reEverything works fine so far, But the output of this code is different from the Technical Debt displayed on the Sonar dashboard.Output of this code: codesqale_index: 15750Dashboard displays: Technical Debt 32dAm I missing something in my understanding or programming? Please help.",Not-TD-related,SonarQube,,,,0.104,0.807,0.089,-0.34
25245753,runWithDocumentContext:passing data back to the xpage,"I was playing around with run With Document Context almost the whole day. Maybe someone can help to find me a feasible solution.If i run the agent in before page load / before render response / query Open Document event i am able to pass values back to the xpage without saving the document. I tried also to save the document but it didnt help.Beside these two events i didn't find a way to call the agent and bring the values from the lotus notes agent back. Can anybody think of an event that would work?",Not-TD-related,SonarQube,,,,0,0.837,0.163,0.9178
25440651,Unable to run sonarqube plugin in eclipse,I want to use sonarqube plugin in eclipse. I've linked it with sonar server and it seems to be ok. The problem occurs during analysis. Output says that codeAccess to the secured property <code>,Not-TD-related,SonarQube,,,,0.071,0.765,0.164,0.3612
25792196,Does Sencha Touch allow direct manipulation of DOM and canvas elements?,"Does Sencha Touch integrate well with code that directly manipulates the DOM and/or   canvas  ? In my case specifically, I have an app that uses KineticJS for several GUI components that need to be responsive or high frame rate. I'm also using WebAudio and reqAnimFrame, both of which assume things about the execution lifecycle (or, well, my code assumes things in how it schedules these). Are such things going to be impossible, difficult, easy to integrate with a Sencha app?Longer versionI am investigating Sencha, having become frustrated with the patchwork approach to JS libraries in a hybrid app. I now have an app that has some impressive functionality but is starting to feel like it cannot stretch beyond refined prototype, as the available libraries add so much technical debt integrating and wrestling to get them to do what I want. GUI In particular is very difficult. What I'm wanting is just proving too cumbersome using tools focused on general purpose web apps. HTML declarative widgets and layout, lots of CSS, external SVG, custom canvas components... Hybrid apps are Frankenstein monsters, at least if they go beyond typical CRUD apps with list views and standard mobile UI (and often even then).Sencha clearly is very robust, mature, and capable -- potentially a good investment for future projects. However I desperately am trying to get this current project back on track, where I can focus on adding features and less on the plumbing. I'd emhappily/em invest a few weeks just getting up to speed with a new (to me) technology like Sencha if I knew it would be possible and not prohibitively difficult to integrate my existing code, or (and I'm not seeing this), if there is some Sencha-preferred way to do high-performance rendering and scheduling. Hopefully this question is clear and not perceived as subjective. I believe it's an objective question (maybe not absolute emyes/em or emno/em), but requires some real experience with Sencha to be able to answer.",Not-TD-related,SonarQube,,,,0.049,0.821,0.13,0.9789
25941976,SonarQube showing issues but 0 days technical debt,"I'm using Cppcheck to run analysis on my C++ project and then loading the results into SonarQube. SonarQube is showing the issues, but the technical debt shows 0.How can I get the technical debt to show up correctly?I'm running Cppcheck with this command: C:\Program Files (x86)\Cppcheck\cppcheck.exe -v --enable=all --xml --xml-version=1 C:\Users\tim\Documents\Visual Studio 2013\Projects\TestCpp 2   cppcheck-TestCpp.xmlreMy sonar-project.properties file: sonar.projectKey=TestCppsonar.projectVersion=1.0sonar.projectName=Temp cpp Testsonar.sources=.sonar.language=c++sonar.sourceEncoding=UTF-8Cppchecksonar.cxx.cppcheck.reportPath=cppcheck-*.xmlreThis is the test code I'm running it against: int main(){ // unused variable int nTmp = 0; // index out of bounds char a[10]; a[10] = 0; return 0;}reSonarQube is showing 3 issues from this code and 0 technical debt. What else do I need to do to show the technical debt?I'm running SonarQube version 4.4 and Sonar Runner version 2.3I've run sonar-runner with debug logging and I'm not seeing any errors loading the Cppcheck results.Cppcheck version 1.63I should also mention this is using the C++ Community plugin version 0.9.0",Not-TD-related,SonarQube,,,,0.067,0.916,0.017,-0.8204
26101226,"SonarRunner works with Sonar 3.2, but not with SonarQube 4.4","Environment: Windows 7 | SonarQube 4.4 | SonarRunner 2.4 | .NET (C)/I have been using Sonar 3.2   SonarRunner 2.0. Projects are being displayed in Sonar dashboard upon typing sonar-runner in command prompt, where project base directory is there.With the same set of configurations, when I upgrade to SonarQube 4.4   SonarRunner 2.4, following exceptions are thrown upon typing sonar-runner in command prompt, where project base directory is there:<code>Please help in sorting out these exceptions   let me know if any additional details are required, thanks.Regards,KP",Not-TD-related,SonarQube,,,,0,0.966,0.034,0.4019
26144995,SonarQube 4.5 does not populate technical debt with mysql datasource,"I mvn sonar:sonar a project and problems with our code is recorded in the technical debt in sonarqube when we use the default database - i.e. default install of version 4.5. It works, out of the box:Blocker 0br Critical 0br Major 88br Minor 70br Info 12 I change the datasource to mysql and Blocker 0br Critical 0br Major 0br Minor 0br Info 0 is recorded. No errors presented by mvn or sonar. I can see all drivers load during mvn run.In .m2/settings.xml I have     profile     id  sonar  /id     activation     activeByDefault  true  /activeByDefault     /activation     properties     sonar.jdbc.url   jdbc:mysql://sonar.company.io:3306/sonar?useUnicode=true characterEncoding=utf8   /sonar.jdbc.url     sonar.jdbc.username  sonar  /sonar.jdbc.username     sonar.jdbc.password  pass  /sonar.jdbc.password     sonar.host.url   http://sonar.company.io:9000   /sonar.host.url     sonar.verbose  true  /sonar.verbose     roperties     rofile  reI can am able to connect via the hostname using mysql -usonar -ppass -h sonar.company.io and there is content in the database. mysql   show databases;<code>What could be the reason?",Not-TD-related,SonarQube,,,,0.101,0.861,0.038,-0.7998
26148234,Sonar installed & started but not accessible,Summary:ulliInstalled standalone sonar liStarted through /etc/init.d/sonar startlisonar.log doesn't show any error liunable to open a<code>,Not-TD-related,SonarQube,,,,0,0.861,0.139,0.3089
26255705,Sonarqube Plugin - Getting issues and characteristic,"I've spent days trying to figure out how to get all issues by characteristic.My scenario is that I want to know how many issuess affects the maintainability and what's the severity of that issue. Ideally I want this for all charactistic, maintainability, readability etc.I've been looking at the sourcecode for the technical debt pyramid, just can't seem to figure out how I get it. Thank youBest regards Martin",Not-TD-related,SonarQube,,,,0.036,0.852,0.112,0.5267
26303004,Sonar eclipse plugin: Unable to compute position of SonarQube marker,"Well I am upgrading my sonar instance to 4.5 (4.4 currently), So I copied my config and profile to the new instance, when I run the first analysis from the console its all OK, errors are showing right. after running the first analysis I linked my SonarTest project with the SonarQube eclipse plugin and when I run the analysis it shows the same errors as the server for while, then this message appears in console: <code>",Not-TD-related,SonarQube,,,,0.062,0.872,0.066,0.0601
26339005,sonar-maven-plugin fails because of invalid checkstyle.xml (The processing instruction target matching [xX][mM][lL] is not allowed),"I use Maven 3.2.1 and SonarQube 4.5 in conjunction with Checkstyle 5.6. Executing mvn sonar:sonarreworks fine for some projects, but others fail with Can not execute Checkstyle:<code>aDoing Google research I found nothing.Can anybody help me on this?",Not-TD-related,SonarQube,,,,0.114,0.767,0.119,-0.2023
26752374,How to enlarge data column in SonarQube?,"I'm trying to check my source code with cppcheck and SonarQube.When I run sonar-runner, I met error below SonarQube Runner 2.4Java 1.6.0_33 Sun Microsystems Inc. (64-bit)Linux 3.11.0-26-generic amd64INFO: Error stacktraces are turned on.INFO: <code>I have a huge source file which is image data file. It's over 100 Megabytes.How can I enlarge data column? Is there setting for it?",Not-TD-related,SonarQube,,,,0.098,0.864,0.039,-0.5362
26991026,calling agent send dialog box to user xpages,"how to send error message to user from agent when using xpages?Here the detail engine:1. The xpages contains a button. when the button was clicked then it will call the agent to process the context info2. On processing the agent, is it possible to send warning message to user (dialog box)? If yes, What command for send it?Thanks",Not-TD-related,SonarQube,,,,0.09,0.866,0.043,-0.4479
27064718,Feature Flagging vs Authorization,"I just stumbled across the concept of feature flagging, and a popular open source Java lib for this called Togglz, which quotes a Martin Fowler blog post:The basic idea is to have a configuration file that defines a bunch of toggles for various features you have pending. The running application then uses these toggles in order to decide whether or not to show the new feature.But to me, this really sounds like authorization: Is the user authorized to view this content?For example, Should the user be able to see the FizzBuzz menu, or not?In Togglz I might implement this check like so:if(MyFeatures.ShowFizzBuzz.isActive()) {// Show the FizzBuzz menu.}In, say, Apache Shiro, I could do the exact same thing:ShowFizzBuzzPermission showFizzBuzz = new ShowFizzBuzzPermission();if(currentUser.isPermitted(showFizzBuzz) {// Show the FizzBuzz menu.}Again, feature flagging just feels like its the same exact problem as role- or permission-checking.I'm sure I'm wrong, but I don't see how. So I ask: How is feature flagging different than authorization and role/permission checking, and what types of concrete use cases exemplify this difference? In other words: When should I use authorization/role/permission checking, and when should I use feature flags?",Not-TD-related,SonarQube,,,,0.038,0.879,0.083,0.8447
27186843,Calculation of modularity from sonarqube,Is there a way to calculate modularity metric from the preexisting metrics in SonarQube? I want to calculate modularity so that I can use it for my technical debt calculation.,Not-TD-related,SonarQube,,,,0.087,0.868,0.045,-0.296
27365005,Sonar Upgrade - Technical debt is different,I am upgrading from sonar 3.3.2 to sonarqube 4.5.1. I am comparing one project in each version. Everything looks good except the technical debt and the unit tests.Why is this happening? Here is the technical debt in 3.3.2:img src=https://i.stack.imgur.com/yhf8g.jpg alt=enter image description hereHere is the technical debt in 4.5.1:img src=https://i.stack.imgur.com/m2F7x.jpg alt=enter image description here,Not-TD-related,SonarQube,,,,0.128,0.822,0.05,-0.5574
27919849,.Net scheduled tasker,"I remember working in a company where we had a scheduled task manager. It was a windows service running on several machines, synchronized in the DB, that we used for running offline batch processes.Now I found myself having to do it all over in my current workplace. Is there a framework that you recommend for jump starting my development?Constraints:ulliIt should be easily deployed to several environments. For example: Windows scheduled task deployment is complicated when done manually.liIt should not start a new task when the same task is already in progress.liA task crushing will not crush the scheduler. ",Not-TD-related,SonarQube,,,,0.042,0.893,0.066,0.3278
27946297,sonar web ui is really slow,"Running SonarQube 4.5.2Backed by a high performance MS SQL 2012 production clusterRendering the dashboard for a project takes about 15-25 seconds.I turned on full debug logging, and in the log I found these 17049ms GET /sonar/dashboard/index/69881?did=2...19891ms GET /sonar/dashboard/index/69881?did=2...19172ms GET /sonar/dashboard/index/69881?did=2reAnd I cannot see any SQL statements in the log that take a unreasonably long timeHowever, I found a lot of statements similar to this 2015.01.14 14:36:50 INFO http-bio-10.230.49.59-9000-exec-8 web[sql] 219ms Executed SQL: SELECT * FROM [project_measures] WHERE (rule_priority is null and rule_id is null and characteristic_id is null and person_id is null and snapshot_id in (N'8469895',N'8469896',N'8469897',N'8469898',N'8469899',N'8469900',N'8469888',N'8469889',N'8469890',N'8469902',N'8469903',N'8469904',N'8469905',N'8469906',N'8469907',N'8469908',N'8469909',N'8469910',N'8469911',N'8469912',N'8469913',N'8469914',N'8469915',N'8469917',N'8469926',N'8469927',N'8469928',N'8469930',N'8469919',N'8469920',N'8469921',N'8469922',N'8469923',N'8469924',N'8469932',N'8469933',N'8469934',N'8469935',N'8469937',N'8469938',N'8469939',N'8469941',N'8469943',N'8469944',N'8469946',N'8469947',N'8469948',N'8469949',N'8469950',N'8469955',N'8469956',N'8469957',N'8469951',N'8469952',N'8469953',N'8470089',N'8470091',N'8470092',N'8470093',N'8470094',N'8470095',N'8470096',N'8470097',N'8470098',N'8470099',N'8470100',N'8470101',N'8470102',N'8470103',N'8470104',N'8470105',N'8470086',N'8470087',N'8466975',N'8466976',N'8466977',N'8466978',N'8466979',N'8470208',N'8470209',N'8470210',N'8470211',N'8470212',N'8470213',N'8470215',N'8470216',N'8470217',N'8470218',N'8470220',N'8470222',N'8470227',N'8470228',N'8470229',N'8470230',N'8470231',N'8470232',N'8470233',N'8470234',N'8470235',N'8470236',N'8470237',N'8470238',N'8470239',N'8470240',N'8470241',N'8470242',N'8470243',N'8470244',N'8470245',N'8470246',N'8470247',N'8470248',N'8470249',N'8470250',N'8470251',N'8470252',N'8470253',N'8470254',N'8470255',N'8470223',N'8470257',N'8470258',N'8470259',N'8470260',N'8470261',N'8470262',N'8470264',N'8470265',N'8470266',N'8470267',N'8470268',N'8470269',N'8470270',N'8470271',N'8470272',N'8470273',N'8470274',N'8470275',N'8470276',N'8470277',N'8470278',N'8470224',N'8470280',N'8470281',N'8470282',N'8470283',N'8470290',N'8470284',N'8470285',N'8470286',N'8470287',N'8470288',N'8470289',N'8470291',N'8470292',N'8470293',N'8470294',N'8470295',N'8470296',N'8470297',N'8470298',N'8470299',N'8470300',N'8470301',N'8470302',N'8470303',N'8470304',N'8470305',N'8470306',N'8470307',N'8470308',N'8470309',N'8470310',N'8470311',N'8470225',N'8470313',N'8470314',N'8470315',N'8470317',N'8470319',N'8470320',N'8470321',N'8470322',N'8470323',N'8470324',N'8470325',N'8470326',N'8470328',N'8470329',N'8470330',N'8470332',N'8470333',N'8470334',N'8470335',N'8470337',N'8470338',N'8470339',N'8470340',N'8470344',N'8470345',N'8470346',N'8470347',N'8470348',N'8470349',N'8470350',N'8470351',N'8470352',N'8470353',N'8470354',N'8470341',N'8470342',N'8470359',N'8470360',N'8470361',N'8470363',N'8470367',N'8470368',N'8470364',N'8470365',N'8470366',N'8470370',N'8470371',N'8470373',N'8470374',N'8470375',N'8470372',N'8470376',N'8470377',N'8470379',N'8470380',N'8470356',N'8470382',N'8470385',N'8470383',N'8470357',N'8470387',N'8470389',N'8470390',N'8470391',N'8470392',N'8470393',N'8470394',N'8470395',N'8470396',N'8470397',N'8470398',N'8470399',N'8470400',N'8470401',N'8470422',N'8470423',N'8470424',N'8470425',N'8470402',N'8470403',N'8470404',N'8470405',N'8470406',N'8470407',N'8470408',N'8470409',N'8470410',N'8470411',N'8470412',N'8470413',N'8470414',N'8470415',N'8470416',N'8470417',N'8470418',N'8470419',N'8470420',N'8470421',N'8470427',N'8470441',N'8470442',N'8470443',N'8470444',N'8470445',N'8470446',N'8470447',N'8470448',N'8470450',N'8470449',N'8470451',N'8470452',N'8470453',N'8470454',N'8470455',N'8470428',N'8470429',N'8470430',N'8470431',N'8470432',N'8470433',N'8470434',N'8470435',N'8470436',N'8470437',N'8470438',N'8470439',N'8470457',N'8470458',N'8470460',N'8470461',N'8470463',N'8470464',N'8470465',N'8470681',N'8470683',N'8470684',N'8470685',N'8470686',N'8470687',N'8470693',N'8470688',N'8470689',N'8470690',N'8470691',N'8470692',N'8470694',N'8470695',N'8470699',N'8470700',N'8470701',N'8470702',N'8470703',N'8470704',N'8470705',N'8470706',N'8470707',N'8470708',N'8470709',N'8470710',N'8470711',N'8470712',N'8470713',N'8470714',N'8470715',N'8470724',N'8470725',N'8470726',N'8470727',N'8470728',N'8470729',N'8470730',N'8470731',N'8470732',N'8470733',N'8470734',N'8470735',N'8470736',N'8470737',N'8470738',N'8470739',N'8470740',N'8470741',N'8470742',N'8470716',N'8470717',N'8470718',N'8470719',N'8470720',N'8470721',N'8470722',N'8470696',N'8470697',N'8470744',N'8470745',N'8470747',N'8470748',N'8470749',N'8470750',N'8470756',N'8470757',N'8470758',N'8470760',N'8470761',N'8470751',N'8470763',N'8470752',N'8470753',N'8470765',N'8470766',N'8470767',N'8470768',N'8470769',N'8470770',N'8470771',N'8470772',N'8470774',N'8470777',N'8470776',N'8470779',N'8470780',N'8470781',N'8470782',N'8470783',N'8470784',N'8470785',N'8470786',N'8470787',N'8470788',N'8470789',N'8470790',N'8470791',N'8470792',N'8470793',N'8470794',N'8470795',N'8470796',N'8470797',N'8470798',N'8470799',N'8470808',N'8470809',N'8470810',N'8470811',N'8470812',N'8470813',N'8470814',N'8470815',N'8470816',N'8470817',N'8470818',N'8470819',N'8470820',N'8470821',N'8470822',N'8470823',N'8470824',N'8470825',N'8470826',N'8470827',N'8470800',N'8470801',N'8470802',N'8470803',N'8470804',N'8470805',N'8470806',N'8470829',N'8470830',N'8470831',N'8470832',N'8470833',N'8470834',N'8470754',N'8470836',N'8470837',N'8470839',N'8470840',N'8470845',N'8470846',N'8470843',N'8470841',N'8468773',N'8468785',N'8468786',N'8468787',N'8468788',N'8468789',N'8468790',N'8468791',N'8468774',N'8468775',N'8468776',N'8468777',N'8468778',N'8468779',N'8468780',N'8468781',N'8468782',N'8468783',N'8468793',N'8468794',N'8468795',N'8468797',N'8468798',N'8468799',N'8468800',N'8468801',N'8468802',N'8468803',N'8468804',N'8468805',N'8471049',N'8471050',N'8471051',N'8471052',N'8471053',N'8471054',N'8471055',N'8471056',N'8471057',N'8471059',N'8471060',N'8471061',N'8471062',N'8471063',N'8471064',N'8471065',N'8471066',N'8471067',N'8471068',N'8471069',N'8471070',N'8471071',N'8471072',N'8471073',N'8471074',N'8471075',N'8471076',N'8471077',N'8471078',N'8471079',N'8471080',N'8471081',N'8471082',N'8471083',N'8471084',N'8471085',N'8471086',N'8471087',N'8471088',N'8471089',N'8471090',N'8471091',N'8471092',N'8471094',N'8471095',N'8468848',N'8468849',N'8468859',N'8468860',N'8468861',N'8468862',N'8468863',N'8468864',N'8468865',N'8468866',N'8468867',N'8468868',N'8468869',N'8468870',N'8468851',N'8468852',N'8468853',N'8468854',N'8468855',N'8468856',N'8468857',N'8468872',N'8468878',N'8468879',N'8468880',N'8468881',N'8468882',N'8468883',N'8468884',N'8468885',N'8468886',N'8468887',N'8468888',N'8468898',N'8468899',N'8468900',N'8468901',N'8468902',N'8468903',N'8468904',N'8468905',N'8468906',N'8468907',N'8468908',N'8468909',N'8468910',N'8468911',N'8468912',N'8468913',N'8468914',N'8468915',N'8468916',N'8468889',N'8468890',N'8468891',N'8468892',N'8468893',N'8468894',N'8468895',N'8468896',N'8468918',N'8468919',N'8468920',N'8468921',N'8468922',N'8468925',N'8468926',N'8468927',N'8468928',N'8468929',N'8468930',N'8468923',N'8468934',N'8468932',N'8468936',N'8468937',N'8468873',N'8468874',N'8468939',N'8468940',N'8468941',N'8468942',N'8468943',N'8468944',N'8468945',N'8468947',N'8468948',N'8468956',N'8468957',N'8468958',N'8468959',N'8468960',N'8468961',N'8468962',N'8468963',N'8468949',N'8468950',N'8468951',N'8468952',N'8468953',N'8468954',N'8468875',N'8468876',N'8468965',N'8468845',N'8468967',N'8468968',N'8468969',N'8468970',N'8468971',N'8468972',N'8468974',N'8468846',N'8468976',N'8468977',N'8468978',N'8468979',N'8468980',N'8468984',N'8468981',N'8468982',N'8468983',N'8468985',N'8468987',N'8469162',N'8469165',N'8469166',N'8469167',N'8469168',N'8469169',N'8469171',N'8469172',N'8469175',N'8469174',N'8469176',N'8469177',N'8469178',N'8469179',N'8469181',N'8469182',N'8469183',N'8469185',N'8469186',N'8469188',N'8469190',N'8469163',N'8469192',N'8469193',N'8469194',N'8469195',N'8469196',N'8469197',N'8469198',N'8469203',N'8469204',N'8469205',N'8469206',N'8469207',N'8469208',N'8469209',N'8469210',N'8469211',N'8469212',N'8469199',N'8469200',N'8469201',N'8469214',N'8469215',N'8469216',N'8469217',N'8469219',N'8469221',N'8469222',N'8469224',N'8469226',N'8469236',N'8469237',N'8469239',N'8469230',N'8469241',N'8469231',N'8469232',N'8469243',N'8469244',N'8469246',N'8469247',N'8469248',N'8469249',N'8469250',N'8469251',N'8469252',N'8469233',N'8469234',N'8469227',N'8469254',N'8469228',N'8469256',N'8469258',N'8469260',N'8469262',N'8469264',N'8469265',N'8469279',N'8469280',N'8469281',N'8469282',N'8469283',N'8469284',N'8469266',N'8469267',N'8469268',N'8469269',N'8469270',N'8469271',N'8469272',N'8469273',N'8469274',N'8469275',N'8469276',N'8469277',N'8469286',N'8469287',N'8469288',N'8469289',N'8469291',N'8469293',N'8469294',N'8469295',N'8469296',N'8469297',N'8469298',N'8469299',N'8469300',N'8469301',N'8469302',N'8469303',N'8469304',N'8469305',N'8469306',N'8469307',N'8469308',N'8469309',N'8469310',N'8469337',N'8469338',N'8469339',N'8469340',N'8469341',N'8469342',N'8469343',N'8469344',N'8469345',N'8469346',N'8469347',N'8469348',N'8469349',N'8469350',N'8469351',N'8469353',N'8469352',N'8469354',N'8469355',N'8469356',N'8469357',N'8469358',N'8469359',N'8469360',N'8469361',N'8469362',N'8469363',N'8469364',N'8469365',N'8469366',N'8469367',N'8469368',N'8469369',N'8469370',N'8469371',N'8469372',N'8469373',N'8469374',N'8469375',N'8469376',N'8469377',N'8469311',N'8469312',N'8469313',N'8469314',N'8469315',N'8469316',N'8469317',N'8469318',N'8469319',N'8469320',N'8469321',N'8469322',N'8469323',N'8469324',N'8469325',N'8469326',N'8469327',N'8469328',N'8469329',N'8469330',N'8469331',N'8469332',N'8469333',N'8469334',N'8469335',N'8469379',N'8469380',N'8469382',N'8469383',N'8469384',N'8469385',N'8469386',N'8469387',N'8469388',N'8469389',N'8469390',N'8469391',N'8469392',N'8469393',N'8469394',N'8469395',N'8469396',N'8469397',N'8469398',N'8469399',N'8469400',N'8469401',N'8469402',N'8469403',N'8469404',N'8469406',N'8469407',N'8469408',N'8469409',N'8469410',N'8469411',N'8469412',N'8469413',N'8469414',N'8469415',N'8469416',N'8469417',N'8469418',N'8469419',N'8469420',N'8469422',N'8469421',N'8469423',N'8469424',N'8469425',N'8469426',N'8469427',N'8469429',N'8469430',N'8469431',N'8469432',N'8469433',N'8469434',N'8469435',N'8469436',N'8469437',N'8469438',N'8469439',N'8469440',N'8469442',N'8469444',N'8469456',N'8469457',N'8469458',N'8469459',N'8469460',N'8469461',N'8469462',N'8469463',N'8469464',N'8469446',N'8469447',N'8469448',N'8469449',N'8469450',N'8469451',N'8469452',N'8469453',N'8469454',N'8469481',N'8469466',N'8469467',N'8469468',N'8469469',N'8469470',N'8469471',N'8469472',N'8469473',N'8469474',N'8469475',N'8469476',N'8469477',N'8469478',N'8469479',N'8469480',N'8469483',N'8469484',N'8469485',N'8469486',N'8471004',N'8471005',N'8471006',N'8471007',N'8471008',N'8471019',N'8471020',N'8471021',N'8471022',N'8471023',N'8471009',N'8471010',N'8471011',N'8471012',N'8471013',N'8471025',N'8471026',N'8471014',N'8471016',N'8471015',N'8471017',N'8466575',N'8466576',N'8466577',N'8466578',N'8466579',N'8466580',N'8466581',N'8466582',N'8466584',N'8466585',N'8466587',N'8466589') and metric_id in (N'3',N'53',N'185')) reThis lead me to execute select count(*) from sonar.snapshotsre= 16003Which I find to be a very high number?What is also interesting is that rendering the dashboard for a new project (about a month of analysis) takes half the time of a project that has been analysed for a couple of years now. We have about 20-30 projects, but only a few of them are really active. I would say only about 3-4 active projects. The rest are only analysed approx 5-10 times a year, so these projects should not really accumulate snapshots. The developers on the team are getting frustrated by the page loading time, so any help on tuning this is much appreciated!Is there a way of cleaning the Sonar DB for all history?UpdateThe dashboard containsulliscale ratinglitechnical debtlidir tangle indedliunit testsliintegrations testslicomplexitylidocumentationlilines of codeliduplicationslifalse positivesliquality gatelimost violated ruleslimost violated componentslihotspots by issueslitechnical debt pyramidlieventsliissueslimy unresolved issuesliunresolved issues pr assigneeliissues og metricslihistory table x 2liclirrliproject motion chartliproject file bubble chartI have created a more focused dashboard, containing fewer widgets. This has reduced the dashboard loading time by 50%, down to 10-11 seconds. Better, but also rather slow. The widgets for this dashboard areulliquality gatelisqale ratinelitechnical debtliunit testsliintegration testslidir tangle indexlicomplexitylihistory tablelifalse positivesliissuesliunresolved issues per assigneelimy unresolved issueslimost violated ruleslimost violated componentslitechnical debtFor the newer, smaller project, loading time is reduced from about 12 to 9 seconds, so I'm not seeing a doubleing of performance here.Log can be found a href=http:/astebin.com/zJcEH4Ex rel=nofollowhttp:/astebin.com/zJcEH4Ex/a",Not-TD-related,SonarQube,,,,0.077,0.856,0.067,-0.7591
28023276,Sonarqube 5.0 install error,"When installing sonarqube 5.0, I got following error messages while starting SonarQube on windows7 with mysql 5.6.22: Launching a JVM...Wrapper (Version 3.2.3) http://wrapper.tanukisoftware.orgCopyright 1999-2006 Tanuki Software, Inc. All Rights Reserved.2015.01.19 11:18:57 INFO app[o.s.p.m.JavaProcessLauncher] Launch process[search]: C:\Tools\jdk1.7.0_71\jre\bin\java -Djava.awt.headless=true -Xmx1G -Xms256m -Xss256k -Djava.net.preferIPv4Stack=true -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+HeapDumpOnOutOfMemoryError -Djava.io.tmpdir=C:\Tools\sonarqube-5.0\temp -cp .b/common/*;.b/search/* org.sonar.search.SearchServer C:\Users\li2\AppData\Local\Temp\sq-process2755720839215931323properties2015.01.19 11:19:09 INFO sea[o.s.p.ProcessEntryPoint] Starting searc015.01.19 11:19:09 INFO sea[o.s.s.SearchServer] Starting Elasticsearch[sonarqube] on port 90012015.01.19 11:19:09 WARN sea[o.s.s.SearchSettings] Elasticsearch HTTP connector is enabled on port 9010. MUST NOT BE USED INTO PRODUCTION2015.01.19 11:19:09 INFO sea[o.elasticsearch.node] [sonar-1421662737113] version[1.1.2], pid[8464], build[e511f7b/2014-05-22T12:27:39Z]2015.01.19 11:19:09 INFO sea[o.elasticsearch.node] [sonar-1421662737113] initializing ...2015.01.19 11:19:09 INFO sea[o.e.plugins] [sonar-1421662737113] loaded [], sites []2015.01.19 11:19:11 INFO sea[o.elasticsearch.node] [sonar-1421662737113] initialized2015.01.19 11:19:11 INFO sea[o.elasticsearch.node] [sonar-1421662737113] starting ...2015.01.19 11:19:27 INFO sea[o.e.transport] [sonar-1421662737113] bound_address {inet[/0.0.0.0:9001]}, publish_address {inet[/192.168.0.107:9001]}2015.01.19 11:19:30 INFO sea[o.e.cluster.service] [sonar-1421662737113] new_master [sonar-1421662737113][RB8i_Ar8Rv-Do_15hhhWtQ][LI21][inet[/192.168.0.107:9001]]{rack_id=sonar-1421662737113}, reason: zen-disco-join (elected_as_master)2015.01.19 11:19:51 WARN sea[o.e.cluster.service] [sonar-1421662737113] failed to connect to node [[sonar-1421662737113][RB8i_Ar8Rv-Do_15hhhWtQ][LI21][inet[/192.168.0.107:9001]]{rack_id=sonar-1421662737113}]org.elasticsearch.transport.ConnectTransportException: [sonar-1421662737113][inet[/192.168.0.107:9001]] connect_timeout[30s] at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:719) ~[elasticsearch-1.1.2.jar:na] at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:648) ~[elasticsearch-1.1.2.jar:na] at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:616) ~[elasticsearch-1.1.2.jar:na] at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:129) ~[elasticsearch-1.1.2.jar:na] at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:405) ~[elasticsearch-1.1.2.jar:na] at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:134) [elasticsearch-1.1.2.jar:na] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_71] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_71] at java.lang.Thread.run(Thread.java:745) [na:1.7.0_71]Caused by: java.net.ConnectException: Connection timed out: no further information: /192.168.0.107:9001 at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[na:1.7.0_71] at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739) ~[na:1.7.0_71] at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:150) ~[elasticsearch-1.1.2.jar:na] at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105) ~[elasticsearch-1.1.2.jar:na] at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79) ~[elasticsearch-1.1.2.jar:na] at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:318) ~[elasticsearch-1.1.2.jar:na] at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42) ~[elasticsearch-1.1.2.jar:na] at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) ~[elasticsearch-1.1.2.jar:na] at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42) ~[elasticsearch-1.1.2.jar:na] ... 3 common frames omitted2015.01.19 11:19:51 INFO sea[o.e.discovery] [sonar-1421662737113] sonarqube/RB8i_Ar8Rv-Do_15hhhWtQ2015.01.19 11:19:51 INFO sea[o.elasticsearch.http] [sonar-1421662737113] bound_address {inet[/127.0.0.1:9010]}, publish_address {inet[/127.0.0.1:9010]}2015.01.19 11:19:52 INFO sea[o.e.gateway] [sonar-1421662737113] recovered [4] indices into cluster_state2015.01.19 11:19:52 INFO sea[o.elasticsearch.node] [sonar-1421662737113] started2015.01.19 11:19:53 INFO app[o.s.p.m.Monitor] Process[search] is up2015.01.19 11:19:53 INFO app[o.s.p.m.JavaProcessLauncher] Launch process[web]: C:\Tools\jdk1.7.0_71\jre\bin\java -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djruby.management.enabled=false -Xmx768m -XX:MaxPermSize=160m -XX:+HeapDumpOnOutOfMemoryError -Djava.net.preferIPv4Stack=true -Djava.io.tmpdir=C:\Tools\sonarqube-5.0\temp -cp .b/common/*;.b/server/*;C:\Tools\sonarqube-5.0\lib\jdbc\mysql\mysql-connector-java-5.1.27.jar org.sonar.server.app.WebServer C:\Users\li2\AppData\Local\Temp\sq-process1889452272417488373properties2015.01.19 11:20:06 INFO web[o.s.p.ProcessEntryPoint] Starting web2015.01.19 11:20:06 INFO web[o.s.s.app.Connectors] HTTP connector is enabled on port 90002015.01.19 11:20:06 INFO web[o.s.s.app.Webapp] Webapp directory: C:\Tools\sonarqube-5.0\web2015.01.19 11:20:07 INFO web[o.e.plugins] [sonar-1421662737113] loaded [], sites []2015.01.19 11:20:19 INFO web[o.s.s.p.ServerImpl] SonarQube Server / 5.0 / dc62506bf3b331ec19c053e225e415d164ee60b02015.01.19 11:20:19 INFO web[o.s.c.p.Database] Create JDBC datasource for jdbc:mysql://localhost:3306/sonar?useUnicode=true characterEncoding=utf8 rewriteBatchedStatements=true useConfigs=maxPerformance2015.01.19 11:20:20 INFO web[o.s.s.p.DefaultServerFileSystem] SonarQube home: C:\Tools\sonarqube-5.02015.01.19 11:20:20 INFO web[o.s.a.u.TimeProfiler] Install plugins...2015.01.19 11:20:20 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin Findbugs / 3.1 / adc09c989cebc856d44239116a00ab0b602b08512015.01.19 11:20:20 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin Duplications / 5.0 / dc62506bf3b331ec19c053e225e415d164ee60b02015.01.19 11:20:20 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin Git / 5.0 / dc62506bf3b331ec19c053e225e415d164ee60b02015.01.19 11:20:20 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin Core / 5.0 / dc62506bf3b331ec19c053e225e415d164ee60b02015.01.19 11:20:20 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin Java / 2.8 / 20a3d682b1334eb1857e7bc8a40e11f04fed95282015.01.19 11:20:20 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin SVN / 5.0 / dc62506bf3b331ec19c053e225e415d164ee60b02015.01.19 11:20:20 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin English Pack / 5.0 / dc62506bf3b331ec19c053e225e415d164ee60b02015.01.19 11:20:20 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin Email notifications / 5.0 / dc62506bf3b331ec19c053e225e415d164ee60b02015.01.19 11:20:20 INFO web[o.s.a.u.TimeProfiler] Install plugins done: 234 ms2015.01.19 11:20:21 INFO web[o.s.s.p.RailsAppsDeployer] Deploy Ruby on Rails applications2015.01.19 11:20:21 INFO web[jruby.rack] jruby 1.7.9 (ruby-1.8.7p370) 2013-12-06 87b108a on Java HotSpot(TM) 64-Bit Server VM 1.7.0_71-b14 [Windows 7-amd64]2015.01.19 11:20:21 INFO web[jruby.rack] using a shared (threadsafe!) runtime2015.01.19 11:20:29 INFO web[DbMigration] == InitialSchema: migrating ==================================================2015.01.19 11:20:29 INFO web[DbMigration] -- create_table(:projects, {})2015.01.19 11:20:29 INFO web[DbMigration] -   0.0310s2015.01.19 11:20:29 INFO web[DbMigration] -   0 rows................2015.01.19 11:20:50 INFO web[o.s.j.s.AbstractDatabaseConnector] Initializing Hibernate2015.01.19 11:20:51 INFO web[o.s.s.p.UpdateCenterClient] Update center: http://update.sonarsource.org/update-center.properties (HTTP proxy: xxx)2015.01.19 11:20:52 INFO web[o.s.s.n.NotificationService] Notification service started (delay 60 sec.)2015.01.19 11:20:52 INFO web[o.s.s.s.IndexSynchronizer] Index rules for updates after Sun Jan 18 20:37:25 CET 20152015.01.19 11:20:52 INFO web[o.s.s.s.IndexSynchronizer] Index activeRules for updates after Sun Jan 18 20:37:27 CET 20152015.01.19 11:20:52 INFO web[o.s.s.s.IndexSynchronizer] Index sonarLogs for updates after null2015.01.19 11:20:52 INFO web[o.s.s.s.IndexSynchronizer] Index issues2015.01.19 11:20:52 INFO web[o.s.s.s.IndexSynchronizer] Index source files2015.01.19 11:20:52 INFO web[o.s.a.u.TimeProfiler] Load metrics...2015.01.19 11:20:52 INFO web[o.s.s.s.RegisterMetrics] Cleaning quality gate conditions2015.01.19 11:20:52 INFO web[o.s.a.u.TimeProfiler] Load metrics done: 234 ms2015.01.19 11:20:52 INFO web[o.s.s.s.RegisterDebtModel] Register technical debt model...2015.01.19 11:20:52 INFO web[o.s.s.s.RegisterDebtModel] Register technical debt model done: 78 ms2015.01.19 11:20:52 INFO web[o.s.a.u.TimeProfiler] Register rules...2015.01.19 11:22:57 WARN sea[o.e.cluster.service] [sonar-1421662737113] failed to reconnect to node [sonar-1421662737113][RB8i_Ar8Rv-Do_15hhhWtQ][LI21][inet[/192.168.0.107:9001]]{rack_id=sonar-1421662737113}org.elasticsearch.transport.ConnectTransportException: [sonar-1421662737113][inet[/192.168.0.107:9001]] connect_timeout[30s] at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:719) ~[elasticsearch-1.1.2.jar:na] at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:648) ~[elasticsearch-1.1.2.jar:na] at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:616) ~[elasticsearch-1.1.2.jar:na] at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:129) ~[elasticsearch-1.1.2.jar:na] at org.elasticsearch.cluster.service.InternalClusterService$ReconnectToNodes.run(InternalClusterService.java:516) ~[elasticsearch-1.1.2.jar:na] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_71] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_71] at java.lang.Thread.run(Thread.java:745) [na:1.7.0_71]Caused by: java.net.ConnectException: Connection timed out: no further information: /192.168.0.107:9001 at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[na:1.7.0_71] at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739) ~[na:1.7.0_71]reI have searched for similar questions but with no success.Does someone have an idea how to fix that?Thanks!",Not-TD-related,SonarQube,,,,0.033,0.962,0.005,-0.9192
28068499,Sonarqube 4.5.1 - 0 Files indexed,"i want to analyse the putty source code with sonarqube 4.5.1 and sonar-runner 2.4.To start the server, i execute iStartSonar.bat/i from briE:\BA_MW\sonarqube-4.5.1\sonarqube-4.5.1\bin\windows-x86-32/iThe source files to analyse are atbriE:\BA_MW\Projects\putty-0.63\putty_source/iThe isonar-project.properties/i is located atbriE:\BA_MW\Projects\putty-0.63/ibrand looks like this:br sonar.projectKey=my:projectsonar.projectName=Putty_Sonar_Xsonar.projectVersion=1.0sonar.sources=putty_sourcesonar.sourceEncoding=UTF-8sonar.my.property=valuerealso from briE:\BA_MW\Projects\putty-0.63/ibri execute the isonar-runner.bat/iand this is what i get: E:\BA_MW\Projects\putty-0.63  sonar-runner.batE:\BA_MW\sonarqube-4.5.1\sonar-runner-dist-2.4\sonar-runner-2.4SonarQube Runner 2.4Java 1.7.0_03 Oracle Corporation (64-bit)Windows 7 6.1 amd64INFO: Runner configuration file: E:\BA_MW\sonarqube-4.5.1\sonar-runner-dist-2.4\sonar-runner-2.4\conf\sonar-runner.propertiesINFO: Project configuration file: E:\BA_MW\Projects\putty-0.63\sonar-project.propertiesINFO: Default locale: en_US, source code encoding: UTF-8INFO: Work directory: E:\BA_MW\Projects\putty-0.63\.\.sonarINFO: SonarQube Server 4.5.113:51:13.072 INFO - Load global referentials...13:51:13.197 INFO - Load global referentials done: 140 ms13:51:13.213 INFO - User cache: C:\Users\admin\.sonar\cache13:51:13.213 INFO - Install plugins13:51:13.337 INFO - Install JDBC driver13:51:13.337 INFO - Create JDBC datasource for jdbc::tcp://localhost/sonar13:51:14.494 INFO - Initializing Hibernate13:51:15.867 INFO - Load project referentials...13:51:16.101 INFO - Load project referentials done: 234 ms13:51:16.101 INFO - Load project settings13:51:16.616 INFO - Loading technical debt model...13:51:16.647 INFO - Loading technical debt model done: 31 ms13:51:16.662 INFO - Apply project exclusions13:51:16.834 INFO - ------------- Scan Putty_Sonar_X13:51:16.850 INFO - Load module settings13:51:17.146 INFO - Loading rules...13:51:17.661 INFO - Loading rules done: 515 ms13:51:17.708 INFO - Configure Maven plugins13:51:17.848 INFO - Compare to previous analysis (2015-01-21)13:51:17.879 INFO - Compare over 30 days (2014-12-22, analysis of 2014-12-23 13:18:42.154)13:51:17.879 INFO - No quality gate is configured.13:51:18.035 INFO - Base dir: E:\BA_MW\Projects\putty-0.63\.13:51:18.035 INFO - Working dir: E:\BA_MW\Projects\putty-0.63\.\.sonar13:51:18.035 INFO - Source paths: putty_source13:51:18.035 INFO - Source encoding: UTF-8, default locale: en_US13:51:18.035 INFO - Index files13:51:18.316 INFO - 0 files indexed13:51:18.332 INFO - Sensor QProfileSensor...13:51:18.347 INFO - Sensor QProfileSensor done: 15 ms13:51:18.347 INFO - Sensor InitialOpenIssuesSensor...13:51:18.363 INFO - Sensor InitialOpenIssuesSensor done: 16 ms13:51:18.363 INFO - Sensor ProjectLinksSensor...13:51:18.363 INFO - Sensor ProjectLinksSensor done: 0 ms13:51:18.363 INFO - Sensor VersionEventsSensor...13:51:18.378 INFO - Sensor VersionEventsSensor done: 15 ms13:51:18.378 INFO - Sensor FileHashSensor...13:51:18.378 INFO - Sensor FileHashSensor done: 0 ms13:51:18.378 INFO - Sensor CPD Sensor (wrapped)...13:51:18.378 INFO - Sensor CPD Sensor (wrapped) done: 0 ms13:51:18.690 INFO - Execute decorators...13:51:18.800 INFO - Store results in database13:51:18.878 INFO - ANALYSIS SUCCESSFUL, you can browse http://localhost:9000/dashboard/index/my:project13:51:18.940 INFO - Executing post-job class org.sonar.plugins.core.issue.notification.SendIssueNotificationsPostJob13:51:18.940 INFO - Executing post-job class org.sonar.plugins.core.batch.IndexProjectPostJob13:51:18.956 INFO - Executing post-job class org.sonar.plugins.dbcleaner.ProjectPurgePostJob13:51:18.971 INFO - -   Keep one snapshot per day between 2014-12-24 and 2015-01-2013:51:18.971 INFO - -   Keep one snapshot per week between 2014-01-22 and 2014-12-2413:51:18.971 INFO - -   Keep one snapshot per month between 2010-01-27 and 2014-01-2213:51:18.971 INFO - -   Delete data prior to: 2010-01-2713:51:18.971 INFO - -   Clean Putty_Sonar_X [id=1]13:51:18.987 INFO -   - Clean snapshot 115INFO: ------------------------------------------------------------------------INFO: EXECUTION SUCCESSINFO: ------------------------------------------------------------------------Total time: 6.585sFinal Memory: 17M/522MINFO: ------------------------------------------------------------------------reNotice there have been b13:51:18.316 INFO - 0 files indexed/bbrThe sonarqube dashboard running on localhost displays just fine, but of course with no data in it, because nothing was actually analysed.I dont know what i did wrong.brBest regardsMarty",Not-TD-related,SonarQube,,,,0.02,0.948,0.032,0.3435
28103672,unable to upload the project in Sonarqube while running sonar-runner,"I am using Ubuntu 14.04 lts, Os type 32-bit, SonarQube 4.5.2, Sonar-runner 2.4, java version 1.7.0_65While Running Sonar-runner in terminal it Shows Following Error: SonarQube Runner 2.4Java 1.7.0_65 Oracle Corporation (32-bit)Linux 3.13.0-24-generic i386INFO: Runner configuration file: /home/musaddiq/Documents/Sonar/sonar-runner-2.4/conf/sonar-runner.propertiesINFO: Project configuration file: /home/musaddiq/Documents/SonarTest/sonar-project.propertiesINFO: Default locale: en_US, source code encoding: UTF-8INFO: Work directory: /home/musaddiq/Documents/SonarTest/./.sonarINFO: SonarQube Server 4.5.210:44:50.726 INFO - Load global referentials...10:44:51.192 INFO - Load global referentials done: 470 ms10:44:51.210 INFO - User cache: /root/.sonar/cache10:44:51.230 INFO - Install plugins10:44:51.498 INFO - Install JDBC driver10:44:51.535 INFO - Create JDBC datasource for jdbc:mysql://localhost:3306/sonar?useUnicode=true characterEncoding=utf810:44:54.369 INFO - Initializing Hibernate10:44:57.521 INFO - Load project referentials...10:44:57.673 INFO - Load project referentials done: 152 ms10:44:57.674 INFO - Load project settings10:44:58.599 INFO - Loading technical debt model...10:44:58.649 INFO - Loading technical debt model done: 49 ms10:44:58.652 INFO - Apply project exclusions10:44:59.218 INFO - ------------- Scan SONARTEST110:44:59.242 INFO - Load module settings10:44:59.495 INFO - Language is forced to javaINFO: ------------------------------------------------------------------------INFO: EXECUTION FAILUREINFO: ------------------------------------------------------------------------Total time: 10.333sFinal Memory: 13M/199MINFO: ------------------------------------------------------------------------ERROR: Error during Sonar runner executionERROR: Unable to execute SonarERROR: Caused by: You must install a plugin that supports the language 'java'ERROR: ERROR: To see the full stack trace of the errors, re-run SonarQube Runner with the -e switch.ERROR: Re-run SonarQube Runner using the -X switch to enable full debug logging.root@EIT-A21:/home/musaddiq/Documents/SonarTest exitexitreUsing codesonar-runner -e ERROR: Error during Sonar runner executionorg.sonar.runner.impl.RunnerException: Unable to execute Sonar at org.sonar.runner.impl.BatchLauncher$1.delegateExecution(BatchLauncher.java:91) at org.sonar.runner.impl.BatchLauncher$1.run(BatchLauncher.java:75) at java.security.AccessController.doPrivileged(Native Method) at org.sonar.runner.impl.BatchLauncher.doExecute(BatchLauncher.java:69) at org.sonar.runner.impl.BatchLauncher.execute(BatchLauncher.java:50) at org.sonar.runner.api.EmbeddedRunner.doExecute(EmbeddedRunner.java:102) at org.sonar.runner.api.Runner.execute(Runner.java:100) at org.sonar.runner.Main.executeTask(Main.java:70) at org.sonar.runner.Main.execute(Main.java:59) at org.sonar.runner.Main.main(Main.java:53)Caused by: You must install a plugin that supports the language 'java'ERROR: ERROR: Re-run SonarQube Runner using the -X switch to enable full debug logging.re",Not-TD-related,SonarQube,,,,0.106,0.858,0.036,-0.959
28154607,Groovy project - Sonar - Publish project and Unit + Integration Test code coverage data,"I have:br/1. Gradle 1.6br/2. SonarQube instance 5.0 (also have 4.1+ instances)br/3. sonar-runner (aka SonarQube runner) version: 2.4br/4. Groovy Version: 2.3.3 JVM: 1.7.0_40 Vendor: Oracle Corporation OS: LinuxI have project's with Java, Java + Groovy or totally Groovy based project.All of these projects have valid Unit and non-Unit tests (Integration, Selenium etc). I'm also running various static analysic tools for both Java/Groovy (pmd, findbugs, checkstyle, codenarc etc).For a Java based project, when I run sonarRunner (Gradle task) OR sonar-runner, I see valid data in project's Sonar dashboard for everything (including combined code coverage and other project health info). So, everything works for a JAVA based project.The same though, is not working for a Groovy based project. i.e. when I pass sonar.language=grvy for a Groovy based project and run Sonar analysis, I do NOT get Unit and IT test coverage as it says 0% coverage OR it doesn't even LIST those in Sonar project's dashboard but I successfully get project health info (issues, lines of code, etc etc). When I pass the above sonar language variable as sonar.language=java for this Groovy project, I do NOT see Groovy project's data info (issues, lines of code etc etc) and any code coverage info for Unit / Integration tests and their combined tests. I have valid jacoco exec files for both Unit tests and Integration tests (jacocoIT.exec is created after jacocoagent is attached to the target Tomcat JVM and after Tomcat instance is stopped).Any ideas! why sonar is not working for a Groovy based project OR for a project which has both Java+Groovy (source Java, tests in Groovy or vice versa or mixed). PS: I tried sonar.language=grvy,java OR sonar.language=java,grvy BUT, it didn't make any improvement on the project's sonar dashboard.emThe latest SonarQube version that I have (5.0) does support multiple language support/em.Sonar's emProject Motion Chart/em plugin also doesn't show any info as well even though Lines of Code is showing up at the right side (when sonar.languages is passed as grvy).img src=https://i.stack.imgur.com/seHN3.png alt=enter image description hereWhen I pass sonar.language=java I get, here Project Motion Chart is showing nothing (not even a blank graph) says No Data. All other project health related info is gone too (Technical debt etc fields says 0):img src=https://i.stack.imgur.com/WOkQ5.png alt=enter image description hereWith the latest SonarQube version, I see there are new sonar.*.* fields and I'm trying to find if I'm missing to provide a field or it's correct value.br/br/br/brOK.. what happens??? when I use emSonarQube instance version 4.1.2/em (instead of 5.0)When I use sonar.language=javaI see some info and Unit test coverage says 0% but Unit test success says 100% successful. Even though I have valid jacoco IT exec file for Integratiojn tests, it still not showing that widget info.img src=https://i.stack.imgur.com/5bFhp.png alt=enter image description herebr/br/When emSonarQube instance is 4.1.2/em and if I set sonar.language=grvy, I do NOT see any Unit tests coverage or IT coverage of state of tests being successful % at all:img src=https://i.stack.imgur.com/hvWey.png alt=enter image description hereThis is what I have in my project's sonar-project.properties file (when I use sonar-runner utility). sonar.projectName=GradlePluginsonar.projectKey=com:company:projectABC:GradlePluginsonar.projectVersion=1.0 optional descriptionsonar.projectDescription=ContainerSvc Business Servicesonar.language=grvy,javasonar.language=javaTells SonarQube that the code coverage tool by unit tests is JaCoCosonar.java.coveragePlugin=jacocoTells SonarQube to reuse existing reports for unit tests execution and coverage reportssonar.dynamicAnalysis=reuseReportsTells SonarQube where the unit tests execution reports aresonar.surefire.reportsPath=build/test-results/UT Some properties that will be inherited by the modulessonar.sources=src/main/groovy,src/main/java,src/test/java,src/test/groovy,src/java-test,src/groovy-test Sonar Unit Test Report pathsonar.jacoco.reportPath=build/jacoco/UT/jacocoUT.exec Sonar Integration Test Report Pathsonar.jacoco.itReportPath=build/jacoco/IT/jacocoIT.execsonar.jacoco.itReportPath=build/jacoco/UT/jacocoUT.exec Sonar Binariessonar.binaries=build/classes/mainsonar.java.binaries=build/classes/mainsonar.groovy.binaries=build/classes/mainsonar.sources=src/main/groovysonar.tests=src/test/groovy Encoding of the source codesonar.sourceEncoding=UTF-8sonar.scm.url=scm:svn:http://kobaloki/Core/GradlePlugin/trunksonar.junit.reportsPath=build/test-results/UTsonar.java.coveragePlugin=jacocosonar.groovy.coveragePlugin=jacocosonar.grvy.coveragePlugin=jacocoreI used/tweaked the above values many time with different values while running sonar-runner.I used the same values with -D / -P parameters when I run sonarRunner task in Gradle. Note: SonarQube 5.0 won't work with Gradle (1.6) version (that I'm using) as I get an error about Failed to download Libraries etc. (this error won't come if I use Gradle 2.2 version).br/One other point I noticed is that, even though I'm using Groovy compile option debug=true for compiling both Groovy project's source and tests code, while doing sonar-runner (with both SonarQube instance 4.1.2 or 5.0 isntances) --or running emsonarRunner/em Gradle task (with 4.1.2), I see the following lines in the analysis output. 15:32:20.647 INFO - Analysing roduction/jenkins/AKS/ma/GradlePlugin/build/jacoco/IT/jacocoIT.exec15:32:21.025 WARN - Coverage information was not collected. Perhaps you forget to include debug information into compiled classes?reand 15:32:24.681 INFO - Analysing roduction/jenkins/AKS/ma/GradlePlugin/build/jacoco/UT/jacocoUT.exec15:32:24.791 WARN - Coverage information was not collected. Perhaps you forget to include debug information into compiled classes?15:32:24.792 INFO - Sensor JaCoCoSensor done: 112 msre",Not-TD-related,SonarQube,,,,0.046,0.899,0.055,0.8918
28371203,SonarQube doesn't store all results in the database?,"I am aware I should not use the database directly from SonarQube, but this is a one-shot complex thing, and saves me days if I can do it directly from the database.I need to know the amount of classes per project, where the amount of lines is less than 200. So far no problem creating this in SQL.Only problem I have: for 2 projects, this information isn't stored at all in the database! In the GUI from SonarQube I can see this measure for each file, but than in the database these files have only 1 measures stored (technical debt).My guess is that for some strange reasons these measures are calculated on the fly for this project? Could that be? And is there a way to force SonarQube to store proejct measures for each file in the database? I tried with the sonar.analysis.mode=analysis parameter but that didn't work?Thanks a lot and regards,Pieter",Not-TD-related,SonarQube,,,,0.095,0.887,0.018,-0.9146
28927113,Performing a PUT update in dojo using GitHub api returns 400: problems parsing JSON,"Basically I am trying to update a file on Github using the api. When I do this in Poster it works no problem and I get a response from the server. When sending the exact same params in an xhr put request however, I receive a 400: Bad request error - Problems parsing JSON. Heres my request:   var contentArgs = { message: Auto TODO commit updating technical debt, committer: { name: TODO, email: tododebttracker@gmail.com }, content: bXkgdXBkYXRlZCBmaWxlIGNvbnRlbnRz, sha: fb617c9e42866ca2446545e0c2725048f6f9530c }; xhr.put({ // The URL to request url : url, headers : {Authorization : token 289543b6aca2454165451a1afcf115fa9a97}, content : contentArgs, handleAs : json, load : lang.hitch(this,function(result) { deferred.resolve({hasError : false, response: result}); }), error : lang.hitch(this,function(result) { deferred.resolve({hasError : true, response: result }); }) });reI've tried every possible variation of the contentArgs JSON and I have also tried using JSON.stringify on the contentArgs but having no joy. Any help is greatly appreciated. Thank you",Not-TD-related,SonarQube,,,,0.104,0.759,0.137,0.8752
28966957,How to fix upgrade to SonarQube 5?,"The upgrade from SonarQube 4.0 to 5.0.1 fails during the database upgrade. I followed a href=http://docs.sonarqube.org/display/SONAR/Upgrading rel=nofollowthese instructions/a, but the setup does not complete:  Error updating database. Cause: java.sql.SQLIntegrityConstraintViolationException: ORA-00001: unique constraint (SONAR.RULES_REPO_KEY) violated The error may involve org.sonar.core.rule.RuleMapper.insert-Inline The error occurred while setting parameters SQL: insert into rules (plugin_rule_key, plugin_name, description, description_format, status, name, plugin_config_key, priority, is_template, language, template_id, characteristic_id, default_characteristic_id, remediation_function, default_remediation_function, remediation_coeff, default_remediation_coeff, remediation_offset, default_remediation_offset, effort_to_fix_description, tags, system_tags, note_data, note_user_login, note_created_at, note_updated_at, created_at, updated_at) values (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?) Cause: java.sql.SQLIntegrityConstraintViolationException: ORA-00001: unique constraint (SONAR.RULES_REPO_KEY) violated org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:26) org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:154) org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:141) org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:51) org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:52) com.sun.proxy.$Proxy79.insert(Unknown Source) org.sonar.server.rule.db.RuleDao.doInsert(RuleDao.java:58) org.sonar.server.rule.db.RuleDao.doInsert(RuleDao.java:36) org.sonar.server.db.BaseDao.insert(BaseDao.java:243) org.sonar.server.db.BaseDao.insert(BaseDao.java:218) org.sonar.server.rule.RegisterRules.createRuleDto(RegisterRules.java:224) org.sonar.server.rule.RegisterRules.registerRule(RegisterRules.java:130) org.sonar.server.rule.RegisterRules.start(RegisterRules.java:106) sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) java.lang.reflect.Method.invoke(Method.java:483) org.picocontainer.lifecycle.ReflectionLifecycleStrategy.invokeMethod(ReflectionLifecycleStrategy.java:110) org.picocontainer.lifecycle.ReflectionLifecycleStrategy.start(ReflectionLifecycleStrategy.java:89) org.picocontainer.injectors.AbstractInjectionFactory$LifecycleAdapter.start(AbstractInjectionFactory.java:84) org.picocontainer.behaviors.AbstractBehavior.start(AbstractBehavior.java:169) org.picocontainer.behaviors.Stored$RealComponentLifecycle.start(Stored.java:132) org.picocontainer.behaviors.Stored.start(Stored.java:110) org.picocontainer.DefaultPicoContainer.potentiallyStartAdapter(DefaultPicoContainer.java:1015) org.picocontainer.DefaultPicoContainer.startAdapters(DefaultPicoContainer.java:1008) org.picocontainer.DefaultPicoContainer.start(DefaultPicoContainer.java:766) org.sonar.api.platform.ComponentContainer.startComponents(ComponentContainer.java:92) org.sonar.server.platform.ServerComponents$1.doPrivileged(ServerComponents.java:665) org.sonar.server.user.DoPrivileged.execute(DoPrivileged.java:43) org.sonar.server.platform.ServerComponents.executeStartupTasks(ServerComponents.java:661) org.sonar.server.platform.Platform.executeStartupTasks(Platform.java:126) org.sonar.server.platform.Platform.startLevel34Containers(Platform.java:122) org.sonar.server.platform.Platform.doStart(Platform.java:81) sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) java.lang.reflect.Method.invoke(Method.java:483) org.jruby.javasupport.JavaMethod.invokeDirectWithExceptionHandling(JavaMethod.java:440) org.jruby.javasupport.JavaMethod.invokeDirect(JavaMethod.java:304) org.jruby.java.invokers.InstanceMethodInvoker.call(InstanceMethodInvoker.java:52) org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:306) org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:136) org.jruby.ast.CallNoArgNode.interpret(CallNoArgNode.java:60) org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) org.jruby.ast.BlockNode.interpret(BlockNode.java:71) org.jruby.evaluator.ASTInterpreter.INTERPRET_METHOD(ASTInterpreter.java:74) org.jruby.internal.runtime.methods.InterpretedMethod.call(InterpretedMethod.java:139) org.jruby.internal.runtime.methods.DefaultMethod.call(DefaultMethod.java:182) org.jruby.runtime.callsite.CachingCallSite.cacheAndCall(CachingCallSite.java:306) org.jruby.runtime.callsite.CachingCallSite.call(CachingCallSite.java:136) org.jruby.ast.CallNoArgNode.interpret(CallNoArgNode.java:60) org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) org.jruby.ast.BlockNode.interpret(BlockNode.java:71) org.jruby.ast.RescueNode.executeBody(RescueNode.java:221) org.jruby.ast.RescueNode.interpret(RescueNode.java:116) org.jruby.ast.BeginNode.interpret(BeginNode.java:83) org.jruby.ast.NewlineNode.interpret(NewlineNode.java:105) org.jruby.evaluator.ASTInterpreter.INTERPRET_BLOCK(ASTInterpreter.java:112) org.jruby.runtime.InterpretedBlock.evalBlockBody(InterpretedBlock.java:384) org.jruby.runtime.InterpretedBlock.yield(InterpretedBlock.java:336) org.jruby.runtime.BlockBody.call(BlockBody.java:73) org.jruby.runtime.Block.call(Block.java:101) org.jruby.RubyProc.call(RubyProc.java:290) org.jruby.RubyProc.call(RubyProc.java:228) org.jruby.internal.runtime.RubyRunnable.run(RubyRunnable.java:97) java.lang.Thread.run(Thread.java:745)reI hope I upgraded the plugins correctly: edit: ... but I didn't.  -rwx------+ 1 pwillems Domain Users 1366553 Nov 12 2012 CSharpPluginsEcosystem-1.4.zip -rwx------+ 1 pwillems Domain Users 105 Mar 5 13:53 README.txt drwx------+ 1 Administrators Domain Users 0 Mar 6 12:41 findbugs-2.0.1 -rwx------+ 1 pwillems Domain Users 29436 Jul 12 2012 findbugs-ant.jar drwx------+ 1 pwillems Domain Users 0 Mar 10 12:58 not for 4.0 drwx------+ 1 pwillems Domain Users 0 Mar 6 16:16 obsolete Java 2.4 -rwx------+ 1 pwillems Domain Users 9205 Mar 5 12:21 sonar-branding-plugin-1.0.jar -rwx------+ 1 Administrators Domain Users 2014901 Mar 6 11:19 sonar-checkstyle-plugin-2.2.jar -rwx------+ 1 Administrators Domain Users 10325 Mar 6 11:34 sonar-cobertura-plugin-1.6.3.jar -rwx------+ 1 pwillems Domain Users 917316 Mar 6 09:42 sonar-csharp-plugin-3.3.jar -rwx------+ 1 pwillems Domain Users 7247 Nov 28 2012 sonar-csv-export-plugin-1.3.jar -rwx------+ 1 pwillems Domain Users 102668 Nov 18 2013 sonar-dotnet-fxcop-plugin-2.1.jar -rwx------+ 1 pwillems Domain Users 84620 Nov 18 2013 sonar-dotnet-gallio-plugin-2.1.jar -rwx------+ 1 pwillems Domain Users 624800 Nov 18 2013 sonar-dotnet-gendarme-plugin-2.1.jar -rwx------+ 1 pwillems Domain Users 280291 Nov 18 2013 sonar-dotnet-ndeps-plugin-2.1.jar -rwx------+ 1 pwillems Domain Users 59047 Nov 18 2013 sonar-dotnet-plugin-2.1.jar -rwx------+ 1 Administrators Domain Users 1012812 Mar 6 11:37 sonar-issues-report-plugin-1.3.jar -rwx------+ 1 Administrators Domain Users 2468589 Mar 6 11:04 sonar-java-plugin-3.0.jar -rwx------+ 1 pwillems Domain Users 30646 Feb 4 2014 sonar-ldap-plugin-1.4.jar -rwx------+ 1 pwillems Domain Users 857763 Sep 16 13:08 sonar-plsql-plugin-2.6.jar -rwx------+ 1 Administrators Domain Users 3568440 Mar 6 11:20 sonar-pmd-plugin-2.3.jar drwx------+ 1 Administrators Domain Users 0 Mar 6 12:41 sonar-runner-2.0 -rwx------+ 1 pwillems Domain Users 36019 Mar 6 09:42 sonar-stylecop-plugin-1.1.jar -rwx------+ 1 pwillems Domain Users 26259 Mar 6 09:42 sonar-visual-studio-plugin-1.2.jarreThis is the recent history in the sonar.log:  2015.03.10 13:14:40 INFO web[o.s.s.s.IndexSynchronizer] Index source files 2015.03.10 13:15:40 INFO web[o.s.s.es.BulkIndexer] 204829 requests processed 2015.03.10 13:16:40 INFO web[o.s.s.es.BulkIndexer] 488960 requests processed 2015.03.10 13:17:40 INFO web[o.s.s.es.BulkIndexer] 769172 requests processed 2015.03.10 13:18:41 INFO web[o.s.s.es.BulkIndexer] 1009002 requests processed 2015.03.10 13:19:41 INFO web[o.s.s.es.BulkIndexer] 1302412 requests processed 2015.03.10 13:20:41 INFO web[o.s.s.es.BulkIndexer] 1608777 requests processed 2015.03.10 13:21:21 INFO web[o.s.a.u.TimeProfiler] Load metrics... 2015.03.10 13:21:22 INFO web[o.s.s.s.RegisterMetrics] Cleaning quality gate conditions 2015.03.10 13:21:22 INFO web[o.s.a.u.TimeProfiler] Load metrics done: 953 ms 2015.03.10 13:21:22 INFO web[o.s.s.s.RegisterDebtModel] Register technical debt model... 2015.03.10 13:21:22 INFO web[o.s.s.s.RegisterDebtModel] Register technical debt model done: 78 ms 2015.03.10 13:21:22 INFO web[o.s.a.u.TimeProfiler] Register rules... 2015.03.10 13:21:35 INFO web[o.s.a.u.TimeProfiler] Register rules done: 12985 ms 2015.03.10 13:21:35 ERROR web[o.s.s.ui.JRubyFacade] Fail to upgrade databasereWhat would be useful to investigate or try? Any help is appreciated.",Not-TD-related,SonarQube,,,,0.067,0.894,0.039,-0.9495
29302078,Jenkins: SonnarQube Error,"I'm currently using Jenkins with SonarQube Runner plugin to analyse my Android app code.I've done this on another app, with the same configurations and it works. The new app I've created doesn't... it returns the following error: [exec] BUILD SUCCESSFUL[exec] Total time: 56 seconds...No JDK named (Inherit From Job) found[Sonar-Job] $ /home/jenkins/tools/hudson.plugins.sonar.SonarRunnerInstallation/Sonar_Runner_JAVA/bin/sonar-runner -Dsonar.jdbc.driver=com.mysql.jdbc.Driver -Dsonar.jdbc.url=jdbc:mysql://10.39.10.44:3306/sonar?useUnicode=true characterEncoding=utf8 rewriteBatchedStatements=true ******** ******** -Dsonar.host.url=https://sonar.xptocompany.com/ ******** ******** -Dsonar.projectBaseDir=/home/jenkins/workspace/Sonar-Job -Dsonar.sourceEncoding=UTF-8 -Dsonar.sources=AndroidApp -Dsonar.language=java -Dsonar.binaries=AndroidApp/bin/classes -Dsonar.projectVersion=1.0 -Dsonar.projectKey=AndroidApp:android -Dsonar.verbose=true -Dsonar.profile=Android Lint -Dsonar.projectName=AndroidApp - Android ClientSonarQube Runner 2.4Java 1.7.0_76 Oracle Corporation (64-bit)Linux 3.2.0-77-generic amd64SONAR_RUNNER_OPTS=-Dcom.android.tools.lint.bindir=/home/jenkins/android-sdk-base/toolsINFO: Runner configuration file: /home/jenkins/tools/hudson.plugins.sonar.SonarRunnerInstallation/Sonar_Runner_JAVA/conf/sonar-runner.propertiesINFO: Project configuration file: NONEINFO: Default locale: en_US, source code encoding: UTF-8INFO: Work directory: /home/jenkins/workspace/Sonar-Job/.sonarINFO: SonarQube Server 4.3.211:06:16.791 INFO - Load batch settings11:06:16.801 DEBUG - Download: https://sonar.xptocompany.com/batch_bootstraproperties?dryRun=false (no proxy)11:06:16.931 INFO - User cache: /home/jenkins/.sonar/cache11:06:16.942 INFO - Install plugins11:06:16.943 DEBUG - Download index of plugins11:06:16.943 DEBUG - Download: https://sonar.xptocompany.com/deploylugins/index.txt (no proxy)11:06:17.134 INFO - Install JDBC driver11:06:17.135 DEBUG - Download index of jdbc-driver11:06:17.135 DEBUG - Download: https://sonar.xptocompany.com/deploy/jdbc-driver.txt (no proxy)11:06:17.160 INFO - Create JDBC datasource for jdbc:mysql://10.39.10.44:3306/sonar?useUnicode=true characterEncoding=utf8 rewriteBatchedStatements=true11:06:17.488 DEBUG - Testing JDBC connection11:06:18.730 DEBUG - Download: https://sonar.xptocompany.com/api/server (no proxy)11:06:18.770 INFO - Initializing Hibernate11:06:18.775 DEBUG - hibernate.generate_statistics: false11:06:18.775 DEBUG - hibernate.dialect: org.sonar.core.persistence.dialect.MySql$MySqlWithDecimalDialect11:06:18.775 DEBUG - hibernate.connection.provider_class: org.sonar.jpa.session.CustomHibernateConnectionProvider11:06:19.787 DEBUG - Loaded 3464 properties from l10n bundles11:06:20.407 ERROR - No license for plugin cpp11:06:20.408 ERROR - No license for plugin plsql11:06:21.076 INFO - Load project settings11:06:21.076 DEBUG - Download: https://sonar.xptocompany.com/batch_bootstraproperties?project=AndroidApp:android dryRun=false (no proxy)11:06:21.112 INFO - Apply project exclusions11:06:21.324 DEBUG - Acquire semaphore on project : org.sonar.api.resources.Project@225840d4[id=521,key=AndroidApp:android,qualifier=TRK], with key batch-AndroidApp:android11:06:21.351 INFO - ------------- Scan AndroidApp - Android Client11:06:21.356 INFO - Load module settings11:06:21.361 DEBUG - Download: https://sonar.xptocompany.com/batch_bootstraproperties?project=AndroidApp:android dryRun=false (no proxy)11:06:21.558 DEBUG - Available languages:11:06:21.558 DEBUG - * JavaScript =   js11:06:21.558 DEBUG - * C =   c11:06:21.558 DEBUG - * C++ =   cpp11:06:21.559 DEBUG - * Web =   web11:06:21.559 DEBUG - * XML =   xml11:06:21.559 DEBUG - * PL/SQL =   plsql11:06:21.559 DEBUG - * Java =   java11:06:22.123 INFO - Language is forced to java11:06:24.198 INFO - Loading technical debt model...11:06:24.233 INFO - Loading technical debt model done: 35 ms11:06:24.234 INFO - Loading rules...11:06:25.582 INFO - Loading rules done: 1348 ms11:06:25.619 INFO - Configure Maven plugins11:06:25.897 INFO - Compare to previous analysis (2015-03-26)11:06:25.909 INFO - Compare over 30 days (2015-02-25, analysis of 2015-03-26 16:14:43.0)11:06:25.910 INFO - No quality gate is configured.11:06:26.225 DEBUG - Initializers : 11:06:26.225 INFO - Base dir: /home/jenkins/workspace/Sonar-Job11:06:26.225 INFO - Working dir: /home/jenkins/workspace/Sonar-Job/.sonar11:06:26.225 INFO - Source dirs: /mnt/data/jenkins/workspace/Sonar-Job/AndroidApp11:06:26.225 INFO - Binary dirs: /mnt/data/jenkins/workspace/Sonar-Job/AndroidApp/bin/classes11:06:26.226 INFO - Source encoding: UTF-8, default locale: en_US11:06:26.226 INFO - Index files11:06:26.229 DEBUG - Declared extensions of language JavaScript were converted to sonar.lang.patterns.js : **/*.js11:06:26.229 DEBUG - Declared extensions of language C were converted to sonar.lang.patterns.c : **/*.c,**/*.1:06:26.229 DEBUG - Declared extensions of language C++ were converted to sonar.lang.patterns.cpp : **/*.cc,**/*.cpp,**/*.cxx,**/*.c++,**/*.hh,**/*.hpp,**/*.hxx,**/*.h++,**/*.ipp11:06:26.229 DEBUG - Declared extensions of language Web were converted to sonar.lang.patterns.web : **/*.html,**/*.xhtml,**/*.jsp,**/*.jspf,**/*.jsf,**/*.php,**/*.erb,**/*.rhtml11:06:26.230 DEBUG - Declared extensions of language XML were converted to sonar.lang.patterns.xml : **/*.xml11:06:26.230 DEBUG - Declared extensions of language PL/SQL were converted to sonar.lang.patterns.plsql : **/*.sql,**/*.pks,**/*.pkb11:06:26.230 DEBUG - Declared extensions of language Java were converted to sonar.lang.patterns.java : **/*.java,**/*.jav11:06:31.151 DEBUG - Language of file 'AndroidApp/tests/TestContactsConnector.java' is detected to be 'java'11:06:31.345 DEBUG - Updating semaphore batch-AndroidApp:android11:06:31.532 DEBUG - Language of file 'AndroidApp/tests/TestsConfigurationManager.java' is detected to be 'java'11:06:31.534 DEBUG - Language of file 'AndroidApp/tests/TestAccountManager.java' is detected to be 'java'...11:06:40.156 INFO - 376 files indexed11:06:41.354 DEBUG - Updating semaphore batch-AndroidApp:android11:06:49.132 INFO - Quality profile for java: Android Lint11:06:49.481 INFO - JaCoCo report not found.11:06:49.482 INFO - JaCoCo IT report not found.11:06:49.482 INFO - JaCoCo reports not found.11:06:49.566 INFO - Redmine issues sensor will not run as some parameters are missing.11:06:49.570 DEBUG - Sensors : JavaSquidSensor -   QProfileSensor -   AndroidLintSensor -   SurefireSensor -   CpdSensor -   InitialOpenIssuesSensor -   ProfileEventsSensor -   ProjectLinksSensor -   VersionEventsSensor -   FileHashSensor -   MantisSensor11:06:49.571 INFO - Sensor JavaSquidSensor...11:06:49.713 INFO - Java Main Files AST scan...11:06:49.729 INFO - 376 source files to be analyzed11:06:51.360 DEBUG - Updating semaphore batch-AndroidApp:android11:06:59.744 INFO - 205/376 files analyzed, current is /mnt/data/jenkins/workspace/Sonar-Job/AndroidApp/src/com/myapp/fragments/Download.java11:07:01.380 DEBUG - Updating semaphore batch-AndroidApp:android11:07:07.165 INFO - 376/376 source files analyzed11:07:07.411 INFO - Java Main Files AST scan done: 17698 ms11:07:07.436 INFO - Java bytecode scan...11:07:07.438 DEBUG - ----- Classpath analyzed by Squid:11:07:07.438 DEBUG - /mnt/data/jenkins/workspace/Sonar-Job/AndroidApp/bin/classes11:07:07.438 DEBUG - -----11:07:07.469 WARN - Class 'android/os/FileObserver' is not accessible through the ClassLoader.11:07:07.493 WARN - Class 'android/os/FileObserver' is not accessible through the ClassLoader....11:07:09.795 INFO - Java bytecode scan done: 2359 ms11:07:09.801 INFO - Java Test Files AST scan...11:07:09.801 INFO - 0 source files to be analyzed11:07:09.804 INFO - Java Test Files AST scan done: 3 ms11:07:09.808 INFO - 0/0 source files analyzed11:07:09.882 INFO - Package design analysis...11:07:09.888 DEBUG - 58 packages to analyze11:07:11.387 DEBUG - Updating semaphore batch-project:android11:07:13.484 DEBUG - 261 cycles11:07:13.484 DEBUG - 59 feedback edges11:07:13.516 INFO - Package design analysis done: 3634 ms11:07:14.493 INFO - Sensor JavaSquidSensor done: 24922 ms11:07:14.493 INFO - Sensor QProfileSensor...11:07:14.500 INFO - Sensor QProfileSensor done: 7 ms11:07:14.500 INFO - Sensor AndroidLintSensor...11:07:14.515 INFO - Execute Android Lint 22.2.0...11:07:21.402 DEBUG - Updating semaphore batch-project:android11:07:31.414 DEBUG - Updating semaphore batch-project:android11:07:35.154 WARN - Incorrect detector reported disabled issue MissingApplicationIcon11:07:41.424 DEBUG - Updating semaphore batch-project:android11:07:49.635 WARN - Incorrect detector reported disabled issue MissingApplicationIcon11:07:51.432 DEBUG - Updating semaphore batch-project:android11:08:01.448 DEBUG - Updating semaphore batch-project:android11:08:05.991 DEBUG - Release semaphore on project : org.sonar.api.resources.Project@225840d4[id=521,keybatch-project:android,qualifier=TRK], with key batch-project:android11:08:06.066 DEBUG - To prevent a memory leak, the JDBC Driver [com.mysql.jdbc.Driver] has been forcibly deregisteredINFO: ------------------------------------------------------------------------INFO: EXECUTION FAILUREINFO: ------------------------------------------------------------------------Total time: 1:50.376sFinal Memory: 62M/1990MINFO: ------------------------------------------------------------------------ERROR: Error during Sonar runner executionERROR: Unable to execute SonarERROR: ERROR: To see the full stack trace of the errors, re-run SonarQube Runner with the -e switch.ERROR: Re-run SonarQube Runner using the -X switch to enable full debug logging.Build step 'Invoke Standalone Sonar Analysis' marked build as failureArchiving artifactsNo JDK named (Inherit From Job) foundNo JDK named (Inherit From Job) foundSending e-mails to: [my.email.not.disclosed]Started calculate disk usage of buildFinished Calculation of disk usage of build in 0 secondsStarted calculate disk usage of workspaceFinished Calculation of disk usage of workspace in 0 secondsFinished: FAILUREreI'm using the following configuration on Invoke Standalone Sonar Analysis: sonar.projectKey=project:androidsonar.projectName=Android Clientsonar.projectVersion=1.0sonar.sources=AndroidAppFoldersonar.binaries=AndroidAppFolder/bin/classessonar.language=javasonar.sourceEncoding=UTF-8sonar.profile=Android Lintsonar.verbose=truereHow can I configure the build to print full logs to console enabling me to understand what is the problem? emNote: This a companies' Jenkins machine, so I do not have access to the machine itself, I can just configure the build or else I'd be using a href=http://docs.sonarqube.org/display/SONAR/Troubleshooting rel=nofollowhttp://docs.sonarqube.org/display/SONAR/Troubleshooting/a/em",Not-TD-related,SonarQube,,,,0.052,0.942,0.006,-0.9899
29340567,Jenkins Perforce Plugin Not Checking Out Code From Perforce,"I am trying to create a jenkins job with perforce SCM.Sonar Runner is used for analysis of the project which would give me execution success while analysing the project.The problem is with perforce jenkins plugin which is not checking out code from perforce and hence sonar analysis is run without checking out code from perforce.preStarted by user jones j alapat[EnvInject] - Loading node environment variables.Building on master in workspace C:\Program Files (x86)\Jenkins\jobs\perforceSpringPOC\workspaceUsing master perforce client: mar30[workspace] $ C:\Program Files\Perforce\p4.exe workspace -o mar30Changing P4 Client Root to: C:\Program Files (x86)\Jenkins\jobs\perforceSpringPOC\workspaceSaving modified client mar30[workspace] $ C:\Program Files\Perforce\p4.exe -s client -iLast build changeset: 42[workspace] $ C:\Program Files\Perforce\p4.exe changes -s submitted -m 1 //mar30/...[workspace] $ C:\Program Files\Perforce\p4.exe -s changes -s submitted //mar30/...@43,@42Sync'ing workspace to changelist 42.[workspace] $ C:\Program Files\Perforce\p4.exe -s sync //mar30/...@42Sync complete, took 36 ms[workspace] $ D:\softwares\sonar-runner-2.4\bin\sonar-runner.bat -Dsonar.jdbc.driver=com.mysql.jdbc.Driver -Dsonar.jdbc.url=jdbc:mysql://localhost:3306/sonar?autoReconnect=true useUnicode=true characterEncoding=utf8 ******** ******** -Dsonar.host.url=http://localhost:9000 ******** ******** -Dsonar.projectBaseDir=C:\Program Files (x86)\Jenkins\jobs\perforceSpringPOC\workspace -Dsonar.projectName=Mar30SpringMVCPOC -Dsonar.projectVersion=1.0 -Dsonar.projectKey=Mar30SpringMVCPOC -Dsonar.sources=.D:\softwares\sonar-runner-2.4SonarQube Runner 2.4Java 1.8.0_11 Oracle Corporation (64-bit)Windows 8.1 6.3 amd64INFO: Runner configuration file: D:\softwares\sonar-runner-2.4\conf\sonar-runner.propertiesINFO: Project configuration file: NONEINFO: Default locale: en_US, source code encoding: windows-1252 (analysis is platform dependent)INFO: Work directory: C:\Program Files (x86)\Jenkins\jobs\perforceSpringPOC\workspace\.sonarINFO: SonarQube Server 5.011:49:16.269 INFO - Load global referentials...11:49:16.398 INFO - Load global referentials done: 129 ms11:49:16.402 INFO - User cache: C:\Windows\system32\config\systemprofile\.sonar\cache11:49:16.408 INFO - Install plugins11:49:16.475 INFO - Install JDBC driver11:49:16.475 INFO - Create JDBC datasource for jdbc:mysql://localhost:3306/sonar?autoReconnect=true useUnicode=true characterEncoding=utf811:49:17.232 INFO - Initializing Hibernate11:49:18.094 ERROR - No license for plugin report11:49:18.251 INFO - Load project referentials...11:49:19.123 INFO - Load project referentials done: 872 ms11:49:19.124 INFO - Load project settings11:49:19.459 INFO - Loading technical debt model...11:49:19.475 INFO - Loading technical debt model done: 16 ms11:49:19.475 INFO - Apply project exclusions11:49:19.590 WARN - SCM provider autodetection failed. No SCM provider claims to support this project. Please use sonar.scm.provider to define SCM of your project.11:49:19.605 INFO - ------------- Scan Mar30SpringMVCPOC11:49:19.609 INFO - Load module settings11:49:20.159 INFO - Loading rules...11:49:20.298 INFO - Loading rules done: 139 ms11:49:20.318 INFO - Configure Maven plugins11:49:20.372 INFO - Compare to previous analysis (2015-03-30)11:49:20.378 INFO - Compare over 30 days (2015-02-28, analysis of 2015-03-30 11:37:50.0)11:49:20.379 INFO - No quality gate is configured.11:49:20.475 INFO - Base dir: C:\Program Files (x86)\Jenkins\jobs\perforceSpringPOC\workspace11:49:20.475 INFO - Working dir: C:\Program Files (x86)\Jenkins\jobs\perforceSpringPOC\workspace\.sonar11:49:20.475 INFO - Source paths: .11:49:20.475 INFO - Source encoding: windows-1252, default locale: en_US11:49:20.475 INFO - Index files11:49:20.475 INFO - 0 files indexed -------------------------No Files Are pulled from perforce11:49:20.490 INFO - Sensor QProfileSensor...11:49:20.506 INFO - Sensor QProfileSensor done: 16 ms11:49:20.506 INFO - Sensor InitialOpenIssuesSensor...11:49:20.520 INFO - Sensor InitialOpenIssuesSensor done: 13 ms11:49:20.520 INFO - Sensor ProjectLinksSensor...11:49:20.524 INFO - Sensor ProjectLinksSensor done: 4 ms11:49:20.525 INFO - Sensor VersionEventsSensor...11:49:20.661 INFO - Sensor VersionEventsSensor done: 136 ms11:49:20.661 INFO - Sensor FileHashSensor...11:49:20.661 INFO - Sensor FileHashSensor done: 0 ms11:49:20.661 INFO - Sensor SCM Sensor...11:49:20.661 INFO - No SCM system was detected. You can use the 'sonar.scm.provider' property to explicitly specify it.11:49:20.661 INFO - Sensor SCM Sensor done: 0 ms11:49:20.661 INFO - Sensor CPD Sensor...11:49:20.661 INFO - Sensor CPD Sensor done: 0 ms11:49:20.742 INFO - Execute decorators...11:49:20.839 INFO - Store results in database11:49:21.043 INFO - ANALYSIS SUCCESSFUL, you can browse http://localhost:9000/dashboard/index/Mar30SpringMVCPOC11:49:21.043 INFO - Note that you will be able to access the updated dashboard once the server has processed the submitted analysis report.11:49:21.043 INFO - Executing post-job class org.sonar.issuesreport.ReportJob11:49:21.044 INFO - Executing post-job class org.sonar.plugins.issueassign.notification.SendIssueNotificationsPostJob11:49:21.044 INFO - Executing post-job class org.sonar.plugins.core.issue.notification.SendIssueNotificationsPostJob11:49:21.044 INFO - Executing post-job class org.sonar.plugins.buildbreaker.AlertBreaker11:49:21.060 INFO - Executing post-job class org.sonar.plugins.buildbreaker.ForbiddenConfigurationBreakerINFO: ------------------------------------------------------------------------INFO: EXECUTION SUCCESSINFO: ------------------------------------------------------------------------Total time: 5.384sFinal Memory: 12M/183MINFO: ------------------------------------------------------------------------Notifying upstream projects of job completionFinished: SUCCESSreAs You Could see, the files from my perforce is not checked out .My Configuration is given below img src=https://i.stack.imgur.com/NbQto.png alt=Perforce jenkins plugin",Not-TD-related,SonarQube,,,,0.047,0.922,0.032,-0.7425
29518853,SonarEclipse plugin analysis using central SonarQube server,We want to set local analysis using SonarEclipse plugin for team of 50+ developers. We currently have SonarQube server installed which is used by CI. Can we use the same SonarQube server for the local analysis on developer boxes as installing sonarqube server locally on each box and keeping it in sync will be difficult? Also what hardware requirements do we need to consider if we use same SonarQube server for CI and local analysis?,Not-TD-related,SonarQube,,,,0.037,0.946,0.017,-0.3736
29543497,Sonar Runner fails with exception with rule,I am trying to publish to Sonar using Gradle on a Java 8 project which is failing with the following error:  INFO: ------------------------------------------------------------------------ INFO: EXECUTION FAILURE INFO: ------------------------------------------------------------------------ Total time: 1:18.786s Final Memory: 25M/764M INFO: ------------------------------------------------------------------------ ERROR: Error during Sonar runner execution ERROR: Unable to execute Sonar ERROR: Caused by: Rule 'squid:S1192' can not use 'Constant/issue' remediation function because this rule does not have a fixed remediation cost.reIf I select my project to use the emFindBugs/em quality profile then everything works and stats are uploaded to sonar. However if I turn on the emsonar way/em profile the error above is thrown.Looking at the error it seems it cannot find a remediation cost (which I think is required to work out how many days it will take to fix all tech debt)I have tried uninstalling other plugins (JavaScriptython/etc) and just leave Java. I have also tried tweaking the defaults in the Technical Debt settings. I have restored the default profiles also. All have had no effect.I am using the following versions:ullisonar 5.0.1 (application)lisonar-runner 2.4 (gradle plugin)ligradle 2.3lijava 8 (project to analyse)lijava plugin 3.1 (sonar plugin)Does anyone have any ideas please?,Not-TD-related,SonarQube,,,,0.169,0.808,0.023,-0.9811
29615241,SonarQube - Views Portfolio Plugin aka Helicopter View nemo - Combined all projects metrics,"I'm doing a POC on getting a href=http://nemo.sonarqube.org/dashboard/?did=67 rel=nofollow noreferrerHelicopter view/a on our SonarQube instance. I'm using latest SonarQube (5.1), sonar-runner (2.4), Gradle 2.3 (build system) on a RHEL 6.6 (Santiago) machine.Helicopter view: Plugin in SonarQube that I'm trying is: a href=http://www.sonarsource.comroductslugins/governanceortfolio-management/ rel=nofollow noreferrerhttp://www.sonarsource.comroductslugins/governanceortfolio-management//a The end result I want on my SonarQube instance is, to look like this: a href=http://nemo.sonarqube.org/ rel=nofollow noreferrerhttp://nemo.sonarqube.org//a and if you click on one of the VIEW(which you can create using Views Portfolio plugin), then it should give you a COMBINED metrics/info for a given view (which can be created by a user for a given Projectroduct team, projects owned by a XYZ manager, department, etc or for all applications / service projects in a given organization, office, domain etc. Whatever projects you select (manually/using regular expression/etc way) in a VIEW, will be shown as one component (thus showing a user combined metrics).Few links that I'm trying: a href=http://www.sonarqube.org/everythings-a-component/ rel=nofollow noreferrerhttp://www.sonarqube.org/everythings-a-component//a, a href=http://www.sonarsource.comroductslugins/governanceortfolio-management/installation-and-usage/ rel=nofollow noreferrerhttp://www.sonarsource.comroductslugins/governanceortfolio-management/installation-and-usage//a and a href=http://www.sonarqube.org/measures-at-your-service/ rel=nofollow noreferrerhttp://www.sonarqube.org/measures-at-your-service//aI'm able to get the above metrics except the COMBINED all projects info (that I'm getting for some widgets for ex: for Unit/IT tests/coverage, Lines of Code, Filter motion chart, Components chart, Technical Debt, Complexity, Tangle index, Duplications, etc etc) is NOT showing up for other widgets (for ex: SCM Top 10 authors, SCM commits per month for a given period, SCM Top 10 author's activity etc).Please NOTE: For the above widgets which are not showing valid data for all the component projects which are part of the VIEW/sub-view, I can see the widgets in the project itself HAVE valid populated data. It's only not showing in the VIEW dashboard where it should show the combined data (for SCM* widgets).I'm getting the following image for SCM* widgets in the VIEW that right now contains only 2 projects (one application and one is a service project).img src=https://i.stack.imgur.com/Uq2Lq.jpg alt=enter image description hereAs I mentioned above, I'm successfully able to see valid info related to these SCM* widgets when I go to the application and service project's individual project dashboard page in SonarQube.Not sure why VIEWS Portfolio plugin is not able to combine SCM* widgets info to show combined info when the widgets are enabled/included in the VIEW's dashboard (which uses the project's dashboard settings/widgets as well as per SonarQube Views plugin a href=http://www.sonarsource.comroductslugins/governanceortfolio-management/installation-and-usage/ rel=nofollow noreferrerinstallation/configuration/a documentation).Has anybody successfully used SCM widgets that are available in SonarQube in a VIEW (created by using emViews Portfolio/em plugin)? Thanks.",Not-TD-related,SonarQube,,,,0.006,0.927,0.067,0.9593
29624476,Sonar analysis causes 0 files indexed on a maven project through Jenkins,"I am trying to integrate a standard maven project with SonarQube through Jenkins. SonarQube has been added a Post-Build Action to the project build.I can see Sonar invoked correctly in the console output of the build, but it doesn't find any files to index. The Sonar analysis finishes successfully as far as I can tell but reports are empty.The same command run locally from command line against a local SonarQube installation works correctly.ulliJenkins: 1.605 liSonar: 5.1 (runs on the same machine as Jenkins, off aMySQL DB) liJenkins Maven Plugin: 2.8 liJenkins SonarQube Plugin: 2.2I've added SonarQube section in Jenkins - Configure Jenkins section with server URL and DB URL.The only configuration parameter on SonarQube additional properties in projects post build actions is -Dsonar.scm.disabled=true, which I believe turns off the uncommitted files check.pre [sonarcore] $ /usr/share/apache-maven/bin/mvn -f /varb/jenkins/workspace/sonarcore/myproject-coreom.xml -e -B sonar:sonar -Dsonar.scm.disabled=true -Dsonar.jdbc.url=jdbc:mysql://localhost:3306/sonar?autoReconnect=true useUnicode=true characterEncoding=utf8 -Dsonar.host.url=http://localhost:9000/ [INFO] Error stacktraces are turned on. [INFO] Scanning for projects... [INFO] [INFO] ------------------------------------------------------------------------ [INFO] Building myproject-core 0.0.1-SNAPSHOT [INFO] ------------------------------------------------------------------------ [INFO] [INFO] --- sonar-maven-plugin:2.5:sonar (default-cli) @ myproject-core --- [INFO] SonarQube version: 5.1 INFO: Default locale: en_US, source code encoding: UTF-8 INFO: Work directory: /varb/jenkins/workspace/sonarcore/myproject-core/target/sonar INFO: SonarQube Server 5.1 [INFO] [10:23:00.144] Load global repositories [INFO] [10:23:00.327] Load global repositories (done) | time=185ms [INFO] [10:23:00.336] Server id: 20150413092802 [INFO] [10:23:00.338] User cache: /varb/jenkins/.sonar/cache [INFO] [10:23:00.353] Install plugins [INFO] [10:23:00.409] Install JDBC driver [INFO] [10:23:00.422] Create JDBC datasource for jdbc:mysql://localhost:3306/sonar?autoReconnect=true useUnicode=true characterEncoding=utf8 [INFO] [10:23:01.722] Initializing Hibernate [INFO] [10:23:03.174] Load project repositories [INFO] [10:23:03.198] Load project repositories (done) | time=24ms [INFO] [10:23:03.198] Load project settings [INFO] [10:23:03.424] Load technical debt model [INFO] [10:23:03.447] Apply project exclusions [INFO] [10:23:03.647] ------------- Scan myproject-core [INFO] [10:23:03.651] Load module settings [INFO] [10:23:03.758] Load rules [INFO] [10:23:03.826] Base dir: /varb/jenkins/workspace/sonarcore/myproject-core [INFO] [10:23:03.826] Working dir: /varb/jenkins/workspace/sonarcore/myproject-core/target/sonar [INFO] [10:23:03.827] Source paths: pom.xml, src/main/java [INFO] [10:23:03.827] Test paths: src/test/java [INFO] [10:23:03.827] Binary dirs: target/classes [INFO] [10:23:03.828] Source encoding: UTF-8, default locale: en_US [INFO] [10:23:03.828] Index files [INFO] [10:23:03.853] 0 files indexed [INFO] [10:23:03.894] Sensor Lines Sensor [INFO] [10:23:03.895] Sensor Lines Sensor (done) | time=1ms [INFO] [10:23:03.896] Sensor QProfileSensorreI found another similar thread on SO that said I need to install more plugins, but I haven't been able to find which plugins do I need.a href=https://stackoverflow.com/questions/25627617/analysing-with-sonarqube-causes-0-files-indexed-and-no-reports-maven-projectAnalysing with SonarQube causes 0 files indexed and no reports (Maven Project)/aI havent added SonarQube Runner on Jenkins as I don't think it is needed. Please see here a href=https://stackoverflow.com/a/13473275/4473028https://stackoverflow.com/a/13473275/4473028/a",Not-TD-related,SonarQube,,,,0.025,0.949,0.026,0.168
29699998,Unit Test Coverage not displaying on Sonarqube - Running through Jenkins Sonar plugin - Test Success displays correctly,"I am currently using jenkins to build a list of different modules for my project. I trigger the builds using Maven. I have sonarqube installed on the server and have set it up correctly so that when a module builds it is displayed on sonarqube and includes all of the basic details such as lines of code, technical debt etc. The modules all have Junit tests that run against them, and sonarqube displays this by saying that the Unit Test Sucess is 100% and it also says the number of tests that have been run in that module. However I cannot get the Unit tests coverage field to display anything and it is blank for all of the modules.Here is an exert (one module) from my pom.xml customer.sonar.projectBaseDir=.customer.sonar.sources=D:/TFS/WorkSpace/DEV_2_HYBRID/APP_FO/application/customer/src/main/javacustomer.sonar.Hybrid=Customercustomer.sonar.tests=D:/TFS/WorkSpace/DEV_2_HYBRID/APP_FO/application/customer/target/surefire-reportscustomer.sonar.junit.reportsPath=D:/TFS/WorkSpace/DEV_2_HYBRID/APP_FO/application/customer/target/surefire-reportsreThe versions of the software I am using are as follows:Sonarqube v.5.0, Jenkins Sonarqube plugin v.2.1, Maven v3.2.5As I said at the beginning the unit test success rate does show successfully, so I believe it is only a small change needed that will get the unit test coverage field working.Any help would be really appreciated!",Not-TD-related,SonarQube,,,,0.014,0.906,0.081,0.9059
30034711,Duplicated resource file when uploading jslint.xml to Sonar,"I have a Jenkins job which has 2 partsulliRun eslint checks via maven and generate jslint.xml file.liUpload jslint.xml to sonar using the Jenkins sonarcube plugin.Our build was working fine until suddenly it starts throwing the exception [INFO] [INFO] --- eslint-maven-plugin:0.1.6:eslint (default) @ gal ---[ERROR] /mnterm_storageersistent/jenkinssolman_web/jenkins/jobs/com.sap.solman.graphical.component-official_branch_sp1-sonar/workspace/SMGC/src/main/webapp/ags_gal_app/Controllers/extendedEditorEventHandler.js 10:57 strict Missing use strict statement. (http://eslint.org/docs/rules/strict)[ERROR] /mnterm_storageersistent/jenkinssolman_web/jenkins/jobs/com.sap.solman.graphical.component-official_branch_sp1-sonar/workspace/SMGC/src/main/webapp/ags_gal_app/Controllers/extendedEditorEventHandler.js 13:5 no-underscore-dangle Unexpected dangling '_' in '_oExtendedEditor'. (http://eslint.org/docs/rules/no-underscore-dangle)[ERROR] /mnterm_storageersistent/jenkinssolman_web/jenkins/jobs/com.sap.solman.graphical.component-official_branch_sp1-sonar/workspace/SMGC/src/main/webapp/ags_gal_app/Controllers/extendedEditorEventHandler.js 14:5 no-underscore-dangle Unexpected dangling '_' in '_oApplicationToolbar'. (http://eslint.org/docs/rules/no-underscore-dangle)[ERROR] /mnterm_storageersistent/jenkinssolman_web/jenkins/jobs/com.sap.solman.graphical.component-official_branch_sp1-sonar/workspace/SMGC/src/main/webapp/ags_gal_app/Controllers/extendedEditorEventHandler.js 15:5 no-underscore-dangle Unexpected dangling '_' in '_oPaletteToolbar'. (http://eslint.org/docs/rules/no-underscore-dangle)......[ERROR] /mnterm_storageersistent/jenkinssolman_web/jenkins/jobs/com.sap.solman.graphical.component-official_branch_sp1-sonar/workspace/SMGC/src/main/webapp/extensions/vc/solmanDiagramEditorExtension.js 4:0 global-strict Use the function form of use strict. (http://eslint.org/docs/rules/global-strict)[ERROR] /mnterm_storageersistent/jenkinssolman_web/jenkins/jobs/com.sap.solman.graphical.component-official_branch_sp1-sonar/workspace/SMGC/src/main/webapp/extensions/vc/constants.js 2:26 strict Missing use strict statement. (http://eslint.org/docs/rules/strict)[ERROR] /mnterm_storageersistent/jenkinssolman_web/jenkins/jobs/com.sap.solman.graphical.component-official_branch_sp1-sonar/workspace/SMGC/src/main/webapp/utilities/globalUtilities.js 6:45 strict Missing use strict statement. (http://eslint.org/docs/rules/strict)[ERROR] /mnterm_storageersistent/jenkinssolman_web/jenkins/jobs/com.sap.solman.graphical.component-official_branch_sp1-sonar/workspace/SMGC/src/main/webapp/utilities/globalUtilities.js 16:5 no-underscore-dangle Unexpected dangling '_' in '_sLocale'. (http://eslint.org/docs/rules/no-underscore-dangle)[ERROR] /mnterm_storageersistent/jenkinssolman_web/jenkins/jobs/com.sap.solman.graphical.component-official_branch_sp1-sonar/workspace/SMGC/src/main/webapp/utilities/globalUtilities.js 23:5 no-underscore-dangle Unexpected dangling '_' in '_oBundle'. (http://eslint.org/docs/rules/no-underscore-dangle)[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 46.050s[INFO] Finished at: Mon May 04 15:35:10 UTC 2015[INFO] Final Memory: 22M/349M[INFO] ------------------------------------------------------------------------2015-05-04 15:35:11.367:INFO:oejsl.ELContextCleaner:javax.el.BeanELResolver purged2015-05-04 15:35:11.367:INFO:oejsh.ContextHandler:stopped o.m.j.p.JettyWebAppContext{/,[file:/mnterm_storageersistent/jenkinssolman_web/jenkins/jobs/com.sap.solman.graphical.component-official_branch_sp1-sonar/workspace/SMGC/src/, jar:file:/usr/sap/ljsersistentfs/.m2/repository/com/sap/ui5/resource/1.26.1/resource-1.26.1.jar!/META-INF/resources/, jar:file:/usr/sap/ljsersistentfs/.m2/repository/com/sap/ui5/core/1.26.1/core-1.26.1.jar!/META-INF/resources/, jar:file:/usr/sap/ljsersistentfs/.m2/repository/com/sap/ui5/commons/1.26.1/commons-1.26.1.jar!/META-INF/resources/, jar:file:/usr/sap/ljsersistentfs/.m2/repository/com/sap/ui5/layout/1.26.1/layout-1.26.1.jar!/META-INF/resources/, jar:file:/usr/sap/ljsersistentfs/.m2/repository/com/sap/ui5/unified/1.26.1/unified-1.26.1.jar!/META-INF/resources/, jar:file:/usr/sap/ljsersistentfs/.m2/repository/com/sap/ui5/ux3/1.26.1/ux3-1.26.1.jar!/META-INF/resources/, jar:file:/usr/sap/ljsersistentfs/.m2/repository/com/sap/ui5/table/1.26.1/table-1.26.1.jar!/META-INF/resources/, jar:file:/usr/sap/ljsersistentfs/.m2/repository/com/sap/ui5/visualization/1.26.1/visualization-1.26.1.jar!/META-INF/resources/, jar:file:/usr/sap/ljsersistentfs/.m2/repository/com/sap/ui5/themelib_sap_ux/1.26.1/themelib_sap_ux-1.26.1.jar!/META-INF/resources/, jar:file:/usr/sap/ljsersistentfs/.m2/repository/com/sap/ui5/themelib_sap_platinum/1.26.1/themelib_sap_platinum-1.26.1.jar!/META-INF/resources/, jar:file:/usr/sap/ljsersistentfs/.m2/repository/com/sap/ui5/mobile/1.26.1/mobile-1.26.1.jar!/META-INF/resources/, jar:file:/usr/sap/ljsersistentfs/.m2/repository/com/sap/ui5/themelib_sap_goldreflection/1.26.1/themelib_sap_goldreflection-1.26.1.jar!/META-INF/resources/, jar:file:/usr/sap/ljsersistentfs/.m2/repository/com/sap/ui5/themelib_sap_bluecrystal/1.26.1/themelib_sap_bluecrystal-1.26.1.jar!/META-INF/resources/]},file:/mnterm_storageersistent/jenkinssolman_web/jenkins/jobs/com.sap.solman.graphical.component-official_branch_sp1-sonar/workspace/SMGC/src/[workspace] $ mvn -f /usr/sap/ljsersistentfs/jenkins/jobs/com.sap.solman.graphical.component-official_branch_sp1-sonar/workspace/SMGCom.xml -e -B sonar:sonar -Dsonar.surefire.reportsPath=target/jslint.xml -Dsonar.profile=ESLint_Fiori -Dsonar.javascript.jslint.reportPath=target/jslint.xml -Dsonar.profile=ESLint_Fiori -Dsonar.jdbc.url=jdbc:mysql://ldisonarci.wdf.sap.corp:3306/sonar?useUnicode=true characterEncoding=utf8 ******** ******** -Dsonar.host.url=http://ldisonarci.wdf.sap.corp:8080/sonar[INFO] Error stacktraces are turned on.[INFO] Scanning for projects...[WARNING] The POM for org.eclipse.m2e:lifecycle-mapping:jar:1.0.0 is missing, no dependency information available[WARNING] Failed to retrieve plugin descriptor for org.eclipse.m2e:lifecycle-mapping:1.0.0: Plugin org.eclipse.m2e:lifecycle-mapping:1.0.0 or one of its dependencies could not be resolved: Failed to read artifact descriptor for org.eclipse.m2e:lifecycle-mapping:jar:1.0.0[INFO] [INFO] ------------------------------------------------------------------------[INFO] Building gal 1.0.0-SNAPSHOT[INFO] ------------------------------------------------------------------------[WARNING] The POM for org.eclipse.m2e:lifecycle-mapping:jar:1.0.0 is missing, no dependency information available[WARNING] Failed to retrieve plugin descriptor for org.eclipse.m2e:lifecycle-mapping:1.0.0: Plugin org.eclipse.m2e:lifecycle-mapping:1.0.0 or one of its dependencies could not be resolved: Failed to read artifact descriptor for org.eclipse.m2e:lifecycle-mapping:jar:1.0.0[INFO] [INFO] --- sonar-maven-plugin:2.6:sonar (default-cli) @ gal ---[INFO] SonarQube version: 4.5.1INFO: Default locale: en_US, source code encoding: UTF-8INFO: Work directory: /usr/sap/ljsersistentfs/jenkins/jobs/com.sap.solman.graphical.component-official_branch_sp1-sonar/workspace/SMGC/target/sonarINFO: SonarQube Server 4.5.1[INFO] [15:35:19.185] Load global referentials...[INFO] [15:35:19.316] Load global referentials done: 133 ms[INFO] [15:35:19.334] User cache: /usr/sap/ljs/home/.sonar/cache[INFO] [15:35:19.348] Install plugins[INFO] [15:35:19.496] Install JDBC driver[INFO] [15:35:19.504] Create JDBC datasource for jdbc:mysql://ldisonarci.wdf.sap.corp:3306/sonar?useUnicode=true characterEncoding=utf8[INFO] [15:35:21.177] Initializing Hibernate[INFO] [15:35:23.421] Load project referentials...[WARN] [15:35:23.422] Ability to set quality profile from command line using 'sonar.profile' is deprecated and will be dropped in a future SonarQube version. Please configure quality profile used by your project on SonarQube server.[INFO] [15:35:23.745] Load project referentials done: 324 ms[INFO] [15:35:23.745] Load project settings[INFO] [15:35:24.064] Loading technical debt model...[INFO] [15:35:24.093] Loading technical debt model done: 29 ms[INFO] [15:35:24.100] Apply project exclusions[WARN] [15:35:24.101] 'sonar.includedModules' property is deprecated since version 4.3 and should not be used anymore.[INFO] [15:35:24.424] ------------- Scan gal[INFO] [15:35:24.429] Load module settings[INFO] [15:35:26.250] Loading rules...[INFO] [15:35:26.582] Loading rules done: 332 ms[INFO] [15:35:26.603] Configure Maven plugins[INFO] [15:35:26.771] Compare to previous analysis (2015-05-04)[INFO] [15:35:26.784] Compare over 30 days (2015-04-04, analysis of 2015-04-07 07:45:54.0)[INFO] [15:35:26.795] Compare to previous version (2015-01-22)[INFO] [15:35:26.796] No quality gate is configured.[INFO] [15:35:26.984] Initializer FindbugsMavenInitializer...[INFO] [15:35:26.986] Initializer FindbugsMavenInitializer done: 2 ms[INFO] [15:35:26.986] Initializer MqrInitializer...[INFO] [15:35:26.986] Skipping non-aggregator project[INFO] [15:35:26.986] Initializer MqrInitializer done: 0 ms[INFO] [15:35:26.986] Base dir: /usr/sap/ljsersistentfs/jenkins/jobs/com.sap.solman.graphical.component-official_branch_sp1-sonar/workspace/SMGC[INFO] [15:35:26.986] Working dir: /usr/sap/ljsersistentfs/jenkins/jobs/com.sap.solman.graphical.component-official_branch_sp1-sonar/workspace/SMGC/target/sonar[INFO] [15:35:26.987] Source paths: src/main/webapp, pom.xml[INFO] [15:35:26.987] Test paths: src/test/java[INFO] [15:35:26.987] Binary dirs: target/classes[INFO] [15:35:26.987] Source encoding: UTF-8, default locale: en_US[INFO] [15:35:26.987] Index files[INFO] [15:35:28.386] 414 files indexed[INFO] [15:35:42.885] Quality profile for java: SAPDefaultProfile_1_3_10[INFO] [15:35:42.885] Quality profile for js@sap: ESLint_Fiori[INFO] [15:35:42.885] Quality profile for mqr: ESLint_Fiori[INFO] [15:35:43.052] Sensor JavaSquidSensor...[INFO] [15:35:43.414] Java Main Files AST scan...[INFO] [15:35:43.417] 0 source files to be analyzed[INFO] [15:35:43.418] Java Main Files AST scan done: 4 ms[INFO] [15:35:43.418] 0/0 source files analyzed[INFO] [15:35:43.421] Java bytecode scan...[INFO] [15:35:43.531] Java bytecode scan done: 110 ms[INFO] [15:35:43.531] Java Test Files AST scan...[INFO] [15:35:43.531] 71 source files to be analyzed[INFO] [15:35:44.546] Java Test Files AST scan done: 1015 ms[INFO] [15:35:44.546] 71/71 source files analyzed[INFO] [15:35:44.551] Package design analysis...[INFO] [15:35:44.565] Package design analysis done: 13 ms[INFO] [15:35:44.573] Sensor JavaSquidSensor done: 1521 ms[INFO] [15:35:44.574] Sensor QProfileSensor...[INFO] [15:35:44.577] Sensor QProfileSensor done: 3 ms[INFO] [15:35:44.577] Sensor CoverageSensor...[INFO] [15:35:44.577] Sensor CoverageSensor done: 0 ms[INFO] [15:35:44.577] Sensor LintSensor...[INFO] [15:35:44.578] parsing /usr/sap/ljsersistentfs/jenkins/jobs/com.sap.solman.graphical.component-official_branch_sp1-sonar/workspace/SMGC/target/jslint.xml[INFO] ------------------------------------------------------------------------[INFO] BUILD FAILURE[INFO] ------------------------------------------------------------------------[INFO] Total time: 31.675s[INFO] Finished at: Mon May 04 15:35:44 UTC 2015[INFO] Final Memory: 36M/320M[INFO] ------------------------------------------------------------------------[ERROR] Failed to execute goal org.codehaus.mojo:sonar-maven-plugin:2.6:sonar (default-cli) on project gal: Duplicate source for resource: org.sonar.api.resources.File@60ba6a62[key=src/main/webapp/ags_gal_app/Controllers/extendedEditorEventHandler.js,deprecatedKey=src/main/webapp/ags_gal_app/Controllers/extendedEditorEventHandler.js,path=src/main/webapp/ags_gal_app/Controllers/extendedEditorEventHandler.js,dir=src/main/webapp/ags_gal_app/Controllers,filename=extendedEditorEventHandler.js,language=JavaScript @ SAP] -   [Help 1]org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.codehaus.mojo:sonar-maven-plugin:2.6:sonar (default-cli) on project gal: Duplicate source for resource: org.sonar.api.resources.File@60ba6a62[key=src/main/webapp/ags_gal_app/Controllers/extendedEditorEventHandler.js,deprecatedKey=src/main/webapp/ags_gal_app/Controllers/extendedEditorEventHandler.js,path=src/main/webapp/ags_gal_app/Controllers/extendedEditorEventHandler.js,dir=src/main/webapp/ags_gal_app/Controllers,filename=extendedEditorEventHandler.js,language=JavaScript @ SAP] at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:217) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145) at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:84) at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:59) at org.apache.maven.lifecycle.internal.LifecycleStarter.singleThreadedBuild(LifecycleStarter.java:183) at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:161) at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:320) at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:156) at org.apache.maven.cli.MavenCli.execute(MavenCli.java:537) at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:196) at org.apache.maven.cli.MavenCli.main(MavenCli.java:141) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:290) at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:230) at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:409) at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:352)reThe error occurs when i try to parse the jslint.xml file.For this i added the properties -Dsonar.javascript.jslint.reportPath=target/jslint.xml in the Addition Properties field in the Jenkins plugin.If I remove it the jobs will work but the file will not be uploaded.Any idea what could cause this problem?",Not-TD-related,SonarQube,,,,0.054,0.938,0.008,-0.9778
30209898,How to reuse fxcop.xml in SonarQube,"We have FxCop analysis being run by Nant/Jenkins. A SonarQube C# analysis is then triggered, and executed successfully.We'd like to reuse fxcop.xml result file from Jenkins for Sonar's analysis.We tried this configuration with no luck:sonar.fxcop.mode=reuseReportsonar.fxcop.reportsPaths=fxcop.xmlSonarQube is asking for path to FxCopCmd.exe. If specified, Sonar is running FxCop analysis one more time. We don't want that.",Not-TD-related,SonarQube,,,,0.052,0.817,0.132,0.7413
30437258,How to make a redirect in velocity template?,"How to redirect to http://google.com in the code .vm file? (I mean within #if <redirect to Google here> #else ... #end statement)Doing setRequestURI('http://google.com') or similar doesn't work and I'm not sure if it is possible at all.Thank you.Can anybody explain please?",Not-TD-related,SonarQube,,,,0.041,0.852,0.107,0.4936
30467652,SonarQube project not updating from Sonar Runner,"I've provisioned three projects, two of which update as expected each time Jenkins deploys to the dev environment. However, while the third job populates with the initial results, each subsequent run does not update the project despite successful SonarRunner execution. (I've scrubbed some of the names and paths).Here is the failing job project file: required metadata sonar.projectKey=xxxxxxx sonar.projectName=xxxxxxx sonar.projectVersion=1.0  path to source directories (required)sonar.sources=src paths to excludesonar.exclusions=sonar.scm.disabled=truesonar.javascript.mode=skipsonar.css.mode=skip Encoding of the source codesonar.sourceEncoding=UTF-8reHere is the console output from Jenkins: SonarQube Runner 2.4Java 1.7.0_71 Oracle Corporation (64-bit)Linux 2.6.32-504.3.3.el6.x86_64 amd64INFO: Error stacktraces are turned on.INFO: Runner configuration file: xxxxxxxx/sonar-runner.propertiesINFO: Project configuration file: NONEINFO: Default locale: en_US, source code encoding: UTF-8INFO: Work directory: xxxxxxx/workspace/.sonarINFO: SonarQube Server 5.112:29:29.558 INFO - Load global repositories12:29:29.784 INFO - Load global repositories (done) | time=228ms12:29:29.786 INFO - Server id: 2015052211324012:29:29.788 INFO - User cache: /varb/jenkins/.sonar/cache12:29:29.797 INFO - Install plugins12:29:30.091 INFO - Install JDBC driver12:29:30.112 INFO - Create JDBC datasource for jdbc:mysql://xxxxxxx/sonar?useUnicode=true characterEncoding=utf8 rewriteBatchedStatements=true useConfigs=maxPerformance12:29:31.619 INFO - Initializing Hibernate12:29:33.037 INFO - Load project repositories12:29:34.129 INFO - Load project repositories (done) | time=1092ms12:29:34.130 INFO - Load project settings12:29:34.834 INFO - Load technical debt model12:29:34.863 INFO - Apply project exclusions12:29:36.001 INFO - ------------- Scan www.XXXXXXXXX.com-XXXXXXXX12:29:36.005 INFO - Load module settings12:29:36.214 INFO - Load rules12:29:37.422 INFO - Base dir: xxxxx/workspace12:29:37.422 INFO - Working dir: xxxxx.sonar12:29:37.422 INFO - Source paths: src12:29:37.423 INFO - Source encoding: UTF-8, default locale: en_US12:29:37.423 INFO - Index files12:29:38.342 INFO - 254 files indexed12:29:43.048 INFO - Quality profile for java: Sonar way12:29:43.048 INFO - Quality profile for xml: Sonar way12:29:43.524 WARN - ----------------------------------------------------------------12:29:43.524 WARN - Sonargraph: Skipping project xxxxx, since no Sonargraph rules are activated in current SonarQube quality profile.12:29:43.524 WARN - ----------------------------------------------------------------12:29:43.526 INFO - JIRA issues sensor will not run as some parameters are missing.12:29:43.541 INFO - Sensor JavaSquidSensor12:29:44.015 INFO - Java Main Files AST scan...12:29:44.017 INFO - 238 source files to be analyzed12:29:55.279 INFO - 238/238 source files analyzed12:29:55.278 INFO - Java Main Files AST scan done: 11263 ms12:29:55.279 WARN - Java bytecode has not been made available to the analyzer. The org.sonar.java.bytecode.visitor.DependenciesVisitor@7cd07967, org.sonar.java.checks.UnusedPrivateMethodCheck@43b7ee4b, org.sonar.java.checks.RedundantThrowsDeclarationCheck@607da0a8 are disabled.12:29:55.280 INFO - Java Test Files AST scan...12:29:55.280 INFO - 0 source files to be analyzed12:29:55.280 INFO - Java Test Files AST scan done: 0 ms12:29:55.280 INFO - 0/0 source files analyzed12:29:55.466 INFO - Sensor JavaSquidSensor (done) | time=11925ms12:29:55.467 INFO - Sensor Lines Sensor12:29:55.501 INFO - Sensor Lines Sensor (done) | time=34ms12:29:55.501 INFO - Sensor QProfileSensor12:29:55.505 INFO - Sensor QProfileSensor (done) | time=4ms12:29:55.506 INFO - Sensor InitialOpenIssuesSensor12:30:29.395 INFO - Sensor InitialOpenIssuesSensor (done) | time=33889ms12:30:29.395 INFO - Sensor ProjectLinksSensor12:30:29.404 INFO - Sensor ProjectLinksSensor (done) | time=9ms12:30:29.404 INFO - Sensor VersionEventsSensor12:30:29.427 INFO - Sensor VersionEventsSensor (done) | time=23ms12:30:29.427 INFO - Sensor XmlSensor12:31:14.500 INFO - Sensor XmlSensor (done) | time=45073ms12:31:14.500 INFO - Sensor LineCountSensor12:31:15.041 INFO - Sensor LineCountSensor (done) | time=541ms12:31:15.041 INFO - Sensor SurefireSensor12:31:15.728 INFO - Sensor SurefireSensor (done) | time=687ms12:31:15.729 INFO - Sensor SCM Sensor12:31:15.729 INFO - SCM Sensor is disabled12:31:15.729 INFO - Sensor SCM Sensor (done) | time=0ms12:31:15.729 INFO - Sensor CPD Sensor12:31:15.729 INFO - JavaCpdEngine is used for java12:31:15.731 INFO - Cross-project analysis disabled12:31:16.474 INFO - DefaultCpdEngine is used for xml12:31:16.476 INFO - Sensor CPD Sensor (done) | time=747ms12:31:16.477 INFO - No quality gate is configured.12:31:16.520 INFO - Compare to previous analysis (2015-05-22)12:31:16.524 INFO - Compare over 30 days (2015-04-26, analysis of Fri May 22 11:08:22 CDT 2015)12:31:17.192 INFO - Execute decorators...12:32:58.147 INFO - Store results in database12:33:12.805 INFO - Analysis reports generated in 4585ms, dir size=64 MB12:33:14.429 INFO - Analysis reports compressed in 1624ms, zip size=9 MB12:33:16.335 INFO - Analysis reports sent to server in 1905ms12:33:16.336 INFO - ANALYSIS SUCCESSFUL, you can browse xxxxxx12:33:16.336 INFO - Note that you will be able to access the updated dashboard once the server has processed the submitted analysis report.INFO: ------------------------------------------------------------------------INFO: EXECUTION SUCCESSINFO: ------------------------------------------------------------------------Total time: 3:47.493sFinal Memory: 37M/2167Mre",Not-TD-related,SonarQube,,,,0.044,0.944,0.012,-0.9309
30523430,The Sonar way to define a constant,"I use Sonarqube 5.1 and experiment with the Sonar way Java quality profile. The job is simple: I want to define a global String constant for a missing media type:public interface Utf8MediaType {String APPLICATION_JSON = ""application/json;charset=UTF-8"";}However, Sonarqube tells me this is bad practice in rule squid:S1214  Constants should not be defined in interfaces. The long text talks about implementing this interface, which I didnt intend to, but I give in and create a class instead:public class Utf8MediaType {public static final String APPLICATION_JSON = ""application/json;charset=UTF-8"";}However, this is considered to be a major design issue in rule squid:S1118  Utility classes should not have public constructors. So its urging me to add a private constructor. Of course, this constructor has then to come first not to violate conventions in rule squid:S1213  The members of an interface declaration or class should appear in a pre-defined order. I guess after that I might even get common-java:InsufficientBranchCoverage because the private constructor is not covered in tests.These are the default rules and I feel they are a bit silly in combination. I have more examples where the defaults just dont work for us (TestNG support is lacking). What can I do about it? What do you recommend?Give in. Make it a class, add a private constructor, use introspection in the unit test. Makes the code ten times as big. For a String constant.Create a list of exceptions. But doing this for each project may lead to long lists and invites people to add exceptions even for important stuff.Deactivate rules. Now I would prefer not to tamper with the default profiles, because that may mean a lot of work on Sonarqube upgrades.Create a profile that inherits from the default and overwrites things. It turns out that when you inherit from a profile you cannot deactivate rules. You can only add additional rules and change the configuration of rules (to lower their severity).",Not-TD-related,SonarQube,,,,0.021,0.906,0.073,0.9371
30615358,"Enable java parser failure rule, but sonarqube still doesn't log a parser failure as an issue","I am using Sonarqube 5.1 now, tried to enable java parser failure rule, but after that, Sonarqube still doesn't log a parser failure as an issue, did i do anything wrong?Here is content of my sonar configuration file, sonar.projectKey=testsonar.projectName=testsonar.projectVersion=1.0sonar.sources=.sonar.language=javareHere is the output log, SonarQube Runner 2.4Java 1.8.0_45-internal Oracle Corporation (64-bit)Linux 3.19.0-18-generic amd64INFO: Runner configuration file: /usr/bin/sonar-runner/conf/sonar-runner.propertiesINFO: Project configuration file: /home/administrator/tmp2/sonar.propertiesINFO: Default locale: en_US, source code encoding: UTF-8INFO: Work directory: /home/administrator/tmp2/./.sonarINFO: SonarQube Server 5.118:09:03.983 INFO - Load global repositories18:09:04.133 INFO - Load global repositories (done) | time=153ms18:09:04.135 INFO - Server id: 2015060414570218:09:04.137 INFO - User cache: /home/administrator/.sonar/cache18:09:04.147 INFO - Install plugins18:09:04.230 INFO - Install JDBC driver18:09:04.237 INFO - Create JDBC datasource for jdbc:mysql://172.17.128.76:3306/sonar?useUnicode=true characterEncoding=utf818:09:05.715 INFO - Initializing Hibernate18:09:07.396 INFO - Load project repositories18:09:07.505 INFO - Load project repositories (done) | time=109ms18:09:07.505 INFO - Load project settings18:09:07.861 INFO - Load technical debt model18:09:07.895 INFO - Apply project exclusions18:09:08.190 WARN - SCM provider autodetection failed. No SCM provider claims to support this project. Please use sonar.scm.provider to define SCM of your project.18:09:08.192 INFO - ------------- Scan test18:09:08.201 INFO - Load module settings18:09:08.404 INFO - Language is forced to java18:09:08.424 INFO - Load rules18:09:08.672 INFO - Base dir: /home/administrator/tmp218:09:08.672 INFO - Working dir: /home/administrator/tmp2/.sonar18:09:08.673 INFO - Source paths: .18:09:08.673 INFO - Source encoding: UTF-8, default locale: en_US18:09:08.674 INFO - Index files18:09:08.691 INFO - 1 files indexed18:09:08.959 INFO - Quality profile for java: My way18:09:08.993 INFO - Sensor JavaSquidSensor18:09:09.601 INFO - Java Main Files AST scan...18:09:09.605 INFO - 1 source files to be analyzed18:09:09.622 ERROR - Unable to parse source file : /home/administrator/tmp2/Test.java18:09:09.622 ERROR - Parse error at line 4 column 3:1: public class Test {2: public static void main(String[] args){3: int a = 14: } ^5: }6: 18:09:09.647 INFO - Java Main Files AST scan done: 46 ms18:09:09.648 WARN - Java bytecode has not been made available to the analyzer. The org.sonar.java.bytecode.visitor.DependenciesVisitor@6b86fed8, org.sonar.java.checks.UnusedPrivateMethodCheck@7d131ef1, org.sonar.java.checks.RedundantThrowsDeclarationCheck@15f45ace are disabled.18:09:09.648 INFO - 1/1 source files analyzedre",Not-TD-related,SonarQube,,,,0.129,0.841,0.03,-0.9856
30616819,NullPointerException when analysing a Java project with SonarQube and when activating rules tracking quality issues in unit test source code,"I try to execute a SonarQube (Post build action) analysis after a Jenkins Job (maven clean install)In my Jenkins job log I have this stack: [INFO] --- sonar-maven-plugin:2.6:sonar (default-cli) @ saga ---[INFO] SonarQube version: 5.0INFO: Default locale: en_US, source code encoding: UTF-8INFO: Work directory: /varb/jenkins/workspace/SAGA - Integration Continue - Sonar/target/sonarINFO: SonarQube Server 5.0[INFO] [11:08:40.072] Load global referentials...[INFO] [11:08:40.547] Load global referentials done: 482 ms[INFO] [11:08:40.570] User cache: /home/jenkins/.sonar/cache[INFO] [11:08:40.617] Install plugins[INFO] [11:08:40.801] Install JDBC driver[INFO] [11:08:40.813] Create JDBC datasource for jdbc:postgresql://localhost/sonar[INFO] [11:08:43.805] Initializing Hibernate[INFO] [11:08:51.583] Load project referentials...[INFO] [11:08:56.748] Load project referentials done: 5165 ms[INFO] [11:08:56.751] Load project settings[INFO] [11:08:58.344] Loading technical debt model...[INFO] [11:08:58.429] Loading technical debt model done: 85 ms[INFO] [11:08:58.468] Apply project exclusions[INFO] [11:08:58.905] ------------- Scan saga[INFO] [11:08:58.908] Load module settings[INFO] [11:09:00.288] Loading rules...[INFO] [11:09:00.877] Loading rules done: 589 ms[INFO] [11:09:01.040] Configure Maven plugins[INFO] [11:09:01.713] Compare to previous analysis (2015-05-09)[INFO] [11:09:01.774] Compare over 30 days (2015-05-04, analysis of 2015-05-05 04:13:40.173)[INFO] [11:09:01.780] No quality gate is configured.[INFO] [11:09:02.133] Initializer FindbugsMavenInitializer...[INFO] [11:09:02.143] Initializer FindbugsMavenInitializer done: 12 ms[INFO] [11:09:02.144] Base dir: /varb/jenkins/workspace/SAGA - Integration Continue - Sonar[INFO] [11:09:02.144] Working dir: /varb/jenkins/workspace/SAGA - Integration Continue - Sonar/target/sonar[INFO] [11:09:02.149] Source paths: src/main/webapp, pom.xml, src/main/java[INFO] [11:09:02.150] Test paths: src/test/java[INFO] [11:09:02.151] Binary dirs: target/classes[INFO] [11:09:02.151] Source encoding: UTF-8, default locale: en_US[INFO] [11:09:02.153] Index files[INFO] [11:09:02.219] Excluded sources: [INFO] [11:09:02.222] **Q*.java[INFO] [11:09:04.555] 319 files indexed[INFO] [11:09:06.639] Quality profile for java: Sonar way with Findbugs[INFO] [11:09:06.971] Sensor JavaSquidSensor...[INFO] ------------------------------------------------------------------------[INFO] BUILD FAILURE[INFO] ------------------------------------------------------------------------[INFO] Total time: 33.595 s[INFO] Finished at: 2015-06-03T11:09:07+02:00[INFO] Final Memory: 28M/169M[INFO] ------------------------------------------------------------------------[ERROR] Failed to execute goal org.codehaus.mojo:sonar-maven-plugin:2.6:sonar (default-cli) on project saga: null: MojoExecutionException: NullPointerException -   [Help 1]org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.codehaus.mojo:sonar-maven-plugin:2.6:sonar (default-cli) on project saga: null at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:216) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145) at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116) at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80) at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51) at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:120) at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:347) at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:154) at org.apache.maven.cli.MavenCli.execute(MavenCli.java:584) at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:213) at org.apache.maven.cli.MavenCli.main(MavenCli.java:157) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:483) at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289) at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229) at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415) at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)Caused by: org.apache.maven.plugin.MojoExecutionException at org.codehaus.mojo.sonar.bootstrap.ExceptionHandling.handle(ExceptionHandling.java:41) at org.codehaus.mojo.sonar.bootstrap.RunnerBootstraper.execute(RunnerBootstraper.java:139) at org.codehaus.mojo.sonar.SonarMojo.execute(SonarMojo.java:132) at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:132) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:208) ... 19 moreCaused by: java.lang.NullPointerException at org.sonar.api.batch.rule.Checks.getField(Checks.java:180) at org.sonar.api.batch.rule.Checks.configureFields(Checks.java:167) at org.sonar.api.batch.rule.Checks.instantiate(Checks.java:152) at org.sonar.api.batch.rule.Checks.addAnnotatedChecks(Checks.java:127) at org.sonar.java.SonarComponents.registerTestCheckClasses(SonarComponents.java:128) at org.sonar.plugins.java.JavaSquidSensor.analyse(JavaSquidSensor.java:82) at org.sonar.batch.phases.SensorsExecutor.executeSensor(SensorsExecutor.java:79) at org.sonar.batch.phases.SensorsExecutor.execute(SensorsExecutor.java:70) at org.sonar.batch.phases.PhaseExecutor.execute(PhaseExecutor.java:122) at org.sonar.batch.scan.ModuleScanContainer.doAfterStart(ModuleScanContainer.java:222) at org.sonar.api.platform.ComponentContainer.startComponents(ComponentContainer.java:93) at org.sonar.api.platform.ComponentContainer.execute(ComponentContainer.java:78) at org.sonar.batch.scan.ProjectScanContainer.scan(ProjectScanContainer.java:235) at org.sonar.batch.scan.ProjectScanContainer.scanRecursively(ProjectScanContainer.java:230) at org.sonar.batch.scan.ProjectScanContainer.doAfterStart(ProjectScanContainer.java:223) at org.sonar.api.platform.ComponentContainer.startComponents(ComponentContainer.java:93) at org.sonar.api.platform.ComponentContainer.execute(ComponentContainer.java:78) at org.sonar.batch.scan.ScanTask.scan(ScanTask.java:65) at org.sonar.batch.scan.ScanTask.execute(ScanTask.java:52) at org.sonar.batch.bootstrap.TaskContainer.doAfterStart(TaskContainer.java:128) at org.sonar.api.platform.ComponentContainer.startComponents(ComponentContainer.java:93) at org.sonar.api.platform.ComponentContainer.execute(ComponentContainer.java:78) at org.sonar.batch.bootstrap.BootstrapContainer.executeTask(BootstrapContainer.java:171) at org.sonar.batch.bootstrapper.Batch.executeTask(Batch.java:95) at org.sonar.batch.bootstrapper.Batch.execute(Batch.java:67) at org.sonar.runner.batch.IsolatedLauncher.execute(IsolatedLauncher.java:48) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:483) at org.sonar.runner.impl.BatchLauncher$1.delegateExecution(BatchLauncher.java:87) at org.sonar.runner.impl.BatchLauncher$1.run(BatchLauncher.java:75) at java.security.AccessController.doPrivileged(Native Method) at org.sonar.runner.impl.BatchLauncher.doExecute(BatchLauncher.java:69) at org.sonar.runner.impl.BatchLauncher.execute(BatchLauncher.java:50) at org.sonar.runner.api.EmbeddedRunner.doExecute(EmbeddedRunner.java:102) at org.sonar.runner.api.Runner.execute(Runner.java:100) at org.codehaus.mojo.sonar.bootstrap.RunnerBootstraper.execute(RunnerBootstraper.java:135) ... 22 more[ERROR] [ERROR] Re-run Maven using the -X switch to enable full debug logging.[ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles:[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionExceptionSonarQube analysis completed: FAILUREBuild step 'SonarQube' changed build result to FAILUREBuild step 'SonarQube' marked build as failureFinished: FAILUREreMy Sonar plugins:br - Checkstyle 2.2br - Cobertura 1.6.3br - Findbugs 3.1br - Java 3.3br - PMD 2.3 If a delete the Sonar step in my Jenkins Job I don't have the problem and my Job is SUCCESSI don't know if it is a Jenkins or a Sonar problem.Thanks for your help",Not-TD-related,SonarQube,,,,0.037,0.936,0.027,-0.7043
30624089,Import Jasmine test results into SonarQube,"I've encountered a couple issues when trying to display the passing and failing Jasmine specs in my SonarQube instance for a Javascript project. I use Maven to manage running the tests, via the very nice maven-jasmine-plugin, which provides a very simple setup for integrating with RequireJS and spitting out a JUnit-style XML report in my code/target directory. I'd like to use that report in Sonar.The first issue is that, if the tests are asynchronous, Jasmine reports a time of undefined for that test, which the Sonar Runner cannot parse, dying with an error:block e Fail to parse the Surefire report: Caused by: java.text.ParseException: Unparseable number: undefined Caused by: Unparseable number: undefined/block eIf I manually edit the TEST-jasmine.xml report to simply change undefined to 0, the report can be parsed, but then I get the following warning:block e WARN - Test result will not be saved for test class jasmine, because SonarQube associated resource has not been found using file name: jasmine.js/block eThis is on SonarQube 5.1 with the 2.5 version of the JavaScript plugin.I've seen some older mailing list and StackOverflow questions around proper Jasmine support in Sonar - is there any way to do what I want to do?EDIT Below is the debug log of the sonar-runner (with some files and names redacted): SonarQube Runner 2.4Java 1.8.0_40 Oracle Corporation (64-bit)Windows 8.1 6.3 amd64INFO: Error stacktraces are turned on.INFO: Runner configuration file: c:\Users\Tom\sonar-runner-dist-2.4\conf\sonar-runner.propertiesINFO: Project configuration file: c:\Users\Tom\Documents\  redacted  \sonar-project.propertiesINFO: Default locale: en_US, source code encoding: windows-1252 (analysis is platform dependent)INFO: Work directory: c:\Users\Tom\Documents\  redacted  \.\.sonarINFO: SonarQube Server 5.108:53:25.409 INFO - Load global repositories08:53:25.415 DEBUG - Download: http://192.168.10.157:9000/batch/global (no proxy)08:53:25.536 INFO - Load global repositories (done) | time=129ms08:53:25.537 INFO - Server id: 2015060816404808:53:25.538 INFO - User cache: C:\Users\Tom\.sonar\cache08:53:25.545 INFO - Install plugins08:53:25.545 DEBUG - Download index of plugins08:53:25.545 DEBUG - Download: http://192.168.10.157:9000/deploylugins/index.txt (no proxy)08:53:25.600 DEBUG - Loaded 2133 properties from l10n bundles08:53:25.600 INFO - Install JDBC driver08:53:25.600 DEBUG - Download index of jdbc-driver08:53:25.600 DEBUG - Download: http://192.168.10.157:9000/deploy/jdbc-driver.txt (no proxy)08:53:25.606 INFO - Create JDBC datasource for jdbc:mysql://192.168.10.157:3306/sonar?useUnicode=true characterEncoding=utf808:53:25.825 DEBUG - Testing JDBC connection08:53:26.389 DEBUG - Download: http://192.168.10.157:9000/api/server (no proxy)08:53:26.420 INFO - Initializing Hibernate08:53:26.421 DEBUG - hibernate.generate_statistics: false08:53:26.421 DEBUG - hibernate.dialect: org.sonar.core.persistence.dialect.MySql$MySqlWithDecimalDialect08:53:26.421 DEBUG - hibernate.connection.provider_class: org.sonar.jpa.session.CustomHibernateConnectionProvider08:53:27.391 INFO - Load project repositories08:53:27.392 DEBUG - Download: http://192.168.10.157:9000/batchroject?key=  redacted   preview=false (no proxy)08:53:27.564 INFO - Load project repositories (done) | time=173ms08:53:27.564 INFO - Load project settings08:53:27.892 INFO - Load technical debt model08:53:27.906 DEBUG - Load technical debt model (done) | time=14ms08:53:27.909 INFO - To enable the analysis bootstraper for Visual Studio projects, set the property sonar.visualstudio.enable to true08:53:27.909 INFO - Apply project exclusions08:53:28.200 DEBUG - Acquire semaphore on project : org.sonar.api.resources.Project@6e6b3dbf[id=  null  ,key=  redacted  ,qualifier=TRK], with key batch-  redacted  08:53:28.227 WARN - SCM provider autodetection failed. No SCM provider claims to support this project. Please use sonar.scm.provider to define SCM of your project.08:53:28.228 INFO - ------------- Scan   redacted  08:53:28.231 INFO - Load module settings08:53:28.326 DEBUG - Available languages:08:53:28.326 DEBUG - * C =   cs08:53:28.327 DEBUG - * Java =   java08:53:28.327 DEBUG - * JavaScript =   js08:53:28.340 INFO - Load rules08:53:28.552 DEBUG - Load rules (done) | time=212ms08:53:28.576 DEBUG - Code colorizer, supported languages: cs08:53:28.582 DEBUG - Initializers : 08:53:28.582 INFO - Base dir: c:\Users\Tom\Documents\  redacted  08:53:28.582 INFO - Working dir: c:\Users\Tom\Documents\  redacted  \.sonar08:53:28.583 INFO - Source paths: sites/allbraries/custom08:53:28.583 INFO - Source encoding: windows-1252, default locale: en_US08:53:28.584 INFO - Index files08:53:28.592 INFO - Excluded sources: 08:53:28.592 INFO - sites/allbraries/custom/vendor/*08:53:28.592 INFO - sites/allbraries/custom/js/*08:53:28.593 DEBUG - Declared extensions of language org.sonar.batch.repository.language.Language@6bbd44e7 were converted to sonar.lang.patterns.cs : **/*.cs08:53:28.593 DEBUG - Declared extensions of language org.sonar.batch.repository.language.Language@16641839 were converted to sonar.lang.patterns.java : **/*.java,**/*.jav08:53:28.593 DEBUG - Declared extensions of language org.sonar.batch.repository.language.Language@62640933 were converted to sonar.lang.patterns.js : **/*.js08:53:28.603 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.603 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.608 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.610 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.612 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.613 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.614 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.614 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.615 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.615 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.618 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.620 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.622 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.623 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.623 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.624 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.624 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.625 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.625 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.625 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.626 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.627 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.629 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.632 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.633 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.634 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.635 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.636 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.637 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.638 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.640 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.642 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.643 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.643 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.644 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.645 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.647 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.648 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.649 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.650 DEBUG - Language of file '  redacted  .js' is detected to be 'js'08:53:28.651 INFO - 40 files indexed08:53:28.652 INFO - 16 files ignored because of inclusion/exclusion patterns08:53:29.226 INFO - Quality profile for js: Sonar way08:53:29.310 DEBUG - Sensors : Lines Sensor (wrapped) -   QProfileSensor -   InitialOpenIssuesSensor -   ProjectLinksSensor -   VersionEventsSensor -   JavaScriptSquidSensor -   JsTestDriverSensor -   SCM Sensor (wrapped) -   org.sonar.plugins.javascript.lcov.UTCoverageSensor@33d1d1ef -   org.sonar.plugins.javascript.lcov.ITCoverageSensor@6d21e89c -   CPD Sensor (wrapped)08:53:29.310 INFO - Sensor Lines Sensor (wrapped)08:53:29.324 INFO - Sensor Lines Sensor (wrapped) (done) | time=14ms08:53:29.324 INFO - Sensor QProfileSensor08:53:29.327 INFO - Sensor QProfileSensor (done) | time=3ms08:53:29.328 INFO - Sensor InitialOpenIssuesSensor08:53:29.372 INFO - Sensor InitialOpenIssuesSensor (done) | time=44ms08:53:29.372 INFO - Sensor ProjectLinksSensor08:53:29.382 INFO - Sensor ProjectLinksSensor (done) | time=10ms08:53:29.382 INFO - Sensor VersionEventsSensor08:53:29.405 INFO - Sensor VersionEventsSensor (done) | time=23ms08:53:29.405 INFO - Sensor JavaScriptSquidSensor08:53:29.620 INFO - 40 source files to be analyzed08:53:30.235 INFO - 40/40 source files analyzed08:53:30.243 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.244 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.244 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.246 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.255 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.257 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.262 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.263 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.264 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.266 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.267 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.268 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.269 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.270 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.270 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.272 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.272 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.273 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.274 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.275 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.276 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.277 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.278 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.279 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.280 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.281 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.282 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.283 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.285 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.286 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.287 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.288 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.288 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.289 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.290 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.291 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.292 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.293 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.294 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.295 DEBUG - Metric lines is an internal metric computed by SonarQube. Provided value is ignored.08:53:30.364 INFO - Sensor JavaScriptSquidSensor (done) | time=959ms08:53:30.364 INFO - Sensor JsTestDriverSensor08:53:30.364 INFO - Parsing Unit Test run results in Surefire format from folder c:\Users\Tom\Documents\  redacted  \target\jasmine08:53:30.408 DEBUG - Release semaphore on project : org.sonar.api.resources.Project@6e6b3dbf[id=3532,key=  redacted  ,qualifier=TRK], with key batch-  redacted  INFO: ------------------------------------------------------------------------INFO: EXECUTION FAILUREINFO: ------------------------------------------------------------------------Total time: 5.474sFinal Memory: 23M/572MINFO: ------------------------------------------------------------------------ERROR: Error during Sonar runner executionorg.sonar.runner.impl.RunnerException: Unable to execute Sonar at org.sonar.runner.impl.BatchLauncher$1.delegateExecution(BatchLauncher.java:91) at org.sonar.runner.impl.BatchLauncher$1.run(BatchLauncher.java:75) at java.security.AccessController.doPrivileged(Native Method) at org.sonar.runner.impl.BatchLauncher.doExecute(BatchLauncher.java:69) at org.sonar.runner.impl.BatchLauncher.execute(BatchLauncher.java:50) at org.sonar.runner.api.EmbeddedRunner.doExecute(EmbeddedRunner.java:102) at org.sonar.runner.api.Runner.execute(Runner.java:100) at org.sonar.runner.Main.executeTask(Main.java:70) at org.sonar.runner.Main.execute(Main.java:59) at org.sonar.runner.Main.main(Main.java:53)Caused by: org.sonar.api.utils.SonarException: Fail to parse the Surefire report: c:\Users\Tom\Documents\  redacted  \target\jasmine\TEST-jasmine.xml at org.sonar.plugins.javascript.unittest.surefireparser.AbstractSurefireParser.parseFiles(AbstractSurefireParser.java:91) at org.sonar.plugins.javascript.unittest.surefireparser.AbstractSurefireParser.parseFiles(AbstractSurefireParser.java:79) at org.sonar.plugins.javascript.unittest.surefireparser.AbstractSurefireParser.collect(AbstractSurefireParser.java:47) at org.sonar.plugins.javascript.unittest.jstestdriver.JsTestDriverSensor.collect(JsTestDriverSensor.java:73) at org.sonar.plugins.javascript.unittest.jstestdriver.JsTestDriverSensor.analyse(JsTestDriverSensor.java:67) at org.sonar.batch.phases.SensorsExecutor.executeSensor(SensorsExecutor.java:59) at org.sonar.batch.phases.SensorsExecutor.execute(SensorsExecutor.java:51) at org.sonar.batch.phases.DatabaseModePhaseExecutor.execute(DatabaseModePhaseExecutor.java:120) at org.sonar.batch.scan.ModuleScanContainer.doAfterStart(ModuleScanContainer.java:264) at org.sonar.api.platform.ComponentContainer.startComponents(ComponentContainer.java:92) at org.sonar.api.platform.ComponentContainer.execute(ComponentContainer.java:77) at org.sonar.batch.scan.ProjectScanContainer.scan(ProjectScanContainer.java:235) at org.sonar.batch.scan.ProjectScanContainer.scanRecursively(ProjectScanContainer.java:230) at org.sonar.batch.scan.ProjectScanContainer.doAfterStart(ProjectScanContainer.java:220) at org.sonar.api.platform.ComponentContainer.startComponents(ComponentContainer.java:92) at org.sonar.api.platform.ComponentContainer.execute(ComponentContainer.java:77) at org.sonar.batch.scan.ScanTask.scan(ScanTask.java:57) at org.sonar.batch.scan.ScanTask.execute(ScanTask.java:45) at org.sonar.batch.bootstrap.TaskContainer.doAfterStart(TaskContainer.java:135) at org.sonar.api.platform.ComponentContainer.startComponents(ComponentContainer.java:92) at org.sonar.api.platform.ComponentContainer.execute(ComponentContainer.java:77) at org.sonar.batch.bootstrap.GlobalContainer.executeTask(GlobalContainer.java:158) at org.sonar.batch.bootstrapper.Batch.executeTask(Batch.java:95) at org.sonar.batch.bootstrapper.Batch.execute(Batch.java:67) at org.sonar.runner.batch.IsolatedLauncher.execute(IsolatedLauncher.java:48) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.sonar.runner.impl.BatchLauncher$1.delegateExecution(BatchLauncher.java:87) ... 9 moreCaused by: javax.xml.stream.XMLStreamException: java.text.ParseException: Unparseable number: undefined at org.sonar.plugins.javascript.unittest.surefireparser.SurefireStaxHandler.getTimeAttributeInMS(SurefireStaxHandler.java:121) at org.sonar.plugins.javascript.unittest.surefireparser.SurefireStaxHandler.parseTestResult(SurefireStaxHandler.java:88) at org.sonar.plugins.javascript.unittest.surefireparser.SurefireStaxHandler.parseTestCase(SurefireStaxHandler.java:73) at org.sonar.plugins.javascript.unittest.surefireparser.SurefireStaxHandler.stream(SurefireStaxHandler.java:60) at org.sonar.api.utils.StaxParser.parse(StaxParser.java:109) at org.sonar.api.utils.StaxParser.parse(StaxParser.java:89) at org.sonar.api.utils.StaxParser.parse(StaxParser.java:79) at org.sonar.plugins.javascript.unittest.surefireparser.AbstractSurefireParser.parseFiles(AbstractSurefireParser.java:89) ... 38 moreCaused by: java.text.ParseException: Unparseable number: undefined at java.text.NumberFormat.parse(Unknown Source) at org.sonar.api.utils.ParsingUtils.parseNumber(ParsingUtils.java:47) at org.sonar.plugins.javascript.unittest.surefireparser.SurefireStaxHandler.getTimeAttributeInMS(SurefireStaxHandler.java:118) ... 45 morere",Not-TD-related,SonarQube,,,,0.023,0.896,0.081,0.9985
30681295,SonarQube doesn't show any issues with Maven project,"I was using Sonar two weeks ago and It worked fine. Now, when I run sonar, without having changed the project, it shows me 0 issues, 0% technical debt, etc .. ( 20-30 issues were found two weeks ago and the project didn't have changed)This is the result of mvn sonar:sonar  mvn sonar:sonar[INFO] Scanning for projects...[INFO][INFO] ------------------------------------------------------------------------[INFO] Building Golzio-Maumert-Rebouh-SillaPellicer 1.0[INFO] ------------------------------------------------------------------------[INFO][INFO] --- sonar-maven-plugin:2.6:sonar (default-cli) @ Golzio-Maumert-Rebouh-SillaPellicer ---[INFO] SonarQube version: 5.1.1INFO: Default locale: en_US, source code encoding: UTF-8INFO: Work directory: /Users/rebouhaymen/Documentsrojects/MinesAles/1ArojetGL/Golzio-Maumert-Rebouh-SillaPellicer/target/sonarINFO: SonarQube Server 5.1.1[INFO] [11:35:12.231] Load global repositories[INFO] [11:35:12.368] Load global repositories (done) | time=140ms[INFO] [11:35:12.370] Server id: 20150606110929[INFO] [11:35:12.372] User cache: /Users/rebouhaymen/.sonar/cache[INFO] [11:35:12.382] Install plugins[INFO] [11:35:12.430] Install JDBC driver[INFO] [11:35:12.437] Create JDBC datasource for jdbc:mysql://localhost:3306/sonar?useUnicode=true characterEncoding=utf8[INFO] [11:35:13.627] Initializing Hibernate[INFO] [11:35:15.128] Load project repositories[INFO] [11:35:15.148] Load project repositories (done) | time=20ms[INFO] [11:35:15.149] Load project settings[INFO] [11:35:15.544] Load technical debt model[INFO] [11:35:15.565] Apply project exclusions[WARN] [11:35:15.843] SCM provider autodetection failed. No SCM provider claims to support this project. Please use sonar.scm.provider to define SCM of your project.[INFO] [11:35:15.844] ------------- Scan Golzio-Maumert-Rebouh-SillaPellicer[INFO] [11:35:15.848] Load module settings[INFO] [11:35:15.974] Load rules[INFO] [11:35:16.027] Base dir: /Users/rebouhaymen/Documentsrojects/MinesAles/1ArojetGL/Golzio-Maumert-Rebouh-SillaPellicer[INFO] [11:35:16.027] Working dir: /Users/rebouhaymen/Documentsrojects/MinesAles/1ArojetGL/Golzio-Maumert-Rebouh-SillaPellicer/target/sonar[INFO] [11:35:16.028] Source paths: pom.xml, src/main/java[INFO] [11:35:16.028] Test paths: src/test/java[INFO] [11:35:16.028] Binary dirs: target/classes[INFO] [11:35:16.028] Source encoding: UTF-8, default locale: en_US[INFO] [11:35:16.029] Index files[INFO] [11:35:16.038] 0 files indexed[INFO] [11:35:16.067] Sensor Lines Sensor[INFO] [11:35:16.068] Sensor Lines Sensor (done) | time=1ms[INFO] [11:35:16.068] Sensor QProfileSensor[INFO] [11:35:16.085] Sensor QProfileSensor (done) | time=17ms[INFO] [11:35:16.085] Sensor InitialOpenIssuesSensor[INFO] [11:35:16.094] Sensor InitialOpenIssuesSensor (done) | time=9ms[INFO] [11:35:16.094] Sensor ProjectLinksSensor[INFO] [11:35:16.108] Sensor ProjectLinksSensor (done) | time=14ms[INFO] [11:35:16.108] Sensor VersionEventsSensor[INFO] [11:35:16.122] Sensor VersionEventsSensor (done) | time=14ms[INFO] [11:35:16.122] Sensor Maven dependencies[INFO] [11:35:16.169] Sensor Maven dependencies (done) | time=47ms[INFO] [11:35:16.169] Sensor SCM Sensor[INFO] [11:35:16.169] No SCM system was detected. You can use the 'sonar.scm.provider' property to explicitly specify it.[INFO] [11:35:16.169] Sensor SCM Sensor (done) | time=0ms[INFO] [11:35:16.169] Sensor CPD Sensor[INFO] [11:35:16.169] Sensor CPD Sensor (done) | time=0ms[INFO] [11:35:16.170] No quality gate is configured.[INFO] [11:35:16.215] Compare to previous analysis (2015-06-06)[INFO] [11:35:16.221] Compare over 30 days (2015-05-07, analysis of Fri May 29 14:22:45 CEST 2015)[INFO] [11:35:16.550] Execute decorators...[INFO] [11:35:16.672] Store results in database[INFO] [11:35:16.749] Analysis reports generated in 31ms, dir size=142 bytes[INFO] [11:35:16.754] Analysis reports compressed in 5ms, zip size=518 bytes[INFO] [11:35:16.782] Analysis reports sent to server in 28ms[INFO] [11:35:16.782] ANALYSIS SUCCESSFUL, you can browse http://localhost:9000/dashboard/indexrojetGL:Golzio-Maumert-Rebouh-SillaPellicer[INFO] [11:35:16.782] Note that you will be able to access the updated dashboard once the server has processed the submitted analysis report.[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 5.774 s[INFO] Finished at: 2015-06-06T11:35:16+02:00[INFO] Final Memory: 18M/420M[INFO] ------------------------------------------------------------------------`reThis is my pom.xml :    project xmlns=http://maven.apache.orgOM/4.0.0 xmlns:xsi=http://www.w3.org/2001/XMLSchema-instance xsi:schemaLocation=http://maven.apache.orgOM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd     modelVersion  4.0.0  /modelVersion     groupId  projetGL  /groupId     artifactId  Golzio-Maumert-Rebouh-SillaPellicer  /artifactId     packaging  jar  ackaging     version  1.0  /version     name  Golzio-Maumert-Rebouh-SillaPellicer  /name     url  http://maven.apache.org  /url     dependencies     dependency     groupId  junit  /groupId     artifactId  junit  /artifactId     version  4.11  /version     scope  test  /scope     /dependency     dependency     groupId  log4j  /groupId     artifactId  log4j  /artifactId     version  1.2.17  /version     /dependency     dependency     groupId  mysql  /groupId     artifactId  mysql-connector-java  /artifactId     version  5.1.35  /version     /dependency     /dependencies     !-- http://maven.apache.org/general.htmlencoding-warning --     properties     project.build.sourceEncoding  UTF-8  roject.build.sourceEncoding     project.reporting.outputEncoding  UTF-8  roject.reporting.outputEncoding     sonar.jdbc.url  jdbc:mysql://localhost:3306/sonar?useUnicode=true characterEncoding=utf8  /sonar.jdbc.url     sonar.jdbc.driver  com.mysql.jdbc.Driver  /sonar.jdbc.driver     sonar.jdbc.username  sonar  /sonar.jdbc.username     sonar.jdbc.password  sonar  /sonar.jdbc.password     sonar.host.url  http://localhost:9000  /sonar.host.url     roperties     build     plugins     plugin     groupId  org.codehaus.mojo  /groupId     artifactId  exec-maven-plugin  /artifactId     version  1.4.0  /version     executions     execution     id  Test  /id     phase  test  hase     goals     goal  java  /goal     /goals     /execution     /executions     configuration     mainClass  projetGL.App  /mainClass     /configuration     lugin     plugin     groupId  org.codehaus.mojo  /groupId     artifactId  sonar-maven-plugin  /artifactId     version  2.6  /version     lugin     lugins     /build    roject  reThis is the server logs : 2015.06.07 14:28:28 INFO es[o.s.p.ProcessEntryPoint] Starting searc015.06.07 14:28:28 INFO es[o.s.s.SearchServer] Starting Elasticsearch[sonarqube] on port 90012015.06.07 14:28:33 INFO es[o.elasticsearch.node] [sonar-1433680102830] version[1.4.4], pid[40316], build[c88f77f/2015-02-19T13:05:36Z]2015.06.07 14:28:33 INFO es[o.elasticsearch.node] [sonar-1433680102830] initializing ...2015.06.07 14:28:33 INFO es[o.e.plugins] [sonar-1433680102830] loaded [], sites []2015.06.07 14:28:36 INFO es[o.elasticsearch.node] [sonar-1433680102830] initialized2015.06.07 14:28:36 INFO es[o.elasticsearch.node] [sonar-1433680102830] starting ...2015.06.07 14:28:41 INFO es[o.e.transport] [sonar-1433680102830] bound_address {inet[/0.0.0.0:9001]}, publish_address {inet[/172.20.10.3:9001]}2015.06.07 14:28:41 INFO es[o.e.discovery] [sonar-1433680102830] sonarqube/dOoDg_ijSRqe9slU7KQPQQ2015.06.07 14:28:44 INFO es[o.e.cluster.service] [sonar-1433680102830] new_master [sonar-1433680102830][dOoDg_ijSRqe9slU7KQPQQ][MacBook-Pro-de-Rebouh.local][inet[/172.20.10.3:9001]]{rack_id=sonar-1433680102830}, reason: zen-disco-join (elected_as_master)2015.06.07 14:28:44 INFO es[o.elasticsearch.node] [sonar-1433680102830] started2015.06.07 14:28:45 INFO es[o.e.gateway] [sonar-1433680102830] recovered [6] indices into cluster_stateJava HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=160m; support was removed in 8.02015.06.07 14:28:45 INFO app[o.s.p.m.Monitor] Process[search] is up2015.06.07 14:28:45 INFO app[o.s.p.m.JavaProcessLauncher] Launch process[web]: /Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/bin/java -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djruby.management.enabled=false -Djruby.compile.invokedynamic=false -Xmx768m -XX:MaxPermSize=160m -XX:+HeapDumpOnOutOfMemoryError -Djava.net.preferIPv4Stack=true -Djava.io.tmpdir=/Users/rebouhaymen/Documents/sonarqube-5.1.1/temp -cp .b/common/*:.b/server/*:/Users/rebouhaymen/Documents/sonarqube-5.1.1b/jdbc/mysql/mysql-connector-java-5.1.34.jar org.sonar.server.app.WebServer /var/folders/30/vc9tg8r5173fr2lzwxd2ywdc0000gn/T/sq-process8400283793441720685properties2015.06.07 14:28:51 INFO web[o.s.p.ProcessEntryPoint] Starting web2015.06.07 14:28:51 INFO web[o.s.s.app.Webapp] Webapp directory: /Users/rebouhaymen/Documents/sonarqube-5.1.1/web2015.06.07 14:28:51 INFO web[o.a.c.h.Http11NioProtocol] Initializing ProtocolHandler [http-nio-0.0.0.0-9000]2015.06.07 14:28:51 INFO web[o.a.t.u.n.NioSelectorPool] Using a shared selector for servlet write/read2015.06.07 14:28:52 INFO web[o.e.plugins] [sonar-1433680102830] loaded [], sites []2015.06.07 14:29:03 INFO web[o.s.s.p.ServerImpl] SonarQube Server / 5.1.1 / 0a231d24c0f1e7ce1d200274b8e9bbe00f9f49fb2015.06.07 14:29:03 INFO web[o.s.c.p.Database] Create JDBC datasource for jdbc:mysql://localhost:3306/sonar?useUnicode=true characterEncoding=utf8 rewriteBatchedStatements=true useConfigs=maxPerformance2015.06.07 14:29:04 INFO web[o.s.s.p.DefaultServerFileSystem] SonarQube home: /Users/rebouhaymen/Documents/sonarqube-5.1.12015.06.07 14:29:04 INFO web[o.s.s.p.ServerPluginJarsInstaller] Install plugins2015.06.07 14:29:04 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin Core / 5.1.1 / 0a231d24c0f1e7ce1d200274b8e9bbe00f9f49fb2015.06.07 14:29:04 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin Email notifications / 5.1.1 / 0a231d24c0f1e7ce1d200274b8e9bbe00f9f49fb2015.06.07 14:29:04 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin English Pack / 5.1.1 / 0a231d24c0f1e7ce1d200274b8e9bbe00f9f49fb2015.06.07 14:29:04 INFO web[o.s.s.p.RailsAppsDeployer] Deploy Ruby on Rails applications2015.06.07 14:29:04 INFO web[o.s.j.s.AbstractDatabaseConnector] Initializing Hibernate2015.06.07 14:29:11 INFO web[o.s.s.p.UpdateCenterClient] Update center: http://update.sonarsource.org/update-center.properties (no proxy)2015.06.07 14:29:11 INFO web[o.s.s.n.NotificationService] Notification service started (delay 60 sec.)2015.06.07 14:29:11 INFO web[o.s.s.s.IndexSynchronizer] Index rules2015.06.07 14:29:12 INFO web[o.s.s.s.IndexSynchronizer] Index activeRules2015.06.07 14:29:13 INFO web[o.s.s.s.RegisterMetrics] Register metrics2015.06.07 14:29:13 INFO web[o.s.s.s.RegisterMetrics] Cleaning quality gate conditions2015.06.07 14:29:13 INFO web[o.s.s.s.RegisterDebtModel] Register technical debt model2015.06.07 14:29:13 INFO web[o.s.s.r.RegisterRules] Register rules2015.06.07 14:29:13 INFO web[o.s.s.q.RegisterQualityProfiles] Register quality profiles2015.06.07 14:29:13 INFO web[o.s.s.s.RegisterNewMeasureFilters] Register measure filters2015.06.07 14:29:13 INFO web[o.s.s.s.RegisterDashboards] Register dashboards2015.06.07 14:29:13 INFO web[o.s.s.s.RegisterPermissionTemplates] Register permission templates2015.06.07 14:29:13 INFO web[o.s.s.s.RenameDeprecatedPropertyKeys] Rename deprecated property keys2015.06.07 14:29:13 INFO web[o.s.s.s.IndexSynchronizer] Index activities2015.06.07 14:29:13 INFO web[o.s.s.s.IndexSynchronizer] Index issues2015.06.07 14:29:13 INFO web[o.s.s.s.IndexSynchronizer] Index source lines2015.06.07 14:29:13 INFO web[o.s.s.s.IndexSynchronizer] Index users2015.06.07 14:29:13 INFO web[o.s.s.s.IndexSynchronizer] Index views2015.06.07 14:29:13 INFO web[jruby.rack] jruby 1.7.9 (ruby-1.8.7p370) 2013-12-06 87b108a on Java HotSpot(TM) 64-Bit Server VM 1.8.0_25-b17 [darwin-x86_64]2015.06.07 14:29:13 INFO web[jruby.rack] using a shared (threadsafe!) runtime2015.06.07 14:29:14 WARN es[o.e.c.r.a.decider] [sonar-1433680102830] high disk watermark [10%] exceeded on [dOoDg_ijSRqe9slU7KQPQQ][sonar-1433680102830] free: 18.6gb[8%], shards will be relocated away from this node2015.06.07 14:29:14 INFO es[o.e.c.r.a.decider] [sonar-1433680102830] high disk watermark exceeded on one or more nodes, rerouting shards2015.06.07 14:29:21 INFO web[jruby.rack] keeping custom (config.logger) Rails logger instance2015.06.07 14:29:21 INFO web[o.a.c.h.Http11NioProtocol] Starting ProtocolHandler [http-nio-0.0.0.0-9000]2015.06.07 14:29:21 INFO web[o.s.s.a.TomcatAccessLog] Web server is started2015.06.07 14:29:21 INFO web[o.s.s.a.EmbeddedTomcat] HTTP connector enabled on port 90002015.06.07 14:29:21 INFO app[o.s.p.m.Monitor] Process[web] is up2015.06.07 14:29:44 WARN es[o.e.c.r.a.decider] [sonar-1433680102830] high disk watermark [10%] exceeded on [dOoDg_ijSRqe9slU7KQPQQ][sonar-1433680102830] free: 18.6gb[8%], shards will be relocated away from this node2015.06.07 14:30:09 INFO web[o.s.s.c.ComputationService] Analysis of project projetGL:Golzio-Maumert-Rebouh-SillaPellicer (report 9) (done) | time=317ms2015.06.07 14:30:14 WARN es[o.e.c.r.a.decider] [sonar-1433680102830] high disk watermark [10%] exceeded on [dOoDg_ijSRqe9slU7KQPQQ][sonar-1433680102830] free: 18.6gb[8%], shards will be relocated away from this node2015.06.07 14:30:44 WARN es[o.e.c.r.a.decider] [sonar-1433680102830] high disk watermark [10%] exceeded on [dOoDg_ijSRqe9slU7KQPQQ][sonar-1433680102830] free: 18.6gb[8%], shards will be relocated away from this node2015.06.07 14:30:44 INFO es[o.e.c.r.a.decider] [sonar-1433680102830] high disk watermark exceeded on one or more nodes, rerouting shards2015.06.07 14:31:14 WARN es[o.e.c.r.a.decider] [sonar-1433680102830] high disk watermark [10%] exceeded on [dOoDg_ijSRqe9slU7KQPQQ][sonar-1433680102830] free: 18.6gb[8%], shards will be relocated away from this nodere",Not-TD-related,SonarQube,,,,0.03,0.934,0.036,0.8883
30706289,set alfresco dateTextBox to empty,"I want to set an empty value for Alfresco Aikau DateTextBox widget. But the date is being set to ""1970/1/1"" automatically. How can i set a date to empty in Aikau ?I'm trying this code in the jsonModel but it's not working:{name:""alfresco/forms/controls/DateTextBox"",widthPx:""90"",config:{fieldId:""DATE_1"",additionalCssClasses:""datefield"",name:""Date1"",value:"""",requirementConfig:{initialValue:false}}}",Not-TD-related,SonarQube,,,,0.071,0.872,0.056,-0.1901
30712585,Reports missing on SonarQube dashboard after upgrade,"Recently I've upgraded SonarQube from 3.5 to 4.5.4 (LTS) and now there are a few users complaining that there are some reports missing on their project dashboards. The reports/numbers missing widgets are: emlines of code/em and emcomplexity/em. Unit tests coverage displays nothing. Other widgets (like technical debt, issues, directory tangle index) display 0 which also is suspicious. The project is in Java using the Sonar way profile.The user does: mvn clean org.jacoco:jacoco-maven-plugin:prepare-agent installmvn sonar:sonar -Dsonar.login=login -Dsonar.password=***** -Dcom.sun.jndi.ldap.connect.pool.prefsize=0 -Dcom.sun.jndi.ldap.connect.pool.timeout=3600000reThe codesonar:sonar step shows 0 files indexed.The log is huge so I don't want to paste it here. I could not find anything helpful in it. What do I need to do to have all reports I used to have?I have a test project where most of the missing data is displayed out of the box.",Not-TD-related,SonarQube,,,,0.126,0.838,0.036,-0.8494
30911961,SonarQube PHP no code coverage,"We're using jenkins with SonarQube to perform code analysis on our php projects. We now generate the phpunit coverage files on different server and want to load these coverage files into SonarQube. The problem is that the coverage files are there and seem to be loaded in SonarQube but the code coverage in SonarQube is still empty. Interesting is the line after the code coverage files are loaded: INFO - Project: nullrePretty much the same error was described on the old sonar mailinglist in this post:a href=http://sonarqube.15.x6.nabble.comHPUnit-test-coverage-from-PHPUnit-not-being-picked-up-with-Giving-Project-null-error-tc5028771.htmlnone rel=nofollowhttp://sonarqube.15.x6.nabble.comHPUnit-test-coverage-from-PHPUnit-not-being-picked-up-with-Giving-Project-null-error-tc5028771.htmlnone/aFull runner log: INFO: Runner configuration file: /opt/sonar-runner/conf/sonar-runner.propertiesINFO: Project configuration file: NONEINFO: Default locale: en_US, source code encoding: UTF-8INFO: Work directory: /varb/jenkins/jobs/FooBarJob-Dev/workspace/.sonarINFO: SonarQube Server 5.0INFO - Load global referentials...INFO - Load global referentials done: 297 msINFO - User cache: /varb/jenkins/.sonar/cacheINFO - Install pluginsINFO - Install JDBC driverINFO - Create JDBC datasource for jdbc:mysql://localhost:3306/sonar?useUnicode=true characterEncoding=utf8 rewriteBatchedStatements=trueINFO - Initializing HibernateINFO - Load project referentials...INFO - Load project referentials done: 1514 msINFO - Load project settingsINFO - Loading technical debt model...INFO - Loading technical debt model done: 30 msINFO - Apply project exclusionsINFO - ------------- Scan FooBarJobINFO - Load module settingsINFO - Language is forced to phpINFO - Loading rules...INFO - Loading rules done: 1442 msINFO - Configure Maven pluginsINFO - Compare to previous analysis (2015-06-18)INFO - Compare over 30 days (2015-05-19, analysis of 2015-06-18 08:18:26.0)INFO - No quality gate is configured.INFO - Base dir: /varb/jenkins/jobs/FooBarJobDev/workspaceINFO - Working dir: /varb/jenkins/jobs/FooBarJob-Dev/workspace/.sonarINFO - Source paths: src/mainINFO - Test paths: src/mainhp/FooBarJob/TestsINFO - Source encoding: UTF-8, default locale: en_USINFO - Index filesINFO - Excluded sources: INFO - **/Tests/**INFO - **/Tests/**INFO - Included tests: INFO - **/Tests/**INFO - 48 files indexedINFO - Quality profile for php: Sonar wayINFO - Sensor NoSonar and Commented out LOC Sensor...INFO - Sensor NoSonar and Commented out LOC Sensor done: 156 msINFO - Sensor QProfileSensor...INFO - Sensor QProfileSensor done: 6 msINFO - Sensor org.sonar.plugins.php.PHPSquidSensor@118b47dc...INFO - Sensor org.sonar.plugins.php.PHPSquidSensor@118b47dc done: 1984 msINFO - Sensor PHPUnit Sensor...INFO - Analyzing PHPUnit tests report: varhpunit.xmlINFO - Analyzing PHPUnit coverage report: var/coverage.xmlINFO - Project: nullINFO - Sensor PHPUnit Sensor done: 1507 msINFO - Sensor InitialOpenIssuesSensor...INFO - Sensor InitialOpenIssuesSensor done: 127 msINFO - Sensor ProjectLinksSensor...INFO - Sensor ProjectLinksSensor done: 15 msINFO - Sensor VersionEventsSensor...INFO - Sensor VersionEventsSensor done: 40 msINFO - Sensor FileHashSensor...INFO - Sensor FileHashSensor done: 114 msINFO - Sensor SCM Sensor...INFO - Sensor SCM Sensor done: 125 msINFO - Sensor CPD Sensor...INFO - DefaultCpdEngine is used for phpINFO - Cross-project analysis disabledINFO - Sensor CPD Sensor done: 373 msINFO - Execute decorators...INFO - Store results in databaseINFO - ANALYSIS SUCCESSFUL, you can browse https://localhost/sonar/dashboard/index/com.barComp:FooBarJobINFO - Note that you will be able to access the updated dashboard once the server has processed the submitted analysis report.INFO - Executing post-job class org.sonar.plugins.core.issue.notification.SendIssueNotificationsPostJobre",Not-TD-related,SonarQube,,,,0.059,0.908,0.033,-0.8538
31160807,Is Chef 10 working with Debian 8?,Bootstraping Chef on a Debian 8 node with Chef 10 returns the following error:codeERROR: Net::SSH::Exception: could not settle on kex algorithmIs Debian 8 not compatible with Chef 10?,Not-TD-related,SonarQube,,,,0,1,0,0
31207843,Is the SonarQube Java analyser supposed to be able to detect duplicate local variable error?,"Create the follow Java class in Eclipse, it will say that there is a duplicate local variable error, public class Test { public static void main(String[] args) { hello(); } private static void hello() { int a=1; int a=1; }}rethen you analyze this Java class with SonarQube, it can be analyzed without any problem, shouldn't a semantic issue be reported? INFO: SonarQube Server 5.1.121:46:51.395 INFO - Load global repositories21:46:51.609 INFO - Load global repositories (done) | time=218ms21:46:51.611 INFO - Server id: 2015070212284921:46:51.614 INFO - User cache: /home/administrator/.sonar/cache21:46:51.622 INFO - Install plugins21:46:51.700 INFO - Install JDBC driver21:46:51.707 INFO - Create JDBC datasource for jdbc:postgresql://localhost/sonar21:46:53.026 INFO - Initializing Hibernate21:46:54.946 INFO - Load project repositories21:46:55.036 INFO - Load project repositories (done) | time=91ms21:46:55.036 INFO - Load project settings21:46:55.400 INFO - Load technical debt model21:46:55.427 INFO - Apply project exclusions21:46:55.700 INFO - ------------- Scan testlatform/frameworks/av21:46:55.710 INFO - Load module settings21:46:55.897 INFO - Load rules21:46:56.119 INFO - Base dir: /home/administrator/tmp/frameworks/av21:46:56.119 INFO - Working dir: /home/administrator/tmp/frameworks/av/.sonar21:46:56.120 INFO - Source paths: .21:46:56.121 INFO - Source encoding: ISO-8859-2, default locale: en_US21:46:56.121 INFO - Index files21:46:56.344 INFO - 1 files indexed21:46:56.390 INFO - Quality profile for java: Sonar way21:46:56.424 INFO - Sensor JavaSquidSensor21:46:57.107 INFO - Java Main Files AST scan...21:46:57.112 INFO - 1 source files to be analyzed21:46:57.416 INFO - Java Main Files AST scan done: 309 ms21:46:57.417 INFO - 1/1 source files have been analyzed21:46:57.417 WARN - Java bytecode has not been made available to the analyzer. The org.sonar.java.bytecode.visitor.DependenciesVisitor@51e55964, org.sonar.java.checks.UnusedPrivateMethodCheck@431dc52b, org.sonar.java.checks.RedundantThrowsDeclarationCheck@7fa7f0c8 are disabled.21:46:57.417 INFO - Java Test Files AST scan...21:46:57.418 INFO - 0 source files to be analyzed21:46:57.418 INFO - Java Test Files AST scan done: 1 ms21:46:57.418 INFO - 0/0 source files have been analyzed21:46:57.443 INFO - Sensor JavaSquidSensor (done) | time=1019ms21:46:57.443 INFO - Sensor Lines Sensor21:46:57.445 INFO - Sensor Lines Sensor (done) | time=2ms21:46:57.445 INFO - Sensor QProfileSensor21:46:57.450 INFO - Sensor QProfileSensor (done) | time=5ms21:46:57.450 INFO - Sensor InitialOpenIssuesSensor21:46:57.472 INFO - Sensor InitialOpenIssuesSensor (done) | time=22ms21:46:57.473 INFO - Sensor ProjectLinksSensor21:46:57.487 INFO - Sensor ProjectLinksSensor (done) | time=14ms21:46:57.487 INFO - Sensor VersionEventsSensor21:46:57.518 INFO - Sensor VersionEventsSensor (done) | time=31ms21:46:57.518 INFO - Sensor SurefireSensor21:46:57.520 INFO - parsing /home/administrator/tmp/frameworks/av/target/surefire-reports21:46:57.520 ERROR - Reports path not found or is not a directory: /home/administrator/tmp/frameworks/av/target/surefire-reports21:46:57.520 INFO - Sensor SurefireSensor (done) | time=2ms21:46:57.520 INFO - Sensor SCM Sensor21:46:57.520 INFO - SCM provider for this project is: git21:46:57.529 INFO - 1 files to be analyzed21:46:57.910 INFO - 0/1 files analyzed21:46:57.910 WARN - Missing blame information for the following files:21:46:57.911 WARN - * /home/administrator/tmp/frameworks/av/Test.java21:46:57.911 WARN - This may lead to missing/broken features in SonarQube21:46:57.911 INFO - Sensor SCM Sensor (done) | time=391ms21:46:57.911 INFO - Sensor CPD Sensor21:46:57.911 INFO - JavaCpdEngine is used for java21:46:57.912 INFO - Cross-project analysis disabled21:46:57.939 INFO - Sensor CPD Sensor (done) | time=28ms21:46:57.941 INFO - No quality gate is configured.21:46:57.985 INFO - Compare to previous analysis (2015-07-03)21:46:57.992 INFO - Compare over 30 days (2015-06-03, analysis of Thu Jul 02 14:53:26 CST 2015)21:46:58.311 INFO - Execute decorators...21:46:58.960 INFO - Store results in database21:46:59.289 INFO - Analysis reports generated in 44ms, dir size=1 KB21:46:59.299 INFO - Analysis reports compressed in 10ms, zip size=1 KB21:46:59.349 INFO - Analysis reports sent to server in 50ms21:46:59.350 INFO - ANALYSIS SUCCESSFUL, you can browse http://localhost:9000/dashboard/index/test-platform-frameworks-av21:46:59.350 INFO - Note that you will be able to access the updated dashboard once the server has processed the submitted analysis report.INFO: ------------------------------------------------------------------------INFO: EXECUTION SUCCESSINFO: ------------------------------------------------------------------------re",Not-TD-related,SonarQube,,,,0.05,0.927,0.023,-0.8742
31462500,Sonar 5.1.1 with Groovy Plugin 1.1.1 project always reports technical debt of 0.0 days,"Upfront: I know there is already the same question on SO, but refereing to different version. (a href=https://stackoverflow.com/questions/20914171/sonar-with-groovy-project-always-reports-technical-debt-of-0-0-daysSonar with Groovy project always reports technical debt of 0.0 days/a)I am trying to get SonarCube 5.1.1 up and running together with the groovy 1.1.1 plugin. Unfortunately, I always the technical debt of 0.0 days.The Sqale information is included in the groovy plugin, so it seems that this isn't the problem.Any other idea?",Not-TD-related,SonarQube,,,,0.129,0.871,0,-0.8625
31474061,Sonar xml schema validation rule causes ClassNotFoundException,"We are using the XML language Sonar plugin and have successfully added some custom XPath rules but when we activate a schema check rule we get a ClassNotFoundException: org.sonar.api.utils.SonarException: java.lang.ClassNotFoundException: org.apache.xerces.dom.DOMImplementationSourceImplreInitially we were using Sonar version 5.1.1 with version 1.3 of the XML language plugin installed on Ubuntu 14.04 using Oracle Java version 1.8.0_45 - we actually tried various 1.7 and 1.8 Javas. We tried running the analysis first using Sonar runner v2.4 and then using the Sonar ant task v2.3 and both gave the same error.We found that there is a JIRA already raised about this: a href=http://jira.sonarsource.com/browse/SONARXML-3 rel=nofollowSONARXML-3/a but it has been closed as won't fix because it could not be reproduced on SonarQube 4.5.4.We did a clean install of Sonar 4.5.4 with version 1.3 of the XML language plugin onto a Windows machine and used a very simple test case.After the install we did the following:ulliCreated a custom rule based on the XML schemas should be valid ruleliLeft the schemas to the default autodetect and set filePattern to **/*.htmlliAdded html to the file suffixes setting of the XML pluginliActivated the custom rule in the Sonar Way profileWhen we ran sonar runner on a single html file we still got the same error.I have looked in the XML plugin jar and there it contains xercesImpl-2.8.1.jar in its META-INFb which contains the class that it complains it can't find.I am not sure what to try next. Have we missed a step when configuring the Sonar server or Sonar runner?EDITED TO ADD SIMPLE PROJECT INFO:A single file for analysis, Basic.html:   !DOCTYPE html PUBLIC -//W3C//DTD XHTML 1.0 Transitional//ENhttp://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd    html xmlns=http://www.w3.org/1999/xhtml     head     title  Title of document  /title     /head     body   some content   /body    /html  resonar-project.properties: sonar.projectKey=simple:schema-testsonar.projectName=Schema Check Testsonar.projectVersion=1.0sonar.sources=.reOutput from sonar-runner: SonarQube Runner 2.4Java 1.8.0_45 Oracle Corporation (64-bit)Linux 3.13.0-57-generic amd64INFO: Runner configuration file: /home/mike/SonarDev/sonar-runner-2.4/conf/sonar-runner.propertiesINFO: Project configuration file: /home/mike/SonarDev/SimpleSchema/sonar-project.propertiesINFO: Default locale: en_GB, source code encoding: UTF-8INFO: Work directory: /home/mike/SonarDev/SimpleSchema/./.sonarINFO: SonarQube Server 4.5.413:08:39.283 INFO - Load global referentials...13:08:39.765 INFO - Load global referentials done: 488 ms13:08:39.805 INFO - User cache: /home/mike/.sonar/cache13:08:39.837 INFO - Install plugins13:08:39.864 INFO - Download sonar-core-plugin-4.5.4.jar13:08:39.933 INFO - Download sonar-email-notifications-plugin-4.5.4.jar13:08:39.979 INFO - Download sonar-findbugs-plugin-2.4.jar13:08:40.258 INFO - Download sonar-java-plugin-2.4.jar13:08:40.328 INFO - Download sonar-xml-plugin-1.3.jar13:08:40.512 INFO - Download sonar-cpd-plugin-4.5.4.jar13:08:40.528 INFO - Download sonar-design-plugin-4.5.4.jar13:08:40.553 INFO - Download sonar-dbcleaner-plugin-4.5.4.jar13:08:40.577 INFO - Download sonar-l10n-en-plugin-4.5.4.jar13:08:40.683 INFO - Install JDBC driver13:08:40.713 INFO - Download mysql-connector-java-5.1.27.jar13:08:40.761 INFO - Create JDBC datasource for jdbc:mysql://localhost:3306/sonar4?useUnicode=true characterEncoding=utf813:08:44.377 INFO - Initializing Hibernate13:08:47.843 INFO - Load project referentials...13:08:48.430 INFO - Load project referentials done: 587 ms13:08:48.438 INFO - Load project settings13:08:49.256 INFO - Loading technical debt model...13:08:49.348 INFO - Loading technical debt model done: 92 ms13:08:49.372 INFO - Apply project exclusions13:08:49.988 INFO - ------------- Scan Schema Check Test13:08:50.018 INFO - Load module settings13:08:51.201 INFO - Loading rules...13:08:51.930 INFO - Loading rules done: 725 ms13:08:52.035 INFO - Configure Maven plugins13:08:52.447 INFO - Compare to previous analysis (2015-07-22)13:08:52.475 INFO - Compare over 30 days (2015-06-22, analysis of 2015-07-22 12:56:55.0)13:08:52.480 INFO - No quality gate is configured.13:08:53.015 INFO - Base dir: /home/mike/SonarDev/SimpleSchema/.13:08:53.022 INFO - Working dir: /home/mike/SonarDev/SimpleSchema/./.sonar13:08:53.024 INFO - Source paths: .13:08:53.024 INFO - Source encoding: UTF-8, default locale: en_GB13:08:53.024 INFO - Index files13:08:53.224 INFO - 1 files indexed13:08:53.370 INFO - Quality profile for xml: Sonar way13:08:53.422 INFO - Sensor QProfileSensor...13:08:53.464 INFO - Sensor QProfileSensor done: 42 ms13:08:53.466 INFO - Sensor InitialOpenIssuesSensor...13:08:53.504 INFO - Sensor InitialOpenIssuesSensor done: 38 ms13:08:53.510 INFO - Sensor ProjectLinksSensor...13:08:53.533 INFO - Sensor ProjectLinksSensor done: 23 ms13:08:53.539 INFO - Sensor VersionEventsSensor...13:08:53.592 INFO - Sensor VersionEventsSensor done: 53 ms13:08:53.593 INFO - Sensor FileHashSensor...13:08:53.608 INFO - Sensor FileHashSensor done: 15 ms13:08:53.608 INFO - Sensor XmlSensor...13:08:54.071 ERROR - Could not analyze the file /home/mike/SonarDev/SimpleSchema/Basic.htmlorg.sonar.api.utils.SonarException: java.lang.ClassNotFoundException: org.apache.xerces.dom.DOMImplementationSourceImpl at org.sonar.plugins.xml.schemas.SchemaResolver.createLSInput(SchemaResolver.java:122) ~[na:na] at org.sonar.plugins.xml.schemas.SchemaResolver.resolveResource(SchemaResolver.java:269) ~[na:na] at com.sun.org.apache.xerces.internal.util.DOMEntityResolverWrapper.resolveEntity(DOMEntityResolverWrapper.java:117) ~[na:1.8.0_45] at com.sun.org.apache.xerces.internal.impl.XMLEntityManager.resolveEntity(XMLEntityManager.java:1079) ~[na:1.8.0_45] at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaLoader.resolveDocument(XMLSchemaLoader.java:660) ~[na:1.8.0_45] at com.sun.org.apache.xerces.internal.impl.xs.traversers.XSDHandler.resolveSchema(XSDHandler.java:2052) ~[na:1.8.0_45] at com.sun.org.apache.xerces.internal.impl.xs.traversers.XSDHandler.constructTrees(XSDHandler.java:1008) ~[na:1.8.0_45] at com.sun.org.apache.xerces.internal.impl.xs.traversers.XSDHandler.parseSchema(XSDHandler.java:620) ~[na:1.8.0_45] at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaLoader.loadSchema(XMLSchemaLoader.java:617) ~[na:1.8.0_45] at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaLoader.loadGrammar(XMLSchemaLoader.java:575) ~[na:1.8.0_45] at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaLoader.loadGrammar(XMLSchemaLoader.java:541) ~[na:1.8.0_45] at com.sun.org.apache.xerces.internal.jaxp.validation.XMLSchemaFactory.newSchema(XMLSchemaFactory.java:255) ~[na:1.8.0_45] at org.sonar.plugins.xml.checks.XmlSchemaCheck.createSchema(XmlSchemaCheck.java:146) ~[na:na] at org.sonar.plugins.xml.checks.XmlSchemaCheck.validate(XmlSchemaCheck.java:232) ~[na:na] at org.sonar.plugins.xml.checks.XmlSchemaCheck.autodetectSchemaAndValidate(XmlSchemaCheck.java:164) ~[na:na] at org.sonar.plugins.xml.checks.XmlSchemaCheck.validate(XmlSchemaCheck.java:222) ~[na:na] at org.sonar.plugins.xml.checks.XmlSchemaCheck.validate(XmlSchemaCheck.java:260) ~[na:na] at org.sonar.plugins.xml.XmlSensor.analyse(XmlSensor.java:77) ~[na:na] at org.sonar.batch.phases.SensorsExecutor.executeSensor(SensorsExecutor.java:79) [sonar-batch-maven-compat-4.5.4.jar:na] at org.sonar.batch.phases.SensorsExecutor.execute(SensorsExecutor.java:70) [sonar-batch-maven-compat-4.5.4.jar:na] at org.sonar.batch.phases.PhaseExecutor.execute(PhaseExecutor.java:119) [sonar-batch-maven-compat-4.5.4.jar:na] at org.sonar.batch.scan.ModuleScanContainer.doAfterStart(ModuleScanContainer.java:194) [sonar-batch-maven-compat-4.5.4.jar:na] at org.sonar.api.platform.ComponentContainer.startComponents(ComponentContainer.java:93) [sonar-batch-maven-compat-4.5.4.jar:na] at org.sonar.api.platform.ComponentContainer.execute(ComponentContainer.java:78) [sonar-batch-maven-compat-4.5.4.jar:na] at org.sonar.batch.scan.ProjectScanContainer.scan(ProjectScanContainer.java:233) [sonar-batch-maven-compat-4.5.4.jar:na] at org.sonar.batch.scan.ProjectScanContainer.scanRecursively(ProjectScanContainer.java:228) [sonar-batch-maven-compat-4.5.4.jar:na] at org.sonar.batch.scan.ProjectScanContainer.doAfterStart(ProjectScanContainer.java:221) [sonar-batch-maven-compat-4.5.4.jar:na] at org.sonar.api.platform.ComponentContainer.startComponents(ComponentContainer.java:93) [sonar-batch-maven-compat-4.5.4.jar:na] at org.sonar.api.platform.ComponentContainer.execute(ComponentContainer.java:78) [sonar-batch-maven-compat-4.5.4.jar:na] at org.sonar.batch.scan.ScanTask.scan(ScanTask.java:64) [sonar-batch-maven-compat-4.5.4.jar:na] at org.sonar.batch.scan.ScanTask.execute(ScanTask.java:51) [sonar-batch-maven-compat-4.5.4.jar:na] at org.sonar.batch.bootstrap.TaskContainer.doAfterStart(TaskContainer.java:125) [sonar-batch-maven-compat-4.5.4.jar:na] at org.sonar.api.platform.ComponentContainer.startComponents(ComponentContainer.java:93) [sonar-batch-maven-compat-4.5.4.jar:na] at org.sonar.api.platform.ComponentContainer.execute(ComponentContainer.java:78) [sonar-batch-maven-compat-4.5.4.jar:na] at org.sonar.batch.bootstrap.BootstrapContainer.executeTask(BootstrapContainer.java:173) [sonar-batch-maven-compat-4.5.4.jar:na] at org.sonar.batch.bootstrapper.Batch.executeTask(Batch.java:95) [sonar-batch-maven-compat-4.5.4.jar:na] at org.sonar.batch.bootstrapper.Batch.execute(Batch.java:67) [sonar-batch-maven-compat-4.5.4.jar:na] at org.sonar.runner.batch.IsolatedLauncher.execute(IsolatedLauncher.java:48) [sonar-runner-batc088275009626652419.jar:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_45] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_45] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_45] at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_45] at org.sonar.runner.impl.BatchLauncher$1.delegateExecution(BatchLauncher.java:87) [sonar-runner-dist-2.4.jar:na] at org.sonar.runner.impl.BatchLauncher$1.run(BatchLauncher.java:75) [sonar-runner-dist-2.4.jar:na] at java.security.AccessController.doPrivileged(Native Method) [na:1.8.0_45] at org.sonar.runner.impl.BatchLauncher.doExecute(BatchLauncher.java:69) [sonar-runner-dist-2.4.jar:na] at org.sonar.runner.impl.BatchLauncher.execute(BatchLauncher.java:50) [sonar-runner-dist-2.4.jar:na] at org.sonar.runner.api.EmbeddedRunner.doExecute(EmbeddedRunner.java:102) [sonar-runner-dist-2.4.jar:na] at org.sonar.runner.api.Runner.execute(Runner.java:100) [sonar-runner-dist-2.4.jar:na] at org.sonar.runner.Main.executeTask(Main.java:70) [sonar-runner-dist-2.4.jar:na] at org.sonar.runner.Main.execute(Main.java:59) [sonar-runner-dist-2.4.jar:na] at org.sonar.runner.Main.main(Main.java:53) [sonar-runner-dist-2.4.jar:na]Caused by: java.lang.ClassNotFoundException: org.apache.xerces.dom.DOMImplementationSourceImpl at java.net.URLClassLoader.findClass(URLClassLoader.java:381) ~[na:1.8.0_45] at java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[na:1.8.0_45] at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[na:1.8.0_45] at org.w3c.dom.bootstrap.DOMImplementationRegistry.newInstance(DOMImplementationRegistry.java:182) ~[na:1.8.0_45] at org.sonar.plugins.xml.schemas.SchemaResolver.createLSInput(SchemaResolver.java:115) ~[na:na] ... 51 common frames omitted13:08:54.077 INFO - Sensor XmlSensor done: 469 ms13:08:54.079 INFO - Sensor LineCountSensor...13:08:54.110 INFO - Sensor LineCountSensor done: 31 ms13:08:54.112 INFO - Sensor CPD Sensor (wrapped)...13:08:54.112 INFO - DefaultCpdEngine is used for xml13:08:54.114 INFO - Cross-project analysis disabled13:08:54.148 INFO - Sensor CPD Sensor (wrapped) done: 36 ms13:08:54.639 INFO - Execute decorators...13:08:55.155 INFO - Store results in database13:08:55.494 INFO - ANALYSIS SUCCESSFUL, you can browse http://localhost:9000/dashboard/index/simple:schema-test13:08:55.592 INFO - Executing post-job class org.sonar.plugins.core.issue.notification.SendIssueNotificationsPostJob13:08:55.593 INFO - Executing post-job class org.sonar.plugins.core.batch.IndexProjectPostJob13:08:55.698 INFO - Executing post-job class org.sonar.plugins.dbcleaner.ProjectPurgePostJob13:08:55.782 INFO - -   Keep one snapshot per day between 2015-06-24 and 2015-07-2113:08:55.793 INFO - -   Keep one snapshot per week between 2014-07-23 and 2015-06-2413:08:55.799 INFO - -   Keep one snapshot per month between 2010-07-28 and 2014-07-2313:08:55.809 INFO - -   Delete data prior to: 2010-07-2813:08:55.826 INFO - -   Clean Schema Check Test [id=312]13:08:55.860 INFO -   - Clean snapshot 695INFO: ------------------------------------------------------------------------INFO: EXECUTION SUCCESSINFO: ------------------------------------------------------------------------Total time: 18.958sFinal Memory: 12M/118MINFO: ------------------------------------------------------------------------re",Not-TD-related,SonarQube,,,,0.027,0.948,0.025,0.1923
31608933,Android Best Practices - Refactoring a big Activity class,"Looking to refactor a Google maps Activity class to something a little more maintainable.Currently it implements the following interfaces:codeLocationListener, codeGoogleApiClient.ConnectionCallbacks, codeGoogleApiClient.OnConnectionFailedListener, codeAdapterView.OnItemClickListenerAs well as this, it contains quite a number of helper methods.I have a few questions relating to the best way of doing this.olliShould I create static helper classes and leave my listener implementations in the Activity class?liShould I create helper classes and create instances of them, passing to their constructors everything I need? e.g. contexts.liShould I abstract my Activity class and implement each listener in its own class separately?Thanks in advance. I'd like to follow some sort of Android/Java standard before my technical debt builds up much further.",Not-TD-related,SonarQube,,,,0.031,0.757,0.212,0.9614
31748268,How To Configure SonarQube GitHub Plugin With Jenkins,"We are very interested in leveraging the GitHub integration on my team:a href=http://docs.sonarqube.org/displayLUG/GitHub+Plugin rel=nofollowhttp://docs.sonarqube.org/displayLUG/GitHub+Plugin/aWe use Jenkins as our CI Server and already have the GitHub Pull Request Builder working there. We have also been using SonarQube for analysis but have not had much luck with the preview or incremental modes and GitHub integration. Current versions are SonarQube 5.1.1 and GitHub Plugin version 1.0.1.We have the plug-in installed on SonarQube and have our GitHub Enterprise API configured. We have attempted using the SonarQube Runner in Jenkins and Maven to get this to work following the codetravis.sh script as a guide:a href=https://github.com/SonarSource/sonarqube/blob/master/travis.sh rel=nofollowhttps://github.com/SonarSource/sonarqube/blob/master/travis.sh/aWe see the Sonar integration show up on GitHub, but it is always successful (we are working with large, legacy code bases and expect to see a lot of output).The thing that is consistent between our javascript and java analysis is that we don't seem to be getting any files indexed and the GitHub Plugin InputFile Cache sensor is used instead of Javascript or Java sensors we are used to seeing during a full analysis. 00:01:57.532 13:12:31.109 INFO - 0 files indexed 00:01:57.533 13:12:31.110 INFO - 25784 files ignored because of inclusion/exclusion patterns00:01:57.535 13:12:31.112 INFO - Quality profile for js: Sonar way00:01:57.758 13:12:31.334 DEBUG - 'SCM Sensor' skipped in preview mode00:01:57.758 13:12:31.335 DEBUG - 'CPD Sensor' skipped in preview mode00:01:57.759 13:12:31.336 DEBUG - Sensors : Lines Sensor (wrapped) -   GitHub Plugin InputFile Cache00:01:57.759 13:12:31.336 INFO - Sensor Lines Sensor (wrapped)00:01:57.759 13:12:31.336 INFO - Sensor Lines Sensor (wrapped) (done) | time=0ms00:01:57.759 13:12:31.336 INFO - Sensor GitHub Plugin InputFile Cache00:01:57.759 13:12:31.336 INFO - Sensor GitHub Plugin InputFile Cache (done) | time=0ms00:01:57.759 13:12:31.336 DEBUG - No previous analysis, skipping issue tracking00:01:57.763 13:12:31.340 INFO - 00:01:57.763 00:01:57.763 ------------- Issues Report -------------00:01:57.763 00:01:57.763 No file analyzed00:01:57.763 00:01:57.763 -------------------------------------------00:01:57.763 00:01:57.763 00:01:57.763 13:12:31.340 INFO - Export issues to /data/jenkins/workspace/mygea-mygeaviation-pullrequests/.sonar/sonar-report.json00:01:57.766 13:12:31.343 INFO - ANALYSIS SUCCESSFUL00:01:57.767 13:12:31.344 DEBUG - Post-jobs : GitHub Pull Request Issue Publisher00:01:57.767 13:12:31.344 INFO - Executing post-job class org.sonar.plugins.github.PullRequestIssuePostJobreAre we missing something simple?Analysis properties are as follows: sonar.projectKey=mygea-ux-pullrequestssonar.projectName=mygea-ux-pullrequestssonar.projectVersion=1.0.0sonar.sourceEncoding=UTF-8sonar.language=jssonar.sources=./sonar.verbose=truesonar.exclusions=static/ge_ux/**/*, node_modules/**/*, custom-login/custom-login-cfm/iids/**/*, custom-login/custom-login-honda/iids/**/*, custom-login/custom-login-ge/iids/**/*, static/ge.com.2013/components/**/*, static/ge.com.2013/widgets/**/*.min.js, testFiles/**/*, coverage/**/*, gulpfile.js, test-tmp/**/*, extend.js, index.js, static/ge.com.2013/js/**/*.min.jssonar.analysis.mode=previewsonar.issuesReport.console.enable=truesonar.forceUpdate=truesonar.github.pullRequest=$ghprbPullIdsonar.github.repository=mygea/mygeaviationsonar.github.login=*****sonar.github.oauth=*****sonar.github.endpoint=*****reAny assistance on this would be much appreciated! This is an awesome plug-in and we think it will really help us get our technical debt under control.Josh",Not-TD-related,SonarQube,,,,0.047,0.895,0.057,0.7755
31772026,0 files indexed after migrating from sonarqube 5.0.1 to 5.1.2,"After migrating our project from sonarqube 5.0.1 to 5.1.2 we get no results after analysing. I gues its because sonar runner is indexing 0 files....The configuration, like basedir, didnt change. Does anyone having an idea? Build step 'Invoke Gradle script' changed build result to SUCCESS[workspace] $ C:\Users\Jenkins\.jenkins\tools\hudson.plugins.sonar.SonarRunnerInstallation\SonarRunner\bin\sonar-runner.bat -e -Dsonar.jdbc.url=jdbc:postgresql://localhost/sonar ******** ******** -Dsonar.host.url=http://zaphod:9000/ ******** ******** -Dsonar.projectBaseDir=C:\Users\Jenkins\.jenkins\jobs\KISSsoftCRM_develop\workspace -Dsonar.sources=src/api,src/main -Dsonar.junit.reportsPath=build/test-results -Dsonar.jacoco.reportPath=build/jacoco/test.exec -Dsonar.jacoco.reportMissing.force.zero=true -Dsonar.projectVersion=1.0.0 -Dsonar.java.binaries=build/classes -Dsonar.modules=CRMUtil -Dsonar.projectKey=com.kisssoft.crm.util -Dsonar.java.libraries=buildbs -Dsonar.java.coveragePlugin=jacoco -Dsonar.projectName=CRMUtil_developC:\Users\Jenkins\.jenkins\tools\hudson.plugins.sonar.SonarRunnerInstallation\SonarRunnerSonarQube Runner 2.4Java 1.8.0_25 Oracle Corporation (64-bit)Windows 7 6.1 amd64INFO: Error stacktraces are turned on.INFO: Runner configuration file: C:\Users\Jenkins\.jenkins\tools\hudson.plugins.sonar.SonarRunnerInstallation\SonarRunner\conf\sonar-runner.propertiesINFO: Project configuration file: NONEINFO: Default locale: de_DE, source code encoding: windows-1252 (analysis is platform dependent)INFO: Work directory: C:\Users\Jenkins\.jenkins\jobs\KISSsoftCRM_develop\workspace\.sonarINFO: SonarQube Server 5.1.214:35:00.881 INFO - Load global repositories14:35:01.213 INFO - Load global repositories (done) | time=334ms14:35:01.215 INFO - Server id: 2015080214134114:35:01.218 INFO - User cache: C:\Users\Jenkins\.sonar\cache14:35:01.228 INFO - Install plugins14:35:01.283 INFO - Install JDBC driver14:35:01.293 INFO - Create JDBC datasource for jdbc:postgresql://localhost/sonar14:35:04.103 INFO - Initializing Hibernate14:35:06.921 INFO - Load project repositories14:35:07.002 INFO - Load project repositories (done) | time=81ms14:35:07.002 INFO - Load project settings14:35:08.261 INFO - Load technical debt model14:35:08.287 INFO - Apply project exclusions14:35:08.975 INFO - ------------- Scan CRMUtil14:35:08.981 INFO - Load module settings14:35:09.162 INFO - Load rules14:35:09.230 INFO - Base dir: C:\Users\Jenkins\.jenkins\jobs\KISSsoftCRM_develop\workspace\CRMUtil14:35:09.230 INFO - Working dir: C:\Users\Jenkins\.jenkins\jobs\KISSsoftCRM_develop\workspace\.sonar\com.kisssoft.crm.util_CRMUtil14:35:09.231 INFO - Source paths: src/api, src/main14:35:09.232 INFO - Source encoding: windows-1252, default locale: de_DE14:35:09.232 INFO - Index files14:35:09.265 INFO - 0 files indexed14:35:09.751 INFO - Sensor Lines Sensor14:35:09.753 INFO - Sensor Lines Sensor (done) | time=2ms14:35:09.753 INFO - Sensor QProfileSensor14:35:09.770 INFO - Sensor QProfileSensor (done) | time=17ms14:35:09.770 INFO - Sensor InitialOpenIssuesSensor14:35:09.791 INFO - Sensor InitialOpenIssuesSensor (done) | time=21ms14:35:09.791 INFO - Sensor ProjectLinksSensor14:35:09.801 INFO - Sensor ProjectLinksSensor (done) | time=10ms14:35:09.801 INFO - Sensor VersionEventsSensor14:35:10.115 INFO - Sensor VersionEventsSensor (done) | time=314ms14:35:10.115 INFO - Sensor SCM Sensor14:35:10.115 INFO - SCM Sensor is disabled14:35:10.115 INFO - Sensor SCM Sensor (done) | time=0ms14:35:10.115 INFO - Sensor CPD Sensor14:35:10.115 INFO - Sensor CPD Sensor (done) | time=0ms14:35:10.147 INFO - Loaded quality gate 'SonarQube way'14:35:10.204 INFO - Compare to previous analysis (2015-08-02)14:35:10.212 INFO - Compare over 30 days (2015-07-03, analysis of Tue Jun 30 23:09:17 CEST 2015)14:35:10.215 INFO - Compare to previous version (2015-07-28)14:35:11.237 INFO - Execute decorators...14:35:11.745 INFO - ------------- Scan CRMUtil_develop14:35:11.746 INFO - Load module settings14:35:11.772 INFO - Base dir: C:\Users\Jenkins\.jenkins\jobs\KISSsoftCRM_develop\workspace14:35:11.772 INFO - Working dir: C:\Users\Jenkins\.jenkins\jobs\KISSsoftCRM_develop\workspace\.sonar14:35:11.772 INFO - Source encoding: windows-1252, default locale: de_DE14:35:11.776 INFO - Sensor Lines Sensor14:35:11.776 INFO - Sensor Lines Sensor (done) | time=0ms14:35:11.776 INFO - Sensor InitialOpenIssuesSensor14:35:11.782 INFO - Sensor InitialOpenIssuesSensor (done) | time=6ms14:35:11.783 INFO - Sensor ProjectLinksSensor14:35:11.786 INFO - Sensor ProjectLinksSensor (done) | time=2ms14:35:11.786 INFO - Sensor VersionEventsSensor14:35:11.793 INFO - Sensor VersionEventsSensor (done) | time=7ms14:35:11.793 INFO - Sensor SCM Sensor14:35:11.793 INFO - SCM Sensor is disabled14:35:11.793 INFO - Sensor SCM Sensor (done) | time=0ms14:35:11.793 INFO - Sensor CPD Sensor14:35:11.793 INFO - Sensor CPD Sensor (done) | time=0ms14:35:11.819 INFO - Loaded quality gate 'SonarQube way'14:35:11.823 INFO - Compare to previous analysis (2015-08-02)14:35:11.825 INFO - Compare over 30 days (2015-07-03, analysis of Tue Jun 30 23:09:17 CEST 2015)14:35:11.827 INFO - Compare to previous version (2015-07-28)14:35:13.311 INFO - Execute decorators...14:35:13.527 INFO - Store results in database14:35:13.792 INFO - Analysis reports generated in 41ms, dir size=169 bytes14:35:13.815 INFO - Analysis reports compressed in 22ms, zip size=777 bytes14:35:13.853 INFO - Analysis reports sent to server in 38ms14:35:13.853 INFO - ANALYSIS SUCCESSFUL, you can browse http://zaphod:9000/dashboard/index/com.kisssoft.crm.util14:35:13.853 INFO - Note that you will be able to access the updated dashboard once the server has processed the submitted analysis report.re",Not-TD-related,SonarQube,,,,0.015,0.966,0.019,0.4084
31892344,SonarQube is not collecting issues from Android gradle project,"When I start code./gradlew sonar it runs analyser and loads files, the project is added to sonarqube database with list of files, complexity etc. but no issues are created for the project. Android Lint (it has 147 rules added) is set as default list of issues and SonarQube way as default (and only) quality gate.Full log: sudokusolver git:(master)  ./gradlew sonar:app:sonarqubeINFO: Default locale: en_GB, source code encoding: UTF-8 (analysis is platform dependent)INFO: Work directory: /home/agilobrojects/sudokusolver/app/build/sonarINFO: SonarQube Server 5.1.211:48:48.324 INFO - Load global repositories11:48:48.552 INFO - Load global repositories (done) | time=234ms11:48:48.554 INFO - Server id: 2015080720300311:48:48.557 INFO - User cache: /home/agilob/.sonar/cache11:48:48.565 INFO - Install plugins11:48:48.949 INFO - Install JDBC driver11:48:48.962 INFO - Create JDBC datasource for jdbc::tcp://localhost/sonar11:48:50.575 INFO - Initializing Hibernate11:48:52.689 INFO - Load project repositories11:48:52.925 INFO - Load project repositories (done) | time=236ms11:48:52.926 INFO - Load project settings11:48:53.265 INFO - Load technical debt model11:48:53.299 INFO - Apply project exclusions11:48:53.555 WARN - 'sonar.dynamicAnalysis' is deprecated since version 4.3 and should no longer be used.11:48:53.574 WARN - SCM provider autodetection failed. No SCM provider claims to support this project. Please use sonar.scm.provider to define SCM of your project.11:48:53.576 INFO - ------------- Scan SudokuSolver11:48:53.583 INFO - Load module settings11:48:53.727 INFO - Language is forced to java11:48:53.739 INFO - Load rules11:48:54.981 INFO - Base dir: /home/agilobrojects/sudokusolver/app11:48:54.981 INFO - Working dir: /home/agilobrojects/sudokusolver/app/build/sonar11:48:54.982 INFO - Source paths: src/main11:48:54.982 INFO - Test paths: src/androidTest11:48:54.983 INFO - Source encoding: UTF-8, default locale: en_GB11:48:54.983 INFO - Index files11:48:55.116 INFO - 35 files indexed11:48:55.304 INFO - Quality profile for java: Android Lint11:48:55.511 WARN - ----------------------------------------------------------------11:48:55.512 WARN - Sonargraph: Skipping projectSudokuSolver [SusokuSolver], since no Sonargraph rules are activated in current SonarQube quality profile.11:48:55.512 WARN - ----------------------------------------------------------------11:48:55.512 INFO - Trying to guess scm provider from project layout...11:48:55.513 INFO - Found SCM type: git11:48:55.523 INFO - Sensor JavaSquidSensor11:48:56.119 INFO - Java Main Files AST scan...11:48:56.122 INFO - 34 source files to be analyzed11:48:59.551 INFO - Java Main Files AST scan done: 3432 ms11:48:59.552 INFO - 34/34 source files have been analyzed11:48:59.552 WARN - Java bytecode has not been made available to the analyzer. The org.sonar.java.bytecode.visitor.DependenciesVisitor@6e61d22c are disabled.11:48:59.553 INFO - Java Test Files AST scan...11:48:59.553 INFO - 1 source files to be analyzed11:48:59.653 INFO - Java Test Files AST scan done: 100 ms11:48:59.653 INFO - 1/1 source files have been analyzed11:48:59.660 INFO - Sensor JavaSquidSensor (done) | time=4137ms11:48:59.660 INFO - Sensor Lines Sensor11:48:59.673 INFO - Sensor Lines Sensor (done) | time=13ms11:48:59.674 INFO - Sensor QProfileSensor11:48:59.680 INFO - Sensor QProfileSensor (done) | time=6ms11:48:59.680 INFO - Sensor InitialOpenIssuesSensor11:48:59.689 INFO - Sensor InitialOpenIssuesSensor (done) | time=9ms11:48:59.689 INFO - Sensor ProjectLinksSensor11:48:59.701 INFO - Sensor ProjectLinksSensor (done) | time=12ms11:48:59.702 INFO - Sensor VersionEventsSensor11:48:59.721 INFO - Sensor VersionEventsSensor (done) | time=19ms11:48:59.722 INFO - Sensor SurefireSensor11:48:59.723 INFO - parsing /home/agilobrojects/sudokusolver/app/target/surefire-reports11:48:59.724 ERROR - Reports path not found or is not a directory: /home/agilobrojects/sudokusolver/app/target/surefire-reports11:48:59.724 INFO - Sensor SurefireSensor (done) | time=2ms11:48:59.725 INFO - Sensor ScmStatsSensor11:48:59.726 INFO - Collection SCM Change log for the last 0 days11:48:59.773 INFO - Executing: /bin/sh -c cd /home/agilobrojects/sudokusolver/app    git whatchanged '--until=2015-08-08 10:48:59 +0000' --date=iso -- /home/agilobrojects/sudokusolver/app11:48:59.774 INFO - Working directory: /home/agilobrojects/sudokusolver/app11:49:00.107 INFO - Sensor ScmStatsSensor (done) | time=382ms11:49:00.107 INFO - Sensor SCM Sensor11:49:00.108 INFO - No SCM system was detected. You can use the 'sonar.scm.provider' property to explicitly specify it.11:49:00.108 INFO - Sensor SCM Sensor (done) | time=1ms11:49:00.108 INFO - Sensor CPD Sensor11:49:00.109 INFO - JavaCpdEngine is used for java11:49:00.110 INFO - Cross-project analysis disabled11:49:00.395 INFO - Sensor CPD Sensor (done) | time=287ms11:49:00.419 INFO - Loaded quality gate 'SonarQube way'11:49:00.456 INFO - Compare to previous analysis (2015-08-08)11:49:00.458 INFO - Compare over 30 days (2015-07-09, analysis of Fri Aug 07 23:19:57 BST 2015)11:49:01.391 INFO - Execute decorators...11:49:02.036 INFO - Store results in database11:49:02.904 INFO - Analysis reports generated in 24ms, dir size=4 KB11:49:02.934 INFO - Analysis reports compressed in 30ms, zip size=14 KB11:49:02.964 INFO - Analysis reports sent to server in 30ms11:49:02.964 INFO - ANALYSIS SUCCESSFUL, you can browse http://localhost:9000/dashboard/index/SusokuSolver11:49:02.964 INFO - Note that you will be able to access the updated dashboard once the server has processed the submitted analysis report.BUILD SUCCESSFULTotal time: 24.204 secsreMy configuration added to main codegradle.build buildscript {dependencies { classpath org.sonarqube.gradle:gradle-sonarqube-plugin:1.0}}reMy configuration added to codeapp/gradle.build apply plugin: org.sonarqubesonarqube {properties { property sonar.projectName, SudokuSolver property sonar.projectKey, SusokuSolver property sonar.host.url, http://localhost:9000 property sonar.projectVersion, 1.0 property sonar.language, java property sonar.sources, src/main/ property sonar.tests, src/androidTest/}}reSonarQube is launched on embedded database, just for testing, but I don't think it matters.When I start code analyser in IDEA, after 60seconds it gives me over 50 messages. Here I get nothing.a href=https://i.stack.imgur.com/DgIjj.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/DgIjj.png alt=enter image description here/aa href=https://gitlab.com/agilob/sudokusolver/tree/master rel=nofollow noreferrerSource code repo is available on gitlab/a it that might help.",Not-TD-related,SonarQube,,,,0.066,0.901,0.033,-0.9694
31945139,How can I pull out useful metrics from SonarQube,"I am trying to pull out useful metrics from SonarQube (like lines of code, technical debt, sqale rating, etc). The issue is I am stuck on the best way to do this. I am looking at their Web Service API documentation, a href=http://docs.sonarqube.orgages/viewpage.action?pageId=2392172 rel=nofollowhttp://docs.sonarqube.orgages/viewpage.action?pageId=2392172/a. Is this same thing as a RESTful service? So as a simple example...Nemo is a public demo of SonarQube.And the following demonstrates how to get lines of code.Get the metric 'Lines of Code' (key = ncloc)brGET a href=http://nemo.sonarsource.org/api/metrics/ncloc rel=nofollowhttp://nemo.sonarsource.org/api/metrics/ncloc/aSo my question is, can I write a Python program or something to grab the metrics I want from SonarQube? Is this a RESTful API? What is the best way to get this data?Thanks!",Not-TD-related,SonarQube,,,,0.038,0.803,0.159,0.9366
32016706,How to make SonarQube analyzing SBT projects (with Java and Scala) and importing code coverage & unit test coverage?,"I have a SBT project with Java,Scala and its integrated with Jenkins for Sonar scan after SBT build. After successful analysis,I can't see the code coverage and unit test coverage in percentages.The project structure after sbt clean compile test is as follows: le-adaptor src-  main/java/.. ,main/scala/.. , test/scala/.. target-  classes,test-classes,test-reportsle-ui src-  main/java/.. ,test/scala/.. target-  classes,test-classes,test-reportsbuild.sbtreMy sonar-project.properties file is as below: sonar.projectKey=MyProjectsonar.projectName=my sbt projectsonar.projectVersion=0.1.0.0-SNAPSHOTsonar.languages=java,scalasonar.modules=le-adaptor,le-uile-adaptor.sonar.binaries=target/classesle-adaptor.sonar.sources=src/main/java,src/main/scalale-adaptor.sonar.tests=src/test/scalale-adaptor.sonar.junit.reportsPath=target/test-reportsle-ui.sonar.binaries=target/classesle-ui.sonar.sources=src/main/javale-ui.sonar.tests=src/test/scalale-ui.sonar.junit.reportsPath=target/test-reportsreSonar version is 4.3.2 and plugins installed are: Checkstyle 2.1.1Clover 3.0Cobertura 1.6.3Fortify 1.0Generic Coverage 1.1JMeter 0.3Java 2.5.1JavaScript 2.1LDAP 1.2.1PMD 2.2Quality Index 1.1.3SCM Activity 1.5Scalastyle 0.0.1-SNAPSHOTTechnical Debt 1.2.1Total Quality 1.1Toxicity Chart 0.1Useless Code Tracker 0.5Violation DensityreWhen I go to a href=http://localhost:9000/dashboard/index/MyProject rel=nofollowhttp://localhost:9000/dashboard/index/MyProject/a , I can't see the percentage code coverage and unit test coverage.What I'm missing here ? Any help would be appreciated.",Not-TD-related,SonarQube,,,,0.037,0.865,0.098,0.8316
32397096,install lower version of Findbugs plugins in sonarQube 4.5.2,"I need to install lower version of Findbugs plugins in sonarQube 4.5.2. I tried Update center in SonarQube, but no success. Please help me out!!",Not-TD-related,SonarQube,,,,0.127,0.521,0.351,0.8669
32424881,Should we use scrum when requirement is clear,"I tried to practice Scrum in my team. But my colleague asks me:Our software has clearly requirement. So why we should use scrumHow can I persuade him from this case.",Not-TD-related,SonarQube,,,,0,0.891,0.109,0.5499
32464277,New Msbuild Sonar runner is skipping analysis for .net projects,"I have setup new Msbuild sonar runner and kickoff analysis for a project type class library. It went successful. To test it further,olliI have created one more project which has only one file with 5 Interface definitions. liI made sure that names of interfaces NOT started with letter 'i'. liI created a quality profile with one stylecop rule i.e. Interface names must begin with i.liI started cmd prompt (VS command prompt) and change it's path to the directory which has .csproj file. Clearly I am NOT at .sln file level. precisely one more level down where we can see .csproj file.liFired Begin - msbuild -end sequence.liIt shows ANALYSIS SUCCESSFUL but when I don't see any issues on dashboard ( Issues zero where as I expect 5, each one is for one interface).liAfter careful observation of Log, It shows following message. I am not sure that I quite understand it.block e WARNING: File is not under the project directory and cannot currently be analysed by SonarQube. File: C:\Users\raja.moparthi\AppData\Local\Temp.NETFramework,Version=v4.5.AssemblyAttributes.cs, project: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\TestFib2.csproj/block ePlease let me know what is going wrong here.Begin command Log given below : Default properties file was found at D:\MsBuildSonarQubeRunner\SonarQube.Analysis.xmlLoading analysis properties from D:\MsBuildSonarQubeRunner\SonarQube.Analysis.xmlPre-processing started.Using environment variables to determine the download directory...Removing the existing directory: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqubeCreating directory: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqubeCreating directory: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\binSonarQube server url: http://{SonarQube ServerName: I removed it}:9000/Downloading SonarQube.MSBuild.Runner.Implementation.zip from http://{SonarQube ServerName: I removed it}/static/csharp/SonarQube.MSBuild.Runner.Implementation.zip to D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\bin\SonarQube.MSBuild.Runner.Implementation.zipExecuting file D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\bin\MSBuild.SonarQube.Internal.PreProcess.exe Args: /k:FibTest /n:FibTestAnalysis /v:1.0.0.0 /s:D:\MsBuildSonarQubeRunner\SonarQube.Analysis.xml Working directory: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube Timeout (ms):-1 Process id: 469210:51:21 PM Loading analysis properties from D:\MsBuildSonarQubeRunner\SonarQube.Analysis.xml10:51:21 PM The file SonarQube.Integration.ImportBefore.targets is up to date at C:\Users\raja.moparthi\AppData\Local\Microsoft\MSBuild\14.0\Microsoft.Common.targets\ImportBefore10:51:21 PM The file SonarQube.Integration.ImportBefore.targets is up to date at C:\Users\raja.moparthi\AppData\Local\Microsoft\MSBuild\12.0\Microsoft.Common.targets\ImportBefore10:51:21 PM The file SonarQube.Integration.ImportBefore.targets is up to date at C:\Users\raja.moparthi\AppData\Local\Microsoft\MSBuild\4.0\Microsoft.Common.targets\ImportBefore10:51:21 PM Not running under TeamBuild10:51:21 PM Analysis base directory: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqubeBuild directory: Bin directory: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\binConfig directory: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\confOutput directory: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\outConfig file: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\out10:51:21 PM Creating config and output folders...10:51:21 PM Creating directory: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\conf10:51:21 PM Creating directory: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\out10:51:21 PM Generating the FxCop ruleset: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\conf\SonarQubeFxCop-cs.ruleset10:51:22 PM Generating the FxCop ruleset: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\conf\SonarQubeFxCop-vbnet.ruleset10:51:22 PM Saving the config file to D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\conf\SonarQubeAnalysisConfig.xmlProcess returned exit code 0Pre-processing succeeded.----------------Msbuild command log is given below.Microsoft (R) Build Engine version 12.0.21005.1[Microsoft .NET Framework, version 4.0.30319.34209]Copyright (C) Microsoft Corporation. All rights reserved.Build started 9/8/2015 10:51:36 PM.Project D:\SonarQube-Test-Projects\Fibanocci\TestFib2\TestFib2.csproj on node 1 (default targets).GenerateTargetFrameworkMonikerAttribute:Skipping target GenerateTargetFrameworkMonikerAttribute because all output files are up-to-date with respect to the input files.CoreCompile:Skipping target CoreCompile because all output files are up-to-date with respect to the input files._CopyAppConfigFile:Skipping target _CopyAppConfigFile because all output files are up-to-date with respect to the input files.CopyFilesToOutputDirectory: TestFib2 -   D:\SonarQube-Test-Projects\Fibanocci\TestFib2\bin\Debug\TestFib2.exeOverrideCodeAnalysisProperties: Skipping FxCop analysis: the SonarQube ruleset does not exist. Ruleset: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\conf\\SonarQubeFxCop-cs.ruleset Skipping FxCop analysis: the project is a test projectSetStyleCopAnalysisSettings: Setting 'sonar.stylecop.projectFilePath' to 'D:\SonarQube-Test-Projects\Fibanocci\TestFib2\TestFib2.csproj'WriteSonarQubeProjectData: Directory D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\out\\TestFib2__AnyCPU_Debug_635773494965392474 doesn't exist. Skipping. Creating directory D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\out\\TestFib2__AnyCPU_Debug_635773494965392474.Done Building Project D:\SonarQube-Test-Projects\Fibanocci\TestFib2\TestFib2.csproj (default targets).Build succeeded. 0 Warning(s) 0 Error(s)Time Elapsed 00:00:00.32End----------------End command log is given below.Default properties file was found at D:\MsBuildSonarQubeRunner\SonarQube.Analysis.xmlLoading analysis properties from D:\MsBuildSonarQubeRunner\SonarQube.Analysis.xmlPost-processing started.Using environment variables to determine the download directory...Executing file D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\bin\MSBuild.SonarQube.Internal.PostProcess.exe Args: Working directory: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube Timeout (ms):-1 Process id: 852810:51:54 PM Not running under TeamBuild10:51:54 PM Analysis base directory: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqubeBuild directory: Bin directory: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\binConfig directory: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\confOutput directory: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\outConfig file: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\out10:51:54 PM Loading the SonarQube analysis config from D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\conf\SonarQubeAnalysisConfig.xml10:51:54 PM Generating SonarQube project properties file to D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\out\sonar-project.properties10:51:54 PM WARNING: File is not under the project directory and cannot currently be analysed by SonarQube. File: C:\Users\raja.moparthi\AppData\Local\Temp\.NETFramework,Version=v4.5.AssemblyAttributes.cs, project: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\TestFib2.csproj10:51:54 PM Writing processing summary to D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\out\ProjectInfo.log10:51:54 PM Creating directory: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\bin\sonar-runner10:51:54 PM The SONAR_RUNNER_HOME environment variable is not required and will be ignored.10:51:54 PM Calling the sonar-runner...10:51:54 PM SONAR_RUNNER_OPTS is not configured. Setting it to the default value of -Xmx1024m10:51:54 PM Setting environment variable 'SONAR_RUNNER_OPTS'. Value: -Xmx1024m10:51:54 PM Executing file D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\bin\sonar-runner\bin\sonar-runner.bat Args: -Dproject.settings=D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\out\sonar-project.properties Working directory: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\bin\sonar-runner\bin Timeout (ms):-1 Process id: 1119610:51:54 PM D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\bin\sonar-runner\bin\..10:51:54 PM SonarQube Runner 2.410:51:54 PM Java 1.8.0_60 Oracle Corporation (64-bit)10:51:54 PM Windows 7 6.1 amd6410:51:54 PM SONAR_RUNNER_OPTS=-Xmx1024m10:51:54 PM INFO: Runner configuration file: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\bin\sonar-runner\bin\..\conf\sonar-runner.properties10:51:54 PM INFO: Project configuration file: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\out\sonar-project.properties10:51:54 PM INFO: Default locale: en_US, source code encoding: UTF-810:51:54 PM INFO: Work directory: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\out\.sonar10:51:55 PM INFO: SonarQube Server 5.0.110:51:56 PM 22:51:56.238 INFO - Load global referentials...10:51:57 PM 22:51:57.049 INFO - Load global referentials done: 813 ms10:51:57 PM 22:51:57.055 INFO - User cache: C:\Users\raja.moparthi\.sonar\cache10:51:57 PM 22:51:57.065 INFO - Install plugins10:51:57 PM 22:51:57.390 INFO - Install JDBC driver10:51:57 PM 22:51:57.600 INFO - Create JDBC datasource for jdbc:jtds:sqlserver://{DB server- I removed original server name for security purpose}/sonar;SelectMethod=Cursor10:52:04 PM 22:52:04.530 INFO - Initializing Hibernate10:52:07 PM 22:52:07.162 INFO - Load project referentials...10:52:10 PM 22:52:10.353 INFO - Load project referentials done: 3191 ms10:52:10 PM 22:52:10.354 INFO - Load project settings10:52:10 PM 22:52:10.884 INFO - Loading technical debt model...10:52:11 PM 22:52:11.930 INFO - Loading technical debt model done: 1046 ms10:52:11 PM 22:52:11.936 INFO - Apply project exclusions10:52:20 PM 22:52:20.949 WARN - SCM provider autodetection failed. No SCM provider claims to support this project. Please use sonar.scm.provider to define SCM of your project.10:52:20 PM 22:52:20.951 INFO - ------------- Scan TestFib210:52:20 PM 22:52:20.955 INFO - Load module settings10:52:57 PM 22:52:57.308 INFO - Loading rules...10:53:07 PM 22:53:07.904 INFO - Loading rules done: 10596 ms10:53:08 PM 22:53:08.100 INFO - Configure Maven plugins10:53:10 PM 22:53:10.219 INFO - Compare to previous analysis (2015-09-08)10:53:10 PM 22:53:10.439 INFO - Compare over 30 days (2015-08-09, analysis of 2015-09-08 21:09:01.457)10:53:10 PM 22:53:10.441 INFO - No quality gate is configured.10:53:10 PM 22:53:10.513 INFO - Base dir: D:\SonarQube-Test-Projects\Fibanocci\TestFib210:53:10 PM 22:53:10.514 INFO - Working dir: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\out\.sonar\FibTest_FibTest_B51D1FBF-8925-45C4-B8C8-5DBE2F60DBCE10:53:10 PM 22:53:10.518 INFO - Test paths: Program.cs, Properties/AssemblyInfo.cs, App.config10:53:10 PM 22:53:10.519 INFO - Source encoding: UTF-8, default locale: en_US10:53:10 PM 22:53:10.519 INFO - Index files10:53:10 PM 22:53:10.576 INFO - 2 files indexed10:53:15 PM 22:53:15.923 INFO - Quality profile for cs: Mks Test Rules10:53:15 PM 22:53:15.949 INFO - Sensor QProfileSensor...10:53:15 PM 22:53:15.961 INFO - Sensor QProfileSensor done: 12 ms10:53:15 PM 22:53:15.961 INFO - Sensor InitialOpenIssuesSensor...10:53:17 PM 22:53:17.547 INFO - Sensor InitialOpenIssuesSensor done: 1586 ms10:53:17 PM 22:53:17.548 INFO - Sensor ProjectLinksSensor...10:53:18 PM 22:53:18.541 INFO - Sensor ProjectLinksSensor done: 993 ms10:53:19 PM 22:53:19.130 INFO - Sensor VersionEventsSensor...10:53:21 PM 22:53:21.896 INFO - Sensor VersionEventsSensor done: 2766 ms10:53:21 PM 22:53:21.896 INFO - Sensor FileHashSensor...10:53:21 PM 22:53:21.904 INFO - Sensor FileHashSensor done: 8 ms10:53:21 PM 22:53:21.904 INFO - Sensor SCM Sensor...10:53:21 PM 22:53:21.904 INFO - No SCM system was detected. You can use the 'sonar.scm.provider' property to explicitly specify it.10:53:21 PM 22:53:21.904 INFO - Sensor SCM Sensor done: 0 ms10:53:21 PM 22:53:21.904 INFO - Sensor CPD Sensor...10:53:21 PM 22:53:21.905 INFO - DefaultCpdEngine is used for cs10:53:21 PM 22:53:21.906 INFO - Sensor CPD Sensor done: 2 ms10:53:22 PM 22:53:22.118 INFO - Execute decorators...10:53:28 PM 22:53:28.033 INFO - ------------- Scan FibTestAnalysis10:53:28 PM 22:53:28.039 INFO - Load module settings10:53:28 PM 22:53:28.086 INFO - Configure Maven plugins10:53:28 PM 22:53:28.291 INFO - Compare to previous analysis (2015-09-08)10:53:28 PM 22:53:28.491 INFO - Compare over 30 days (2015-08-09, analysis of 2015-09-08 21:09:01.457)10:53:28 PM 22:53:28.493 INFO - No quality gate is configured.10:53:28 PM 22:53:28.518 INFO - Base dir: D:\SonarQube-Test-Projects\Fibanocci\TestFib210:53:28 PM 22:53:28.518 INFO - Working dir: D:\SonarQube-Test-Projects\Fibanocci\TestFib2\.sonarqube\out\.sonar10:53:28 PM 22:53:28.518 INFO - Source encoding: UTF-8, default locale: en_US10:53:29 PM 22:53:29.121 INFO - Sensor InitialOpenIssuesSensor...10:53:30 PM 22:53:30.301 INFO - Sensor InitialOpenIssuesSensor done: 1180 ms10:53:30 PM 22:53:30.302 INFO - Sensor ProjectLinksSensor...10:53:30 PM 22:53:30.893 INFO - Sensor ProjectLinksSensor done: 591 ms10:53:31 PM 22:53:31.483 INFO - Sensor VersionEventsSensor...10:53:33 PM 22:53:33.659 INFO - Sensor VersionEventsSensor done: 2176 ms10:53:33 PM 22:53:33.659 INFO - Sensor FileHashSensor...10:53:33 PM 22:53:33.660 INFO - Sensor FileHashSensor done: 1 ms10:53:33 PM 22:53:33.660 INFO - Sensor SCM Sensor...10:53:33 PM 22:53:33.660 INFO - No SCM system was detected. You can use the 'sonar.scm.provider' property to explicitly specify it.10:53:33 PM 22:53:33.660 INFO - Sensor SCM Sensor done: 0 ms10:53:33 PM 22:53:33.660 INFO - Sensor CPD Sensor...10:53:33 PM 22:53:33.660 INFO - Sensor CPD Sensor done: 0 ms10:53:33 PM 22:53:33.774 INFO - Execute decorators...10:53:37 PM 22:53:37.356 INFO - Store results in database10:53:42 PM 22:53:42.464 INFO - ANALYSIS SUCCESSFUL, you can browse http://{ server- I removed original server name for security purpose}:9000/dashboard/index/FibTest10:53:42 PM 22:53:42.464 INFO - Note that you will be able to access the updated dashboard once the server has processed the submitted analysis report.10:53:42 PM 22:53:42.465 INFO - Executing post-job class org.sonar.plugins.core.issue.notification.SendIssueNotificationsPostJob10:53:44 PM INFO: ------------------------------------------------------------------------10:53:44 PM INFO: EXECUTION SUCCESS10:53:44 PM INFO: ------------------------------------------------------------------------10:53:44 PM Total time: 1:49.413s10:53:44 PM Final Memory: 14M/457M10:53:44 PM INFO: ------------------------------------------------------------------------10:53:44 PM Process returned exit code 010:53:44 PM The sonar-runner has finished10:53:44 PM Creating a summary markdown file...10:53:44 PM Analysis results: http://{ server- I removed original server name for security purpose}:9000/dashboard/index/FibTestProcess returned exit code 0Post-processing succeeded.re",Not-TD-related,SonarQube,,,,0.03,0.904,0.066,0.9919
32501390,How to get list of fixed issues during a sonar scan,"After every sonar scan we can see the list of newly added issues in both portal and Scan logs like shown below. Iam able to get the list of newly added issues using the Rest APIhttp://localhost:9000/api/issues/search?createdAfter=2015-08-15Here we can see 18 Major issues have been fixed , and being shown in green. Is there any way to find out the list of fixed issues in a particular scan. Using API or any other approachenter image description here[sonar:sonar] 07:06:13.946 INFO - ANALYSIS SUCCESSFUL, you can browse http://localhost:9000/dashboard/index/ICDP_NOV_2015[sonar:sonar] 07:06:14.012 INFO - Executing post-job class org.sonar.issuesreport.ReportJob [sonar:sonar] 07:06:21.327 INFO - HTML Issues Report generated: /hosting/workspace/Sonar_20151102/make/sonar_deploy/.sonar/issues-report/issues-report.html[sonar:sonar] 07:06:21.494 INFO - Light HTML Issues Report generated: /hosting/workspace/Sonar_20151102/make/sonar_deploy/.sonar/issues-report/issues-report-light.html[sonar:sonar] 07:06:21.497 INFO - [sonar:sonar] [sonar:sonar] ------------- Issues Report -------------[sonar:sonar] [sonar:sonar] +27 issues[sonar:sonar] [sonar:sonar] +20 major[sonar:sonar] +7 minor[sonar:sonar] [sonar:sonar] -------------------------------------------[sonar:sonar] [sonar:sonar] [sonar:sonar] 07:06:21.497 INFO - Executing post-job class org.sonar.plugins.issueassign.notification.SendIssueNotificationsPostJob[sonar:sonar] 07:06:21.902 INFO - Executing post-job class org.sonar.plugins.core.issue.notification.SendIssueNotificationsPostJob[sonar:sonar] 07:06:22.361 INFO - Executing post-job class org.sonar.pl",Not-TD-related,SonarQube,,,,0,0.956,0.044,0.7925
32595124,sonar-runner lcov report discrepency,"SonarQube Community,When doing an analysis of a Node/JS project the coverage valued reported via istanbul show much different than what gets reported and shows on our SonarQube server.Our SonarQube server is at 4.5.4Our sonar-runner version is 2.4The project generated the following report:Code coverage report for All filesStatements: 67.65% (1520 / 2247) Branches: 49.76% (418 / 840) Functions: 65.13% (269 / 413) Lines: 68.31% (1481 / 2168) Ignored: none File Statements Branches Functions Linesbrclasses/ 94.4% (118 / 125) 70% (7 / 10) 100% (9 / 9) 94.35% (117 / 124)helpers/ 84% (126 / 150) 75.44% (43 / 57) 86.67% (26 / 30) 84.25% (123 / 146)services/ 82.64% (976 / 1181) 66.67% (272 / 408) 81.63% (160 / 196) 83.26% (955 / 1147)view_controllers/ 37.93% (300 / 791) 26.3% (96 / 365) 41.57% (74 / 178) 38.08% (286 / 751)Generated by istanbul at Tue Sep 15 2015 17:01:21 GMT+0000 (UTC)The coverage values shown in the SonarQube 4.5.4 drill down differ greatly from what the other report shows: ( I apologize for not being able to post an image but I do not have a high enough reputation yet to do this.)Technical Debt64d Issues5,707 Blocker 0br Critical 3br Major 3,922br Minor 696br Info 1,086brUnit Tests Coverage28.6%Line Coverage25.6%brCondition Coverage49.8%SQALE RatingATechnical Debt Ratio1.0% The project has warnings on the following quality gate conditions: Coverage28.6%    70.0%Critical issues3 0 cd-services-test-Indexing web client cd-services-test-RECORDS-IDX-indexing-web-clientProfiles: Sonar way (JavaScript)Quality Gate: SonarWayWithFindbugsForNFSWithBuildBreaker - java (Default)Lines Of Code104,320 JavaScriptFiles426 Directories109brLines120,238 Functions6,726 Classes4brStatements32,377brAccessors0Useless Code18,26018,260 lines in duplicationsDuplications41.5%Lines49,923brBlocks10,915brFiles89 Complexity4.9 /function 4.5 /class 29.5 /file Total: 12,588 If you should need the actual lcov.info file or if you would like pngs of the data above to better analyze this problem I can send them via an e-mail directly to you.What would you suggest I do to try and track down why there is such a discrepency?Any thoughts on how I can proceed to get correct data logged would be very much appreciated.Doug",Not-TD-related,SonarQube,,,,0.047,0.913,0.04,-0.4767
32633108,SonarQube doesn't generate duplications information,"I've managed to install SonarQube 5.1 using the official docker image from SonarSource.I am actually running sonar using the default H2 DB and I have got almost eveything woking for my demo Java project: Coverage, unit tests and issues.However, the duplications are 0%. I have created a test classes with the following code: public class Test {public Test() { for(int i = 0; i    10; i++) { System.out.println(Test); System.out.println(Test); System.out.println(Test); } for(int i = 0; i    10; i++) { System.out.println(Test); System.out.println(Test); System.out.println(Test); }}reHow can be the duplications 0%? I think something is not working in my set...In addition, Sonar has detected some major issues in my class, but nothing related with the duplications:ulliHide this public constructorliReplace this usage of System.out or System.err by a loggerIn order to generate the sonar report, I am executing sonar:sonar using maven. That's the output:pre class=lang-html prettyprint-overridecode[INFO] Scanning for projects...[INFO] [INFO] ------------------------------------------------------------------------[INFO] Building demoservice 0.1.0.-SNAPSHOT[INFO] ------------------------------------------------------------------------[INFO] [INFO] --- sonar-maven-plugin:2.6:sonar (default-cli) @ demoservice ---[INFO] SonarQube version: 5.1INFO: Default locale: en_GB, source code encoding: UTF-8INFO: Work directory: W:\DemoService\target\sonarINFO: SonarQube Server 5.1[INFO] [15:52:47.080] Load global repositories[INFO] [15:52:47.290] Load global repositories (done) | time=212ms[INFO] [15:52:47.293] Server id: 20150917085707[INFO] [15:52:47.295] User cache: C:\Users\jose.valencia\.sonar\cache[INFO] [15:52:47.303] Install plugins[INFO] [15:52:47.402] Install JDBC driver[INFO] [15:52:47.412] Create JDBC datasource for jdbc::tcp://localhost:9092/sonar[INFO] [15:52:48.524] Initializing Hibernate[INFO] [15:52:50.183] Load project repositories[INFO] [15:52:51.840] Load project repositories (done) | time=1657ms[INFO] [15:52:51.841] Load project settings[INFO] [15:52:52.252] Load technical debt model[INFO] [15:52:52.285] Apply project exclusions[INFO] [15:52:53.136] ------------- Scan demoservice[INFO] [15:52:53.139] Load module settings[INFO] [15:52:53.238] Language is forced to java[INFO] [15:52:53.244] Load rules[INFO] [15:52:53.437] Base dir: W:\DemoService[INFO] [15:52:53.437] Working dir: W:\DemoService\target\sonar[INFO] [15:52:53.438] Source paths: pom.xml, src/main/java[INFO] [15:52:53.438] Test paths: src/test/java[INFO] [15:52:53.439] Binary dirs: target/classes[INFO] [15:52:53.439] Source encoding: UTF-8, default locale: en_GB[INFO] [15:52:53.439] Index files[INFO] [15:52:53.456] 9 files indexed[INFO] [15:52:53.642] Quality profile for java: Sonar way[INFO] [15:52:53.672] Sensor JavaSquidSensor[INFO] [15:52:55.794] Java Main Files AST scan...[INFO] [15:52:55.796] 6 source files to be analyzed[INFO] [15:52:57.434] Java Main Files AST scan done: 1640 ms[INFO] [15:52:57.435] 6/6 source files have been analyzed[INFO] [15:52:57.437] Java bytecode scan...[INFO] [15:52:57.551] Java bytecode scan done: 114 ms[INFO] [15:52:57.551] Java Test Files AST scan...[INFO] [15:52:57.552] 3 source files to be analyzed[INFO] [15:52:58.106] Java Test Files AST scan done: 555 ms[INFO] [15:52:58.107] 3/3 source files have been analyzed[INFO] [15:52:58.111] Package design analysis...[INFO] [15:52:58.164] Package design analysis done: 53 ms[INFO] [15:52:58.193] Sensor JavaSquidSensor (done) | time=4521ms[INFO] [15:52:58.193] Sensor Lines Sensor[INFO] [15:52:58.196] Sensor Lines Sensor (done) | time=3ms[INFO] [15:52:58.196] Sensor QProfileSensor[INFO] [15:52:58.201] Sensor QProfileSensor (done) | time=5ms[INFO] [15:52:58.201] Sensor InitialOpenIssuesSensor[INFO] [15:52:58.270] Sensor InitialOpenIssuesSensor (done) | time=69ms[INFO] [15:52:58.270] Sensor ProjectLinksSensor[INFO] [15:52:58.286] Sensor ProjectLinksSensor (done) | time=16ms[INFO] [15:52:58.286] Sensor VersionEventsSensor[INFO] [15:52:58.309] Sensor VersionEventsSensor (done) | time=23ms[INFO] [15:52:58.309] Sensor Maven dependencies[INFO] [15:53:01.186] Sensor Maven dependencies (done) | time=2877ms[INFO] [15:53:01.186] Sensor CoberturaSensor[INFO] [15:53:01.186] parsing W:\DemoService\target\site\cobertura\coverage.xml[INFO] [15:53:01.283] Sensor CoberturaSensor (done) | time=97ms[INFO] [15:53:01.283] Sensor SurefireSensor[INFO] [15:53:01.284] parsing W:\DemoService\target\surefire-reports[INFO] [15:53:01.302] Sensor SurefireSensor (done) | time=19ms[INFO] [15:53:01.302] Sensor SCM Sensor[INFO] [15:53:01.309] SCM provider for this project is: git[INFO] [15:53:01.313] 1 files to be analyzed[INFO] [15:53:01.548] 1/1 files analyzed[INFO] [15:53:01.549] Sensor SCM Sensor (done) | time=247ms[INFO] [15:53:01.549] Sensor CPD Sensor[INFO] [15:53:01.549] JavaCpdEngine is used for java[INFO] [15:53:01.549] Cross-project analysis disabled[INFO] [15:53:01.595] Sensor CPD Sensor (done) | time=46ms[INFO] [15:53:01.596] No quality gate is configured.[INFO] [15:53:01.642] Compare to previous analysis (2015-09-17)[INFO] [15:53:01.651] Compare over 30 days (2015-08-18, analysis of Wed Sep 16 17:23:06 BST 2015)[INFO] [15:53:01.944] Execute decorators...[INFO] [15:53:02.987] Store results in database[INFO] [15:53:04.851] Analysis reports generated in 75ms, dir size=8 KB[INFO] [15:53:04.879] Analysis reports compressed in 28ms, zip size=8 KB[INFO] [15:53:04.914] Analysis reports sent to server in 35ms[INFO] [15:53:04.915] ANALYSIS SUCCESSFUL, you can browse http://10.1.2.77:9001/dashboard/indexbs.demoservice:demoservice[INFO] [15:53:04.915] Note that you will be able to access the updated dashboard once the server has processed the submitted analysis report.[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 24.371s[INFO] Finished at: Thu Sep 17 15:53:05 BST 2015[INFO] Final Memory: 37M/896M[INFO] ------------------------------------------------------------------------reI am not sure if I have missed something or something is not configured properly. Any ideas? Thanks!",Not-TD-related,SonarQube,,,,0.026,0.951,0.023,0.1676
32651469,Sonar doesn't import coverage.xml result,"I'm using SonarQube 5.1, sonar-runner 2.4, grails 2.4.4 and cobertura.I am able to generate a coverage.xml file but then using sonar-runner or mvn sonar:sonar doesn't show any test coverag in SonarQube dashboard...nothing...Any idea?sonar-project.properties file: sonar.projectKey=testsonar.projectName=testsonar.projectVersion=1.0sonar.sources=src/java,src/groovy,grails-app/assets,grails-app/services,grails-app/controllers,grails-app/domain,grails-app/viewssonar.language=grvysonar.sourceEncoding=UTF-8sonar.dynamicAnalysis=reuseReportssonar.surefire.reportsPath=target/test-reportssonar.groovy.cobertura.reportPath=target/test-reports/cobertura/coverage.xmlrehrand here is the trace of sonar-runner:  C:\Temp\sonar-runner-dist-2.4\sonar-runner-2.4C:\Program Files\Java\jdk1.7.0_71\bin\java.exe -cp C:\Temp\sonar-runner-dist-2.4\sonar-runner-2.4\lib\sonar-runner-dist-2.4.jar -Drunner.home=C:\Temp\sonar-runner-dist-2.4\sonar-runner-2.4 -Dproject.home=C:\test org.sonar.runner.MainSonarQube Runner 2.4Java 1.7.0_71 Oracle Corporation (64-bit)Windows 7 6.1 amd64INFO: Runner configuration file: C:\Temp\sonar-runner-dist-2.4\sonar-runner-2.4\conf\sonar-runner.propertiesINFO: Project configuration file: C:\test\sonar-project.propertiesINFO: Default locale: no_NO, source code encoding: UTF-8INFO: Work directory: C:\test\.\.sonarINFO: SonarQube Server 5.1INFO - Load global repositoriesINFO - Load global repositories (done) | time=384msINFO - Server id: 20150918133629INFO - User cache: R:\Users\kho\.sonar\cacheINFO - Install pluginsINFO - Install JDBC driverINFO - Create JDBC datasource for jdbc:mysql://localhost:3306/sonar?useUnicode=true characterEncoding=utf8INFO - Initializing HibernateINFO - Load project repositoriesINFO - Load project repositories (done) | time=255msINFO - Load project settingsINFO - Load technical debt modelINFO - Apply project exclusionsWARN - 'sonar.dynamicAnalysis' is deprecated since version 4.3 and should no longer be used.INFO - ------------- Scan AbonnementsregisteretINFO - Load module settingsINFO - Language is forced to grvyINFO - Load rulesINFO - Base dir: C:\testINFO - Working dir: C:\test\.sonarINFO - Source paths: test/unit, test/integration, src/java, src/groovy, grails-app/assets, grails-app/services, grails-app/controllersgrails-app/domain, grails-app/viewsINFO - Source encoding: UTF-8, default locale: no_NOINFO - Index filesINFO - 23 files indexedINFO - Quality profile for grvy: Sonar wayINFO - Sensor Lines SensorINFO - Sensor Lines Sensor (done) | time=47msINFO - Sensor QProfileSensorINFO - Sensor QProfileSensor (done) | time=9msINFO - Sensor InitialOpenIssuesSensorINFO - Sensor InitialOpenIssuesSensor (done) | time=111ms INFO - Sensor ProjectLinksSensorINFO - Sensor ProjectLinksSensor (done) | time=34msINFO - Sensor VersionEventsSensorINFO - Sensor VersionEventsSensor (done) | time=67msINFO - Sensor CodeNarcINFO - Executing CodeNarcINFO - Loaded properties file in 72ms; 346 rulesINFO - Loading ruleset from [file:C:\test\.sonar\codenarc\profile.xml]INFO - RuleSet configuration properties file [codenarc.properties] not found.INFO - No custom message bundle found for [codenarc-messages]. Using default messages.INFO - Report file [C:\test\.sonar\codenarc\report1.xml] created.CodeNarc completed: (p1=0; p2=0; p3=0) 4030msINFO - Loaded properties file in 1ms; 346 rulesINFO - Loading ruleset from [file:C:\test\.sonar\codenarc\profile.xml]INFO - RuleSet configuration properties file [codenarc.properties] not found.INFO - No custom message bundle found for [codenarc-messages]. Using default messages.INFO - Report file [C:\test\.sonar\codenarc\report2.xml] created.CodeNarc completed: (p1=0; p2=0; p3=2) 600msINFO - Loaded properties file in 1ms; 346 rulesINFO - Loading ruleset from [file:C:\test\.sonar\codenarc\profile.xml]INFO - RuleSet configuration properties file [codenarc.properties] not found.INFO - No custom message bundle found for [codenarc-messages]. Using default messages.INFO - Report file [C:\test\.sonar\codenarc\report3.xml] created.CodeNarc completed: (p1=0; p2=0; p3=0) 158msINFO - Loaded properties file in 0ms; 346 rulesINFO - Loading ruleset from [file:C:\test\.sonar\codenarc\profile.xml]INFO - RuleSet configuration properties file [codenarc.properties] not found.INFO - No custom message bundle found for [codenarc-messages]. Using default messages.INFO - Report file [C:\test\.sonar\codenarc\report4.xml] created.CodeNarc completed: (p1=0; p2=5; p3=0) 472msINFO - Loaded properties file in 1ms; 346 rulesINFO - Loading ruleset from [file:C:\test\.sonar\codenarc\profile.xml]INFO - RuleSet configuration properties file [codenarc.properties] not found.INFO - No custom message bundle found for [codenarc-messages]. Using default messages.INFO - Report file [C:\test\.sonar\codenarc\report5.xml] created.CodeNarc completed: (p1=0; p2=0; p3=0) 84msINFO - Loaded properties file in 0ms; 346 rulesINFO - Loading ruleset from [file:C:\test\.sonar\codenarc\profile.xml]INFO - RuleSet configuration properties file [codenarc.properties] not found.INFO - No custom message bundle found for [codenarc-messages]. Using default messages.INFO - Report file [C:\test\.sonar\codenarc\report6.xml] created.CodeNarc completed: (p1=0; p2=10; p3=2) 1271msINFO - Loaded properties file in 1ms; 346 rulesINFO - Loading ruleset from [file:C:\test\.sonar\codenarc\profile.xml]INFO - RuleSet configuration properties file [codenarc.properties] not found.INFO - No custom message bundle found for [codenarc-messages]. Using default messages.INFO - Report file [C:\test\.sonar\codenarc\report7.xml] created.CodeNarc completed: (p1=0; p2=7; p3=0) 562msINFO - Loaded properties file in 1ms; 346 rulesINFO - Loading ruleset from [file:C:\test\.sonar\codenarc\profile.xml]INFO - RuleSet configuration properties file [codenarc.properties] not found.INFO - No custom message bundle found for [codenarc-messages]. Using default messages.INFO - Report file [C:\test\.sonar\codenarc\report8.xml] created.CodeNarc completed: (p1=0; p2=0; p3=0) 241msINFO - Loaded properties file in 1ms; 346 rulesINFO - Loading ruleset from [file:C:\test\.sonar\codenarc\profile.xml]INFO - RuleSet configuration properties file [codenarc.properties] not found.INFO - No custom message bundle found for [codenarc-messages]. Using default messages.INFO - Report file [C:\test\.sonar\codenarc\report9.xml] created.CodeNarc completed: (p1=0; p2=0; p3=0) 81msINFO - Sensor CodeNarc (done) | time=12286msINFO - Sensor GroovySensorINFO - GMetrics completed: 542msINFO - Sensor GroovySensor (done) | time=1091msINFO - Sensor Groovy CoberturaSensorINFO - Analyzing Cobertura report: target/test-reports/cobertura/coverage.xmlINFO - Sensor Groovy CoberturaSensor (done) | time=338msINFO - Sensor SCM SensorINFO - Sensor SCM Sensor (done) | time=45msINFO - Sensor GroovySurefireSensorINFO - parsing C:\test\target\surefire-reportsWARN - Reports path not found: C:\test\target\surefire-reportsINFO - Sensor GroovySurefireSensor (done) | time=28msINFO - Sensor CPD SensorINFO - DefaultCpdEngine is used for grvyINFO - Cross-project analysis disabledINFO - Sensor CPD Sensor (done) | time=309msINFO - No quality gate is configured.INFO - Compare to previous analysis (2015-09-18)INFO - Compare over 30 days (2015-08-19, analysis of Tue Sep 15 17:12:33 CEST 2015)INFO - Execute decorators...INFO - Store results in databaseINFO - Analysis reports generated in 83ms, dir size=9 KBINFO - Analysis reports compressed in 279ms, zip size=13 KBINFO - Analysis reports sent to server in 101msINFO - ANALYSIS SUCCESSFUL, you can browse http://localhost:9000/dashboard/index/testINFO - Note that you will be able to access the updated dashboard once the server has processed the submitted analysis report.INFO: EXECUTION SUCCESSre",Not-TD-related,SonarQube,,,,0.014,0.941,0.045,0.9617
32814120,jQuery DataTables show no results message on 404 ajax response,"I am using DataTables with: $t = $('users-table').DataTable({ 'paging' : true, 'searching' : true, 'ordering' : false, 'info' : false, 'serverSide': true, 'processing': true, 'ajax' : { 'url' : 'http://localhost/api/users', 'type' : 'GET', 'dataSrc' : 'users', 'error': function() { // how can i handle the 404 response and show the no results found message? } } ...reThe server will return a 404 not found response if the query had no results. I'm trying to show the no results message and remove the current data from the table, but instead data will remain the same in the table on an error response like that.Edit:I am using the search functionality like this: $('data-filter').keyup(function() { $t.search($(this).val()).draw();});reSo when no results are found with a query word a 404 is returned.",Not-TD-related,SonarQube,,,,0.092,0.792,0.116,0.4497
32890986,Sonarqube 5.1.2 with sonar-runner 2.4 doesnt display Groovy cobertura report,"I have the below setup:olliSonarqube v5.1.2liSonar Runner v2.4liCobertura plugin for Sonarqube v1.6.3liGroovy plugin for Sonarqube v1.2All are having the latest versions.My project structure is like below: ParentProject|-sonar-project.properties|- Grails Project A| |-sonar-project.propertiesreThe ParentProject folder sonar-project.properties contains the below: sonar.projectKey=ParentProjectsonar.projectName=Parent Project SONARQUBEsonar.projectVersion=1.0sonar.scm.url=scm:svn:https://server/svn/nv/frontend/grails/trunksonar.scm.provider=svnsonar.language=grvysonar.core.codeCoveragePlugin=coberturasonar.grvy.coveragePlugin=coberturasonar.groovy.cobertura.reportPath=target/test-reports/cobertura/coverage.xmlsonar.cobertura.reportPath=target/test-reports/cobertura/coverage.xmlsonar.sourceEncoding=UTF-8sonar.web.file.suffixes=gspsonar.modules= ProjectA Settings for servicemodelProjectA.sonar.projectBaseDir=.rojectAreAnd inside ProjectA, we have the below sonar-project.properties: sonar.modules = projectA-groovymodule, projectA-javascriptmodule, projectA-webmoduleprojectA-groovymodule.sonar.projectBaseDir=.projectA-groovymodule.sonar.language=grvyprojectA-groovymodule.sonar.sources=grails-app/services,grails-app/controllers,grails-app/domain,grails-app/taglib,src/groovyprojectA-groovymodule.sonar.tests=test/unit,test/integrationprojectA-groovymodule.sonar.junit.reportsPath=target/test-reportsprojectA-groovymodule.sonar.cobertura.reportPath = target/test-reports/cobertura/coverage.xmlprojectA-groovymodule.sonar.groovy.cobertura.reportPath=target/test-reports/cobertura/coverage.xmlprojectA-groovymodule.sonar.grvy.coveragePlugin=coberturaprojectA-javascriptmodule.sonar.projectBaseDir=.projectA-javascriptmodule.sonar.language=jsprojectA-javascriptmodule.sonar.sources=grails-app, web-app/jsprojectA-javascriptmodule.sonar.exclusions=web-app/jsb/**/*projectA-webmodule.sonar.projectBaseDir=.projectA-webmodule.sonar.language=webprojectA-webmodule.sonar.sources=grails-app/viewsreI can confirm that the coverage.xml has been generated and is available on the folder specified in here.The output of sonar-runner is as follows: D:\Build\ParentProject  sonar-runnerD:\Apps\sonar-runner-2.4SonarQube Runner 2.4Java 1.7.0_51 Oracle Corporation (64-bit)Windows Server 2008 R2 6.1 amd64INFO: Runner configuration file: D:\Apps\sonar-runner-2.4\conf\sonar-runner.propertiesINFO: Project configuration file: D:\Build\ParentProject\sonar-project.propertiesINFO: Default locale: en_EN, source code encoding: UTF-8INFO: Work directory: D:\Build\ParentProject\.\.sonarINFO: SonarQube Server 5.1.216:05:40.180 INFO - Load global repositories16:05:40.644 INFO - Load global repositories (done) | time=470ms16:05:40.689 INFO - Server id: 2015093016122716:05:40.696 INFO - User cache: d:\gebruikers\user\.sonar\cache16:05:40.888 INFO - Install plugins16:05:43.829 INFO - Install JDBC driver16:05:44.278 INFO - Create JDBC datasource for jdbc:jtds:sqlserver://dbserver:port/db;instance=instance;SelectMethod=Cursor16:05:48.516 INFO - Initializing Hibernate16:05:56.529 INFO - Load project repositories16:05:57.659 INFO - Load project repositories (done) | time=1130ms16:05:57.822 INFO - Load project settings16:05:59.033 INFO - Load technical debt model16:05:59.085 INFO - Apply project exclusions16:06:01.353 INFO - ------------- Scan projectA-groovymodule16:06:01.360 INFO - Load module settings16:06:01.731 INFO - Language is forced to grvy16:06:01.734 INFO - Load rules16:06:03.153 INFO - Base dir: D:\Build\ParentProject\ProjectA16:06:03.156 INFO - Working dir: D:\Build\ParentProject\.sonar\ParentProject_ProjectA_ProjectA-groovymodule16:06:03.158 INFO - Source paths: grails-app/services, grails-app/controllers, grails-app/domain, grails-app/taglib, src/groovy16:06:03.159 INFO - Test paths: test/unit, test/integration16:06:03.160 INFO - Source encoding: UTF-8, default locale: en_EN16:06:03.161 INFO - Index files16:06:03.179 INFO - Excluded sources:16:06:03.181 INFO - web-app/js/jquery/**16:06:03.314 INFO - 18 files indexed16:06:03.315 INFO - 0 files ignored because of inclusion/exclusion patterns16:06:03.648 INFO - Quality profile for grvy: profile16:06:04.398 INFO - Sensor Lines Sensor16:06:04.512 INFO - Sensor Lines Sensor (done) | time=114ms16:06:04.513 INFO - Sensor QProfileSensor16:06:04.522 INFO - Sensor QProfileSensor (done) | time=9ms16:06:04.525 INFO - Sensor InitialOpenIssuesSensor16:06:04.682 INFO - Sensor InitialOpenIssuesSensor (done) | time=157ms16:06:04.683 INFO - Sensor ProjectLinksSensor16:06:04.696 INFO - Sensor ProjectLinksSensor (done) | time=13ms16:06:04.697 INFO - Sensor VersionEventsSensor16:06:04.716 INFO - Sensor VersionEventsSensor (done) | time=19ms16:06:04.717 INFO - Sensor CodeNarc16:06:04.718 INFO - Executing CodeNarc16:06:05.580 INFO - Loaded properties file in 67ms; 346 rules16:06:05.641 INFO - Loading ruleset from [file:D:\Build\ParentProject\.sonar\ParentProject_ProjectA_ProjectA-groovymodule\codenarc\profile.xml]16:06:07.175 INFO - RuleSet configuration properties file [codenarc.properties] not found.16:06:09.625 INFO - No custom message bundle found for [codenarc-messages]. Using default messages.16:06:11.759 INFO - Report file [D:\Build\ParentProject\.sonar\ParentProject_ProjectA_ProjectA-groovymodule\codenarc\report1.xml] created.CodeNarc completed: (p1=0; p2=2; p3=2) 4140ms16:06:11.764 INFO - Loaded properties file in 1ms; 346 rules16:06:11.765 INFO - Loading ruleset from [file:D:\Build\ParentProject\.sonar\ParentProject_ProjectA_ProjectA-groovymodule\codenarc\profile.xml]16:06:11.869 INFO - RuleSet configuration properties file [codenarc.properties] not found.16:06:15.067 INFO - No custom message bundle found for [codenarc-messages]. Using default messages.16:06:17.707 INFO - Report file [D:\Build\ParentProject\.sonar\ParentProject_ProjectA_ProjectA-groovymodule\codenarc\report2.xml] created.CodeNarc completed: (p1=0; p2=17; p3=13) 3298ms16:06:17.710 INFO - Loaded properties file in 1ms; 346 rules16:06:17.711 INFO - Loading ruleset from [file:D:\Build\ParentProject\.sonar\ParentProject_ProjectA_ProjectA-groovymodule\codenarc\profile.xml]16:06:17.826 INFO - RuleSet configuration properties file [codenarc.properties] not found.16:06:17.837 INFO - No custom message bundle found for [codenarc-messages]. Using default messages.16:06:18.969 INFO - Report file [D:\Build\ParentProject\.sonar\ParentProject_ProjectA_ProjectA-groovymodule\codenarc\report3.xml] created.CodeNarc completed: (p1=0; p2=0; p3=0) 127ms16:06:18.972 INFO - Loaded properties file in 1ms; 346 rules16:06:18.973 INFO - Loading ruleset from [file:D:\Build\ParentProject\.sonar\ParentProject_ProjectA_ProjectA-groovymodule\codenarc\profile.xml]16:06:19.040 INFO - RuleSet configuration properties file [codenarc.properties] not found.16:06:19.167 INFO - No custom message bundle found for [codenarc-messages]. Using default messages.16:06:19.532 INFO - Report file [D:\Build\ParentProject\.sonar\ParentProject_ProjectA_ProjectA-groovymodule\codenarc\report4.xml] created.CodeNarc completed: (p1=0; p2=0; p3=2) 195ms16:06:19.537 INFO - Loaded properties file in 1ms; 346 rules16:06:19.540 INFO - Loading ruleset from [file:D:\Build\ParentProject\.sonar\ParentProject_ProjectA_ProjectA-groovymodule\codenarc\profile.xml]16:06:19.586 INFO - RuleSet configuration properties file [codenarc.properties] not found.16:06:19.774 INFO - No custom message bundle found for [codenarc-messages]. Using default messages.16:06:20.092 INFO - Report file [D:\Build\ParentProject\.sonar\ParentProject_ProjectA_ProjectA-groovymodule\codenarc\report5.xml] created.CodeNarc completed: (p1=0; p2=4; p3=38) 233ms16:06:20.765 INFO - Sensor CodeNarc (done) | time=16048ms16:06:20.766 INFO - Sensor GroovySensor16:06:21.158 INFO - GMetrics completed: 237ms16:06:21.203 INFO - Sensor GroovySensor (done) | time=437ms16:06:21.204 INFO - Sensor Groovy CoberturaSensor16:06:21.205 INFO - Analyzing Cobertura report: target/test-reports/cobertura/coverage.xml16:06:21.377 INFO - Sensor Groovy CoberturaSensor (done) | time=173ms16:06:21.378 INFO - Sensor SCM Sensor16:06:21.414 INFO - Sensor SCM Sensor (done) | time=36ms16:06:21.415 INFO - Sensor GroovySurefireSensor16:06:21.417 INFO - parsing D:\Build\ParentProject\ProjectA\target\test-reports16:06:21.418 INFO - Sensor GroovySurefireSensor (done) | time=3ms16:06:21.419 INFO - Sensor CPD Sensor16:06:21.420 INFO - DefaultCpdEngine is used for grvy16:06:21.421 INFO - Cross-project analysis enabled16:06:21.760 INFO - Sensor CPD Sensor (done) | time=341ms16:06:21.769 INFO - No quality gate is configured.16:06:21.853 INFO - Compare to previous analysis (2015-10-01)16:06:21.861 INFO - Compare over 30 days (2015-09-01, analysis of Mon Aug 31 01:18:52 CEST 2015)16:06:21.864 INFO - Compare over 21 days (2015-09-10, analysis of Wed Sep 09 01:18:12 CEST 2015)16:06:22.556 INFO - Execute decorators...16:06:24.684 INFO - ------------- Scan ProjectA-javascriptmodule16:06:24.686 INFO - Load module settings16:06:24.727 INFO - Language is forced to js16:06:24.744 INFO - Base dir: D:\Build\ParentProject\ProjectA16:06:24.745 INFO - Working dir: D:\Build\ParentProject\.sonar\ParentProject_ProjectA_ProjectA-javascriptmodule16:06:24.746 INFO - Source paths: grails-app, web-app/js16:06:24.747 INFO - Source encoding: UTF-8, default locale: en_EN16:06:24.748 INFO - Index files16:06:24.749 INFO - Excluded sources:16:06:24.750 INFO - web-app/jsb/**/*16:06:24.815 INFO - 9 files indexed16:06:24.816 INFO - 3 files ignored because of inclusion/exclusion patterns16:06:24.903 INFO - Quality profile for js: ParentProject16:06:24.948 INFO - Sensor Lines Sensor16:06:24.952 INFO - Sensor Lines Sensor (done) | time=4ms16:06:24.953 INFO - Sensor QProfileSensor16:06:24.954 INFO - Sensor QProfileSensor (done) | time=1ms16:06:24.954 INFO - Sensor InitialOpenIssuesSensor16:06:25.024 INFO - Sensor InitialOpenIssuesSensor (done) | time=70ms16:06:25.031 INFO - Sensor ProjectLinksSensor16:06:25.040 INFO - Sensor ProjectLinksSensor (done) | time=9ms16:06:25.043 INFO - Sensor VersionEventsSensor16:06:25.096 INFO - Sensor VersionEventsSensor (done) | time=53ms16:06:25.097 INFO - Sensor JavaScriptSquidSensor16:06:25.101 INFO - 9 source files to be analyzed16:06:26.722 INFO - Sensor JavaScriptSquidSensor (done) | time=1625ms16:06:26.723 INFO - 9/9 source files have been analyzed16:06:26.724 INFO - Sensor SCM Sensor16:06:26.732 INFO - Sensor SCM Sensor (done) | time=8ms16:06:26.733 INFO - Sensor org.sonar.plugins.javascript.lcov.UTCoverageSensor@4d2f36b216:06:26.733 INFO - Sensor org.sonar.plugins.javascript.lcov.UTCoverageSensor@4d2f36b2 (done) | time=0ms16:06:26.734 INFO - Sensor org.sonar.plugins.javascript.lcov.ITCoverageSensor@56b007b416:06:26.735 INFO - Sensor org.sonar.plugins.javascript.lcov.ITCoverageSensor@56b007b4 (done) | time=1ms16:06:26.735 INFO - Sensor CPD Sensor16:06:26.736 INFO - DefaultCpdEngine is used for js16:06:26.736 INFO - Cross-project analysis enabled16:06:27.151 INFO - Sensor CPD Sensor (done) | time=416ms16:06:27.153 INFO - No quality gate is configured.16:06:27.159 INFO - Compare to previous analysis (2015-10-01)16:06:27.161 INFO - Compare over 30 days (2015-09-01, analysis of Mon Aug 31 01:18:52 CEST 2015)16:06:27.163 INFO - Compare over 21 days (2015-09-10, analysis of Wed Sep 09 01:18:12 CEST 2015)16:06:27.518 INFO - Execute decorators...16:06:27.916 INFO - ------------- Scan ProjectA-webmodule16:06:27.918 INFO - Load module settings16:06:27.949 INFO - Language is forced to web16:06:27.968 INFO - Base dir: D:\Build\ParentProject\ProjectA16:06:27.969 INFO - Working dir: D:\Build\ParentProject\.sonar\ParentProject_ProjectA_ProjectA-webmodule16:06:27.970 INFO - Source paths: grails-app/views16:06:27.970 INFO - Source encoding: UTF-8, default locale: en_EN16:06:27.971 INFO - Index files16:06:27.972 INFO - Excluded sources:16:06:27.973 INFO - web-app/js/jquery/**16:06:28.027 INFO - 28 files indexed16:06:28.028 INFO - 0 files ignored because of inclusion/exclusion patterns16:06:28.273 INFO - Quality profile for web: ParentProject16:06:28.306 INFO - Sensor Lines Sensor16:06:28.312 INFO - Sensor Lines Sensor (done) | time=6ms16:06:28.312 INFO - Sensor QProfileSensor16:06:28.313 INFO - Sensor QProfileSensor (done) | time=1ms16:06:28.314 INFO - Sensor InitialOpenIssuesSensor16:06:28.409 INFO - Sensor InitialOpenIssuesSensor (done) | time=95ms16:06:28.410 INFO - Sensor ProjectLinksSensor16:06:28.413 INFO - Sensor ProjectLinksSensor (done) | time=3ms16:06:28.414 INFO - Sensor VersionEventsSensor16:06:28.424 INFO - Sensor VersionEventsSensor (done) | time=10ms16:06:28.424 INFO - Sensor WebSensor16:06:28.722 INFO - Sensor WebSensor (done) | time=298ms16:06:28.723 INFO - Sensor SCM Sensor16:06:28.738 INFO - Sensor SCM Sensor (done) | time=15ms16:06:28.739 INFO - Sensor CPD Sensor16:06:28.740 INFO - DefaultCpdEngine is used for web16:06:28.740 INFO - Cross-project analysis enabled16:06:29.201 INFO - Sensor CPD Sensor (done) | time=462ms16:06:29.203 INFO - No quality gate is configured.16:06:29.207 INFO - Compare to previous analysis (2015-10-01)16:06:29.209 INFO - Compare over 30 days (2015-09-01, analysis of Mon Aug 31 01:18:52 CEST 2015)16:06:29.211 INFO - Compare over 21 days (2015-09-10, analysis of Wed Sep 09 01:18:12 CEST 2015)16:06:29.522 INFO - Execute decorators...16:06:31.389 INFO - ------------- Scan ProjectA16:06:31.391 INFO - Load module settings16:06:31.440 INFO - Base dir: D:\Build\ParentProject\ProjectA16:06:31.441 INFO - Working dir: D:\Build\ParentProject\.sonar\ParentProject_ProjectA16:06:31.442 INFO - Source encoding: UTF-8, default locale: en_EN16:06:31.474 INFO - Sensor Lines Sensor16:06:31.474 INFO - Sensor Lines Sensor (done) | time=0ms16:06:31.475 INFO - Sensor InitialOpenIssuesSensor16:06:31.513 INFO - Sensor InitialOpenIssuesSensor (done) | time=38ms16:06:31.514 INFO - Sensor ProjectLinksSensor16:06:31.517 INFO - Sensor ProjectLinksSensor (done) | time=3ms16:06:31.518 INFO - Sensor VersionEventsSensor16:06:31.528 INFO - Sensor VersionEventsSensor (done) | time=10ms16:06:31.529 INFO - Sensor SCM Sensor16:06:31.530 INFO - Sensor SCM Sensor (done) | time=1ms16:06:31.530 INFO - Sensor CPD Sensor16:06:31.531 INFO - Sensor CPD Sensor (done) | time=1ms16:06:31.532 INFO - No quality gate is configured.16:06:31.537 INFO - Compare to previous analysis (2015-10-01)16:06:31.538 INFO - Compare over 30 days (2015-09-01, analysis of Mon Aug 31 01:18:52 CEST 2015)16:06:31.540 INFO - Compare over 21 days (2015-09-10, analysis of Wed Sep 09 01:18:12 CEST 2015)16:06:31.808 INFO - Execute decorators...16:06:31.932 INFO - ------------- Scan ParentProject SonarQube Runner16:06:31.934 INFO - Load module settings16:06:31.985 INFO - Base dir: D:\Build\ParentProject16:06:31.986 INFO - Working dir: D:\Build\ParentProject\.sonar16:06:31.986 INFO - Source encoding: UTF-8, default locale: en_EN16:06:32.020 INFO - Sensor Lines Sensor16:06:32.021 INFO - Sensor Lines Sensor (done) | time=1ms16:06:32.021 INFO - Sensor InitialOpenIssuesSensor16:06:32.062 INFO - Sensor InitialOpenIssuesSensor (done) | time=41ms16:06:32.063 INFO - Sensor ProjectLinksSensor16:06:32.067 INFO - Sensor ProjectLinksSensor (done) | time=4ms16:06:32.067 INFO - Sensor VersionEventsSensor16:06:32.077 INFO - Sensor VersionEventsSensor (done) | time=10ms16:06:32.078 INFO - Sensor SCM Sensor16:06:32.078 INFO - Sensor SCM Sensor (done) | time=0ms16:06:32.079 INFO - Sensor CPD Sensor16:06:32.079 INFO - Sensor CPD Sensor (done) | time=0ms16:06:32.081 INFO - No quality gate is configured.16:06:32.086 INFO - Compare to previous analysis (2015-10-01)16:06:32.088 INFO - Compare over 30 days (2015-09-01, analysis of Mon Aug 31 01:18:52 CEST 2015)16:06:32.090 INFO - Compare over 21 days (2015-09-10, analysis of Wed Sep 09 01:18:12 CEST 2015)16:06:32.280 INFO - Execute decorators...16:06:32.437 INFO - Store results in database16:06:34.455 INFO - Analysis reports generated in 269ms, dir size=85 KB16:06:34.762 INFO - Analysis reports compressed in 305ms, zip size=57 KB16:06:35.137 INFO - Analysis reports sent to server in 374ms16:06:35.138 INFO - ANALYSIS SUCCESSFUL, you can browse http://server/dashboard/indexarentProject16:06:35.139 INFO - Note that you will be able to access the updated dashboard once the server has processed the submitted analysis report.INFO: ------------------------------------------------------------------------INFO: EXECUTION SUCCESSINFO: ------------------------------------------------------------------------Total time: 56.500sFinal Memory: 73M/1274MINFO: ------------------------------------------------------------------------reThere are no errors thrown and as per the logs, the cobertura report files were found and read. But, in the SonarQube screen, the coverage section is empty.a href=https://i.stack.imgur.com/irt63.jpg rel=nofollow noreferrerimg src=https://i.stack.imgur.com/irt63.jpg alt=SonarQube 5.1.2 Screenshot showing empty coverage/aCan anyone provide any help in this?****UPDATE****:Coverage.xml contents (truncated):   coverage line-rate=0.1625615763546798 branch-rate=0.034403669724770644 lines-covered=33 lines-valid=203 branches-covered=15 branches-valid=436 complexity=0.0 version=2.0.3 timestamp=1444086827204     sources     source   D:/BuildarentProject/grails-app/services   /source     source   D:/BuildarentProject/src/groovy   /source     source   D:/BuildarentProject/grails-app/taglib   /source     source   D:/BuildarentProject/grails-app/controllers   /source     /sources     packages     package name= line-rate=0.5 branch-rate=0.0 complexity=0.0     classes     class name=GrailsMelodyConfig filename=GrailsMelodyConfig.groovy line-rate=1.0 branch-rate=1.0 complexity=0.0     methods     method name=run signature=()Ljava/lang/Object; line-rate=1.0 branch-rate=1.0     lines     line number=24 hits=1 branch=false/     nes     /method     /methods     lines     line number=24 hits=1 branch=false/     nes     /class     class name=HelpContextFilters filename=HelpContextFilters.groovy line-rate=1.0 branch-rate=1.0 complexity=0.0     methods/     lines/     /class     class name=Filters filename=Filters.groovy line-rate=1.0 branch-rate=1.0 complexity=0.0     methods/     lines/     /class     class name=Filters$_closure1 filename=Filters.groovy line-rate=1.0 branch-rate=1.0 complexity=0.0     methods     method name=doCall signature=(Ljava/lang/Object;)Ljava/lang/Object; line-rate=1.0 branch-rate=1.0     lines     line number=5 hits=1 branch=false/     nes     /method     /methods     lines     line number=5 hits=1 branch=false/     nes     /class     class name=Filters$_closure1$_closure2 filename=Filters.groovy line-rate=1.0 branch-rate=1.0 complexity=0.0     methods     method name=doCall signature=(Ljava/lang/Object;)Ljava/lang/Object; line-rate=1.0 branch-rate=1.0     lines     line number=6 hits=1 branch=false/     nes     /method     /methods     lines     line number=6 hits=1 branch=false/     nes     /class     class name=Filters$_closure1$_closure2$_closure3 filename=Filters.groovy line-rate=0.0 branch-rate=0.0 complexity=0.0     methods     method name=doCall signature=(Ljava/lang/Object;)Ljava/lang/Object; line-rate=0.0 branch-rate=0.0     lines     line number=7 hits=0 branch=true condition-coverage=0% (0/2)     conditions     condition number=0 type=jump coverage=0%/     /conditions     ne     line number=8 hits=0 branch=true condition-coverage=0% (0/4)     conditions     condition number=0 type=jump coverage=0%/     condition number=1 type=jump coverage=0%/     /conditions     ne     line number=9 hits=0 branch=false/     nes     /method     /methods     lines     line number=7 hits=0 branch=true condition-coverage=0% (0/2)     conditions     condition number=0 type=jump coverage=0%/     /conditions     ne     line number=8 hits=0 branch=true condition-coverage=0% (0/4)     conditions     condition number=0 type=jump coverage=0%/     condition number=1 type=jump coverage=0%/     /conditions     ne     line number=9 hits=0 branch=false/     nes     /class     /classes     ackage     package name=com line-rate=0.0 branch-rate=0.0 complexity=0.0     classes     class name=com.CustomHtmlTagLib filename=com/CustomHtmlTagLib.groovy line-rate=1.0 branch-rate=1.0 complexity=0.0     methods/     lines/     /class     class name=com.CustomHtmlTagLib$_closure1 filename=com/CustomHtmlTagLib.groovy line-rate=0.0 branch-rate=0.0 complexity=0.0     methods     method name=doCall signature=(Ljava/lang/Object;)Ljava/lang/Object; line-rate=0.0 branch-rate=0.0     lines     line number=16 hits=0 branch=false/     line number=18 hits=0 branch=true condition-coverage=0% (0/4)     conditions     condition number=0 type=jump coverage=0%/     condition number=1 type=jump coverage=0%/     /conditions     ne     line number=19 hits=0 branch=false/     line number=21 hits=0 branch=false/     nes     /method     /methods     lines     line number=16 hits=0 branch=false/     line number=18 hits=0 branch=true condition-coverage=0% (0/4)     conditions     condition number=0 type=jump coverage=0%/     condition number=1 type=jump coverage=0%/     /conditions     ne     line number=19 hits=0 branch=false/     line number=21 hits=0 branch=false/     nes     /class     class name=com.CustomHtmlTagLib$_closure2 filename=com/CustomHtmlTagLib.groovy line-rate=0.0 branch-rate=1.0 complexity=0.0     methods     method name=doCall signature=(Ljava/lang/Object;)Ljava/lang/Object; line-rate=0.0 branch-rate=1.0     lines     line number=26 hits=0 branch=false/     nes     /method     /methods     lines     line number=26 hits=0 branch=false/     nes     /class     /classes     ackage   ... TRUNCATED ...   ackages    /coverage  re",Not-TD-related,SonarQube,,,,0.013,0.973,0.014,-0.0627
33033166,How can I make SonarQube PHP plugin work with PHPUnit?,"I had install jenkins and SonarQube Runner 2.4 ,SonarQube Server 5.1.2, php plugin 2.6,phpunit5.1and then i run with standalone sonarqube analysis,this is my configuration: sonar.language=phpsonar.projectVersion=1.0sonar.sourceEncoding=UTF-8sonar.phpCodesniffer.timeout=120sonar.projectKey=xxxsonar.projectName=xxxxsonar.sources=.sonar.tests=./tests/tests/reHere is the console output: $ /apps/svr/sonar-runner/bin/sonar-runner -e -Dsonar.projectBaseDir=/home/apps/.jenkins/workspacec_dev_example -Dsonar.sourceEncoding=UTF-8 -Dsonar.sources=. -Dsonar.language=php -Dsonar.projectVersion=1.0 -Dsonar.projectKey=php:pc_dev_example -Dsonar.phpUnit.argumentLine=/apps/svr/sonar -Dsonar.inclusions=applications/vipuserublicassport.php -Dsonar.phpCodesniffer.timeout=120 -Dsonar.tests=./tests/tests/ -Dsonar.projectName=pc_dev_exampleSonarQube Runner 2.4Java 1.7.0_71 Oracle Corporation (64-bit)Linux 2.6.32-504.23.4.el6.x86_64 amd64INFO: Error stacktraces are turned on.INFO: Runner configuration file: /apps/svr/sonar-runner/conf/sonar-runner.propertiesINFO: Project configuration file: NONEINFO: Default locale: en_US, source code encoding: UTF-8INFO: Work directory: /home/apps/.jenkins/workspacec_dev_example/.sonarINFO: SonarQube Server 5.1.215:56:42.207 INFO - Load global repositories15:56:42.471 INFO - Load global repositories (done) | time=267ms15:56:42.474 INFO - Server id: 2015100915130915:56:42.477 INFO - User cache: /home/apps/.sonar/cache15:56:42.490 INFO - Install plugins15:56:42.634 INFO - Install JDBC driver15:56:42.642 INFO - Create JDBC datasource for jdbc:mysql://localhost:3306/sonar?useUnicode=true characterEncoding=utf815:56:44.209 INFO - Initializing Hibernate15:56:45.887 INFO - Load project repositories15:56:46.582 INFO - Load project repositories (done) | time=695ms15:56:46.582 INFO - Load project settings15:56:47.405 INFO - Load technical debt model15:56:47.432 INFO - Apply project exclusions15:56:47.697 INFO - ------------- Scan pc_dev_vip_example15:56:47.702 INFO - Load module settings15:56:47.862 INFO - Language is forced to php15:56:47.871 INFO - Load rules15:56:48.455 INFO - Base dir: /home/apps/.jenkins/workspacec_dev_example15:56:48.455 INFO - Working dir: /home/apps/.jenkins/workspacec_dev_example/.sonar15:56:48.456 INFO - Source paths: .15:56:48.456 INFO - Test paths: tests/tests15:56:48.457 INFO - Source encoding: UTF-8, default locale: en_US15:56:48.457 INFO - Index files15:56:48.470 INFO - Included sources: 15:56:48.470 INFO - applications/vipuserublicassport.php15:56:48.542 INFO - 2 files indexed15:56:48.542 INFO - 470 files ignored because of inclusion/exclusion patterns15:56:48.610 INFO - Quality profile for php: Sonar way15:56:48.736 INFO - Sensor NoSonar and Commented out LOC Sensor15:56:48.769 INFO - Sensor NoSonar and Commented out LOC Sensor (done) | time=33ms15:56:48.769 INFO - Sensor Lines Sensor15:56:48.771 INFO - Sensor Lines Sensor (done) | time=2ms15:56:48.771 INFO - Sensor QProfileSensor15:56:48.775 INFO - Sensor QProfileSensor (done) | time=4ms15:56:48.775 INFO - Sensor InitialOpenIssuesSensor15:56:48.798 INFO - Sensor InitialOpenIssuesSensor (done) | time=23ms15:56:48.798 INFO - Sensor ProjectLinksSensor15:56:48.806 INFO - Sensor ProjectLinksSensor (done) | time=8ms15:56:48.806 INFO - Sensor VersionEventsSensor15:56:48.833 INFO - Sensor VersionEventsSensor (done) | time=27ms15:56:48.834 INFO - Sensor PHPSquidSensor15:56:48.880 INFO - 1 source files to be analyzed15:56:49.109 INFO - 1/1 source files have been analyzed15:56:49.132 INFO - Sensor PHPSquidSensor (done) | time=298ms15:56:49.132 INFO - Sensor PHPUnit Sensor15:56:49.132 INFO - No PHPUnit test report provided (see 'sonar.php.tests.reportPath' property)15:56:49.133 INFO - No PHPUnit unit test coverage report provided (see 'sonar.php.coverage.reportPath' property)15:56:49.133 INFO - No PHPUnit integration test coverage report provided (see 'sonar.php.coverage.itReportPath' property)15:56:49.133 INFO - No PHPUnit overall coverage report provided (see 'sonar.php.coverage.overallReportPath' property)15:56:49.133 INFO - Sensor PHPUnit Sensor (done) | time=1ms15:56:49.133 INFO - Sensor SCM Sensor15:56:49.137 INFO - Sensor SCM Sensor (done) | time=4ms15:56:49.137 INFO - Sensor CPD Sensor15:56:49.137 INFO - DefaultCpdEngine is used for php15:56:49.137 INFO - Cross-project analysis disabled15:56:49.180 INFO - Sensor CPD Sensor (done) | time=43ms15:56:49.182 INFO - No quality gate is configured.15:56:49.240 INFO - Compare to previous analysis (2015-10-09)15:56:49.249 INFO - Compare over 30 days (2015-09-09, analysis of Fri Oct 09 10:02:34 CST 2015)15:56:49.618 INFO - Execute decorators...15:56:50.177 INFO - Store results in database15:56:50.494 INFO - Analysis reports generated in 21ms, dir size=1 KB15:56:50.504 INFO - Analysis reports compressed in 10ms, zip size=2 KB15:56:50.552 INFO - Analysis reports sent to server in 48ms15:56:50.552 INFO - ANALYSIS SUCCESSFUL, you can browse http://10.199.250.171:9040/dashboard/indexhp:pc_dev_vip_example15:56:50.552 INFO - Note that you will be able to access the updated dashboard once the server has processed the submitted analysis report.INFO: ------------------------------------------------------------------------INFO: EXECUTION SUCCESSINFO: ------------------------------------------------------------------------Total time: 8.930sFinal Memory: 17M/563MINFO: ------------------------------------------------------------------------Finished: SUCCESSreIt run success,and I can see the sonar report,but PHPUnit Test is not work,look at this,it seems that it can not find phpunit,but i had install on the server.Any one knows how does this happen?How can i make PHPunit work? 15:56:49.132 INFO - Sensor PHPUnit Sensor 15:56:49.132 INFO - No PHPUnit test report provided (see 'sonar.php.tests.reportPath' property) 15:56:49.133 INFO - No PHPUnit unit test coverage report provided (see 'sonar.php.coverage.reportPath' property) 15:56:49.133 INFO - No PHPUnit integration test coverage report provided (see 'sonar.php.coverage.itReportPath' property) 15:56:49.133 INFO - No PHPUnit overall coverage report provided (see 'sonar.php.coverage.overallReportPath' property) 15:56:49.133 INFO - Sensor PHPUnit Sensor (done) | time=1msre",Not-TD-related,SonarQube,,,,0.054,0.935,0.012,-0.9596
33154111,SonarQube showing some issues with Technical debt as blank,"I'm using SonarQube 4.5.4 to run analysis on my JAVA project and then loading the results into SonarQube. SonarQube is showing the issues, but for few issues technical debt is blank.When I pullout reports using Sonar webservice api I get issues with blank debt for certain rulesFollowing are 2 sample rules for which debt is blank, these below rules are part of findbugs plugin:findsecbugs:XXE_DOCUMENT The usage of DocumentBuilder.parse(...) is vulnerable to XML External Entity attackscheckstyle:com.puppycrawl.tools.checkstyle.checks.imports.ImportControlCheck Missing an import control file.Is technical debt not defined for all rules in findbugs plugin ruleset?",Not-TD-related,SonarQube,,,,0.178,0.796,0.026,-0.9382
33239912,MsbuildSonar Runner +Fxcop - No fxcop issues are posted to server.SonarDashBoard shows 0 technical debt,"I am using Sonarqube 5.1 with MsBuildSonarRunner for my c.net project analysis. Sonarqube 5.1 has come with C 4.1 plugin, Recently I upgraded to 4.2. I have created a quality profile with ONLY Fxcop rules. I have followed the steps mentioned in Sonar site for analysis.In analysis, I see that FXcop rule violations are captured. But when I browse to SonarDash board, It shows technical debt as 0 and issues as 0. I have reviewed my steps many times and I don't see any mistakes from my side. What could be the reason why Issues are not posted to server.Here is my Build command log. I see clearly FXCOP rules are applied and violations are printed on console during build phase. =========================================================== Microsoft (R) Build Engine version 12.0.21005.1[Microsoft .NET Framework, version 4.0.30319.34209]Copyright (C) Microsoft Corporation. All rights reserved.Build started 10/19/2015 12:20:14 PM.Project D:\Sqp\Polindrome\Polindrome\Polindrome.csproj on node 1 (default targets).GenerateTargetFrameworkMonikerAttribute:Skipping target GenerateTargetFrameworkMonikerAttribute because all output files are up-to-date with respect to the input files.CoreCompile:Skipping target CoreCompile because all output files are up-to-date with respect to the input files._CopyAppConfigFile:Skipping target _CopyAppConfigFile because all output files are up-to-date with respect to the input files.CopyFilesToOutputDirectory: Polindrome -   D:\Sqp\Polindrome\Polindrome\bin\Debug\Polindrome.exeOverrideCodeAnalysisProperties: Running FxCop analysis using the SonarQube ruleset. Ruleset: D:\Sqp\Polindrome\Polindrome\.sonarqube\conf\\SonarQubeFxCop-cs.rulesetRunCodeAnalysis: Running Code Analysis... C:\Program Files (x86)\Microsoft Visual Studio 12.0\Team Tools\Static Analysis Tools\FxCop\FxCopCmd.exe /outputCulture:1033 /out:bin\Debug\Polindrome.exe.CodeAnalysisLog.xml /file:bin\Debug\Polindrome.exe /reference:C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.5.1\Microsoft.CSharp.dll /reference:C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.5.1\mscorlib.dll /reference:C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.5.1\System.Core.dll /reference:C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.5.1\System.Data.DataSetExtensions.dll /reference:C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.5.1\System.Data.dll /reference:C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.5.1\System.dll /reference:C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.5.1\System.Xml.dll /reference:C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.5.1\System.Xml.Linq.dll /directory:C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.5.1 /ruleSet:=D:\Sqp\Polindrome\Polindrome\.sonarqube\conf\\SonarQubeFxCop-cs.ruleset /rulesetdirectory:C:\Program Files (x86)\Microsoft Visual Studio 12.0\Team Tools\Static Analysis Tools\\Rule Sets /rule:-C:\Program Files (x86)\Microsoft Visual Studio 12.0\Team Tools\Static Analysis Tools\FxCop\\Rules /searchgac /ignoreinvalidtargets /forceoutput /successfile /ignoregeneratedcode /saveMessagesToReport:Active /timeout:120 MSBUILD : **warning CA1823: Microsoft.Performance : It appears that field 'Program.AccountList' is never used or is only ever assigned to. Use this field or remove it.** [D:\Sqp\Polindrome\Polindrome\Polindrome.csproj]Code Analysis Complete -- 0 error(s), 1 warning(s)SetStyleCopAnalysisSettings:Setting 'sonar.stylecop.projectFilePath' to 'D:\Sqp\Polindrome\Polindrome\Polindrome.csproj'WriteSonarQubeProjectData: Directory D:\Sqp\Polindrome\Polindrome\.sonarqube\out\\Polindrome__AnyCPU_Debug_635803356164104589 doesn't exist. Skipping. Creating directory D:\Sqp\Polindrome\Polindrome\.sonarqube\out\\Polindrome__AnyCPU_Debug_635803356164104589.Done Building Project D:\Sqp\Polindrome\Polindrome\Polindrome.csproj (default targets).Build succeeded.D:\Sqp\Polindrome\Polindrome\Polindrome.csproj (default target) (1) -  (RunCodeAnalysis target) -   MSBUILD : warning CA1823: Microsoft.Performance : It appears that field 'Program.AccountList' is never used or is only ever assigned to. Use this field or remove it. [D:\Sqp\Polindrome\Polindrome\Polindrome.csproj] 1 Warning(s) 0 Error(s)Time Elapsed 00:00:01.82re",Not-TD-related,SonarQube,,,,0.042,0.904,0.054,0.6891
33666239,Sonarqube timemachine API and metrics characteristics,"Is there a way to retrieve the characteristic of a metric of a project over time? For instance TESTABILITY is a characteristic of the metric ""squale_index"". Squale Index can be retrieved for each project using the /api/timemachine interface. However I could not find a reference to filter it in the api documentation. Is there another way?",Not-TD-related,SonarQube,,,,0,1,0,0
33711412,Trying to understand a Booth's multiplication radix-4 implementation,"I'm trying to understand some VHDL code describing Booth multiplication with a radix-4 implementation. I know how the algorithm works but I can't seem to understand what some parts of the code do specifically.
Here is the whole implementation:
library ieee;
use ieee.std_logic_1164.all;
use ieee.std_logic_arith.all;
use ieee.std_logic_signed.all;
entity booth_mult is
port(
clk : in std_logic;
start : in std_logic;
n_reset : in std_logic;
mcand : in std_logic_vector(15 downto 0);
mplier : in std_logic_vector(15 downto 0);
done : out std_logic;
product : out std_logic_vector(31 downto 0)
);
end booth_mu 
architecture arch of booth_mult is
type state_type is(IDLE, BUSY);
attribute ENUM_ENCODING : string; -- used for explicit state machine encoding
attribute ENUM_ENCODING of state_type : type is ""01 10"";
signal state_reg, state_next : state_type;
signal q_reg, q_next : unsigned(6 downto 0);
signal mcand_reg : std_logic_vector(15 downto 0); -- registers for the multiplicand
signal prod_reg, prod_next : std_logic_vector(32 downto 0);
signal result_reg, result_next : std_logic_vector(32 downto 0); -- this holds the result before shift
signal q_add, q_reset : std_logic;
begin
-- increment sequential logic on rising clock edge process
process(clk, n_reset) begin
if rising_edge(clk) then
if n_reset = '0' then
state_reg <= IDLE;
q_reg <= (others => '0');
prod_reg <= (others => '0');
else
q_reg <= q_next;
state_reg <= state_next;
prod_reg <= prod_next(32) & prod_next(32 downto 1); -- shift prod register each time
result_reg <= prod_next;
end if; end if;
end process;
-- control unit process
process(state_reg, q_reg, result_reg, start, prod_reg, mplier, mcand ) begin
-- initialize signals and no register update
q_add <= '0';
q_reset <= '0';
done <= '0';
state_next <= state_reg;
prod_next <= prod_reg;
result_next <= result_reg; case state_reg is
when IDLE => if (start = '1') then -- load numbers to multiply
mcand_reg <= mcand;
prod_next(32 downto 17) <= (others => '0'); -- prod_next reg = [0000...0000(mplier)0]
prod_next(16 downto 1) <= mplier;
prod_next(0) <= '0';
state_next <= BUSY;
end if;
when BUSY =>
q_add <= '1';
if (q_reg = '0' & conv_unsigned(16, 7)(6 downto 1) and start /= '1') then -- after 8 clock cycles multiplication is done
product <= prod_next(32) & prod_next(32 downto 2);
done <= '1' ;
q_add <= '0';
q_reset <= '1';
state_next <= IDLE;
end if;
-- radix-4 decoding
case result_reg(2 downto 0) is when ""001"" | ""010"" => -- + mcand
prod_next <= ((prod_reg(32) & prod_reg(32 downto 17)) + (mcand_reg(16 - 1) & mcand_reg)) & prod_reg(16 downto 1);
when ""011"" => -- + 2*mcand
prod_next <= ((prod_reg(32) & prod_reg(32 downto 17)) + (mcand_reg & '0' )) & prod_reg(16 downto 1);
when ""100"" => -- - 2*mcand
prod_next <= ((prod_reg(32) & prod_reg(32 downto 17)) - (mcand_reg & '0' )) & prod_reg(16 downto 1);
when ""101"" | ""110"" => -- - mcand
prod_next <= ((prod_reg(32) & prod_reg(32 downto 17)) - (mcand_reg(16 - 1) & mcand_reg)) & prod_reg(16 downto 1); -- 2*mcand
when others => -- shift only
prod_next <= prod_reg(32) & prod_reg(32 downto 1);
end case;
end case;
end process;
-- timer/counter for timed logic
q_next <= (others => '0') when q_reset = '1' else -- reset q_next to bottom if q_reset is 1
q_reg + 1 when q_add = '1' else -- increment q_reg by 1 if q_add is 1
q_reg; end arch; What I don't understand is:
if (q_reg = '0' & conv_unsigned(16, 7)(6 downto 1) and start /= '1') then -- after 8 clock cycles multiplication is done.
The comment makes it obvious but what does it do exactly? The documentation for conv_unsigned says that it should return the value 16 as an unsigned value (which it is) of size 7 (which I guess it could be). Doesn't &ing whatever is returned by conv_usigned with 0 just make the whole thing 0?
prod_next <= prod_reg(32) & prod_reg(32 downto 1);
Referring to the comment again, this should just be a shift. What I understand is actually happening is that the 32nd bit of the prod_reg register is &ed with each bit of the same register between the 32nd and 1st bits and then assigned to prod_next. How exactly is this a shift?
The code works when tested so this is 100% a problem with my lack of VHDL knowledge so please forgive me if the questions are dumb.",Not-TD-related,SonarQube,,,,0.029,0.95,0.021,-0.6942
33776367,Technical debt ratio sonar decimal,I am using Sonarqube version 5.1 and saw that the technical debt ratio percentage shows very little or no variation for the monthly reports that we generate. It is seen that the value is rounded off to only one decimal point and so the variation is not identified. Is there any setting by which we can increase the number of decimal points in technical debt ratio.,Not-TD-related,SonarQube,,,,0.1,0.817,0.083,-0.2927
33788988,Gather statistics for shared project,"I have a C solution with 3 projects.ulliApp.Console\App.Console.csprojliApp.Web\App.Web.csprojliApp.Shared\App.Shared.csprojBoth codeApp.Console and codeApp.Web reference codeApp.Shared. Currently, I build each project separately as they have slightly different MSBuild arguments.My current build process is as follows MSBuild.SonarQube.Runner.exe begin /k:MyApp /n:My App /v:1.0msbuild.exe msbuild App.Console\App.Console.csproj /t:'Rebuild' :Configuration=Release :OutDir=C:\Out\Consolemsbuild.exe msbuild App.Web\App.Web.csproj :DeployOnBuild=True :DeployDefaultTarget=WebPublish :WebPublishMethod=FileSystem :DeleteExistingFiles=True :publishUrl=C:\Out\WebMSBuild.SonarQube.Runner.exe endreI see statistics for both codeApp.Console and codeApp.Web, however, statistics for codeApp.Shared is missing. Instead, I notice a warning in the SonarQube runner output.block e WARNING: Duplicate project GUID: 21889c3d-d9c4-40d6-a4e4-971735d19ee2. Check that the project is only being built for a single platform/configuration and that that the project guid is unique. The project will not be analyzed by SonarQube. Project file: C:\Projects\MyApp\App.Shared\App.Shared.csproj/block eI believe this warning is the root of my problem.If I do the following: MSBuild.SonarQube.Runner.exe begin /k:MyConsoleApp /n:My Console App /v:1.0msbuild.exe msbuild App.Console\App.Console.csproj /t:'Rebuild' :Configuration=Release :OutDir=C:\Out\ConsoleMSBuild.SonarQube.Runner.exe endMSBuild.SonarQube.Runner.exe begin /k:MyWebApp /n:My Web App /v:1.0msbuild.exe msbuild App.Web\App.Web.csproj :DeployOnBuild=True :DeployDefaultTarget=WebPublish :WebPublishMethod=FileSystem :DeleteExistingFiles=True :publishUrl=C:\Out\WebMSBuild.SonarQube.Runner.exe endreI now have 2 separate projects in SonarQube which both contain statistics for codeApp.Shared. This is bad because this information is duplicated between the two projects and does not accurately give me an overall technical debt for my solution.I have been able to get all three set of statistics in one project by building the solution only: MSBuild.SonarQube.Runner.exe begin /k:MyApp /n:My App /v:1.0msbuild.exe msbuild App.sln /t:'Rebuild' :Configuration=ReleaseMSBuild.SonarQube.Runner.exe endreThis is emnot ideal/em because building the solution does not build the web project the way I need, thus I must do a 2nd build after SonarQube completes (build the way emI/em need it, not the way SonarQube wants it).Is it possible to run codemsbuild multiple times in-conjunction with the SonarQube MSBuild runner and get one set of complete statistics?",Not-TD-related,SonarQube,,,,0.058,0.917,0.025,-0.8494
33824281,sonarqube in c shows no technical debt nor Issues,"Used sonarqube 5.1.2 with sonarrunner 2.4 jdk 32 bit 1.8 version in XP (sp3),when analyzing any c project my execution is successful but no results in tech debt and Issues,only I could see LOC,duplication and lines,block,what is the reason behind it?what must be added to get the details in dashboard.Is anything missing?",Not-TD-related,SonarQube,,,,0.157,0.766,0.078,-0.6852
33881849,Polymorphic function over types combined by typeclass,"Consider such domain logic: three types of users: Civilians, ServiceMembers and Veterans. Each of them has 'name', stored in different attributes.Task is to write a function, accepting each of the types and returning 'C' char for Civilians, 'V' char for Veterans and 'S' char for ServiceMembers.I have such record declarations: data ServiceMemberInfo = ServiceMemberInfo { smname::String }data VeteranInfo = VeteranInfo { vname::String }data CivilianInfo = CivilianInfo { cname::String }reMy first idea was to combine them by such typeclass: class UserLetter a where userLetter :: a -   CharreAnd implement instances: instance UserLetter ServiceMemberInfo where userLetter _ = 'S'instance UserLetter VeteranInfo where userLetter _ = 'V'instance UserLetter CivilianInfo where userLetter _ = 'C'reIn this case, codeuserLetter is a function I wanted.But I really would like to write something like that (without typeclasses) userLetter1 :: UserLetter a =   a -   CharuserLetter1 (CivilianInfo _) = 'C'userLetter1 (ServiceMemberInfo _) = 'S'userLetter1 (VeteranInfo _) = 'V'rewhich throws compilation error: 'a' is a rigid type variable bound byAnother way is to use ADT:  data UserInfo = ServiceMemberInfo { smname::String } | VeteranInfo { vname::String } | CivilianInfo { cname::String }reThen userLetter1 declaration becomes obvious: userLetter1 :: UserInfo -   CharuserLetter1 (CivilianInfo _) = 'C'userLetter1 (ServiceMemberInfo _) = 'S'userLetter1 (VeteranInfo _) = 'V'reBut, lets say, I don't have control over ServiceMemberInfo (and others) declarations. How userLetter1 can be defined?Is there a way to declare one ADT with existing ServiceMemberInfo (and others) types?",Not-TD-related,SonarQube,,,,0.021,0.936,0.043,0.6505
33913008,Community C++ plugin - advantages or stable against the Sonarqube C++ plugin,I understand that there is the Community C++ plugin available for C++ code to be analysed and there is a plugin from sonar which is not free. I did use the community C++ plugin however i would like to know what is the difference between these two plugins.olliAre the set of rules different in both of these plugins.liHow stable is Community C++ plugin - and will it have or capture the results or technical debt etc similar to the Sonar C++ plugin.ThanksSandeep,Not-TD-related,SonarQube,,,,0.063,0.881,0.057,-0.1285
34064773,How to use Sencha EXT JS,"I'm developing a web application on a Debian environment. It contains a lot of graphics, so I would like to use Sencha EXT JS framework for the client-side in order to make scripts, but I don't know very well where to start. I read a lot of pages that explain it, but I have doubts like: which version should i use, etc...Could someone help me?",Not-TD-related,SonarQube,,,,0.08,0.783,0.137,0.5804
34222564,How to know the ID (@GeneratedValue) of a POJO at runtime,"I have a form to fill a POJO called codeFather. Inside it, I have a codeFotoFather field. When I save a new Father, I save automatically the object FotoFather (with Hibernate ORM pattern).codeFotoFather.fotoNaturalUrl must be filled with the value of codeFather.id and here is the problem!When i'm saving codeFather on the db, of course I still haven't codeFather.id value to fill codeFotoFather.fotoNaturalUrl. How can I solve this problem?Thank you  @Entity@Table(name = father)public class Father implements Serializable{ ... @Id @Column(name = id) @GeneratedValue(strategy = GenerationType.AUTO) private int id; ... @OneToOne(targetEntity = FotoFather.class, fetch = FetchType.EAGER) @JoinColumn(name = fotoFather, referencedColumnName = id) @Cascade(CascadeType.ALL) private FotoFather fotoFather;}reFotoFather.class @Entity@Table(name = foto_father)public class FotoFather.class{ @Id @Column(name = id) @GeneratedValue(strategy = GenerationType.AUTO) private int id; ... @Column(name = foto_natural_url) private String fotoNaturalUrl; ...}re",Not-TD-related,SonarQube,,,,0,0.884,0.116,0.906
34560230,Get Current User in Models,"I am working on a project that has an Investment and Invoice class in the models.py. The way they work is that a user places an investment and while saving the Investment model creates an invoice. Here is the relevant code: class Investment(models.Model): ... def save(self, *args, **kwargs): current_investment = Investment.objects.get(pk=self.pk) create_invoice = Invoice.objects.create(investment=current_investment, fee_type='Mngmt.', amount=self.amount*fee_amount)class Invoice(models.Model): user = models.ForeignKey(User) investment = models.ForeignKey(Investment) fee_type = models.CharField(max_length=24) amount = models.DecimalField(max_digits=12, decimal_places=2, default=0) date = models.DateTimeField(default=timezone.now, blank=True) def __str__(self): return self.investment.fund.name reSo basically when the Investment class is saved an Invoice object is created, however I want to get the current user and set it to the user field in the Invoice class. Any ideas on how I can get this done? Thanks.",Not-TD-related,SonarQube,,,,0,0.904,0.096,0.8442
34600498,SonarQube Analysis not showing code coverage,"I have a Jenkins project to do SonarQube analysis of my NodeJS project. I added codeistanbul as a dependency to my project's codepackage.json. In the Jenkins build configuration, first I run a shell script: cd .roject-namenpm installnode_modules/.bin/istanbul cover ./node_modules/.bin/_mocha path-to-unit-testsnode_modules/.bin/istanbul report coberturacd ..reThis installs the dependencies, runs the tests and generates a code coverage report and generates a cobertura-coverage.xml file.After the shell script, I run a codeInvoke Standalone SonarQube Analysis with the following properties for code coverage: sonar.java.coveragePlugin=coberturasonar.dynamicAnalysis=reuseReportssonar.cobertura.reportPath=.roject-name/coverage/cobertura-coverage.xmlreThe Jenkins job runs successfully with a SonarQube dashboard describing various things such as the lines of code, technical debt, issues and so on for the project. But the code coverage for the unit tests doesn't show up on the SonarQube dashboard. I made sure that the dashboard has the Unit Tests widget. Version of SonarQube server: 5.2Version of JavaScript plguin used on SonarQube: 2.9Version of Cobertura plugin used on SonarQube: 1.6.3Version of Cobertura plugin used on Jenkins: 1.9.7Version of NodeJS plugin used on Jenkins: 0.2.1reI verified that the workspace does have the codecobertura-coverage.xml file. Also checked the build console logs and found no bugs. I have also tried pushing the code coverage using LCOV format before: sonar.dynamicAnalysis=reuseReportssonar.javascript.lcov.reportPath=.roject-name/coverage/lcov.inforeThe report doesn't get published to SonarQube even though the coverage report does get generated in Jenkins workspace. I looked at the workspace contents and verified. The console logs show the coverage report getting generated. Also tried sonar.dynamicAnalysis=reuseReportssonar.javascript.lcov.reportPath=project-name/coverage/lcov.inforeand  sonar.dynamicAnalysis=reuseReportssonar.cobertura.reportPath=project-name/coverage/cobertura-coverage.xmlreto no avail. I also restarted the Jenkins and SonarQube servers 2 times each. Looked at many similar questions on StackOverflow and elsewhere but didn't find anything that works.If I add a post-build action codePublish Cobetura Coverage Report and specify the path to the cobetura-coverage.xml file in the codeCobertura xml report pattern field, the code coverage report does get published in Jenkins.Looked at the background task logs in SonarQube and saw an exception. java.lang.IllegalStateException: Cannot persist sources of project-key:project-name/node_modules/jscs/jscs-browser.jsat org.sonar.server.computation.step.PersistFileSourcesStep$FileSourceVisitor.visitFile(PersistFileSourcesStep.java:132) ~[sonar-server-5.2.jar:na]at org.sonar.server.computation.component.DepthTraversalTypeAwareCrawler.visitNode(DepthTraversalTypeAwareCrawler.java:72) ~[sonar-server-5.2.jar:na]at org.sonar.server.computation.component.DepthTraversalTypeAwareCrawler.visit(DepthTraversalTypeAwareCrawler.java:44) ~[sonar-server-5.2.jar:na]at org.sonar.server.computation.component.DepthTraversalTypeAwareCrawler.visitChildren(DepthTraversalTypeAwareCrawler.java:91) ~[sonar-server-5.2.jar:na]at org.sonar.server.computation.component.DepthTraversalTypeAwareCrawler.visit(DepthTraversalTypeAwareCrawler.java:47) ~[sonar-server-5.2.jar:na]at org.sonar.server.computation.component.DepthTraversalTypeAwareCrawler.visitChildren(DepthTraversalTypeAwareCrawler.java:91) ~[sonar-server-5.2.jar:na]at org.sonar.server.computation.component.DepthTraversalTypeAwareCrawler.visit(DepthTraversalTypeAwareCrawler.java:47) ~[sonar-server-5.2.jar:na]at org.sonar.server.computation.step.PersistFileSourcesStep.execute(PersistFileSourcesStep.java:89) ~[sonar-server-5.2.jar:na]at org.sonar.server.computation.step.ComputationStepExecutor.execute(ComputationStepExecutor.java:39) ~[sonar-server-5.2.jar:na]at org.sonar.server.computation.taskprocessor.report.ReportTaskProcessor.process(ReportTaskProcessor.java:53) ~[sonar-server-5.2.jar:na]at org.sonar.server.computation.taskprocessor.CeWorkerRunnableImpl.executeTask(CeWorkerRunnableImpl.java:78) [sonar-server-5.2.jar:na]at org.sonar.server.computation.taskprocessor.CeWorkerRunnableImpl.run(CeWorkerRunnableImpl.java:55) [sonar-server-5.2.jar:na]at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_45-internal]at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [na:1.8.0_45-internal]at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [na:1.8.0_45-internal]at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [na:1.8.0_45-internal]at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_45-internal]at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_45-internal]at java.lang.Thread.run(Thread.java:745) [na:1.8.0_45-internal]Caused by: org.apache.ibatis.exceptions.PersistenceException: Error updating database. Cause: com.mysql.jdbc.PacketTooBigException: Packet for query is too large (7989143    4194304). You can change this value on the server by setting the max_allowed_packet' variable. The error may involve org.sonar.db.source.FileSourceMapper.insert-Inline The error occurred while setting parameters SQL: INSERT INTO file_sources (project_uuid, file_uuid, created_at, updated_at, binary_data, line_hashes, data_hash, src_hash, data_type, revision) VALUES (?, ?, ?, ?, ?, ?, ?, ?,?, ?) Cause: com.mysql.jdbc.PacketTooBigException: Packet for query is too large (7989143    4194304). You can change this value on the server by setting the max_allowed_packet' variable.at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:26) ~[mybatis-3.2.7.jar:3.2.7]at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:154) ~[mybatis-3.2.7.jar:3.2.7]at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:141) ~[mybatis-3.2.7.jar:3.2.7]at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:51) ~[mybatis-3.2.7.jar:3.2.7]at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:52) ~[mybatis-3.2.7.jar:3.2.7]at com.sun.proxy.$Proxy84.insert(Unknown Source) ~[na:na]at org.sonar.db.source.FileSourceDao.insert(FileSourceDao.java:117) ~[sonar-db-5.2.jar:na]at org.sonar.server.computation.step.PersistFileSourcesStep$FileSourceVisitor.persistSource(PersistFileSourcesStep.java:160) ~[sonar-server-5.2.jar:na]at org.sonar.server.computation.step.PersistFileSourcesStep$FileSourceVisitor.visitFile(PersistFileSourcesStep.java:130) ~[sonar-server-5.2.jar:na]... 18 common frames omittedCaused by: com.mysql.jdbc.PacketTooBigException: Packet for query is too large (7989143    4194304). You can change this value on the server by setting the max_allowed_packet' variable.at com.mysql.jdbc.MysqlIO.send(MysqlIO.java:3540) ~[mysql-connector-java-5.1.35.jar:5.1.35]at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2417) ~[mysql-connector-java-5.1.35.jar:5.1.35]at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2582) ~[mysql-connector-java-5.1.35.jar:5.1.35]at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2535) ~[mysql-connector-java-5.1.35.jar:5.1.35]at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1911) ~[mysql-connector-java-5.1.35.jar:5.1.35]at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:1203) ~[mysql-connector-java-5.1.35.jar:5.1.35]at org.apache.commons.dbcp.DelegatingPreparedStatement.execute(DelegatingPreparedStatement.java:172) ~[commons-dbcp-1.4.jar:1.4]at org.apache.commons.dbcp.DelegatingPreparedStatement.execute(DelegatingPreparedStatement.java:172) ~[commons-dbcp-1.4.jar:1.4]at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:44) ~[mybatis-3.2.7.jar:3.2.7]at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:69) ~[mybatis-3.2.7.jar:3.2.7]at org.apache.ibatis.executor.ReuseExecutor.doUpdate(ReuseExecutor.java:50) ~[mybatis-3.2.7.jar:3.2.7]at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:105) ~[mybatis-3.2.7.jar:3.2.7]at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:71) ~[mybatis-3.2.7.jar:3.2.7]at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:152) ~[mybatis-3.2.7.jar:3.2.7]... 25 common frames omittedreSo now I've updated the shell script code coverage generation line to node_modules/.bin/istanbul cover -x node_modules ./node_modules/.bin/_mocha path-to-unit-testsreStill getting the exception. Based on a href=https://stackoverflow.com/questions/30862537/max-allowed-packet-i-dont-have-mysqlmax_allowed_packet, I don 39;t have MySQL/a, I need to bump up the value of codeMAX_ALLOWED_PACKET in the database settings. Just done that and retriggered the Jenkins job for SonarQube analysis. The exception disappeared. The background task in SonarQube was successful. But I still don't see Unit test code coverage in the dashboard. There are no other exceptions. When I click on 'Configure Widgets' button, the Unit test widget has 'No data' label on it. When I go back to the dashboard, the Unit test widget disappears.Any idea what I am missing?",Not-TD-related,SonarQube,,,,0.045,0.908,0.047,0.6818
34881219,SonarQube: Is there a way to reset the technical debt analysis,"We have a build step in TFS 2015 (vNext build system, on prem) that kicks of a code analysis in SonarQube (also on prem | runs a service | database in SQLExpress). Last week we've updated to SonarQube 5.3 (from 5.2) and apparently the first analysis run on 5.3 caused all open issues to be closed/marked as fixed. We had a technical debt of several days (even weeks) and more than 1000 open issues. After the first run the debt was down to    1h and just 2 issues. After another analysis run the debt is now 10min and 5 issues. All the previous issues are marked as 'Fixed'.I've opened a few or those 'fixed' issues, but the code hasn't been changed. Most of the files haven't been touched in months.What I have done so far: ulliI've added a new project to SonarQube and changed the Project Key and Project Name in our build to the new temporary name. Started a build that caused an analysis to run. I was hoping a new analysis on a new project would discover all issues again, but also this analysis doesn't result in all previous found issues.liI've installed SonarLint on VS2015 and it emdoes/em show all issues (about 1500) on the same solution that was analysed.Is there a way to 'reset' the SonarQube technical analysis so that it will analyse emall/em files and create (or re-open) issues?Thanks!",Not-TD-related,SonarQube,,,,0.023,0.934,0.042,0.7463
35046155,"Sonarqube 5.3, edit project level view","Currently Sonarqube 5.3 has a pre-configured view for project level analysis.It basically displays the following tabs, Home button, Technical Debt, Coverage, Duplications ...Dashboard etca href=https://i.stack.imgur.com/cdjVP.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/cdjVP.png alt=Tabs in SQ 5.3/aSo basically I wanted to customize the sequence/remove some of the tabs etc. Is there a way to edit the same?I basically want to display the custom dashboard first then some of the tabs.I couldnt find a way to customize it.",Not-TD-related,SonarQube,,,,0.036,0.946,0.019,-0.296
35237294,Slow query with order and limit clause but only if there are no records,"I am running the following query: SELECT * FROM foo WHERE name = 'Bob' ORDER BY address DESC LIMIT 25 OFFSET 1reBecause I have records in the table with name = 'Bob' the query time is fast on a table of 10M records (  .5 seconds)However, if I search for name = 'Susan' the query takes over 45 seconds. I have no records in the table where name = 'Susan'.I have an index on each of name and address. I've vacuumed the table, analyzed it and have even tried to re-write the query: SELECT * FROM (SELECT * FROM foo WHERE name = 'Bob' ORDER BY address DESC) f LIMIT 25 OFFSET 1reand can't find any solution. I'm not really sure how to proceed. Please note this is different than a href=https://stackoverflow.com/questions/6037843/extremely-slow-postgresql-query-with-order-and-limit-clausesthis post/a as my slowness only happens when there are no records.EDIT:If I take out the ORDER BY address then it runs quickly. Obviously, I need that there. I've tried re-writing it (with no success): SELECT * FROM (SELECT * FROM foo WHERE name = 'Bob') f ORDER BY address DESC LIMIT 25 OFFSET 1re",Not-TD-related,SonarQube,,,,0.063,0.924,0.013,-0.7536
35427667,How to have a projects treemap widget with code compliance % as squares color in sonarcube 5,"We've recently moved to sonarcube 5 and our projects treemap widget which display all projects by colored squares became all grey :-(On our previous version of sonar, square size was the number of line of code and color was the code compliance (green is good compliance, red is really bad).it seems that this colored indicator is not available anymore, Ive try many other (like SQALE or technical debt) but none give a good result (with SQALE, all projects are green because granularity seems too small).Some plugins exist but are all deprecateda href=http://docs.sonarqube.org/displayLUG/Issues+Density+Plugin rel=nofollowhttp://docs.sonarqube.org/displayLUG/Issues+Density+Plugin/a a href=http://docs.sonarqube.org/displayLUG/Violation+Density+Plugin rel=nofollowhttp://docs.sonarqube.org/displayLUG/Violation+Density+Plugin/aIs there a way to have the same functionality as the previous sonar version?Thanks for your support!",Not-TD-related,SonarQube,,,,0,0.896,0.104,0.8718
35460330,Is SonarQube analysis incremental or?,"We have a process to check-in PL/SQL store procedures changes into TFS, then I use a Jenkins job to analysis them with SonarQube PL/SQL plugin. I see it always index all files (162). How does SonarQube Runner update the result to the database? Delete the existing one and create a new one, or update incrementally? Getting version 'C378149' to 'D:\public_jendevslave_1\workspace\DevOps\SonarQube-PLSQL-TFS'...Finished getting version 'C378149'.[SonarQube-PLSQL-TFS] $ D:\sonar-runner\sonar-runner-2.4\bin\sonar-runner.bat -e -Dsonar.jdbc.url=jdbc:postgresql://ip:5432/sonar ******** ******** -Dsonar.host.url=http://sonarqube.dev.com/ ******** ******** -Dsonar.projectBaseDir=D:\public_jendevslave_1\workspace\DevOps\SonarQube-PLSQL-TFS -Dsonar.language=plsql -Dsonar.projectName=PL/SQL :: Schedule Snapshot 2013 :: EDBDEV -Dsonar.projectVersion=1.0 -Dsonar.sourceEncoding=UTF-8 -Dsonar.projectKey=PLSQL.EDBDEV -Dsonar.sources=ACCTROCEDURE,ADMINROCEDURE,ADMINDBAROCEDURE,DMBOROCEDURE,DSROCEDURE,EQDRVROCEDURE,ETLROCEDURE,FAMEROCEDURE,FIQRROCEDURE,FIRVFOROCEDURE,GLOBALROCEDURE,IPAROCEDURE,ITROCEDURE,MKTROCEDURE,MREFROCEDURE,OMS/SEQUENCE,PAROCEDURE,PA_UATROCEDURE,PCONFOROCEDURE,PRCROCEDURE,RECROCEDURE,RISKROCEDURE,VREP/SEQUENCED:\sonar-runner\sonar-runner-2.4SonarQube Runner 2.4Java 1.8.0_31 Oracle Corporation (64-bit)Windows Server 2012 R2 6.3 amd64INFO: Error stacktraces are turned on.INFO: Runner configuration file: D:\sonar-runner\sonar-runner-2.4\conf\sonar-runner.propertiesINFO: Project configuration file: NONEINFO: Default locale: en_US, source code encoding: UTF-8INFO: Work directory: D:\public_jendevslave_1\workspace\DevOps\SonarQube-PLSQL-TFS\.sonarINFO: SonarQube Server 5.114:28:24.824 INFO - Load global repositories14:28:25.315 INFO - Load global repositories (done) | time=498ms14:28:25.321 INFO - Server id: 2016020811421614:28:25.327 INFO - User cache: C:\Users\svc_selfserv_dev\.sonar\cache14:28:25.350 INFO - Install plugins14:28:25.826 INFO - Install JDBC driver14:28:25.838 INFO - Create JDBC datasource for jdbc:postgresql://ip:5432/sonar14:28:27.873 INFO - Initializing Hibernate14:28:29.618 INFO - views plugin licensed to OTPP, EVALUATION [Expiration: 2016-02-19, Server: *]14:28:30.213 INFO - Load project repositories14:28:31.117 INFO - Load project repositories (done) | time=904ms14:28:31.118 INFO - Load project settings14:28:31.937 INFO - Load technical debt model14:28:32.033 INFO - Apply project exclusions14:28:33.795 WARN - SCM provider autodetection failed. No SCM provider claims to support this project. Please use sonar.scm.provider to define SCM of your project.14:28:33.799 INFO - ------------- Scan PL/SQL :: Schedule Snapshot 2013 :: EDBDEV14:28:33.832 INFO - Load module settings14:28:34.298 INFO - Language is forced to plsql14:28:34.324 INFO - Load rules14:28:34.945 INFO - Base dir: D:\public_jendevslave_1\workspace\DevOps\SonarQube-PLSQL-TFS14:28:34.946 INFO - Working dir: D:\public_jendevslave_1\workspace\DevOps\SonarQube-PLSQL-TFS\.sonar14:28:34.958 INFO - Source paths: ACCTROCEDURE, ADMINROCEDURE, ADMINDBAROCEDURE, DMBOROCEDURE, DSROCEDURE, EQDRVROCEDURE, ETLROCEDURE, FAMEROCEDURE, FIQRROCEDURE, FIRVFOROCEDURE, GLOBALROCEDURE, IPAROCEDURE, ITROCEDURE, MKTROCEDURE, MREFROCEDURE, OMS/SEQUENCE, PAROCEDURE, PA_UATROCEDURE, PCONFOROCEDURE, PRCROCEDURE, RECROCEDURE, RISKROCEDURE, VREP/SEQUENCE14:28:34.959 INFO - Source encoding: UTF-8, default locale: en_US14:28:34.959 INFO - Index files14:28:35.274 INFO - 162 files indexed14:28:37.459 INFO - Quality profile for plsql: Sonar way14:28:38.372 INFO - JIRA issues sensor will not run as some parameters are missing.14:28:38.409 INFO - plsql EVALUATION [Expiration: 2016-02-19, Server: *]14:28:38.410 INFO - Sensor Lines Sensor14:28:38.528 INFO - Sensor Lines Sensor (done) | time=118ms14:28:38.529 INFO - Sensor QProfileSensor14:28:38.536 INFO - Sensor QProfileSensor (done) | time=7ms14:28:38.536 INFO - Sensor InitialOpenIssuesSensor14:28:39.221 INFO - Sensor InitialOpenIssuesSensor (done) | time=685ms14:28:39.222 INFO - Sensor ProjectLinksSensor14:28:39.236 INFO - Sensor ProjectLinksSensor (done) | time=14ms14:28:39.236 INFO - Sensor VersionEventsSensor14:28:39.255 INFO - Sensor VersionEventsSensor (done) | time=19ms14:28:39.255 INFO - Sensor com.sonar.plsql.plugin.K@4526b3d514:28:39.319 INFO - 162 source files to be analyzed14:28:39.823 WARN - 14:28:39.824 WARN - Unable to fully parse: D:\public_jendevslave_1\workspace\DevOps\SonarQube-PLSQL-TFS\ADMIN\PROCEDURE\WINDOWS_MONITOR_FILE_SYS.prc14:28:39.824 WARN - Parse error starting from line 114:28:39.824 WARN - 14:28:41.390 INFO - Sensor com.sonar.plsql.plugin.K@4526b3d5 (done) | time=2135ms14:28:41.390 INFO - Sensor SCM Sensor14:28:41.391 INFO - No SCM system was detected. You can use the 'sonar.scm.provider' property to explicitly specify it.14:28:41.391 INFO - Sensor SCM Sensor (done) | time=1ms14:28:41.391 INFO - Sensor CPD Sensor14:28:41.391 INFO - DefaultCpdEngine is used for plsql14:28:41.392 INFO - Cross-project analysis enabled14:28:41.399 INFO - 162/162 source files have been analyzed14:28:46.099 INFO - Sensor CPD Sensor (done) | time=4708ms14:28:46.101 INFO - No quality gate is configured.14:28:46.194 INFO - Compare to previous analysis (2016-02-08)14:28:46.206 INFO - Compare over 30 days (2016-01-09, analysis of Thu Feb 04 16:28:50 EST 2016)14:28:46.764 INFO - Execute decorators...14:28:50.496 INFO - Store results in database14:28:55.612 INFO - Analysis reports generated in 1041ms, dir size=1016 KB14:28:58.352 INFO - Analysis reports compressed in 2738ms, zip size=360 KB14:28:58.605 INFO - Analysis reports sent to server in 253ms14:28:58.605 INFO - ANALYSIS SUCCESSFUL, you can browse http://sonarqube.dev/dashboard/indexLSQL.EDBDEV14:28:58.605 INFO - Note that you will be able to access the updated dashboard once the server has processed the submitted analysis report.INFO: ------------------------------------------------------------------------INFO: EXECUTION SUCCESSINFO: ------------------------------------------------------------------------Total time: 35.693sFinal Memory: 20M/621MINFO: ------------------------------------------------------------------------Started calculate disk usage of buildFinished Calculation of disk usage of build in 0 secondsStarted calculate disk usage of workspaceFinished Calculation of disk usage of workspace in 1 secondFinished: SUCCESSre",Not-TD-related,SonarQube,,,,0.055,0.922,0.024,-0.9336
35574738,Issues (auto) closed and re-open,"Dear SonarQube Development team and other experts,I use SonarQube 5.3 and MSBuild Runner. A few weeks ago, I experienced issues when closing the program. These issues persisted even when leaving a file unchanged. Furthermore, these issues may be oustide the range of 1000 lines.I'm working on improving myself thanks especially to SonarQube.Currently, I eagerly await the next release, because:ulliThe next release has promised to fix among other things, the 1000 line restriction.liMy hope is that another issue called, the sonar.issue.ignore.multicriteria will be fixed too.Since yesterday, we have installed the latest versions of Sprint and SonarQube. By the evening, we experienced many additional file issues, where they had changed, but not in-line with the issues raised.In the previous week, I updated the C plugin. Doing this added 11000 issues from already active rules. These issues are primarilly from, 'Fxcop'.For now, we can't trust the 'technical debt' on Sprint.",Not-TD-related,SonarQube,,,,0.044,0.852,0.104,0.6403
36159221,set string to a fixed space?,"I have some vehicle information that I want to send in an email. I have all code working but spacing out the information is a problem. Each vehicle has a checklist and that checklist then gets emailed. So I loop through the list and get the defect and the comment. foreach (var item in chkList.CheckItems) { if (item.Defect == true) { defect += string.Format({0,-40} {1}\n, item.ItemTitle, item.Comment); } } if (hasDefect == true) { Utils.ChecklistSendMail(Checklist, ToAddresses.Split(';'), Vehicle Reg: + reg + \n + Checklist No: + chkList.CheckListNo + \n+ Date: + ChecklistDate.ToShortDateString() + \n + Defects: Comments: + \n + defect); }reEmail then looks like this: Vehicle Reg: XLZ 8194Checklist No: 0Date: 22/03/2016Defects: Comments: Vehicle Secure comment1Brakes comment2reI want the defects and the comments to be displayed like this: Defects: Comments: Vehicle Secure comment1Brakes comment2reSince codeVehicle Secure is longer than codeBrakes the comment is being pushed further out. But is there a way to fix the string at a certain position no matter how long first word is? EDITcode now looks like this:  string defect = ; string comment = ; string aheading = Defects:; string bheading = Comments:;foreach (var item in chkList.CheckItems) { if (item.Defect == true) { defect += item.ItemTitle; comment += item.Comment; } } string result = aheading.PadRight(20, ' ') + bheading.PadRight(20, ' ') + Environment.NewLine + defect.PadRight(20, ' ') + comment.PadRight(20, ' ') + Environment.NewLine;reBut the output looks like this: Defects: Comments: Vehicle SecureBrakestest1test2 re",Not-TD-related,SonarQube,,,,0.16,0.72,0.119,-0.9161
36195913,Technical Debt showing Zero in Sonar,"I am using Jenkins for CI and added the sonar plugins for Jenkins. After sonar scan Technical Debt shown Zero.But actually its is not zero previously was using latest version of sonar there it was showing Technical Debt but after downgrading it is not shown .(Duplicate code ,Lines of code ,complexity are shown)Below are the version of sonar used Before Downgrading following version are used (Working fine) sonar scanner 2.5.1 , Sonar Plugin 2.3 , SonarQube 5.4 , Jenkins version. 1.651reAfter Downgrading (Technical Debt not shown) Sonar scanner 2.5, sonar plugin 2.1 , SonarQube 4.5 , Jenkins version 1.651reHow this problem can be solved ?ThanksGanesh",Not-TD-related,SonarQube,,,,0.102,0.874,0.025,-0.8067
36287221,SonarQube/SonarLint/Visual Studio: Use one ruleset fo all projects in solution,"We are currently in the process of evaluating the use of SonarQube/SonarLint for our .NET applications. We are pretty happy with what we've seen so far (and, btw, kudos for bringing SonarQube this far - I've used it a couple of years ago for my PhD project, and it has improved greatly since then!).However, one thing was a bit surprising: When I connected my SonarLint instance to our SonarQube server (which worked just fine) and started syncing the bound project, SonarLint started to download nuget packages (which was kind of expected) and then created one or even two .ruleset files for each project of our solution (in addition to a file SonarQube/<solution name>CSharp.ruleset which I assume is the solution-wide ruleset).What I expected and would prefer is only the single ruleset valid for the complete solution (and possibly the option to override that ruleset for projects where this makes sense (e.g., test projects)).Is this behavior possible at all, i.e., did I miss anything? Documentation is the only area I've identified so far where SonarLint is lacking.",Not-TD-related,SonarQube,,,,0.009,0.871,0.121,0.9622
36294091,"Is it possible to hide the Technical Debt metric from SonarQube dashboard, entirely?","I understand that the Technical Debt metric became part of SonarQube after it was a plugin, but I would like to remove it from the dashboard completely, and only show other metrics. Is that possible from the dashboard settings? if not, I appreciate any directions on what parts of the source code have to be edited.",Not-TD-related,SonarQube,,,,0.082,0.861,0.057,-0.0994
36425261,Developing a new component/sub application within an existing architecture,"I've got a fairly large Spring MVC application (80K loc) that I manage. Our team is going to be developing a new feature/sub-application.The question is, should we build it/deploy it as its own application (a whole new WAR) or build it/deploy it as part of the current application (part of the existing WAR)? Are there pros and cons to each?",Not-TD-related,SonarQube,,,,0,1,0,0
36562791,Parse query not returning new data on onResume,"I'm developing a feature where users can join a room and I'm using Parse to hold the room's data. My problem is that when a new user joins a room and an existing user of that room resumes the room's activity, the existing user doesn't see the new user.Entry before a user joinedSo here's an entry for my table where a user created a room but no one's joined yet.Here's my GameOnSession class which is an extension of the ParseObject class.@ParseClassName(""GameOnSession"")public class GameOnSession extends ParseObject {public JSONArray getParticipants() { return getJSONArray(""participants""); }public String getNumberOfParticipants() {int getParticipantsNumber = getParticipants().length();return String.valueOf(getParticipantsNumber);}public static ParseQuery<GameOnSession> getQuery() {return ParseQuery.getQuery(GameOnSession.class);}}This is my query that I run to check the number of people in the room.ParseQuery<GameOnSession> query = ParseQuery.getQuery(GameOnSession.class);query.whereEqualTo(""objectId"", QueryPreferences.getStoredSessionId(getActivity()));query.findInBackground(new FindCallback<GameOnSession>() {@Overridepublic void done(List<GameOnSession> objects, ParseException e) {GameOnSession sess = objects.get(0);Log.d(""GAMEONSESSION"", ""Current # "" + sess.getNumberOfParticipants());}});So it returns what I expect: 0.Now when a new user joins the room, the entry looks like this.Entry after a user joinedThen I press a button that runs the query above. And it still returns 0, when I expect 1.I'm not sure what's the problem here, did I set up my query wrong?In short, when User A creates a room, the Parse query returns number of users as 0 which is expected. When User B joins User A's room, Parse query STILL returns the numbers of users as 0 and NOT 1. This is unexpected and I'm not sure how to proceed.",Not-TD-related,SonarQube,,,,0.068,0.877,0.054,-0.764
36627002,Is it possible to disable duplicate code detection in Intellij?,"Is it possible to disable duplicate code detection in Intellij?I haven't found this feature to be useful and it continues to distract me.",Not-TD-related,SonarQube,,,,0.084,0.805,0.111,0.1779
36863484,The number of differences in a column,"I would like to retrieve a column of how many differences in letters in each row. For instanceIf you have a a value ""test"" and another row has a value ""testing "", then the differences is 4 letter between ""test"" and ""testing "". The data of the column would be value 4I have reflected about it and I don't know where to beginid || value || category || differences --------------------------------------------------1 || test || 1 || 42 || testing || 1 || null 11 || candy || 2 || -3 12 || ca || 2 || null In this scenario and context it is no difference between ""Test"" and ""rest"".",Not-TD-related,SonarQube,,,,0.021,0.865,0.114,0.836
36868433,SonarQube service not starting,"We are seeing below error while starting SonarQube service. Looks like there is a duplicate entry while registering Quality Profile but I am not sure on the table. Since the service is not started, we cannot verify it from web. Can someone please advise.The issue occurred post creation of a new DB and copy of tables data from old DB. We are performing this to check new collation which is required for Sonar. 2016.04.26 15:41:53 INFO web[o.s.s.s.RegisterDebtModel] Register technical debt model2016.04.26 15:41:53 INFO web[o.s.s.r.RegisterRules] Register rules2016.04.26 15:41:58 INFO web[o.s.s.q.RegisterQualityProfiles] Register quality profiles2016.04.26 15:42:00 INFO web[o.s.s.n.NotificationService] Notification service stopped2016.04.26 15:42:00 ERROR web[o.a.c.c.C.[.[.[/]] Exception sending context initialized event to listener instance of class org.sonar.server.platform.PlatformServletContextListener org.apache.ibatis.exceptions.TooManyResultsException: Expected one result (or null) to be returned by selectOne(), but found: 2 at org.apache.ibatis.session.defaults.DefaultSqlSession.selectOne(DefaultSqlSession.java:70) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:68) ~[mybatis-3.2.7.jar:3.2.7] at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:52) ~[mybatis-3.2.7.jar:3.2.7] at com.sun.proxy.$Proxy34.selectDefaultProfile(Unknown Source) ~[na:na] at org.sonar.db.qualityprofile.QualityProfileDao.selectDefaultProfile(QualityProfileDao.java:176) ~[sonar-db-5.3.jar:na] at org.sonar.server.qualityprofile.RegisterQualityProfiles.setDefault(RegisterQualityProfiles.java:161) ~[sonar-server-5.3.jar:na] at org.sonar.server.qualityprofile.RegisterQualityProfiles.registerProfilesForLanguage(RegisterQualityProfiles.java:131) ~[sonar-server-5.3.jar:na] at org.sonar.server.qualityprofile.RegisterQualityProfiles.start(RegisterQualityProfiles.java:95) ~[sonar-server-5.3.jar:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_25] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_25] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_25] at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_25] at org.picocontainer.lifecycle.ReflectionLifecycleStrategy.invokeMethod(ReflectionLifecycleStrategy.java:110) ~[picocontainer-2.15.jar:na] at org.picocontainer.lifecycle.ReflectionLifecycleStrategy.start(ReflectionLifecycleStrategy.java:89) ~[picocontainer-2.15.jar:na] at org.sonar.core.platform.ComponentContainer$1.start(ComponentContainer.java:291) ~[sonar-core-5.3.jar:na] at org.picocontainer.injectors.AbstractInjectionFactory$LifecycleAdapter.start(AbstractInjectionFactory.java:84) ~[picocontainer-2.15.jar:na] at org.picocontainer.behaviors.AbstractBehavior.start(AbstractBehavior.java:169) ~[picocontainer-2.15.jar:na] at org.picocontainer.behaviors.Stored$RealComponentLifecycle.start(Stored.java:132) ~[picocontainer-2.15.jar:na] at org.picocontainer.behaviors.Stored.start(Stored.java:110) ~[picocontainer-2.15.jar:na] at org.picocontainer.DefaultPicoContainer.potentiallyStartAdapter(DefaultPicoContainer.java:1016) ~[picocontainer-2.15.jar:na] at org.picocontainer.DefaultPicoContainer.startAdapters(DefaultPicoContainer.java:1009) ~[picocontainer-2.15.jar:na] at org.picocontainer.DefaultPicoContainer.start(DefaultPicoContainer.java:767) ~[picocontainer-2.15.jar:na] at org.sonar.core.platform.ComponentContainer.startComponents(ComponentContainer.java:131) ~[sonar-core-5.3.jar:na] at org.sonar.server.platform.platformlevel.PlatformLevel.start(PlatformLevel.java:84) ~[sonar-server-5.3.jar:na] at org.sonar.server.platform.platformlevel.PlatformLevelStartup.access$001(PlatformLevelStartup.java:45) ~[sonar-server-5.3.jar:na] at org.sonar.server.platform.platformlevel.PlatformLevelStartup$1.doPrivileged(PlatformLevelStartup.java:82) ~[sonar-server-5.3.jar:na] at org.sonar.server.user.DoPrivileged.execute(DoPrivileged.java:45) ~[sonar-server-5.3.jar:na] at org.sonar.server.platform.platformlevel.PlatformLevelStartup.start(PlatformLevelStartup.java:78) ~[sonar-server-5.3.jar:na] at org.sonar.server.platform.Platform.executeStartupTasks(Platform.java:197) ~[sonar-server-5.3.jar:na] at org.sonar.server.platform.Platform.doStart(Platform.java:114) ~[sonar-server-5.3.jar:na] at org.sonar.server.platform.Platform.doStart(Platform.java:99) ~[sonar-server-5.3.jar:na] at org.sonar.server.platform.PlatformServletContextListener.contextInitialized(PlatformServletContextListener.java:43) ~[sonar-server-5.3.jar:na] at org.apache.catalina.core.StandardContext.listenerStart(StandardContext.java:4720) [tomcat-embed-core-8.0.18.jar:8.0.18] at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5154) [tomcat-embed-core-8.0.18.jar:8.0.18] at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) ~[tomcat-embed-core-8.0.18.jar:8.0.18] at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1409) ~[tomcat-embed-core-8.0.18.jar:8.0.18] at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1399) ~[tomcat-embed-core-8.0.18.jar:8.0.18] at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334) ~[na:1.7.0_25] at java.util.concurrent.FutureTask.run(FutureTask.java:166) ~[na:1.7.0_25] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_25] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) ~[na:1.7.0_25]re",Not-TD-related,SonarQube,,,,0.047,0.925,0.028,-0.7043
36982225,Possible to add custom extensions to Bluemix delivery pipeline instance?,"I want to add custom extensions like Istanbul for code coverage, SonarQube for static code analysis, custom tool for technical debt calculation. Is it possible to add custom extensions to a Bluemix Delivery Pipeline instance?",Not-TD-related,SonarQube,,,,0.069,0.826,0.105,0.0772
37159088,Exclude files from coverage calculation in SonarQube,"Using SonarQube 5.3, maven and jacoco-maven-plugin (0.7.6.201602180812) with the following property in the pom   sonar.coverage.exclusions  **/*.css  /sonar.coverage.exclusions  reHowever, it does not seem to work. The css-files are still reported and it clutters up the graphs, see screen-shot below.We do not wish to exclude the css-files completely by using the more general sonar.exclusions-property as we find it useful to see the technical debts of the css-files. I've searched the archive for an answer, but there does not seem to be an answer to this particular issue. And I did not find any help in a href=http://docs.sonarqube.org/display/SONAR/Narrowing+the+Focus rel=nofollowhttp://docs.sonarqube.org/display/SONAR/Narrowing+the+Focus/a either. Would be grateful for any hints!a href=http://i.stack.imgur.com/57rdx.png rel=nofollowcustom.css with 0% coverage/a",Not-TD-related,SonarQube,,,,0.04,0.893,0.067,0.4694
37283272,Configure time period/interval for SonarQube history diagram,It looks SonarQube's History diagram is always configured for about a two-month period. I'd like to produce a diagram that shows decreasing technical debt for a specific time period that correlates with a certain clean-up initiative? How can I configure the diagram to show a specific time period?,Not-TD-related,SonarQube,,,,0.054,0.839,0.107,0.3527
37463297,RAILS: Custom function in where block,"shirt.rb [ id, size, color ]reAs the input I get value codeparams[:size] which equals for example 170. Data in codeshirts table codesize column stores in format - code160-180 (so it is a string)How can I preform query like: Shirt.where(parse_first_number(size)    ? AND parse_second_number(size)    ?, params[:size], params[:size]) re",Not-TD-related,SonarQube,,,,0,0.878,0.122,0.644
37726655,Publishing JUnit test reports on Sonar,"I have the JUnit XML reports of a Maven Java project, not the source files.I'd like Sonarqube 4.5.7 to publish those reports by executing the following command : mvn sonar:sonar.Sonarqube is installed on a remote server, java-plugin-3.8 and other plugins are installed.All my JUnit XML reports are in a directory named reports.The pom.xml on the root of my projet looks like this :    project xmlns=http://maven.apache.orgOM/4.0.0 xmlns:xsi=http://www.w3.org/2001/XMLSchema-instance xsi:schemaLocation=http://maven.apache.orgOM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd     modelVersion  4.0.0  /modelVersion     groupId  ***  /groupId     artifactId  ***  /artifactId     version  1.0.0  /version     packaging  pom  ackaging     name  MEDIATION-DEV1_SMED-Apporteur  /name     properties     sonar.junit.reportsPath  reports  /sonar.junit.reportsPath     sonar.dynamicAnalysis  reuseReports  /sonar.dynamicAnalysis     sonar.jdbc.username  ***  /sonar.jdbc.username     sonar.jdbc.password  ***  /sonar.jdbc.password     sonar.jdbc.url  jdbc:mysql://***useUnicode=true characterEncoding=utf8  /sonar.jdbc.url     sonar.language  java  /sonar.language     sonar.jdbc.driver  com.mysql.jdbc.Driver  /sonar.jdbc.driver     sonar.jdbc.dialect  mysql  /sonar.jdbc.dialect     sonar.host.url  ***  /sonar.host.url     roperties    roject  reWhen I execute mvn sonar:sonar I get : Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=256m; support was removed in 8.0[INFO] Scanning for projects...[INFO][INFO] ------------------------------------------------------------------------[INFO] Building ***[INFO] ------------------------------------------------------------------------[INFO][INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ Apporteur ---[INFO] Deleting E:\jenkins-slave\workspace\workspace\Mediation-Sonar-Test-Alex\target[INFO][INFO] ------------------------------------------------------------------------[INFO] Building ***[INFO] ------------------------------------------------------------------------[INFO][INFO] --- sonar-maven-plugin:3.0.2:sonar (default-cli) @ Apporteur ---[INFO] User cache: C:\Users\S046499\.sonar\cache[INFO] SonarQube version: 4.5.7[INFO] Default locale: en_US, source code encoding: windows-1252 (analysis is platform dependent)[INFO] [14:01:41.624] Load global referentials...[INFO] [14:01:41.861] Load global referentials done: 241 ms[INFO] [14:01:41.888] User cache: C:\Users\S046499\.sonar\cache[INFO] [14:01:41.904] Install plugins[INFO] [14:01:42.141] Install JDBC driver[INFO] [14:01:42.161] Create JDBC datasource for jdbc:*** useUnicode=true characterEncoding=utf8[INFO] [14:01:43.969] Initializing Hibernate[INFO] [14:01:47.254] views plugin licensed to ***, EVALUATION [Expiration: 2016-06-17, Server: *][INFO] [14:01:47.560] Load project referentials...[INFO] [14:01:48.253] Load project referentials done: 693 ms[INFO] [14:01:48.255] Load project settings[INFO] [14:01:48.837] Loading technical debt model...[INFO] [14:01:48.889] Loading technical debt model done: 52 ms[INFO] [14:01:48.895] Apply project exclusions[WARN] [14:01:49.305] 'sonar.dynamicAnalysis' is deprecated since version 4.3 and should no longer be used.[INFO] [14:01:49.408] ------------- Scan ***[INFO] [14:01:49.421] Load module settings[INFO] [14:01:51.137] Language is forced to java[INFO] [14:01:51.144] Loading rules...[INFO] [14:01:52.704] Loading rules done: 1560 ms[INFO] [14:01:52.749] Configure Maven plugins[INFO] [14:01:53.031] Compare to previous analysis (2016-06-09)[INFO] [14:01:53.053] Compare over 30 days (2016-05-10, analysis of 2016-06-01 14:22:45.0)[INFO] [14:01:53.057] No quality gate is configured.[INFO] [14:01:54.287] Base dir: E:\jenkins-slave\workspace\workspace\Mediation-Sonar-Test-Alex[INFO] [14:01:54.288] Working dir: E:\jenkins-slave\workspace\workspace\Mediation-Sonar-Test-Alex\target\sonar[INFO] [14:01:54.292] Source paths: pom.xml[INFO] [14:01:54.308] Source encoding: windows-1252, default locale: en_US[INFO] [14:01:54.309] Index files[INFO] [14:01:54.366] 0 files indexed[INFO] [14:01:54.368] Quality profile for java: Sonar way[INFO] [14:01:54.416] Sensor QProfileSensor...[INFO] [14:01:54.446] Sensor QProfileSensor done: 30 ms[INFO] [14:01:54.447] Sensor InitialOpenIssuesSensor...[INFO] [14:01:54.623] Sensor InitialOpenIssuesSensor done: 176 ms[INFO] [14:01:54.624] Sensor ProjectLinksSensor...[INFO] [14:01:54.677] Sensor ProjectLinksSensor done: 53 ms[INFO] [14:01:54.682] Sensor VersionEventsSensor...[INFO] [14:01:54.733] Sensor VersionEventsSensor done: 51 ms[INFO] [14:01:54.734] Sensor FileHashSensor...[INFO] [14:01:54.735] Sensor FileHashSensor done: 1 ms[INFO] [14:01:54.735] Sensor Maven dependencies...[INFO] [14:01:55.009] Sensor Maven dependencies done: 273 ms[INFO] [14:01:55.013] Sensor CPD Sensor (wrapped)...[INFO] [14:01:55.017] JavaCpdEngine is used for java[INFO] [14:01:55.018] Sensor CPD Sensor (wrapped) done: 6 ms[INFO] [14:01:55.464] Execute decorators...[INFO] [14:01:55.955] Store results in database[INFO] [14:01:56.238] ANALYSIS SUCCESSFUL, you can browse ***[INFO] [14:01:56.329] Executing post-job class org.sonar.plugins.dbcleaner.ProjectPurgePostJob[INFO] [14:01:56.348] -   Keep one snapshot per day between 2016-05-12 and 2016-06-08[INFO] [14:01:56.354] -   Keep one snapshot per week between 2015-06-11 and 2016-05-12[INFO] [14:01:56.358] -   Keep one snapshot per month between 2011-06-16 and 2015-06-11[INFO] [14:01:56.365] -   Delete data prior to: 2011-06-16[INFO] [14:01:56.375] -   Clean MEDIATION-DEV1_SMED-Apporteur [id=4094][INFO] [14:01:56.387]   - Delete aborted builds[INFO] [14:01:56.491]   - Clean snapshot 7289[INFO] [14:01:56.646] Executing post-job class org.sonar.plugins.core.issue.notification.SendIssueNotificationsPostJob[INFO] [14:01:56.647] Executing post-job class org.sonar.plugins.core.batch.IndexProjectPostJob[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 18.157 s[INFO] Finished at: 2016-06-09T14:01:56+02:00[INFO] Final Memory: 23M/428M[INFO] ------------------------------------------------------------------------reWhen I browse the given address, no results are displayed in the (configured) dashboard.Do you have any idea ?Regards.Thomas",Not-TD-related,SonarQube,,,,0.036,0.928,0.036,0.2577
37874178,moment.js timezone inconsistency,"I am formatting a given date using momentjs. The following behaves differently in different timezones:codemoment(new Date(2016 + - + 06 + -01).toISOString()).format('MMMM YYYY')It gives me codeMay 2016 in timezone of America/Denver and codeJune 2016 in Asia/Karachi. I tested by changing the browser timezone to different timezones. It should be codeJune 2016 in both.When i change the format in codenew Date() to use slashes instead of hyphens like below, it gives me correct result in both timezones i.e. codeMay 2016.codemoment(new Date(2016 + / + 06 + /01).toISOString()).format('MMMM YYYY')Both seem to be valid ISO strings, what would cause this inconsistency?",Not-TD-related,SonarQube,,,,0.02,0.951,0.028,0.1779
38016202,How can I override the date_hierarchy function for a single ModelAdmin?,"I would like to set date_hierarchy on a ModelAdmin to a field on a related model, for example:date_hierarchy = 'item__menu__date'This is not possible in Django 1.9, but will be possible in Django 1.11. The code for the 1.11 feature already exists. (ref. 1 2 3)As far as I can tell, overriding just def date_hierarchy(cl) from django/contrib/admin/templatetags/admin_list.py for a single ModelAdmin will make this possible for that ModelAdmin.I've found writeups on overriding templatetags, but these tend to focus on HTML files. Is it possible to override the date_hierarchy() function in the context of a single ModelAdmin? If so, how?",Not-TD-related,SonarQube,,,,0,0.977,0.023,0.2755
38806930,C Error when attempting to pass Type as parameter when method requires a type,"As a test case Ive created the following very simple method: public static object TestMethod(Type t) { return t; }reFor the type I am attempting to pass through it, I have created a very basic class also as a test: public class TestClass { public string name { get; set; } }reFinally I am attempting to call the method normally: TestClass sample = TestMethod(TestClass);reHowever it seems that when TestClass is passed as a parameter for codeTestMethod, I receive the error: 'TestClass' is a type, which is not valid in the given context.This makes no sense to me as the parameter required IS a type.",Not-TD-related,SonarQube,,,,0.052,0.905,0.043,-0.2263
39274518,why sonarqube 6.0 doesn't allow to select metrics of type Rating in quality gate definitions?,"Reliability Rating, Security Rating and SQUALE Rating doesn't appear in quality gate definition form. Is this a bug or there's some hidden reason for this?",Not-TD-related,SonarQube,,,,0,0.906,0.094,0.34
39346929,Can I restrict document types uploaded to a Sharepoint Online Document Set?,I have created a Document Set in SharePoint online and allowed the Document content type to the document set. Is it possible to restrict the types of documents uploaded to the document set? I only want users to be able to upload Word 2007 documents and above and not any older versions of Word documents such as Word 2003.Not sure if it is possible or not? I can't see of a way to restrict this from the content type or document set.,Not-TD-related,SonarQube,,,,0.063,0.866,0.072,-0.2406
39353125,"SonarQube Scanner: I know there are errors in the javascript, but the scan doesn't seem to catch them","I am having trouble running SonarQube Scanner. Everything seems to be configured correctly according to the build log. However, when I click on the link to view my report, the report show 0 technical debt and 0 issues. I know there are errors in the javascript, but the scan doesn't seem to catch them. I think I may be missing something in the configuration, but according to the log, everything went well.I am attaching the log and a jpeg of the report page.a href=http://i.stack.imgur.com/d0vlC.jpg rel=nofollowreport jpeg/ablock e [INFO] --- sonar-maven-plugin:3.0.2:sonar (default-cli) @ myproject --- [INFO] User cache: /home/ltbldmgt/.sonar/cache [INFO] SonarQube version: 4.5.5 [INFO] Default locale: en_US, source code encoding: UTF-8 [INFO] [14:03:15.487] Load global referentials... [INFO] [14:03:16.286] Load global referentials done: 802 ms [INFO] [14:03:16.304] User cache: /home/ltbldmgt/.sonar/cache [INFO] [14:03:16.316] Install plugins [INFO] [14:03:16.490] Install JDBC driver [INFO] [14:03:16.511] Create JDBC datasource for jdbc:postgresql://lt00nxam00f5000.opr.mysite.org/sonar [INFO] [14:03:18.358] Initializing Hibernate [INFO] [14:03:20.687] Load project referentials... [INFO] [14:03:21.343] Load project referentials done: 656 ms [INFO] [14:03:21.343] Load project settings [INFO] [14:03:21.807] Loading technical debt model... [INFO] [14:03:21.831] Loading technical debt model done: 24 ms [INFO] [14:03:21.835] Apply project exclusions [INFO] [14:03:22.184] ------------- Scan myproject [INFO] [14:03:22.188] Load module settings [INFO] [14:03:22.678] Language is forced to js [INFO] [14:03:22.680] Loading rules... [INFO] [14:03:23.696] Loading rules done: 1016 ms [INFO] [14:03:23.733] Configure Maven plugins [INFO] [14:03:23.923] Compare to previous analysis (2016-09-01) [INFO] [14:03:23.940] Compare over 30 days (2016-08-02, analysis of 2016-08-01 13:50:56.779) [INFO] [14:03:23.942] No quality gate is configured. [WARN] [14:03:25.039] Accessing the filesystem before the Sensor phase is deprecated and will not be supported in the future. Please update your plugin. [INFO] [14:03:25.039] Index files [INFO] [14:03:25.150] 0 files indexed [INFO] [14:03:25.156] Base dir: /opt/ltsapps/jenkins/workspace/myproject [INFO] [14:03:25.156] Working dir: /opt/ltsapps/jenkins/workspace/myproject/src [INFO] [14:03:25.156] Source paths: pom.xml [INFO] [14:03:25.157] Binary dirs: target/classes [INFO] [14:03:25.157] Source encoding: UTF-8, default locale: en_US [INFO] [14:03:25.157] Index files [INFO] [14:03:25.212] 0 files indexed [INFO] [14:03:25.213] Quality profile for js: Sonar way [INFO] [14:03:25.244] Sensor QProfileSensor... [INFO] [14:03:25.268] Sensor QProfileSensor done: 24 ms [INFO] [14:03:25.268] Sensor ScmActivitySensor... [INFO] [14:03:25.268] Trying to guess scm provider from project layout... [INFO] [14:03:25.268] Found SCM type: svn [INFO] [14:03:25.270] Retrieve SCM blame information with encoding UTF-8... [INFO] [14:03:25.271] Retrieve SCM blame information with encoding UTF-8 done: 1 ms [INFO] [14:03:25.271] Sensor ScmActivitySensor done: 3 ms [INFO] [14:03:25.271] Sensor InitialOpenIssuesSensor... [INFO] [14:03:25.282] Sensor InitialOpenIssuesSensor done: 11 ms [INFO] [14:03:25.282] Sensor ProjectLinksSensor... [INFO] [14:03:25.294] Sensor ProjectLinksSensor done: 12 ms [INFO] [14:03:25.294] Sensor VersionEventsSensor... [INFO] [14:03:25.339] Sensor VersionEventsSensor done: 45 ms [INFO] [14:03:25.339] Sensor FileHashSensor... [INFO] [14:03:25.340] Sensor FileHashSensor done: 1 ms [INFO] [14:03:25.340] Sensor Maven dependencies... [INFO] [14:03:25.409] Sensor Maven dependencies done: 69 ms [INFO] [14:03:25.411] Sensor CPD Sensor (wrapped)... [INFO] [14:03:25.412] DefaultCpdEngine is used for js [INFO] [14:03:25.412] Sensor CPD Sensor (wrapped) done: 1 ms [INFO] [14:03:25.890] Execute decorators... [INFO] [14:03:25.944] Saving metrics for: myproject project. [INFO] [14:03:25.974] Metrics saved successfully. [INFO] [14:03:26.260] Store results in database [INFO] [14:03:26.372] ANALYSIS SUCCESSFUL, you can browse a href=http://lt00nxam00f5000.opr.mysite.org/sonar/dashboard/index/myproject rel=nofollowhttp://lt00nxam00f5000.opr.mysite.org/sonar/dashboard/index/myproject/a [INFO] [14:03:26.759] Executing post-job class org.sonar.plugins.core.issue.notification.SendIssueNotificationsPostJob [INFO] [14:03:26.760] Executing post-job class org.sonar.plugins.core.batch.IndexProjectPostJob [INFO] [14:03:26.780] Executing post-job class org.sonar.plugins.dbcleaner.ProjectPurgePostJob [INFO] [14:03:26.803] - Keep one snapshot per day between 2016-08-04 and 2016-08-31 [INFO] [14:03:26.809] - Keep one snapshot per week between 2015-09-03 and 2016-08-04 [INFO] [14:03:26.816] - Keep one snapshot per month between 2011-09-08 and 2015-09-03 [INFO] [14:03:26.825] - Delete data prior to: 2011-09-08 [INFO] [14:03:26.833] - Clean myproject [id=7000] [INFO] [14:03:26.839]   - Clean snapshot 81696 [INFO] [14:03:26.889] Executing post-job class org.sonar.plugins.buildbreaker.AlertBreaker [INFO] [14:03:26.900] Executing post-job class org.sonar.plugins.buildbreaker.ForbiddenConfigurationBreaker [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 14.798 s [INFO] Finished at: 2016-09-01T14:03:26-05:00 [INFO] Final Memory: 32M/1238M [INFO] ------------------------------------------------------------------------ Sonar analysis completed: SUCCESS/block eAny ideas as to what I may be missing here?Thank you!",Not-TD-related,SonarQube,,,,0.052,0.896,0.053,0.7648
39525909,SonarQube Technical Debt management with Quality Gate,"Configuring a custom Quality Gate, the default SonarQube Way has been taken as initial reference and further adjusted and customized (adding further checks). Our current quality gate looks as following (old version vs current version): Blocker issues: error threshold at 0Complexity/class: error threshold at 12Complexity/file: error threshold at 12Complexity/function error threshold at 2Coverage error threshold at 100      changed to 65Critical issues error threshold at 0Duplicated lines (%) error threshold at 5Info issues error threshold at 10Major issues error threshold at 50Minor issues error threshold at 100Overall coverage error threshold at 100      changed to 65Public documented API (%) error threshold at 50Skipped Unit tests error threshold at 0Technical Debts error threshold at 10d      change to (??    10)Unit test errors error threshold at 0Unit test failures error threshold at 0reThe main point is about the Technical Debts days, which should be enforced from 10 to something smaller, given that other checks have been relaxed (complexity and coverage). This is indeed reasonable: relaxing some rules you should have more margin for controlled technical debt and hence shorter threshold for the number of accumulated days for uncontrolled technical debt.However, the overall quality gate should somehow (mathematically?) follow a certain proportion.Question: how to calculate the most appropriate technical debt threshold given the relaxations above?From an a href=http://www.sonarqube.org/evaluate-your-technical-debt-with-sonar/ rel=nofollowold article/a (2009, hence most probably not applicable any longer) the following formula has been deducted: TechDebt = (cost_to_fix_one_block * duplicated_blocks) + \ (cost_to fix_one_violation * mandatory_violations) + \ (cost_to_comment_one_API * public_undocumented_api) + \ (cost_to_cover_one_of_complexity * uncovered_complexity_by_tests) + \ (cost_to_split_a_method * function_complexity_distribution) + \ (cost_to_split_a_class * class_complexity_distribution)reNote: code\ added for readability.However, there are too many unknown variables to make a proper calculation, yet it is not covering all of the quality gate items above (again, it's an old reference).Other more recent a href=http://docs.sonarqube.org/display/SONAR/Metric+Definitions rel=nofollowsources/a explain in details concerned items, but not how to adjust values in a proportionated manner.The codesonar.technicalDebt.developmentCost (emAdmin/em / emConfiguration/em / emTechnical Debt/em) has a default value of 30 minutes, which means 1 LOC (cost to develop 1 line of code) = 30, but still not at the granularity level of the variables above nor useful in this case.",Not-TD-related,SonarQube,,,,0.12,0.838,0.043,-0.954
39698937,Jenkins-Git -Retrieving commited user,"I want to get the user who commits in Git or other SCM tool.I am running sonarqube from jenkins for each commit(Plugin is already available) to run.But i need to get the user for each commit before running sonarqube, so that i could show the metrics for each user with respective to technical debts,function points etc from Sonarqube.Thanks in advance",Not-TD-related,SonarQube,,,,0,0.877,0.123,0.6597
40110151,Can SonarQube be configured to show code coverage in preview mode reports?,"I am currently working with SonarQube v5.6 and have a need to generate comprehensive preview reports locally before pushing the results to my remote SonarQube server. Specifically, I need to be able to see technical debt, code coverage, and duplicated blocks in the local HTML and/or console reports which are created when running the analysis in preview mode.Currently, I am able to see issues -- new, existing, resolved, minor, major, etc. -- and nothing else. I would like to be able to see technical debt, code coverage, and duplicated blocks as well (at the very least, I need to see code coverage). Can SonarQube be configured to show these details in preview mode reports, via a command line argument or some other setting? I am using Maven and JaCoCo.",Not-TD-related,SonarQube,,,,0.101,0.84,0.059,-0.6818
40592900,Swift 3 JSON Multi-dimensional NSArray to String,"I am taking in a multi-dimensional array from JSON and trying to store it into a NSArray object. I then want to iterate that object through picker. This worked on Swift 2, but once I converted to swift 3 I get 'Type Any has no subscript members' errors in my pickerView function. Relevant Code (names and faces changed): func pickerView(_ pickerView: UIPickerView, titleForRow row: Int, forComponent component: Int) -   String? { let ticket_number = pvds_ticket_number[row][ticket_number] as! String let customer_name = pvds_ticket_number[row][customer_name] as! String return \(ticket_number) - \(customer_name)}func pickerView(_ pickerView: UIPickerView, didSelectRow row: Int, inComponent component: Int){ let ticket_number = pvds_ticket_number[row][ticket_number] as! String txt_ticket_number.text = ticket_number}func get_tickets (){ let userID = UserDefaults.standard.string(forKey: userID) let url_path: NSString = my_url_that_isnt_relevant as NSString; let url_path_formatted: NSString = url_path.addingPercentEscapes(using: String.Encoding.utf8.rawValue)! as NSString let url = URL(string: url_path_formatted as String) let session = URLSession.shared let task = session.dataTask(with: url!, completionHandler: {data, response, error -   Void in if(error != nil) { // If there is an error in the web request, print it to the console print(error!.localizedDescription) } do { let json = try JSONSerialization.jsonObject(with: data!, options: .mutableContainers) as? NSDictionary if let parseJSON = json { if let results: NSArray = parseJSON[results] as? NSArray{ DispatchQueue.main.async(execute: { self.pvds_ticket_number = results as! [Any] as NSArray self.pv_ticket_number.reloadAllComponents() }) } } } catch { print(something went wrong) } }) task.resume()}reThese lines show the errors:br let ticket_number = pvds_ticket_number[row][ticket_number] as! Stringbr let customer_name = pvds_ticket_number[row][customer_name] as! String",Not-TD-related,SonarQube,,,,0.07,0.908,0.023,-0.9179
41180301,How to convert ios app into Xamarin.ios app?,"Actually I have an ios app written in Objective -C , I want to convert it into Xamarin.ios I followed a href=https://developer.xamarin.com/guides/ios/advanced_topics/binding_objective-c/walkthrough/Creating_A_Static_Library rel=nofollow noreferrerThis link/a but I could not do that , Is there another way instead of this. Please give me any idea before negate post i am new in xamarin.Any idea will be appareciated thanks in Advance.",Not-TD-related,SonarQube,,,,0,0.85,0.15,0.8145
41550260,What does the leak period mean in sonarQube?,I'm new in SonarQube I started reading documentation but a lot of time a found The leak period but I didn't found anything about it can someone explain me what it means my second question it's what is the role of sonar-runner ? I found it a lot of time when i was searching about sonar installation even I have installed sonarQube and asscociate it with my project just using maven-sonar plugin and eclipse plugin sonarLint Thank u,Not-TD-related,SonarQube,,,,0.043,0.912,0.045,0.0387
42968469,How to browse an assembly's content without source code in Roslyn,"Roslyn allows you to get the CSharpCompilation from the source code:// Getting the AST nodevar tree = (CSharpSyntaxTree)CSharpSyntaxTree.ParseText(""my code"");// Loading the semantic modelCSharpCompilation compilation = CSharpCompilation.Create(""Compilation"", new[] { tree });Then I get the SemanticModel:var sm = compilation.GetSemanticModel(tree);The I usually try to get symbols like this:sm.GetSymbolInfo(node);No source codeWhat if I have no source code?How can I get a CSharpCompilation without having the source code but just the DLL?How can I enumerate all symbols in the DLL and retrieve all the information about those types?Is Roslyn capable of this?",Not-TD-related,SonarQube,,,,0.034,0.902,0.064,0.6007
43312822,Implementing unique_ptr: Deleting non-allocated objects,"My goal here is to implement a simple version of unique_ptr which offers only a constructor, destructor, -, *, and release().However, I don't know what to do in the case where a unique_ptr is initialized using a non-allocated pointer.eg int i = 0;unique_ptr  int   p{ i};reIf the unique_ptr simply calls delete on it owned pointer, this will produced undefined (and undesirable) behavior, at least as far as I know. What can I do to prevent this?EDIT: My attempt at the problem is as follows... template  typename T  class Uptr{public: Uptr  T  (T* pt) : mp_owned{pt} {} ~Uptr  T  () {delete mp_owned;} Uptr  T  (const Uptr  T   ) = delete; Uptr  T    operator=(const Uptr  T   ) = delete; T  operator*() const {return *mp_owned;} T* operator-  () const {return mp_owned;} T* release() {return mp_owned;}private: T* mp_owned;};re",Not-TD-related,SonarQube,,,,0.024,0.967,0.01,-0.3818
43363377,Direct link to a SonarQube Widget,"I've been looking for a way to directly access a widget from my SonarQube instance with a direct URL, the way it's possible to access a Dashboard. Is it possible to do that adding the respective metrics from the configuration of the Widget? The problem I found is that I can only build a widget and it takes the filter parameter, sizes, but when it comes to the metrics, they are ignored and it builds it with the default ones for the respective widget.I have the following Widget configured (with metrics: Classes, Comment_Density and size - Complexity):a href=https://i.stack.imgur.com/aWPRh.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/aWPRh.png alt=enter image description here/aWhen building the URL to get directly this widget, I found it impossible to access it by its Id. So, I added all configuration details, but the widget I get is this, holding the default metrics - Lines of Code, Issues and Technical Debt. Built widget:a href=https://i.stack.imgur.com/Ma2dc.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/Ma2dc.png alt=enter image description here/aIs accessing directly a configured Widget even possible with the current versions of the SonarQube?The URL I used is :   sonarqubeinstance  /widget?id=measure_filter_bubble_chart filter=1 chartTitle=Measure%20Bubble%20Chart chartHeight=400 widget_width=1279px metric1=classes metric2=comment_lines_density metric3=complexityreThanks in advance for your help!",Not-TD-related,SonarQube,,,,0.043,0.904,0.053,0.4464
43386675,Is there a proper replacement for the Filter Motion Chart in sonarqube 6.x,"Sonar is a very good tool to get an overview over the codebase. Its strenght is that you can see a lot of data(and select which data you want) in a single chart.The most useful chart in that sense is the Filter Motion Chart. It aggregates data over projects   time giving the broadest overview possible.I tried and searched a lot and was not able to find a proper replacement in sonar 6.x.ulliHave I overlooked a solution?liIs something planned for a replacement?liWill the Filter Motion Chart be fixed for sonar 6.x?We decided in our company not to upgrade sonar until this problem is fixed. We think that the usefulness of sonar is crippled without this.Edit: Added details as a response to Fabrice solution: (does not fit into comment)I will give you some details so you better understand our needs:We are a team that works together on multible projects. No one has ownership of a single project but the responsibility is shared in the whole team.In our daily work we use sonar to monitor the quality of the code we are working on (writing or reviewing).But as we collaborate on the same codebase and have shared responsibilty, we have to agree on certain standards with the whole team (Coding conventions, typical design patterns, sonar rules and much more...).These things need to be discussed with the whole team. One start point for such discussions is that we look at. What we do is:ulliMark the projects that had changes since we last looked at sonar asfavorites(typically 2 weeks ago)liOpen the filter motion chart to get an overview over the changes since we last metliDrill into the detailsliIf needed Discuss problems, rules, etc.I agree that in my daily work I do not need the broad overview. But as we are a team that is working together weneed this team view as well.block e SonarQube is not meant to be a multi-purpose aggregation platform (...)/block eIt is a pity that you think that way. As a matter of fact: Sonar does a very good job in aggregating data.Timeline, Bubble, etc. are very useful tools for aggregating data. Throwing this away will diminish the usefulnessof sonar. I hope you think about this a second time.block e (...)embrace quality as a day-to-day practice(...)/block eI understand that this is a big part of sonar. The reason that we do not rate this part as important may be related to the fact that we develop c with Visual Studio. With build in features   3rd party plugins Visual Studiois quite ok in giving direct feedback on code quality. This may be different for other languages   toolsets givingthis part of sonar a bigger importace.block e (...)and we feel this is not a good thing (performance wise, UX wise, product wise, ...) (...)/block eI could accept that at an answer: You do not want to do it, because it is difficult!I think that sonar is a very useful tool. You did a very good job developing it. And you developed not onlyrules   quality gates but Timelines, Bubble Charts,...You cannot blame your users for using them!As a user I can tell you: You have users that use these tools! For good reason! I hope you rethink your data aggregation is bad-concept!",Not-TD-related,SonarQube,,,,0.024,0.813,0.162,0.9977
43591076,Hibernate - Envers : Is it possible to use SQL triggers to create revisions,"I want Envers not to create revisions but only retrieve them, the use of triggers is much faster imho.Is there a way to set Envers to 'read-only' ?",Not-TD-related,SonarQube,,,,0.053,0.904,0.043,-0.0662
43629818,Technical debt formula doesn't take into account complexity,"In Sonarqube versions prior to 5.5 there was the possibility to change the way that technical debt is calculated in order to take into account the complexity, but after 5.5 I cant see how to change it. Did you remove this configuration?IMHO, the cost of remediation is much harder in a complex code than in a simpler one. Here is a a href=https://www.adictosaltrabajo.com/tutoriales/sonarqube-4-5-2/ rel=nofollow noreferrerpost/a where you can see and compare two similar projects with similar technical debt based on size, but with quite different technical debt based on complexity. Also, coverage is affecting to this measure; and I think that it is easier to modify code when you have enough tests and coverage that assures that you are not breaking anything.In sonarqube documentation, the formula that is used to calculate the technical debt ratio is: Remediation cost / (Cost to develop 1 line of code * Number of lines of code)reBut the remediation cost is a fixed amount of time configured on each rule, isn't it?. So it is independent from the complexity you can find in the code.Here is an image where you can see how this could be done in version 5.1.2:a href=https://i.stack.imgur.com/OBGpl.png rel=nofollow noreferrerTechnical debt with complexity/aIs there any way to configure, in LTS or version 6.x , the technical debt so that the complexity is taken into account like it was in previous versions?If not, is that in your road map? Do you have any reference that complexity or coverage does not affect to remediation cost?Thanks in advance.Note: The new concept of cognitive complexity seems very interesting, we're talking again about complexity, it would be a good candidate. But I haven't seen how to see it in Sonarqube 6.3.1, is it possible?",Not-TD-related,SonarQube,,,,0.059,0.86,0.081,0.8248
44053981,Does SonarQube calculates Effort to reach Maintainability Rating A considering code duplication?,"it looks like that out-of-the-box SonarQube 6 (6.3.1) does not consider the time to fix Duplicated Code and Comments when presenting the effort in the Effort to reach Maintainability Rating A metric. Is that correct?If so, is there a way to add in the effort the time needed to fix duplicated code and/or lack of comments (%) ? I see there is a rule Source files should not have any duplicated blocks that can be activated. Is that all is needed to calculate time to fix duplicated code?Does technical debt also accounts for comments ?Sonar documentation does not state how Effort to reach Maintainability Rating A metric is calculated in a href=https://docs.sonarqube.org/display/SONAR/Metric+Definitions rel=nofollow noreferrerhttps://docs.sonarqube.org/display/SONAR/Metric+Definitions/a",Not-TD-related,SonarQube,,,,0.068,0.89,0.042,-0.6072
44344350,Travis CI. Show results of SonarQube execution on Github,"I've created GitHub repository, added Travis CI into it, added an icon with Travis CI build information (it works fine).Also, I've added SonarQube via Travis CI. It also runs, but I didn't know how to show information from SonarQube execution in my Github README.rst.Any ideas?It will be amazing to show somehow all the data (technical debts, code smells, etc.)",Not-TD-related,SonarQube,,,,0,0.893,0.107,0.7717
44559938,Sonar Error Logs while restarting Sonar,"Below are the error logs observed when I am restarting the Sonar.Versions used-MySql-  mysql Ver 14.14 Distrib 5.5.55, for debian-linux-gnu (x86_64) using readline 6.3reJava- java version 1.8.0_131Java(TM) SE Runtime Environment (build 1.8.0_131-b11)Java HotSpot(TM) 64-Bit Server VM (build 25.131-b11, mixed mode)reSonar- Version 5.1.1 - LGPL v3 - Community - Documentation - Get Support - Plugins - Web Service API reMy Sonar.properties file- sonar.jdbc.username=sonarsonar.jdbc.password=sonarsonar.jdbc.url=jdbc:mysql://localhost:3306/sonar?useUnicode=true characterEncoding=utf8 rewriteBatchedStatements=true useConfigs=maxPerformancesonar.web.port=9000reAlso I have added my IP under /ets/hosts.Please suggest why is the cause of the error logs. TERM trapped. Shutting down.2017.06.15 06:03:45 INFO app[o.s.p.m.TerminatorThread] Process[web] is stopping2017.06.15 06:03:46 INFO web[o.s.p.StopWatcher] Stopping process2017.06.15 06:03:46 INFO web[o.a.c.h.Http11NioProtocol] Pausing ProtocolHandler [http-nio-0.0.0.0-9080]2017.06.15 06:03:46 INFO web[o.s.s.n.NotificationService] Notification service stopped2017.06.15 06:03:46 WARN web[o.a.c.l.WebappClassLoaderBase] The web application [ROOT] appears to have started a thread named [Abandoned connection cleanup thread] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread: java.lang.Object.wait(Native Method) java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143) com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43)2017.06.15 06:03:46 INFO web[o.a.c.h.Http11NioProtocol] Stopping ProtocolHandler [http-nio-0.0.0.0-9080]2017.06.15 06:03:47 INFO web[o.a.c.h.Http11NioProtocol] Destroying ProtocolHandler [http-nio-0.0.0.0-9080]2017.06.15 06:03:47 INFO web[o.s.s.a.TomcatAccessLog] Web server is stopped2017.06.15 06:03:47 INFO app[o.s.p.m.TerminatorThread] Process[web] is stopped2017.06.15 06:03:47 INFO app[o.s.p.m.TerminatorThread] Process[search] is stopping2017.06.15 06:03:47 INFO es[o.s.p.StopWatcher] Stopping process2017.06.15 06:03:47 INFO es[o.elasticsearch.node] [sonar-1497506533409] stopping ...2017.06.15 06:03:47 INFO es[o.elasticsearch.node] [sonar-1497506533409] stopped2017.06.15 06:03:47 INFO es[o.elasticsearch.node] [sonar-1497506533409] closing ...2017.06.15 06:03:47 INFO es[o.elasticsearch.node] [sonar-1497506533409] closed2017.06.15 06:03:47 INFO app[o.s.p.m.TerminatorThread] Process[search] is stopped  -- Wrapper Stopped--   Wrapper Started as DaemonLaunching a JVM...Wrapper (Version 3.2.3) http://wrapper.tanukisoftware.org Copyright 1999-2006 Tanuki Software, Inc. All Rights Reserved.2017.06.15 06:03:52 INFO app[o.s.p.m.JavaProcessLauncher] Launch process[search]: /usrb/jvm/java-8-oracle/jre/bin/java -Djava.awt.headless=true -Xmx1G -Xms256m -Xss256k -Djava.net.preferIPv4Stack=true -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+HeapDumpOnOutOfMemoryError -Djava.io.tmpdir=/opt/sonar/temp -cp .b/common/*:.b/search/* org.sonar.search.SearchServer /tmp/sq-process5953723730418892518properties2017.06.15 06:03:53 INFO es[o.s.p.ProcessEntryPoint] Starting searc017.06.15 06:03:53 INFO es[o.s.s.SearchServer] Starting Elasticsearch[sonarqube] on port 90012017.06.15 06:03:53 INFO es[o.elasticsearch.node] [sonar-1497506632689] version[1.4.4], pid[2762], build[c88f77f/2015-02-19T13:05:36Z]2017.06.15 06:03:53 INFO es[o.elasticsearch.node] [sonar-1497506632689] initializing ...2017.06.15 06:03:53 INFO es[o.e.plugins] [sonar-1497506632689] loaded [], sites []2017.06.15 06:03:54 INFO es[o.elasticsearch.node] [sonar-1497506632689] initialized2017.06.15 06:03:54 INFO es[o.elasticsearch.node] [sonar-1497506632689] starting ...2017.06.15 06:03:54 WARN es[o.e.common.network] failed to resolve local host, fallback to loopbackjava.net.UnknownHostException: ip-10-10-1-144: ip-10-10-1-144: Name or service not known at java.net.InetAddress.getLocalHost(InetAddress.java:1505) ~[na:1.8.0_131] at org.elasticsearch.common.network.NetworkUtils.  clinit  (NetworkUtils.java:55) ~[elasticsearch-1.4.4.jar:na] at org.elasticsearch.transport.netty.NettyTransport.createClientBootstrap(NettyTransport.java:350) [elasticsearch-1.4.4.jar:na] at org.elasticsearch.transport.netty.NettyTransport.doStart(NettyTransport.java:250) [elasticsearch-1.4.4.jar:na] at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:85) [elasticsearch-1.4.4.jar:na] at org.elasticsearch.transport.TransportService.doStart(TransportService.java:91) [elasticsearch-1.4.4.jar:na] at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:85) [elasticsearch-1.4.4.jar:na] at org.elasticsearch.node.internal.InternalNode.start(InternalNode.java:242) [elasticsearch-1.4.4.jar:na] at org.sonar.search.SearchServer.start(SearchServer.java:46) [sonar-search-5.1.1.jar:na] at org.sonar.process.ProcessEntryPoint.launch(ProcessEntryPoint.java:77) [sonar-process-5.1.1.jar:na] at org.sonar.search.SearchServer.main(SearchServer.java:80) [sonar-search-5.1.1.jar:na]Caused by: java.net.UnknownHostException: ip-10-10-1-144: Name or service not known at java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method) ~[na:1.8.0_131] at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:928) ~[na:1.8.0_131] at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1323) ~[na:1.8.0_131] at java.net.InetAddress.getLocalHost(InetAddress.java:1500) ~[na:1.8.0_131] ... 10 common frames omitted2017.06.15 06:03:54 INFO es[o.e.transport] [sonar-1497506632689] bound_address {inet[/0.0.0.0:9001]}, publish_address {inet[/10.10.1.144:9001]}2017.06.15 06:03:55 INFO es[o.e.discovery] [sonar-1497506632689] sonarqube/Q6auH-7JTS2lEBIKDkZ0bQ2017.06.15 06:03:58 INFO es[o.e.cluster.service] [sonar-1497506632689] new_master [sonar-1497506632689][Q6auH-7JTS2lEBIKDkZ0bQ][localhost][inet[/10.10.1.144:9001]]{rack_id=sonar-1497506632689}, reason: zen-disco-join (elected_as_master)2017.06.15 06:03:58 INFO es[o.elasticsearch.node] [sonar-1497506632689] started2017.06.15 06:03:58 INFO es[o.e.gateway] [sonar-1497506632689] recovered [6] indices into cluster_stateJava HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=160m; support was removed in 8.02017.06.15 06:04:00 INFO app[o.s.p.m.Monitor] Process[search] is up2017.06.15 06:04:00 INFO app[o.s.p.m.JavaProcessLauncher] Launch process[web]: /usrb/jvm/java-8-oracle/jre/bin/java -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djruby.management.enabled=false -Djruby.compile.invokedynamic=false -Xmx768m -XX:MaxPermSize=160m -XX:+HeapDumpOnOutOfMemoryError -Djava.net.preferIPv4Stack=true -Djava.io.tmpdir=/opt/sonar/temp -cp .b/common/*:.b/server/*:/opt/sonarb/jdbc/mysql/mysql-connector-java-5.1.34.jar org.sonar.server.app.WebServer /tmp/sq-process611872039216276506properties2017.06.15 06:04:00 INFO web[o.s.p.ProcessEntryPoint] Starting web2017.06.15 06:04:00 INFO web[o.s.s.app.Webapp] Webapp directory: /opt/sonar/web2017.06.15 06:04:01 INFO web[o.a.c.h.Http11NioProtocol] Initializing ProtocolHandler [http-nio-0.0.0.0-9000]2017.06.15 06:04:01 INFO web[o.a.t.u.n.NioSelectorPool] Using a shared selector for servlet write/read2017.06.15 06:04:01 INFO web[o.e.plugins] [sonar-1497506632689] loaded [], sites []2017.06.15 06:04:01 WARN web[o.e.common.network] failed to resolve local host, fallback to loopbackjava.net.UnknownHostException: ip-10-10-1-144: ip-10-10-1-144: Name or service not known at java.net.InetAddress.getLocalHost(InetAddress.java:1505) ~[na:1.8.0_131] at org.elasticsearch.common.network.NetworkUtils.  clinit  (NetworkUtils.java:55) ~[elasticsearch-1.4.4.jar:na] at org.elasticsearch.transport.netty.NettyTransport.createClientBootstrap(NettyTransport.java:350) [elasticsearch-1.4.4.jar:na] at org.elasticsearch.transport.netty.NettyTransport.doStart(NettyTransport.java:250) [elasticsearch-1.4.4.jar:na] at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:85) [elasticsearch-1.4.4.jar:na] at org.elasticsearch.transport.TransportService.doStart(TransportService.java:91) [elasticsearch-1.4.4.jar:na] at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:85) [elasticsearch-1.4.4.jar:na] at org.elasticsearch.client.transport.TransportClient.  init  (TransportClient.java:189) [elasticsearch-1.4.4.jar:na] at org.elasticsearch.client.transport.TransportClient.  init  (TransportClient.java:123) [elasticsearch-1.4.4.jar:na] at org.sonar.server.search.SearchClient.  init  (SearchClient.java:75) [sonar-server-5.1.1.jar:na] at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) [na:1.8.0_131] at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) [na:1.8.0_131] at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) [na:1.8.0_131] at java.lang.reflect.Constructor.newInstance(Constructor.java:423) [na:1.8.0_131] at org.picocontainer.injectors.AbstractInjector.newInstance(AbstractInjector.java:145) [picocontainer-2.14.3.jar:na] at org.picocontainer.injectors.ConstructorInjector$1.run(ConstructorInjector.java:342) [picocontainer-2.14.3.jar:na] at org.picocontainer.injectors.AbstractInjector$ThreadLocalCyclicDependencyGuard.observe(AbstractInjector.java:270) [picocontainer-2.14.3.jar:na] at org.picocontainer.injectors.ConstructorInjector.getComponentInstance(ConstructorInjector.java:364) [picocontainer-2.14.3.jar:na] at org.picocontainer.injectors.AbstractInjectionFactory$LifecycleAdapter.getComponentInstance(AbstractInjectionFactory.java:56) [picocontainer-2.14.3.jar:na] at org.picocontainer.behaviors.AbstractBehavior.getComponentInstance(AbstractBehavior.java:64) [picocontainer-2.14.3.jar:na] at org.picocontainer.behaviors.Stored.getComponentInstance(Stored.java:91) [picocontainer-2.14.3.jar:na] at org.picocontainer.DefaultPicoContainer.getInstance(DefaultPicoContainer.java:698) [picocontainer-2.14.3.jar:na] at org.picocontainer.DefaultPicoContainer.getComponent(DefaultPicoContainer.java:646) [picocontainer-2.14.3.jar:na] at org.picocontainer.DefaultPicoContainer.getComponent(DefaultPicoContainer.java:631) [picocontainer-2.14.3.jar:na] at org.picocontainer.parameters.BasicComponentParameter$1.resolveInstance(BasicComponentParameter.java:118) [picocontainer-2.14.3.jar:na] at org.picocontainer.parameters.ComponentParameter$1.resolveInstance(ComponentParameter.java:136) [picocontainer-2.14.3.jar:na] at org.picocontainer.injectors.SingleMemberInjector.getParameter(SingleMemberInjector.java:78) [picocontainer-2.14.3.jar:na] at org.picocontainer.injectors.ConstructorInjector$CtorAndAdapters.getParameterArguments(ConstructorInjector.java:309) [picocontainer-2.14.3.jar:na] at org.picocontainer.injectors.ConstructorInjector$1.run(ConstructorInjector.java:335) [picocontainer-2.14.3.jar:na] at org.picocontainer.injectors.AbstractInjector$ThreadLocalCyclicDependencyGuard.observe(AbstractInjector.java:270) [picocontainer-2.14.3.jar:na] at org.picocontainer.injectors.ConstructorInjector.getComponentInstance(ConstructorInjector.java:364) [picocontainer-2.14.3.jar:na] at org.picocontainer.injectors.AbstractInjectionFactory$LifecycleAdapter.getComponentInstance(AbstractInjectionFactory.java:56) [picocontainer-2.14.3.jar:na] at org.picocontainer.behaviors.AbstractBehavior.getComponentInstance(AbstractBehavior.java:64) [picocontainer-2.14.3.jar:na] at org.picocontainer.behaviors.Stored.getComponentInstance(Stored.java:91) [picocontainer-2.14.3.jar:na] at org.picocontainer.DefaultPicoContainer.getInstance(DefaultPicoContainer.java:698) [picocontainer-2.14.3.jar:na] at org.picocontainer.DefaultPicoContainer.getComponent(DefaultPicoContainer.java:646) [picocontainer-2.14.3.jar:na] at org.picocontainer.DefaultPicoContainer.getComponent(DefaultPicoContainer.java:631) [picocontainer-2.14.3.jar:na] at org.picocontainer.parameters.BasicComponentParameter$1.resolveInstance(BasicComponentParameter.java:118) [picocontainer-2.14.3.jar:na] at org.picocontainer.parameters.ComponentParameter$1.resolveInstance(ComponentParameter.java:136) [picocontainer-2.14.3.jar:na] at org.picocontainer.injectors.SingleMemberInjector.getParameter(SingleMemberInjector.java:78) [picocontainer-2.14.3.jar:na] at org.picocontainer.injectors.ConstructorInjector$CtorAndAdapters.getParameterArguments(ConstructorInjector.java:309) [picocontainer-2.14.3.jar:na] at org.picocontainer.injectors.ConstructorInjector$1.run(ConstructorInjector.java:335) [picocontainer-2.14.3.jar:na] at org.picocontainer.injectors.AbstractInjector$ThreadLocalCyclicDependencyGuard.observe(AbstractInjector.java:270) [picocontainer-2.14.3.jar:na] at org.picocontainer.injectors.ConstructorInjector.getComponentInstance(ConstructorInjector.java:364) [picocontainer-2.14.3.jar:na] at org.picocontainer.injectors.AbstractInjectionFactory$LifecycleAdapter.getComponentInstance(AbstractInjectionFactory.java:56) [picocontainer-2.14.3.jar:na] at org.picocontainer.behaviors.AbstractBehavior.getComponentInstance(AbstractBehavior.java:64) [picocontainer-2.14.3.jar:na] at org.picocontainer.behaviors.Stored.getComponentInstance(Stored.java:91) [picocontainer-2.14.3.jar:na] at org.picocontainer.DefaultPicoContainer.instantiateComponentAsIsStartable(DefaultPicoContainer.java:1033) [picocontainer-2.14.3.jar:na] at org.picocontainer.DefaultPicoContainer.addAdapterIfStartable(DefaultPicoContainer.java:1025) [picocontainer-2.14.3.jar:na] at org.picocontainer.DefaultPicoContainer.startAdapters(DefaultPicoContainer.java:1002) [picocontainer-2.14.3.jar:na] at org.picocontainer.DefaultPicoContainer.start(DefaultPicoContainer.java:766) [picocontainer-2.14.3.jar:na] at org.sonar.api.platform.ComponentContainer.startComponents(ComponentContainer.java:91) [sonar-plugin-api-5.1.1.jar:na] at org.sonar.server.platform.Platform.startLevel1Container(Platform.java:96) [sonar-server-5.1.1.jar:na] at org.sonar.server.platform.Platform.init(Platform.java:72) [sonar-server-5.1.1.jar:na] at org.sonar.server.platform.PlatformServletContextListener.contextInitialized(PlatformServletContextListener.java:43) [sonar-server-5.1.1.jar:na] at org.apache.catalina.core.StandardContext.listenerStart(StandardContext.java:4720) [tomcat-embed-core-8.0.18.jar:8.0.18] at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5154) [tomcat-embed-core-8.0.18.jar:8.0.18] at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) [tomcat-embed-core-8.0.18.jar:8.0.18] at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1409) [tomcat-embed-core-8.0.18.jar:8.0.18] at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1399) [tomcat-embed-core-8.0.18.jar:8.0.18] at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_131] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_131] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_131] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]Caused by: java.net.UnknownHostException: ip-10-10-1-144: Name or service not known at java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method) ~[na:1.8.0_131] at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:928) ~[na:1.8.0_131] at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1323) ~[na:1.8.0_131] at java.net.InetAddress.getLocalHost(InetAddress.java:1500) ~[na:1.8.0_131] ... 63 common frames omitted2017.06.15 06:04:02 INFO web[o.s.s.p.ServerImpl] SonarQube Server / 5.1.1 / 0a231d24c0f1e7ce1d200274b8e9bbe00f9f49fb2017.06.15 06:04:02 INFO web[o.s.c.p.Database] Create JDBC datasource for jdbc:mysql://localhost:3306/sonar?useUnicode=true characterEncoding=utf8 rewriteBatchedStatements=true useConfigs=maxPerformance2017.06.15 06:04:03 INFO web[o.s.s.p.DefaultServerFileSystem] SonarQube home: /opt/sonar2017.06.15 06:04:03 INFO web[o.s.s.p.ServerPluginJarsInstaller] Install plugins2017.06.15 06:04:03 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin Core / 5.1.1 / 0a231d24c0f1e7ce1d200274b8e9bbe00f9f49fb2017.06.15 06:04:03 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin Email notifications / 5.1.1 / 0a231d24c0f1e7ce1d200274b8e9bbe00f9f49fb2017.06.15 06:04:03 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin Java / 3.0 / 65396a609ddface8b311a6a665aca92a7da694f12017.06.15 06:04:03 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin Git / 1.0 / 9ce9d330c313c296fab051317cc5ad4b26319e072017.06.15 06:04:03 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin English Pack / 5.1.1 / 0a231d24c0f1e7ce1d200274b8e9bbe00f9f49fb2017.06.15 06:04:03 INFO web[o.s.s.p.ServerPluginJarsInstaller] Deploy plugin SVN / 1.0 / 213fc8a8b582ff530b12dd4a59a6512be10712342017.06.15 06:04:03 INFO web[o.s.s.p.RailsAppsDeployer] Deploy Ruby on Rails applications2017.06.15 06:04:03 INFO web[o.s.j.s.AbstractDatabaseConnector] Initializing Hibernate2017.06.15 06:04:04 INFO web[o.s.s.p.UpdateCenterClient] Update center: http://update.sonarsource.org/update-center.properties (no proxy)2017.06.15 06:04:05 INFO web[o.s.s.n.NotificationService] Notification service started (delay 60 sec.)2017.06.15 06:04:05 INFO web[o.s.s.s.IndexSynchronizer] Index rules2017.06.15 06:04:06 INFO web[o.s.s.s.IndexSynchronizer] Index activeRules2017.06.15 06:04:06 INFO web[o.s.s.s.RegisterMetrics] Register metrics2017.06.15 06:04:07 INFO web[o.s.s.s.RegisterMetrics] Cleaning quality gate conditions2017.06.15 06:04:07 INFO web[o.s.s.s.RegisterDebtModel] Register technical debt model2017.06.15 06:04:07 INFO web[o.s.s.r.RegisterRules] Register rules2017.06.15 06:04:07 INFO web[o.s.s.q.RegisterQualityProfiles] Register quality profiles2017.06.15 06:04:07 INFO web[o.s.s.s.RegisterNewMeasureFilters] Register measure filters2017.06.15 06:04:07 INFO web[o.s.s.s.RegisterDashboards] Register dashboards2017.06.15 06:04:07 INFO web[o.s.s.s.RegisterPermissionTemplates] Register permission templates2017.06.15 06:04:07 INFO web[o.s.s.s.RenameDeprecatedPropertyKeys] Rename deprecated property keys2017.06.15 06:04:07 INFO web[o.s.s.s.IndexSynchronizer] Index activities2017.06.15 06:04:08 INFO web[o.s.s.s.IndexSynchronizer] Index issues2017.06.15 06:04:08 INFO web[o.s.s.s.IndexSynchronizer] Index source lines2017.06.15 06:04:08 INFO web[o.s.s.s.IndexSynchronizer] Index users2017.06.15 06:04:08 INFO web[o.s.s.s.IndexSynchronizer] Index views2017.06.15 06:04:08 INFO web[jruby.rack] jruby 1.7.9 (ruby-1.8.7p370) 2013-12-06 87b108a on Java HotSpot(TM) 64-Bit Server VM 1.8.0_131-b11 [linux-amd64]2017.06.15 06:04:08 INFO web[jruby.rack] using a shared (threadsafe!) runtime2017.06.15 06:04:14 INFO web[jruby.rack] keeping custom (config.logger) Rails logger instance2017.06.15 06:04:14 INFO web[o.a.c.h.Http11NioProtocol] Starting ProtocolHandler [http-nio-0.0.0.0-9000]2017.06.15 06:04:14 INFO web[o.s.s.a.TomcatAccessLog] Web server is started2017.06.15 06:04:14 INFO web[o.s.s.a.EmbeddedTomcat] HTTP connector enabled on port 90002017.06.15 06:04:15 INFO app[o.s.p.m.Monitor] Process[web] is upre",Not-TD-related,SonarQube,,,,0.055,0.921,0.023,-0.9831
44649649,How to retrieve SonarQube metrics of previous build versions through the api?,"How do I get the measures (like code-coverage, technical debt, complexity, nloc, ...) of a certain build version (eg. 1.0.0.20) from the api of SonarQube?My goal is to get these information and display it along with some-other info pertaining to that version got from other sources like bitbucket.I am able to only see the measures of the current (latest) build (eg. 1.0.0.45) version through the codeapi/measure/component api link.Although, I can see these measures for individual builds through the UI under the compare option. But how to get it through rest api?SonarQube Version 5.5Plugins:ullisonar-scoverage-plugin-5.1.3.jarlisonar-scm-git-plugin-1.2.jarlisonar-scalastyle-plugin-0.0.1-SNAPSHOT.jarlisonar-javascript-plugin-2.11.jar",Not-TD-related,SonarQube,,,,0.019,0.941,0.04,0.2287
44848135,Trouble connecting to my database with entity framework c web api,"I have a LogContext Model : using System.Data.Entity;namespace Logging.Models{ public class LogContext : DbContext { // You can add custom code to this file. Changes will not be overwritten. // // If you want Entity Framework to drop and regenerate your database // automatically whenever you change your model schema, add the following // code to the Application_Start method in your Global.asax file. // Note: this will destroy and re-create your database with every model change. // // System.Data.Entity.Database.SetInitializer(new System.Data.Entity.DropCreateDatabaseIfModelChanges  Logging.Models.ProductContext  ()); public LogContext() : base(name=LogContext) { Database.SetInitializer  LogContext  (null); } public DbSet  Log   Logs { get; set; } }}rebut when I try to reference the Logs in my other LogContext class under App_code I'm getting an error trying to reference the context.Logs.Load();cannot be accessed with an instance reference; qualify it with a type nameHow do I reference and render all the rows in my table? What am i doing wrong? Thanks using System;using System.Collections.Generic;using System.Linq;using Logging.Controllers;using Logging.Models;namespace Logging{ public class LogContext : IDisposable { private static readonly List  Log   Logs = new List  Log  (); static LogContext() { using (var context = new LogContext()) { **context.Logs.Load();** } //Logs.Add(new Log() { Id = 1, LoggerName = TESTSYS1, InnerException = InnerException, LogText = LogText, ThreadID = 1, StackTrace = Stack Trace, eLevel = INFO }); //Logs.Add(new Log() { Id = 2, LoggerName = TESTSYS2, InnerException = InnerException, LogText = LogText, ThreadID = 2, StackTrace = Stack Trace, eLevel = ERROR }); //Logs.Add(new Log() { Id = 3, LoggerName = TESTSYS3, InnerException = InnerException, LogText = LogText, ThreadID = 3, StackTrace = Stack Trace, eLevel = WARN }); } void IDisposable.Dispose() { } public void GetLoggies() { using (var context = new LogContext()) { foreach (var log in context.GetLogs()) { Logs.Add(log); } } } public Log GetLog(int id) { var log = Logs.Find(p =   p.Id == id); return log; } public IEnumerable  Log   GetLogs() { return LogContext.Logs; } public Log AddLog(Log p) { Logs.Add(p); return p; } public void Delete(int id) { var product = Logs.FirstOrDefault(p =   p.Id == id); if (product != null) { Logs.Remove(product); } } public bool Update(int id, Log log) { Log rLog = Logs.FirstOrDefault(p =   p.Id == id); if (rLog != null) { rLog = log; return true; } return false; } }}re",Not-TD-related,SonarQube,,,,0.057,0.921,0.022,-0.8981
45158713,Is there any way to reference column with different datatype?,"I have 2 schemas/tables as shown:
CREATE TABLE schema1.code_tbl ( code CHAR(6) PRIMARY KEY,
description CHAR(30)
);
CREATE TABLE schema2.record_tbl
( rec_id VARCHAR(10) PRIMARY KEY,
curr_code VARCHAR(6),
remarks VARCHAR(30)
);
I need to create a foreign key reference from curr_code in RECORD_TBL to code in CODE_TBL.
ALTER TABLE schema2.record_tbl
ADD CONSTRAINT record_code_fk
FOREIGN KEY (curr_code)
REFERENCES schema1.code_tbl (code);
This obviously gives me an ORA-02267 (column type incompatible with referenced column) error.
I cannot alter the code column in CODE_TBL because I do not own or control schema1. I cannot alter the curr_code column in RECORD_TBL because it would break many functions in my application because we don't account for trailing whitespaces.
Is there any other way to enforce referential integrity between the 2 columns?",Not-TD-related,SonarQube,,,,0.022,0.893,0.085,0.7695
45273199,How to resolve technical debts in sonaQube?,I've technical debt for my java project i need to resolve them in sonarQube. can somebody guide me how to solve those technical debts.,Not-TD-related,SonarQube,,,,0.093,0.743,0.164,0.2263
45659839,Java Plug-in is not supported by this browser on Apache Pivot web-site,"21st century.Apache Pivot web site.Latest release July 04, 2017, Pivot 2.0.5 Demos page: a href=https:/ivot.apache.org/demos/ rel=nofollow noreferrerhttps:/ivot.apache.org/demos//aClicking any demo causes the following banner appear:a href=https://i.stack.imgur.com/9c9BQ.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/9c9BQ.png alt=enter image description here/aI tried in Chrome, Firefox and Opera.If click codeMore info it passes you to java download page: a href=https://java.com/en/download/win10.jsp rel=nofollow noreferrerhttps://java.com/en/download/win10.jsp/aHow to fix? I don't want to download and install latest JRE. I have JDK/JRE version installed and satisfied by it. I want it to run.",Not-TD-related,SonarQube,,,,0.033,0.929,0.038,0.3304
46723315,Should I use Laravel or other PHP MVC framework for single page application?,"What is the benefits of using Laravel or other PHP MVC framework for single page application?I used to work with Laravel but now I only need a single page application, should I use laravel for it or any other MVC framework, or any kind of SPA framework? Or should I go with a bunch of homemade php scripts instead?P.S.The single-page-app is going to be a big one.",Not-TD-related,SonarQube,,,,0,0.962,0.038,0.327
46793504,How to drill down into Sonarqube coverage reports and see changes in coverage and specific files responsible,"We like the ability we have with sonarqube to see in detail the changes in source code that are impacting our KPIs, for example using a project's technical debt tab in version 5.3 we can see in RED the added issues for example, click on these numbers and see the underlying files responsible for the change.What we are missing is the same exact feature for COVERAGE KPIs, currently we are not given the option to click on a delta in the coverage tab and see files and associated changes, is it something available but we are not seeing ? is this sth coming soon? We also have version 5.6 and I did not find the option in there as well.",Not-TD-related,SonarQube,,,,0.028,0.906,0.066,0.5733
46831806,SonarQube: Result not displayed,"Have just started to use SonarQube for a university project. I have successfully analysed some sample projects (a href=https://github.com/SonarSource/sonar-scanning-examples rel=nofollow noreferrerhttps://github.com/SonarSource/sonar-scanning-examples/a). When I enter a href=http://localhost:9000 rel=nofollow noreferrerhttp://localhost:9000/a in my browser I can see the results perfectly.However when I try to run the scan on the maven project a href=https://www.openmrs.org rel=nofollow noreferrerhttps://www.openmrs.org/a, the scanner seems to run successfully, but I can see no results in the browser.This is the progress log: D:\openmrs-core  mvn sonar:sonar[INFO] Scanning for projects...[INFO] ------------------------------------------------------------------------[INFO] Reactor Build Order:[INFO][INFO] OpenMRS[INFO] openmrs-tools[INFO] openmrs-test[INFO] openmrs-api[INFO] openmrs-web[INFO] openmrs-webapp[WARNING] The POM for org.eclipse.m2e:lifecycle-mapping:jar:1.0.0 is missing, no dependency information available[WARNING] Failed to retrieve plugin descriptor for org.eclipse.m2e:lifecycle-mapping:1.0.0: Plugin org.eclipse.m2e:lifecycle-mapping:1.0.0 or one of its dependencies could not be resolved: Failure to find org.eclipse.m2e:lifecycle-mapping:jar:1.0.0 in http://mavenrepo.openmrs.org/nexus/content/repositoriesublic was cached in the local repository, resolution will not be reattempted until the update interval of openmrs-repo has elapsed or updates are forced[INFO][INFO] ------------------------------------------------------------------------[INFO] Building OpenMRS 2.2.0-SNAPSHOT[INFO] ------------------------------------------------------------------------[WARNING] The POM for org.eclipse.m2e:lifecycle-mapping:jar:1.0.0 is missing, no dependency information available[WARNING] Failed to retrieve plugin descriptor for org.eclipse.m2e:lifecycle-mapping:1.0.0: Plugin org.eclipse.m2e:lifecycle-mapping:1.0.0 or one of its dependencies could not be resolved: Failure to find org.eclipse.m2e:lifecycle-mapping:jar:1.0.0 in http://mavenrepo.openmrs.org/nexus/content/repositoriesublic was cached in the local repository, resolution will not be reattempted until the update interval of openmrs-repo has elapsed or updates are forced[INFO][INFO] --- sonar-maven-plugin:4.5.4:sonar (default-cli) @ openmrs ---INFO: Default locale: en_GB, source code encoding: UTF-8INFO: Work directory: D:\openmrs-core\target\sonarINFO: SonarQube Server 4.5.4[INFO] [14:41:24.624] Load global referentials...[INFO] [14:41:25.711] Load global referentials done: 1092 ms[INFO] [14:41:25.712] Incremental mode[INFO] [14:41:25.730] User cache: C:\Users\ALI\.sonar\cache[INFO] [14:41:25.745] Install plugins[INFO] [14:41:25.920] Include plugins: buildbreaker[INFO] [14:41:25.920] Exclude plugins: devcockpit, buildstability, pdfreport, report, buildbreaker, scmactivity, views, jira[INFO] [14:42:21.436] Create JDBC datasource for jdbc::D:\openmrs-core\target\sonar\.sonartmp\preview1508416887090-0[INFO] [14:42:22.792] Initializing Hibernate[INFO] [14:42:24.835] Load project referentials...[INFO] [14:42:28.280] Load project referentials done: 3445 ms[INFO] [14:42:28.282] Load project settings[INFO] [14:42:28.607] Loading technical debt model...[INFO] [14:42:28.675] Loading technical debt model done: 68 ms[INFO] [14:42:28.683] Apply project exclusions[INFO] [14:42:29.194] ------------- Scan openmrs-tools[INFO] [14:42:29.198] Load module settings[INFO] [14:42:29.831] Loading rules...[INFO] [14:42:30.027] Loading rules done: 196 ms[INFO] [14:42:30.075] Configure Maven plugins[INFO] [14:42:30.257] Compare to previous analysis (2017-10-18)[INFO] [14:42:30.272] Compare over 30 days (2017-09-19, analysis of 2017-09-22 10:38:19.0)[INFO] [14:42:30.282] Compare to previous version (2017-03-03)[INFO] [14:42:30.471] Loaded quality gate 'OpenMRS Gate'[INFO] [14:42:30.655] Initializer FindbugsMavenInitializer...[INFO] [14:42:30.655] Initializer FindbugsMavenInitializer done: 0 ms[INFO] [14:42:30.656] Base dir: D:\openmrs-core\tools[INFO] [14:42:30.656] Working dir: D:\openmrs-core\tools\target\sonar[INFO] [14:42:30.657] Source paths: src/main/java[INFO] [14:42:30.657] Binary dirs: target/classes[INFO] [14:42:30.657] Source encoding: UTF-8, default locale: en_GB[INFO] [14:42:30.658] Index files[INFO] [14:42:30.733] 0 files indexed[INFO] [14:42:30.757] Sensor QProfileSensor...[INFO] [14:42:30.778] Sensor QProfileSensor done: 20 ms[INFO] [14:42:30.780] Sensor InitialOpenIssuesSensor...[INFO] [14:42:30.924] Sensor InitialOpenIssuesSensor done: 144 ms[INFO] [14:42:30.925] Sensor ProjectLinksSensor...[INFO] [14:42:30.944] Sensor ProjectLinksSensor done: 19 ms[INFO] [14:42:30.946] Sensor Maven dependencies...[INFO] [14:42:30.985] Sensor Maven dependencies done: 39 ms[INFO] [14:42:30.986] Sensor CPD Sensor (wrapped)...[INFO] [14:42:30.986] Sensor CPD Sensor (wrapped) done: 0 ms[INFO] [14:42:31.283] Execute decorators...[INFO] [14:42:31.396] ------------- Scan openmrs-test[INFO] [14:42:31.398] Load module settings[INFO] [14:42:31.443] Configure Maven plugins[INFO] [14:42:31.444] Compare to previous analysis (2017-10-18)[INFO] [14:42:31.445] Compare over 30 days (2017-09-19, analysis of 2017-09-22 10:38:19.0)[INFO] [14:42:31.446] Compare to previous version (2017-03-03)[INFO] [14:42:32.342] Loaded quality gate 'OpenMRS Gate'[INFO] [14:42:32.383] Initializer FindbugsMavenInitializer...[INFO] [14:42:32.385] Initializer FindbugsMavenInitializer done: 2 ms[INFO] [14:42:32.385] Base dir: D:\openmrs-core\test[INFO] [14:42:32.385] Working dir: D:\openmrs-core\test\target\sonar[INFO] [14:42:32.386] Binary dirs: target/classes[INFO] [14:42:32.386] Source encoding: UTF-8, default locale: en_GB[INFO] [14:42:32.386] Index files[INFO] [14:42:32.388] 0 files indexed[INFO] [14:42:32.394] Sensor QProfileSensor...[INFO] [14:42:32.396] Sensor QProfileSensor done: 2 ms[INFO] [14:42:32.396] Sensor InitialOpenIssuesSensor...[INFO] [14:42:32.447] Sensor InitialOpenIssuesSensor done: 51 ms[INFO] [14:42:32.449] Sensor ProjectLinksSensor...[INFO] [14:42:32.461] Sensor ProjectLinksSensor done: 12 ms[INFO] [14:42:32.461] Sensor Maven dependencies...[INFO] [14:42:32.776] Sensor Maven dependencies done: 315 ms[INFO] [14:42:32.776] Sensor CPD Sensor (wrapped)...[INFO] [14:42:32.777] Sensor CPD Sensor (wrapped) done: 1 ms[INFO] [14:42:32.867] Execute decorators...[INFO] [14:42:32.888] ------------- Scan openmrs-api[INFO] [14:42:32.890] Load module settings[INFO] [14:42:32.923] Configure Maven plugins[INFO] [14:42:32.924] Compare to previous analysis (2017-10-18)[INFO] [14:42:32.925] Compare over 30 days (2017-09-19, analysis of 2017-09-22 10:38:19.0)[INFO] [14:42:32.925] Compare to previous version (2017-03-03)[INFO] [14:42:33.146] Loaded quality gate 'OpenMRS Gate'[INFO] [14:42:33.183] Initializer FindbugsMavenInitializer...[INFO] [14:42:33.183] Initializer FindbugsMavenInitializer done: 0 ms[INFO] [14:42:33.184] Base dir: D:\openmrs-core\api[INFO] [14:42:33.184] Working dir: D:\openmrs-core\api\target\sonar[INFO] [14:42:33.185] Source paths: src/main/java[INFO] [14:42:33.185] Test paths: src/test/java[INFO] [14:42:33.186] Binary dirs: target/classes[INFO] [14:42:33.186] Source encoding: UTF-8, default locale: en_GB[INFO] [14:42:33.186] Index files[INFO] [14:42:33.186] Excluded sources:[INFO] [14:42:33.186] src/main/java/org/openmrs/arden/**/*[INFO] [14:42:33.732] 0 files indexed[INFO] [14:42:33.737] Sensor QProfileSensor...[INFO] [14:42:33.737] Sensor QProfileSensor done: 0 ms[INFO] [14:42:33.737] Sensor InitialOpenIssuesSensor...[INFO] [14:42:34.293] Sensor InitialOpenIssuesSensor done: 556 ms[INFO] [14:42:34.294] Sensor ProjectLinksSensor...[INFO] [14:42:34.301] Sensor ProjectLinksSensor done: 7 ms[INFO] [14:42:34.305] Sensor Maven dependencies...[INFO] [14:42:35.656] Sensor Maven dependencies done: 1351 ms[INFO] [14:42:35.658] Sensor CPD Sensor (wrapped)...[INFO] [14:42:35.658] Sensor CPD Sensor (wrapped) done: 0 ms[INFO] [14:42:35.727] Execute decorators...[INFO] [14:42:36.202] ------------- Scan openmrs-web[INFO] [14:42:36.203] Load module settings[INFO] [14:42:36.235] Configure Maven plugins[INFO] [14:42:36.237] Compare to previous analysis (2017-10-18)[INFO] [14:42:36.238] Compare over 30 days (2017-09-19, analysis of 2017-09-22 10:38:19.0)[INFO] [14:42:36.239] Compare to previous version (2017-03-03)[INFO] [14:42:36.415] Loaded quality gate 'OpenMRS Gate'[INFO] [14:42:36.445] Initializer FindbugsMavenInitializer...[INFO] [14:42:36.446] Initializer FindbugsMavenInitializer done: 1 ms[INFO] [14:42:36.446] Base dir: D:\openmrs-core\web[INFO] [14:42:36.446] Working dir: D:\openmrs-core\web\target\sonar[INFO] [14:42:36.447] Source paths: src/main/java[INFO] [14:42:36.448] Test paths: src/test/java[INFO] [14:42:36.448] Binary dirs: target/classes[INFO] [14:42:36.448] Source encoding: UTF-8, default locale: en_GB[INFO] [14:42:36.448] Index files[INFO] [14:42:36.488] 0 files indexed[INFO] [14:42:36.491] Sensor QProfileSensor...[INFO] [14:42:36.492] Sensor QProfileSensor done: 1 ms[INFO] [14:42:36.492] Sensor InitialOpenIssuesSensor...[INFO] [14:42:36.559] Sensor InitialOpenIssuesSensor done: 67 ms[INFO] [14:42:36.560] Sensor ProjectLinksSensor...[INFO] [14:42:36.570] Sensor ProjectLinksSensor done: 10 ms[INFO] [14:42:36.570] Sensor Maven dependencies...[INFO] [14:42:38.222] Sensor Maven dependencies done: 1652 ms[INFO] [14:42:38.224] Sensor CPD Sensor (wrapped)...[INFO] [14:42:38.224] Sensor CPD Sensor (wrapped) done: 0 ms[INFO] [14:42:38.304] Execute decorators...[INFO] [14:42:38.339] ------------- Scan openmrs-webapp[INFO] [14:42:38.341] Load module settings[INFO] [14:42:38.367] Configure Maven plugins[INFO] [14:42:38.368] Compare to previous analysis (2017-10-18)[INFO] [14:42:38.369] Compare over 30 days (2017-09-19, analysis of 2017-09-22 10:38:19.0)[INFO] [14:42:38.370] Compare to previous version (2017-03-03)[INFO] [14:42:38.811] Loaded quality gate 'OpenMRS Gate'[INFO] [14:42:38.838] Initializer FindbugsMavenInitializer...[INFO] [14:42:38.839] Initializer FindbugsMavenInitializer done: 1 ms[INFO] [14:42:38.839] Base dir: D:\openmrs-core\webapp[INFO] [14:42:38.839] Working dir: D:\openmrs-core\webapp\target\sonar[INFO] [14:42:38.841] Test paths: src/test/java[INFO] [14:42:38.841] Binary dirs: target/classes[INFO] [14:42:38.841] Source encoding: UTF-8, default locale: en_GB[INFO] [14:42:38.841] Index files[INFO] [14:42:38.845] 0 files indexed[INFO] [14:42:38.847] Sensor QProfileSensor...[INFO] [14:42:38.848] Sensor QProfileSensor done: 1 ms[INFO] [14:42:38.849] Sensor InitialOpenIssuesSensor...[INFO] [14:42:38.867] Sensor InitialOpenIssuesSensor done: 18 ms[INFO] [14:42:38.868] Sensor ProjectLinksSensor...[INFO] [14:42:38.879] Sensor ProjectLinksSensor done: 11 ms[INFO] [14:42:38.880] Sensor Maven dependencies...[INFO] [14:42:39.158] Sensor Maven dependencies done: 278 ms[INFO] [14:42:39.159] Sensor CPD Sensor (wrapped)...[INFO] [14:42:39.160] Sensor CPD Sensor (wrapped) done: 1 ms[INFO] [14:42:39.221] Execute decorators...[INFO] [14:42:39.233] ------------- Scan OpenMRS[INFO] [14:42:39.235] Load module settings[INFO] [14:42:39.259] Configure Maven plugins[INFO] [14:42:39.264] Compare to previous analysis (2017-10-18)[INFO] [14:42:39.274] Compare over 30 days (2017-09-19, analysis of 2017-09-22 10:38:19.0)[INFO] [14:42:39.275] Compare to previous version (2017-03-03)[INFO] [14:42:39.865] Loaded quality gate 'OpenMRS Gate'[INFO] [14:42:39.896] Initializer FindbugsMavenInitializer...[INFO] [14:42:39.896] Initializer FindbugsMavenInitializer done: 0 ms[INFO] [14:42:39.897] Base dir: D:\openmrs-core[INFO] [14:42:39.897] Working dir: D:\openmrs-core\target\sonar[INFO] [14:42:39.897] Binary dirs: target/classes[INFO] [14:42:39.897] Source encoding: UTF-8, default locale: en_GB[INFO] [14:42:39.899] Sensor InitialOpenIssuesSensor...[INFO] [14:42:39.920] Sensor InitialOpenIssuesSensor done: 21 ms[INFO] [14:42:39.922] Sensor ProjectLinksSensor...[INFO] [14:42:39.930] Sensor ProjectLinksSensor done: 8 ms[INFO] [14:42:39.930] Sensor Maven dependencies...[INFO] [14:42:39.931] Sensor Maven dependencies done: 1 ms[INFO] [14:42:39.931] Sensor CPD Sensor (wrapped)...[INFO] [14:42:39.931] Sensor CPD Sensor (wrapped) done: 0 ms[INFO] [14:42:39.991] Execute decorators...[INFO] [14:42:40.074] Export results to D:\openmrs-core\target\sonar\sonar-report.json[INFO] [14:42:40.271] Store results in database[INFO] [14:42:40.385] ANALYSIS SUCCESSFUL[INFO] [14:42:40.387] Executing post-job class org.sonar.issuesreport.ReportJob[INFO] [14:42:40.865] Light HTML Issues Report generated: D:\openmrs-core\target\sonar\issues-report\issues-report-light.html[INFO] [14:42:40.960]------------- Issues Report ------------- No new issue-------------------------------------------[INFO] [14:42:40.962] Executing post-job class org.sonar.plugins.buildbreaker.AlertBreaker[INFO] [14:42:40.963] Executing post-job class org.sonar.plugins.buildbreaker.ForbiddenConfigurationBreaker[INFO] ------------------------------------------------------------------------[INFO] Reactor Summary:[INFO][INFO] OpenMRS ............................................ SUCCESS [01:22 min][INFO] openmrs-tools ...................................... SKIPPED[INFO] openmrs-test ....................................... SKIPPED[INFO] openmrs-api ........................................ SKIPPED[INFO] openmrs-web ........................................ SKIPPED[INFO] openmrs-webapp ..................................... SKIPPED[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 01:25 min[INFO] Finished at: 2017-10-19T14:42:41+02:00[INFO] Final Memory: 34M/465M[INFO] ------------------------------------------------------------------------reAny help appreciated, thank you.",Not-TD-related,SonarQube,,,,0.034,0.937,0.029,-0.4851
47128712,How to get last n number of elements from an array an element of that array,"I'm working with angular4 and I've been having a lot of trouble trying to display some elements of an array in my view.I got this a href=https://i.stack.imgur.com/JzKWL.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/JzKWL.png alt=enter image description here/athe number of elements can change according to the current month so if it was February it would be only M01 and M02 in the array.I've been trying to loop it in for loop but I can't seem to get it right.any ideas on how to do it?I'd like to get something like this, all values that start with M in a single property [0: M: [...] cod_item:... cod_condominio:......]reit doesn't matter if it is an array or object as long as i can loop that element to show it in my view.",Not-TD-related,SonarQube,,,,0.023,0.889,0.088,0.8496
47875679,How to send all current params to path?,"I've got a form that has the option to export to a spreadsheet, but I need the spreadsheet to have the same current params(Filters) as the report in my page. Something like this:<a href=""<%= reports_orders_path(params, format: 'xlsx') %>""><span><i class=""fa fa-file-excel-o""></i></span><%= t '.export_xlsx' %></a>I've managed to do so like this:<a href=""<%= reports_orders_path(""by_event"" => @event.id.to_s, ""by_document"" => params[:by_document],""by_status"" => params[:by_status],""by_method"" => params[:by_method], ""by_date"" => params[:by_date], ""by_period_init"" => params[:by_period_init],""by_period_end"" => params[:by_period_end],format: 'xlsx') %>""><span ><i class=""fa fa-file-excel-o""></i></span><%= t '.export_xlsx' %></a>But this feels and looks so messy.Is there a nicer way to get all current params and apply them to my path?",Not-TD-related,SonarQube,,,,0.037,0.875,0.088,0.7174
47925590,Technical debt ratio on new code always appear 0%,"I have a problem related Tech Debt ratio on new code .when i introduce new code smells , I can see that Debt increased on the new code however the debt ratio always shown as 0 .I have tried changing development code (10 ,15,20) but still i am seeing same issue .Did i missed any configurationSonarQube version : 5.6.6   6.7 also .a href=https://i.stack.imgur.com/r3ImM.png rel=nofollow noreferrerimg src=https://i.stack.imgur.com/r3ImM.png alt=enter image description here/a",Not-TD-related,SonarQube,,,,0.149,0.828,0.023,-0.7469
48023224,Using OpenCover coverage data with NDepend?,"My project uses OpenCover to analyse unit test coverage.We've recently started using NDepend to improve the project. We're getting a lot out of it, but are stumped by one feature...NDepend has functionality to incorporate data on code coverage into it's overall reports on technical debt. Unfortunately, a href=https://www.ndepend.com/docs-coverageTechno rel=nofollow noreferrerit can only consume reports from the following tools/a:block e NDepend can import coverage data from: ul liNCover 3.x and above coverage files liVisual Studio 2017, 2015, 2013, 2012 and 2010 XML coverage files liJetBrains DotCover 1.1 and above XML coverage files (with special NDepend formatting) /block eThese are all commercial (i.e. paid-for) tools. As our project is open source, Open Cover (which itself is free as in beer as well as speech) suits our budget much better.Is there any way to convert OpenCover reports into the format of one of the aforementioned tools? Or, is there some other way to squeeze data from OpenCover into NDepend?",Not-TD-related,SonarQube,,,,0.038,0.884,0.078,0.7657
48495165,string returned from function refer to local object address,"I have worked on technical debts and found the below issue, maybe false positive for the below C++ code: string CXXXIXMLImp::GetString(U32 val){ char bufVal[64] = { 0 }; sprintf_s(bufVal, 63, %ld, val, 63); string strRetVal = bufVal; return strRetVal;}reblock e error: Address of a local variable is returned via return statement expression /block eNote: codestring in the above is codestd::stringI have modified code at line 5 with string assign function or using string::copy. Need suggestion for the same",Not-TD-related,SonarQube,,,,0.036,0.915,0.048,0.2263
48612607,Hiding an element on page load,"This question is a second part of a href=https://stackoverflow.com/questions/48531345/hide-show-a-table-row-when-clicking-on-a-link-in-angular2Hide/show a table row when clicking on a link in Angular2/abr/ I am displaying all products on the page, but I also have a select dropdown to just show the individual products details. Lets say in the first page( All Products page), I expanded the first product. And then I go to the dropdown and select a product, so it displays that products details along with the inner table expanded - but with the details of the product expanded in the first page. I need to click on the link to get the correct product details -bcoz we do the hide and show on (click) event. So my question is -Is there a way to always collapse the link when going to a new page? Adding the relevant code - html file div class=table-responsive *ngFor=let total of totals; let i=index    table class=table     ng-container *ngIf=total     h4 class=productName  Product: {{total.projectGroup}}  /h4     tr     th  Total LOC  /th     th  Total Test Coverage  /th     th  Total Coverage on New Code  /th     th  Total Technical Debt  /th     th  Total Issues  /th     /tr     tr     td  {{total.totalLOC}}  /td     td  {{total.totalCoverage}}    /td     td  {{total.totalNewCoverage}}  /td     td  {{total.totalTechDebtDays}}  /td     td    span *ngIf=total.totalCriticalIssues   = 0  Critical:   /span  {{total.totalCriticalIssues}}   br/     span *ngIf=total.totalNonCriticalIssues   = 0  Non-critical:   /span  {{total.totalNonCriticalIssues}}  /td     /tr     tr     td    a id={{i}} class =a_link (click)=toggle[i]=!toggle[i]; expand(total.projectGroup, i)   Expand/Collapse  /a    /td     /tr     tr *ngIf=toggle[i]     div class=table-responsive     table class=table width=100%     tr class=table-header     th  Project Key  /th     th  Quality Gate  /th     th  LOC  /th     th  Test Coverage  /th     th  Coverage on New Code  /th     th  Technical Debt  /th     th  Issues  /th     /tr     tr *ngFor=let pjt of indProjects[i] class=table-condensed     td  {{pjt.projectKey}}  /td     td  {{pjt.qualityGate}}  /td     td  {{pjt.loc}}  /td     td  {{pjt.coverage}}  /td     td  {{pjt.newCoverage}}  /td     td  {{pjt.techDebtDays}}  /td     td    span *ngIf=pjt.criticalIssues   = 0  Critical:   /span  {{pjt.criticalIssues}}   br/     span *ngIf=pjt.nonCriticalIssues   = 0  Non-critical:   /span  {{pjt.nonCriticalIssues}}  /td     /tr     /table     /div     /tr     /ng-container    /table  re And the component.ts file  expand(value, index) {console.log(Product to be expanded=+value); return this.service.expandProduct(value).subscribe(response =   this.indProjects[index] = response.json().data) re}",Not-TD-related,SonarQube,,,,0.06,0.94,0,-0.9586
49001189,SQALE plugin for sonar,"I was trying to add SQALE plugin for SonarQube. I was doing some research and there was a SonarSource blog (a href=https://blog.sonarsource.com/sqale-the-ultimate-quality-model-to-assess-technical-debt rel=nofollow noreferrerhttps://blog.sonarsource.com/sqale-the-ultimate-quality-model-to-assess-technical-debt/a) talks about a commercial SQALE plugin for Sonar, but the link to the plugin gives a 404.Is there any other documentation for SQALE plugin or is it something fully out from Sonar?, the official SQALE website still refers Sonar for implementation.",Not-TD-related,SonarQube,,,,0,1,0,0
49179522,How does sonarQube calculate technical debt,"In the new version of sonarqube, the documntation states that technical debt (TD) TD= Effort to fix all maintainability issues. The measure is stored in minutes in the DB. An 8-hour day is assumed when values are shown in days.reHowever, how does sonarqube measure maintainability issues?",Not-TD-related,SonarQube,,,,0.051,0.894,0.055,0.0516
49446411,Fragments deprecated in Android P,"I was looking at the documentation and found this
This class was deprecated in API level P.
Why are fragments deprecated in android P?",Not-TD-related,SonarQube,,,,0,1,0,0
49495967,Is it possible to mount Azure Data Lake Store or Azure Blob Storage as a drive on a Windows or Linux VM,"My task is to migrate our data store which is currently located on a network drive to Azure Data Lake Store or Blob Storage, as well as to migrate the ingestion and postprocessing software.If I can mount Azure Data Lake Store or Blob Storage as a drive, it would make my task much easier.",Not-TD-related,SonarQube,,,,0,0.909,0.091,0.5994
50213267,Scanning multi-language projects with SonarQube,"I'm trying to implement SonarQube (SonarCloud) to our development pipeline. We are using TFS (on-premise) and our project has just one repository. In this repository, we have two different applications, one .NET application, and one javascript application.The folder structure is like this: ||- NetProjectFolder|- JSProjectFolderreAnd our build definition (which is working with Pull Requests) steps are like this:olliSonarQube Scanner for MSBuild - Begin Analysis (for .NET project)liVisual Studio Build (build .NET project solution)liVisual Studio Test (tests of the .NET solution)liSonarQube Scanner CLI (To scan JS project)liSonarQuber Scanner for MSBuild - End AnalysisI was thinking that step 4 and step 5 will analyze our .NET and JS projects and at the end, I will see a full report of our all projects. But, when step 4 completed it's automatically uploading the report of JS project and when step 5 completed it's overwriting JS report, uploading the report of .NET project.In the end, there are only .NET project's report/warning / technical debt etc. Because step 5 overwriting step 4's result.How can I configure these steps so SOnarQube can analyze both our JS and .NET projects properly?",Not-TD-related,SonarQube,,,,0.018,0.962,0.02,-0.1901
50378523,Backdating issues after SonarQube upgrade,"We have migrated from SonarQube5.5 to SonarQube 6.7.2LTS.Upon the first analysis using the new version, projects started showing new issues based on overall rules improvements. While this is interesting, that makes the Quality Gate fail as part of our CI/CD pipelines.Looking at the following page:a href=https://blog.sonarsource.com/sonarqube-6-3-in-screenshots rel=nofollow noreferrerhttps://blog.sonarsource.com/sonarqube-6-3-in-screenshots/a... we can see that there is some kind of issue backdating overhead, which looks broken for that specific scenario.Any recommendation or workaround as for not making everything red for all projects. We still want to keep that technical debt visible and not necessarily hide it using Wont't fixes of False Positives.Thank you",Not-TD-related,SonarQube,,,,0.083,0.846,0.071,-0.5076
51853158,What is alternate for CreatePerOwinContext in .net core 2.1,"I had a webapi in which I was using app.CreatePerOwinContext in startup.cs file but I want to migrate that webapi to .net core 2.1. So I have stuck at this point as I can't fine any alternate for CreatePerOwinContext.Here is my webapi code:public static UserManager<IdentityUser> Create(IdentityFactoryOptions<UserManager<IdentityUser>> options, IOwinContext context){var manager = new UserManager<IdentityUser>(new UserStore());return manager;}public void ConfigureAuth(IAppBuilder app){app.CreatePerOwinContext<UserManager<IdentityUser>>(Create);...}So how can I convert the above code in .net core 2.1?",Not-TD-related,SonarQube,,,,0.067,0.913,0.02,-0.5196
53234954,Git:get changes released to master over time,"as a personal project, I'd like to check different python libraries and projects (be it proprietary or open source) and analyze how the code was changed over time in different releases to gather some info about the technical debt (mainly through static code analysis). I'm doing this using codegitpython library. However, I'm struggling to filter the merge commits to the codemaster. I filter the merge commits using codegit.log(--merges, --first-parent, master) from where I extract the commit hashes and filter these particular commits from all repository commits. As the second part, I'd like to get all changed files in each merge commit. I'm able to access the blobs via git tree, but I don't know how to get only changed files.Is there some efficient way how to accomplish this? Thanks!",Not-TD-related,SonarQube,,,,0.026,0.807,0.167,0.9383
53537025,Magento 1.7: Strict Notice warning after SUPEE-10975 security patch,"After installing SUPEE-10975 in Magento 1.7.0.2 I get this PHP notice:Strict Notice: Declaration of Mage_Core_Controller_Request_Http::getBaseUrl() should be compatible with that of Zend_Controller_Request_Http::getBaseUrl() in app/code/core/Mage/Core/Controller/Request/Http.php on line 36#0 app/code/core/Mage/Core/Controller/Request/Http.php(36): mageCoreErrorHandler(2048, 'Declaration of ...', '/kunden/12345_8...', 36, Array)#1 lib/Varien/Autoload.php(93): include('/kunden/12345_8...')#2 [internal function]: Varien_Autoload->autoload('Mage_Core_Contr...')#3 app/code/core/Mage/Core/Model/App.php(1219): spl_autoload_call('Mage_Core_Contr...')#4 app/code/core/Mage/Core/Model/Cookie.php(83): Mage_Core_Model_App->getRequest()#5 app/code/core/Mage/Core/Model/Cookie.php(273): Mage_Core_Model_Cookie->_getRequest()#6 app/code/core/Mage/Core/Model/App.php(568): Mage_Core_Model_Cookie->get()#7 app/code/core/Mage/Core/Model/App.php(488): Mage_Core_Model_App->_checkCookieStore('website')#8 app/code/core/Mage/Core/Model/App.php(349): Mage_Core_Model_App->_initCurrentStore('', 'store')#9 app/Mage.php(683): Mage_Core_Model_App->run(Array)#10 index.php(87): Mage::run('', 'store')#11 {main}It seems that the code is available twice in my installation:app/code/core/Zend/Controller/Request/Http.php => introduced with SUPEE-10975lib/Zend/Controller/Request/Http.php => available in the basic installation package of Magento 1.7.0.2Is this a regression of SUPEE-10975 or a problem of my installation?",Not-TD-related,SonarQube,,,,0.025,0.975,0,-0.4019
54261670,Why are absolute units with media queries the CSS industry standard?,"I have been programming professionally for 5 years now, and I recently was asked the question: If viewport values are so good at making responsive designs based on the device dimensions, why not just write CSS in viewport values, to begin with?My immediate answer was that it's much easier to write in pixels, as we all know what one pixel looks like, whereas one codeview-height or one codeview-width is kind of hard to visually picture when playing around with CSS.But it does make me wonder, why we don't intrinsically write in relative viewport values, instead of absolute pixel values. I know that media queries were made to make our lives easier, scaling the design based on the device, but that also means that you have to keep a whole separate set of code for each and every device you want to target, adding technical debt and development time.So why is this still an industry standard?",Not-TD-related,SonarQube,,,,0.028,0.848,0.124,0.8559
54587531,Multiple elements sharing the same positive tabindex value?,"I have multiple elements in my form , having tabindex as 1 for all....How should it behave?What should be the behaviour of Multiple elements sharing the same positive tabindex value...?",Not-TD-related,SonarQube,,,,0,0.787,0.213,0.7757
56498570,How to python import a specific variable from a file without getting undefined name error for other variables,"I'm trying to import a certain variable from file1 into file2. I import the variable I want, but then get an error because it doesn't recognize other objects in file1. Those objects are defined elsewhere, but I don't care about them in file2.I tried removing the other objects in file2, as a test, and it works fine. But I can't just remove that content, as other files need it.In file1.py:  var1 = 5 object1.member1 = 4 object1 class instantiation created elsewherereIn file2.py:  from file1 import var1 var2 = var1 + 6reError:  File file1.py, line 2, in   module   object1.member1 = 4 NameError: name object1 is not definedreI would expect from fileX import varX to only import the value of varX and not worry about the rest of fileX.Ideal result is: var2 = 11.",Not-TD-related,SonarQube,,,,0.054,0.841,0.105,0.5599
57242969,Carry over data without using for loop,"I have a vector of strings and a vector of person. vector  std::string   namesvector  Person   personsreEach Person object has a name field. Now I want to populate names vector from persons. Instead of using a for loop, any other way to do it?",Not-TD-related,SonarQube,,,,0,0.965,0.035,0.0772
312388,How did you adapt your unit tests to deal with changing requirements?,"I have a project where I've been using TDD and unit tests as software vises. In essence I translate the requirements into tests that verify that the code conforms to the requirements. I rarely have to go back and edit the unit tests, which rather is the point: only the real code should be modified. At the moment, there are 900 unit tests.Now some requirements have been changed by the gold-owners. Since the former requirements are so thorougly encoded in the existing unit tests, it seems that changing them to conform to the new requirements would be inviting disaster. How do you adapt your unit test suites to handle this kind of change?",TD-related,test,"td_resolution, software_methodology",2,113,0.036,0.944,0.02,-0.4215
385730,How do you deal with failing Unit Tests?,"I have a number of projects in a solution file that have unit tests written for them and I am wanting to set them up to be run by our continuous integration server. However, because many of the tests have been written poorly and have not been run regularly there are many that are failing.I don't have the time at the moment to fix all of the tests but I do believe there is value in having the existing tests run. What is the best way do deal with the failing Unit Tests?What I am currently doing is marking each failing test as Explicit and leaving a TODO comment.  [Test, Explicit] //TODO: Rewrite this test because it failsreIs there a better way of doing this? Or should I fix all the tests before including them in the tests that are run by the CIS?",TD-related,test,"self-admitted, debugging, warnings",2,144,0.058,0.837,0.105,0.7343
1681174,"Besides treat warnings as errors and fixing memory leaks, what other ideas should we implement as part of our coding standards?","First let me say, I am not a coder but I help manage a coding team. No one on the team has more than about 5 years experience, and most of them have only worked for this company.. So we are flying a bit blind, hence the question.We are trying to make our software more stable and are looking to implement some best practices and coding standards. Recently we started taking this very seriously as we determined that much of the instability in our product could be linked back to the fact that we allowed Warnings to go through without fixing when compiling. We also never bothered to take memory leaks seriously enough. In reading through this site we are now quickly fixing this problem with our team but it begs the question, what other practices can we implement team wide that will help us? Edit: We do fairly complex 2D/3D Graphics Software that is cross-platform Mac/Windows in C++.",TD-related,test,"coding_standards, warnings",4,159,0.134,0.785,0.081,-0.818
1891466,So.. I need to train the team on Unit Testing - could use C&C on lesson plan,"So - management is looking to do a push to move towards doing unit-testing in all the applications moving forward - and eventually get into full TDD/Continuous Integration/Automated build mode (I hope). At this point however we are just concerned about getting everyone developing apps moving forward using unit-testing. I'd like to just start with the basics.I won't lie - I'm by far no expert by any means in unit-testing, but I do have a good enough understanding to start the initiative with the basics, and allow us to grow togeather as a team. I'd really love to get some comments   critisism from all you experts on my plan of attack on this thing. It's a team of about 10 developers in a small shop, which makes for a great opportunity to move forward with agile development methodologies and best practices.First off - the team consists of mainly mid level developers with a couple of junior devs and one senior, all with minimal to no exposure to unit testing. The training will be a semi-monthly meeting for about 30-60 minutes each time (probably wind up running an hour long i'd guess, and maybe have them more often). We will continue these meetings until it makes sense to stop them to allow others to catch up with their own 'homework' and experience - but the push will always be on.Anyway - here is my lesson plan I have come up with. Well, the first two at least. Any advice from your experts out there on the actual content or structure of the lessons, etc, would be great. Comments   Critisism greatly appreciated. Thanks very much.I apologize if this is 'too much' to post in here or read through. I think this would be a great thread for SO users looking to get into unit testing in the first place as well. Perhaps you could just skip to the 'lesson plans' section - thanks again everyone.emCLIFF NOTES/em - I realize this post is incredibly long and ugly, so here is the cliff notes - Lesson 1 will be 'hello world unit tests' - Lesson 2 will be opening the solution to my most recent application, and showing how to apply each 'hello world' example in real life... Thanks so much everyone for the feedback you've given me so far.. just wantd to highlight the fact that lesson 2 emis/em going to have real life production unit tests in it, since many suggested I do that when it was my plan from the begining =)emUnit Testing Lesson Plan/emOverviewWhy unit test? Seems like a bunch of extra work - so why do it? Become the master of your own destiny. Most of our users do not do true UATs, and unfortunately tend to do their testing once in production. With unit-tests, we greatly decrease risk associated with this, especially when we create enough test data and take into account as many top level inputs as we possibly can. While not being a silver bullet that prevents all bugs  it is your first line of defense  a huge front line, comparable to that of the SB championship Giants. Unit-Testing enforces good design and architecture practices. It is the violent psychopath who maintains your code and knows where you live so to say. You simply cant write poor quality code that is well unit-tested How many times have you not refactored smelly code because you were too scared of breaking something? Automated testing remove this fear, makes refactoring much easier, in turn making code more readable and easier to maintain. Bottom line  maintenance becomes much easier and cheaper. The time spent writing unit tests might be costly now  but the time it saves you down the road has been proven time and time again to be far more valuable. This is the 1 reason to automate testing your code. It gives us confidence that allows us to take on more ambitious changes to systems that we might have otherwise had to reduce requirements on, or maybe even not take on at all.Terminology Review Unit testing - testing the lowest level, single unit of work. E.G.  test all possible code paths that a single function can flow through. Integration testing - testing how your units work together. E.g.  run a job (or series of function calls) that does a bunch of work, with known inputs - and then query the database at the end and assert the values are what you expect from those known inputs (instead of having to eye-ball a grid on a web page somewhere, e.g. doing a functional test).  Fakes  a fake is a type of object whose purpose is to use for your testing. It allows you too easily emnot/em test code that you do not want to test. Instead of having to call code that you do not want  like a database call  you use a fake object to fake that DB call and perhaps read the data from an XML/Excel file or a mocking framework.o Mock  a type of fake to which you make assert statements against. o Stub  a type of fake to which you use as placeholder code, so you can skip the database call, but do not make asserts againstemLessons/emLesson one  Hello Worlds Hello World unit test - I will create a hello world console application that is unit tested. Will create this application on the fly during the meeting, showing the tools in Visual Studio 2008 (test-project, test tools toolbar, etc.) that we are going to use along the way while explaining what they do. This will have only a single unit-test. (OK, maybe I wont create it on the fly =), have to think about it more). Will also explain the Assert class and its purpose and the general flow of a unit-test. Hello World, a bit more complicated. Now our function has different paths/logical branches the code can flow through. We will have ~3 unit tests for this function. This will be a pre-written solution I make before the meeting. Hello World, dependency injection. (Not using any DI frameworks). A pre-written solution that builds off the previous one, this time using dependency injection. Will explain what DI is and show a sample of how it works. Hello World, Mock Objects. A pre-written solution that builds off the previous one, this time using our newly added DI code to inject a mock object into our class to show how mocking works. Will use NMock2.0 as this is the only one I have exposure to. Very simple example to just display the use of mock objects. (Perhaps put this one in a separate lesson?). Hello World, (non-automated) Integration Test. Building off the previous solution, we create an integration test so show how to test 2 functions together, or entire class together (perhaps put this one in a separate lesson?)Lesson two  now we know the basics  how to apply this in real life? General overview of best practices o Rule 1- Single Responsibility Principal. Single Responsibility Principal. Single Responsibility Principal. Facetiously stating that this is the single most important thing to keep in mind while writing your code. A class should have only one purpose; a function should do only one thing. The key word here is unit test  and the SRP will keep your classes   functions encapsulated into units.o Dependency Injection is your second best friend. DI allows you to plug behavior into classes you have, at run time. Among other things, this is how we use mocking frameworks to make our bigger classes more easily testable.o Always think how will I test this as you are writing code. If it seems too hard to test, it is likely that your code is too complicated. Re-factor until it into more logical units of classes/functions - take that one class that does 5 things and turn it into 5 classes, one which calls the other 4. Now your code will be much easier to test  and also easier to read and refactor as well.o Test embehavior/em, not implementation. In nutshell, this means that we can for the most part test only the Public functions on our classes. We dont care about testing the private ones (implementation), because the public ones (behavior) are what our calling code uses. For example... Im a millionaire software developer and go to the Aston Martin dealership to buy myself a brand new DB9. The sales guy tells me that it can do 0-60 in 3 seconds. How would you test this? Would you lift the engine out and perform diagnostics tests, etc..? No... You would take it onto the parkway and do 160 MPH =). This is testing behavior vs. implementation. Reviewing a real life unit-tested application. Here we will go over each of the above hello world examples  but the real life versions, using my most recent project as an example. I'll open a simple unit test, a more complex one, one that uses DI, and one that uses Mocks (probably coupled to the DI one). This project is fairly small   simple so it is really a perfect fit. This will also include testing the DAL and how to setup a test database to run these tests against.",TD-related,test,"software_methodology, missing_tests, automation, complex_testing",3,1554,0.061,0.819,0.12,0.9986
1915124,Should code coverage be used as a Milestone that can block a project's progression?,I am a development manager on a project with a painfully low unit test code coverage and we are definately feeling the weight of the techincal debt in the legacy code in our system.My question is if anyone uses code coverage as a milestone or development threshold that prevents the project from moving to the next sprint until the code coverage reaches a specific level? What is the best practice for using the code coverage metric?,TD-related,test,"coverage, management",3,76,0.101,0.792,0.108,-0.2869
2143368,"Given a short (2-week) sprint, is it ever acceptable to forgo TDD to get things done?","Given a short sprint, is it ever acceptable to forgo TDD to get things done within the sprint.For example a given piece of work might need say 1/3 of the sprint to design the object model around an existing implementation. Under this scenario you might well end up with implemented code, say half way through the sprint, without any tests (implementing unit tests during this design stage would add significant effort and the tests would likely be thrown away a few times until the final design is settled upon).You might then spend a day or two in the second week adding in unit / integration tests after the fact.Is this acceptable?",TD-related,test,"software_methodology, missing_tests",4,111,0,0.923,0.077,0.7579
2748162,How should developers cope with so many GUI configuration combinations?,"These days, any decent Windows desktop application must perform well and look good under the following conditions:olliXP and Vista and Windows 7.li32 bit and 64 bit.liWith and without Themes.liWith and without Aero.liAt 96 and 120 and perhaps custom DPIs.liOne or more monitors (screens).liEach OS has its own preferred font.Oh my! What is a lowly little Windows desktop application developer to do? :(I'm hoping to get a thread started with suggestions on how to deal with this GUI dilemma.First off, I'm on Delphi 7.bra) Does Delphi 2010 bring anything new to the table to help with this situation?brb) Should we pick an aftermarket component suite and rely on them to solve all these problems?brc) Should we go with an aftermarket skinning engine?brd) Perhaps a more HTML-type GUI is the way to go. Can we make a relatively complex GUI app with HTML that doesn't require using a browser? (prefer to keep it form based)bre) Should we just knuckle down and code through each one of these scenarios and quit bitching about it?brf) And finally, how in the world are we supposed to test all these conditions?",TD-related,test,complex_testing,5,185,0.022,0.907,0.071,0.8574
3476054,"Can unit testing be successfully added into an existing production project? If so, how and is it worth it?","I'm ly considering adding unit testing to an existing project that is in production. It was started 18 months ago before I could really see any benefit of TDD (face palm), so now it's a rather large solution with a number of projects and I haven't the foggiest idea where to start in adding unit tests. What's making me consider this is that occasionally an old bug seems to resurface, or a bug is checked in as fixed without really being fixed. Unit testing would reduce or prevents these issues occuring.By reading similar questions on SO, I've seen recommendations such as starting at the bug tracker and writing a test case for each bug to prevent regression. However, I'm concerned that I'll end up missing the big picture and end up missing fundamental tests that would have been included if I'd used TDD from the get go.Are there any process/steps that should be adhered to in order to ensure that an existing solutions is properly unit tested and not just bodged in? How can I ensure that the tests are of a good quality and aren't just a case of any test is better than no tests.So I guess what I'm also asking is;Is it worth the effort for an existing solution that's in production?Would it better to ignore the testing for this project and add it in a possible future re-write?What will be more benefical; spending a few weeks adding tests or a few weeks adding functionality?
(Obviously the answer to the third point is entirely dependant on whether you're speaking to management or a developer)Reason for BountyAdding a bounty to try and attract a broader range of answers that not only confirm my existing suspicion that it is a good thing to do, but also some good reasons against.I'm aiming to write this question up later with pros and cons to try and show management that it's worth spending the man hours on moving the future development of the product to TDD. I want to approach this challenge and develop my reasoning without my own biased point of view.",TD-related,test,"software_methodology, missing_tests",4,350,0.024,0.865,0.111,0.9685
3663075,Speeding up RSpec tests in a large Rails application,"I have a Rails application with over 2,000 examples in my RSpec tests. Needless to say, it's a large application and there's a lot to be tested. Running these tests at this point is very inefficient and because it takes so long, we're almost at the point of being discouraged from writing them before pushing a new build. I added --profile to my spec.opts to find the longest running examples and there are at least 10 of them that take an average of 10 seconds to run. Is that normal amongst you RSpec experts? Is 10 seconds entirely too long for one example? I realize that with 2,000 examples, it will take a non-trivial amount of time to test everything thoroughly - but at this point 4 hours is a bit ludicrous.What kind of times are you seeing for your longest running examples? What can I do to troubleshoot my existing specs in order to figure out bottlenecks and help speed things up. Every minute would really help at this point.",TD-related,test,complex_testing,5,171,0.011,0.93,0.059,0.8398
4351233,"unit testing, how far to take it when black box testing?","Greetings,I ran into a odd question.I believe when testing code, you drop in parameters x, y, z into a function, you need to test the output to insure that the work was done properly. But what if your code uses a facade pattern or contacts an internal source that you can query, but that would quickly causes tight coupling issues in the test code.Here is a example: class Notifier def send_notification action_string contact messaging server and deliver message endendclass DoSpecialStuff def my_method code.. code.. n = Notifier.new n.send_notification WOOT endendreNow, DoSpecialStuff.my_method doens't have any output, but the Notifier which is meant to abstract the complexity of where the output goes! Thus resulting in an untestable function!Do we test this code by doing this? def test assert_no_execption_raised do hurm... a test in name only? o = DoSpecialStuff.new o.my_method endendreNow, we can check where this message goes, but that takes away from the point of the facade object, we're trying to hide complexity.We can test the output, but should we? What is right and proper?-daniel",TD-related,test,coverage,4,173,0.04,0.932,0.028,0.6241
4444838,How do I measure the benefits of unit testing?,"I'm in the process of pushing my company towards having unit tests as a major part of the development cycle. I've gotten the testing framework working with our MVC framework, and multiple members of the team are now writing unit tests. I'm at the point, though, where there's work that needs to be done to improve our hourly build, the ease of figuring out what fixtures you need to use, adding functionality to the mock object generator, etc., etc., and I want to be able to make the case for this work to management. In addition, I'd like us to allocate time to write unit tests for the most critical pieces of existing code, and I just don't see that happening without a more specific case than everyone knows unit tests are good.How do you quantify the positive impact of (comprehensive and reliable) unit tests on your projects? I can certainly look at the number and severity of bugs filed and correlate it with our increases in code coverage, but that's a rather weak metric.",TD-related,test,"software_methodology, coverage, metrics",3,175,0.042,0.892,0.066,0.0525
4699430,Debugging HTML & JavaScript with Firebug,"I made a JSONP widget.However, when one of the partner sites put it in their page, (1) it doesn't render at all in IE and (2) in other browsers (Firefox & Google Chrome), the HTML of the widget renders incorrectly: the <aside> closes prematurely, before the Financial Aid Glossary. It's something specific to that page because it works fine on this example college resource center page.To fix these two issues, I tried saving the page source to a local file and messing around with the local file and with Firebug, deleting DOM elements and stuff. I even tried fixing the errors that The W3C Markup Validation Service found. But, I still couldn't get it to render correctly.How should I tell them to change their page so that the widget renders correctly? Or, how should I update the widget script I wrote?",TD-related,test,debugging,3,141,0.016,0.974,0.011,-0.168
7238105,Java unit testing - proper isolation?,"I'd like to know if my approach to unit testing has been wrong:My application has a boot strap process that initializes a several components and provides services to various sub-systems - let's call it the controller.In many cases, in order to unit test these sub-systems, I would need access to the controller as these sub-systems may depend on it. My approach to doing this unit test would be to initialize the system, and then provide the controller to any unit test that requires it. I achieve this via inheritance: I have a base unit test that initializes and tests the controller, then any unit test requiring the controller would extend this base class, and hence, have access to it.My question is this: (1) Is this achieving proper isolation? It makes sense to me that unit tests should be done in isolation so that they are repeatable and independent - is it ok that I am providing a real initialized controller rather than mocking it or attempting to mock the specific environment required by each test?(2) As a best practice (assuming that my previous approach is OK) - should I be creating the controller over and over for each unit test, or would it suffice to create it once (its state is not changing).",TD-related,test,"complex_testing, dependency, mock",4,213,0.05,0.879,0.071,0.5204
8620480,Will a development process that doesn't emphasize automated unit tests get worse with Scrum?,"I work in a development group with perhaps 120 developers, with smaller divisions within that. Our process is somewhere between waterfall and agile, more towards the former. We do NOT have our builds executing unit tests and there is only casual use of them in the various teams. Nothing resembling TDD happens here.We've been going through Scrum training, and are trying to use agile methods for some projects, and move others towards agile in the future.I've been concerned about our de-emphasis of automated unit tests for quite a while. During this Scrum/Agile training process, I've tried to make the point that the lack of automated unit tests in our builds could be a problem, even more so with agile processes, specifically using short iterations. The response to this from the ""movers and shakers"" is that this is an XP topic, and we're implementing Scrum.Assuming you agree with my concerns, what arguments could I present to the people who pay the bills that the development of a good automated unit test infrastructure (and understanding) needs to have higher priority?",TD-related,test,"software_methodology, automation",4,178,0.049,0.886,0.064,0.4084
9947241,Should I use TDD at the beginning of a new project?,"I am working on a new PHP project and while I like TTD, I am finding that it seem to be more hindering than being helpful at this stage of the project. I started off writing unit tests however now that I am deeper into prototyping of some the application features, I find myself rewriting bits and pieces of the core framework along with writing the tests. It just seems like I am spending a lot more time rewriting tests where maybe I should wait until I am in more of an alpha/beta phase of the project. Should I be writing unit test from the beginning even though there is a high chance I am going to have to rewrite them?",TD-related,test,software_methodology,2,121,0,0.913,0.087,0.8316
17105526,"Browser Overflow ... How to ensure Cross Browser, Cross Platform Testing and Compatability","My team is working on a new site which should be cross browser compatible (IE 8+, Chrome, Safari, Firefox, Opera) and cross platform compatible (Desktop, Tablet, Smartphone). We've been looking at a lot of the new methodologies for achieving this such as HTML 5, responsive design, using JS libraries that abstract a lot of the browser mess away from the user but since the browsers and even MVVM, but the one major issue that I've been facing is how fast the browsers are changing. With both Chrome and Firefox using a model of continuous delivery it becomes harder and harder to test. And from the looks of it other sites have the same problem (it seems like it's hit or miss these days as to whether a site will work in a particular browser)ulliWhat suggestions do you or your team have for testing new browsers as they come out? liWhat things do you do during development to decrease possibility of having code break when a browser update comes out?liAnd how do you decide when you will or will drop support for a browser version?",TD-related,test,complex_testing,2,184,0.055,0.899,0.045,-0.212
19659827,Spock Integration Test fails when run with other integration tests-succeeds in isolation using integration:spock,"I am adding a first spock integration test to an existing set of tests for a grails 2.1.1 application. The test runs and tests pass when run using: grails test-app integration:spock CreditServiceSpecre(Yes, everything is in the default package - fixing this is a ton of work that will not be approved...file under technical debt.)However, when I run all the tests (grails test-app), unit test pass, spock unit tests pass, integration tests pass, but I get the following failure for spock integration:block e | Completed 818 integration tests, 0 failed in 104001ms | Running 1 spock test... | Failure: CreditServiceSpec | groovy.lang.GroovyRuntimeException: failed to invoke constructor: public org.codehaus.groovy.grails.test.support.GrailsTestAutowirer(org.springframework.context.ApplicationContext) with arguments: [] reason: java.lang.IllegalArgumentException at grails.plugin.spock.IntegrationSpec.$spock_initializeSharedFields(IntegrationSpec.groovy:33) | Completed 0 spock test, 0 failed in 33ms | Tests PASSED - view reports in /Users/em*/emrojects/GrailsPlugins/DomainServices/target/test-reports/block eI get the exact same exception whether I run the full test I built or the following, very strip down example: import grails.plugin.spock.IntegrationSpecclass CreditServiceSpec extends IntegrationSpec { def setup() {} def cleanup() {} public void sample() { setup:Nothing to do here. expect:This is the truest of truths... true == true }}reI did crack open IntegrationSpec and looked at line 33: @Shared private autowirer = new GrailsTestAutowirer(applicationContext)reBut determining how/why the applicationContext is not being passed in properly is beyond me and, perhaps, is the thrust of my question.Has anyone encountered this kind of behavior and found a way to get spock integration to play nice with other tests? Thanks.",TD-related,test,debugging,3,239,0.103,0.803,0.094,-0.631
20995502,Tomcat with multiple instances of the same application,"We're building a java web application where each customer will have an instance of it with it's own database schema. It will be managed by my company so I would like to know what is the best approach to have several apps instances running on the same Tomcat runtime since we tried to run 3 instances on a single Tomcat and it ended up on an Out of memory exception.We considered to run multiple tomcat instances in the same server but we haven't already tested it. Also we are considering to have a separate server for each customer.From your experience with similar scenarios, what is your opinion?EDITED: This application can't be multi-tenant since there will be code customizations in some parts of it as well as some other business facts that require an application instance per client. So please the application architecture is not the subject here. Thank you,Gyo",TD-related,test,complex_testing,3,149,0,0.91,0.09,0.9149
24367789,SonarQube configurable technical debt,"We get a java app source code shipped from a partner, but it doesn't include test code.We want to run sonar qube against the code; but against our standard quality profile (PMD/Findbugs etc) technical debt gets skewed by no test coverage. I tried disabling the coverage rules, or setting the coverage ration to 0 but that just killed everything, no issues, no technical debt or useful feedback on the code.Can anyone suggest a ruleset or mechanism that would allow us to run a sonar report on the code and retain some of the useful feedback relating to technical debt? Other than writing a new plugin....",TD-related,test,"metrics, td_documentation, coverage",2,105,0.226,0.682,0.091,-0.9587
33734475,Inheritance of TestCases on Android,"I was wondering if it was good practice to subclass the test cases on Android. I mean, I need to test a lot of Parcelable objects and I could create a class like GenerericParcelableAndroidTestCase to test all these objects.
I also have a problem implementing it, I have something like this:
public class GenericParcelableTest extends AndroidTestCase {
private Parcelable p = null;
GenericParcelableTest(Parcelable p) {
this.p = p;
}
public void testDescribeContents() throws Exception {
assertEquals(0, p.describeContents());
}
}
And that:
public class AttachmentTest extends GenericParcelableTest {
public AttachmentTest() {
super(new Attachment());
}
}
Attachment implements Parcelable of course.
It returns me this error:
junit.framework.AssertionFailedError: Class GenericParcelableTest has no public constructor TestCase(String name) or TestCase()
I mean, I know that I created no empty constructor but why would I need one?
And generally, is there some known issues with this approach? If not why is there very few article on this topic on the internet (and actually some say even that it's not a good idea).",TD-related,test,"coding_standards, dependency",2,145,0.057,0.832,0.112,0.7428
36172204,"TDD. I have quite complex coding exercise, do I test private methods if they are very complex?","TDD. I have quite complex coding exercise, do I test private methods if they are very complex?So my class only exposes one public method, but contains few very complex methods, which should be tested I think?there is doubt: do I test them or not?",TD-related,test,"software_methodology, complex_testing",5,44,0.117,0.883,0,-0.6174
38563315,how do people struggling with TDD feel about leaving out the asserts?,"I've had a love/hate relationship with testing/tdd my whole career. Recenty I've started to enjoy writing tests by leaving off the assert statements. It's made all the difference in the world for me. Here's why:ullispeed close to where it was when I was not writing any tests.lii don't waste time trying to make assert(foo, 2) or !assert(foo, nil) logic at the end of each testliI just puts foo.inspect at the end of the test, run it, and move on when it's workinglithe next programmer still has a wonderful little test that shows my intent and knows this code was at one point working or it wouldn't exist.lithere's no breaking the build when tests fails because without asserts tests never fail.litests are not run 24/7 over and over to catch something. They are there when you want to debug some code and leave very nice notes to the next programmer (maybe you)lithere's no technical debt to pay down as years go by and tests break. The tests are always just there as archaeological relics of code that puts some useful information to the console at some point in time.My question is, is this like a known style of testing? Because I just found it out of necessity. But are TDD people using this sytem?",TD-related,test,"software_methodology, legacy",2,213,0.027,0.896,0.077,0.8312
40103805,Enzyme/React/Redux - Invariant Violation.,"Have some legacy code that I wrote without unit tests (I know, I know, bad engi, no cookie), but we were in a rush and literally needed the site to go up in a matter of days.Now I'm trying to pay off the technical debt. Most of it's easy, but I still have to test the react components. Trying to do so using JSDom and enzyme, but often get this error: block e Invariant Violation: Could not find store in either the context or props of Connect(ThankYou). Either wrap the root component in a , or explicitly pass store as a prop to Connect(ThankYou)./block eSo my question is: What's causing this error, and how should I approach this? I'm sure I'll have more questions, but this is the big blocker for now. So, here's the setup for the test:  import React from 'react';import chai from 'chai';const expect = chai.expect;import { shallow, mount } from 'enzyme';import ThankYou from '../src/frontend/js/containers/ThankYou';describe('  ThankYou /  ', () =   { it('is trying to get React testing to work', () =   { const wrapper = shallow(  ThankYou /  ); //(I know this test *will* fail, but it's failing in the wrong way.) expect(wrapper).to.eql({}); });});reHere's the component itself.  class ThankYou extends Component { constructor(props){ super(props); } render () { return (   Paper zDepth={1}      div   {thankYou.map((pgraph, i) =   (  div key={pg + i}   {pgraph[this.props.language]}   /div  ))}   /div     Social /     aper   ); }}// reduxify is a library I wrote which maps // state, actions, and dispatch to props. // source: https://github.com/brianboyko/reduxify/blob/master/reduxify.jsexport default reduxify(actions, ['language'], ThankYou);re",TD-related,test,"legacy, warnings",6,255,0.149,0.812,0.039,-0.9841
42363292,How can I implement unit tests in big and complex classes?,"I'm implementing unit tests in a finance system that involves several calculations. One of the methods, receives an object by parameter with more than 100 properties, and based on this object's properties, it calculates the return.In order to implement unit tests for this method, I need to have all of this object filled with valid values.br/br/So...question: today this object is populated via database. On my Unit Tests (I'm using NUnit), I'd need to avoid the database and create a mock object of that, to test only the method's return. How can I efficiently test this method with this huge object? Do I really need to manually fill all of the 100 properties of it?Is there a way to automatize this object creation using Moq (for example)?br/br/obs: I'm writing unit tests for a system that is already created. It's not feasible to re-write all the architecture at this moment.br/Thanks a million!",TD-related,test,"complex_testing, automation, mock",6,150,0.033,0.886,0.081,0.7474
44203976,What is the best strategy to do decoupling assemblies,"I got a problem with a legacy code base in my new company.Basically, they have 2 big code basesrojects or assemblies which I would say assembly A and assembly B. Also, we are having assembly Test A and assembly Test B.The problem I got here is assembly Test A is using some classes from assembly Test B. And assembly Test B is using some classes from assembly Test A. But not finish, assembly Test A is using some classes from assembly B. It is really nasty, I know that. That is the reason now in technically, we are having 2 separate projects but actually we put them in one package. Then you can imagine that every time we deploy A then we have to deploy B.My task is to decouple those assemblies or splitting them into 2 separate assemblyroject so it will be good for future deployment and testing and whatever.I came to a strategy which is a slow process but it might make sure that we still guarantee the functionalities. My initial strategy is that I will slowly remove the dependencies of assembly B in testing assembly A and make the tests pass with testing assembly A. It means I am removing dependencies of assembly B from assembly A. Next step is doing the same way with assembly B and finally we will have 2 completed separate assemblies.For me, I believe that it is not a easy task but I dont mind to work on that. However, I need your opinion or advises on my initial strategy. I dont want to take a risk of coming back to the beginning in the middle of that kind of project.
So could you guys give me any honest opinion or pieces of advice on that task?
I highly appreciate that.
Thanks",TD-related,test,"legacy, dependency",5,297,0.055,0.871,0.074,0.834
49172427,What to test after changing only the source and target version,"We have been following the official a href=http://www.oracle.com/technetwork/java/javase/8-compatibility-guide-2156366.html rel=nofollow noreferrerJava migration guide/a to upgrade our application from Java 6 to Java 8. Unfortunately we haven't set source and target version to 1.8 to prevent the usage of new language features. So currently we are compiling and executing our application with codeJDK 1.8 / JRE 1.8 but set source and target level to code1.6.Nevertheless, we now even want to level up the source and target level for our applications to 1.8. Does setting those properties only changes the allowed features for the compilation and the binary format of the classes or does the configuration changes the semantics of the application? We expect that there shouldn't be any known issues or incompatibility when updating the source and target version to a higher version, when staying on the same JRE for execution and JDK for compilation.",TD-related,test,dependency,2,143,0.012,0.97,0.018,-0.0516
50614573,turn on/off test in the source code,"I am reproducing a spreadsheet in python. The spreadsheet contains the data and the processing logic on every Monday not on the rest weekdays.I want to run the python code on everyday, if it is Monday, I want to compare the python result with the spreadsheet result. I have 20+ tests spread across the python code doing the comparisons.The tests include: 1) comparing data that I got from production database is the same as in the excel 2) comparing the python produces the same results as excel(the logic is the same) if the inputs are the same.How can I turn on the test for Monday, without inserting 20+ if Monday: run test_n to the python code?I don't think I can separate the test and the source code, since later tests takes inputs from previous processing steps.",TD-related,test,automation,2,136,0,0.957,0.043,0.5574
50756436,The cost of setting up tests in JUnit - using mocked objects versus repository-tests in legacy code,"I work on a project which has existed for many years. The time it takes to build the project with all tests is almost sensational (not in a good way). This is mainly due to a lot of modules, as well as heaps of unit tests which uses a repository to set up test data rather then to mock the desired behaviour. Unit tests using a repository use a lot of time for test setup, and they run quite slowly. This adds up to a lot of time as the system is quite large.We write all new unit tests by using Mockito to mock the repository (except when we are emactually/em testing the repository obviously). We also try to rewrite all existing unit tests to using mocks of the repository instead of an actual repository whenever we have the time and opportunity. Completely eliminating the use of repo's in our tests has a emhuge/em effect on how much time it takes to run the tests.A lot of the legacy code sets up its test data by using builders and test-utilities which in turn uses the repository. As the domain is quite complex, this often involves setting up a fair amount of objects and how they are related to each other. Re-writing a class of tests (say ~15 tests) to using only mocked object can therefore be quite time-consuming. And as everywhere else, time is not an infinite resource.If we are adding some new functionality to a class, it would be far easier to just write one new repository test (in addition to the existing 15) than to find out exactly how the test data needs to be set up by using different mock objects.I have tried to find some information on how and to what extent the test setup affects the actual time it takes to run the tests, but I have failed to find any useful information. My only facts are the observations I make when running a test class. The test setup for a repo test may easily take ~10 seconds, while the test setup for a mocked test class starts in less than a second.NOTE: I am aware that I can use JUnit Stopwatch to benchmark a single or a set of tests, but my question is more concerned with best practices than exactly how long it takes me to run my tests. I have two questions:olliSay I encounter a test class which already has 15 unit tests where none of them mocks any behaviour. I write a test and do a small fix in the class. I do not have the time to re-write the whole test class to mock objects. Should I just add a new test without mocking any behaviour and follow the existing (and bad) pattern? Does it really matter whether I have 15 non-mocked tests and 1 mocked test or if I have 16 non-mocked tests?liIn my test class with 15 unit tests, some of the tests are easier to refactor than others. Is it worth it to re-write only five of the tests to using mocked objects? Is it against best practice or in any other way not good to have a test class where some of the tests uses mocks and some don't?",TD-related,test,"legacy, mock",6,543,0.061,0.858,0.081,0.8963
51554308,mocking external service with mockito,"I have an application with following structure: block e Client class:/block e class Client{ private Requests requests; private Settings settings; protected Client(Settings settings){ this.settings = settings; this.requests = new Requests(settings); } public Requests getRequests(){ return requests; }}reblock e Requests class:/block e class Requests{ private RequestsHandler requestsHandler; private Settings settings; protected Requests(Settings settings){ this.requestHandler = new RequestHandler(); this.settings = settings; } public Bicycles getBicycles(BicyclesParameters bicycleParams){ return requestsHandler.callService(bicycleParams, settings, service/getBicycles, Bicycles.class) }}reAnd my block e RequestsHandler class: /block e class RequestsHandler{ public BaseResponse callService(BaseParams params, Settings settings, String serviceURL, Class  ? extends BaseResponse   responseType ) { here I use RestTemplate to get data from external Service } }reIn my Unit tests, I would like to mock the data from external service, so I did as following: create a mocking emRequestsHandler/em object, mock the emcallService/em method and register this mock object with em@Bean/em: @Configurationpublic class TestConfiguration { @Bean public RequestsHandler requestsHandler() { RequestsHandler requestsHandler = Mockito.mock(RequestsHandler.class); when(requestsHandler.callService(new BicyclesParameters(), new Settings(), /service/getBicyles, Bicycles.class)) .thenReturn(new Bicycles().setBicyclesList(new Bicycle[] {new Bicycle(), new Bicycle()})); return requestsHandler; }}reand my test class:  @RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(classes = TestConfiguration.class)public class TestGetBicycles{ @Test public void testGetBicycles() { Client = new Client(new Settings); Bicycles bicycles = client.getRequests.getBicycles(new BicyclesParamters()); assertNotNull(bicycles.getBicyclesList()); }}reBut when I run the test, I had two problems: olliI become an block e org.mockito.exceptions.misusing.InvalidUseOfMatchersException/block e, I have no idea why but when I changed my mock object to:   when(requestsHandler.callService(any(), any(), any(), any())) .thenReturn(new Bicycles().setBicyclesList(new Bicycle[] {new Bicycle(), new Bicycle()}));rethe error went away, but ol start=2lithe result I become is not the mock result, instead the result from the external service. This means the mock object was not taken into account. Can anyone help me at these points? This is my first time working with Mockito so I am so confused now.Thank you in advanced!",TD-related,test,"complex_testing, mock",2,289,0.129,0.82,0.051,-0.9688
52152618,"In a C++ unit test context, should an abstract base class have other abstract base classes as function parameters?","I try to implement uni tests for our C++ legacy code base. I read through Michael Feathers ""Working effectively with legacy code"" and got some idea how to achieve my goal. I use GooleTest/GooleMock as a framework and already implemented some first tests involving mock objects.To do that, I tried the ""Extract interface"" approach, which worked quite well in one case:class MyClass{...void MyFunction(std::shared_ptr<MyOtherClass> parameter);}became:class MyClass{...void MyFunction(std::shared_ptr<IMyOtherClass> parameter);}and I passed a ProdMyOtherClass in production and a MockMyOtherClass in test. All good so far.But now, I have another class using MyClass like:class WorkOnMyClass{...void DoSomeWork(std::shared_ptr<MyClass> parameter);}If I want to test WorkOnMyClass and I want to mock MyClass during that test, I have to extract interface again. And that leads to my question, which I couldn't find an answer to so far: how would the interface look like? My guess is, that it should be all abstract, so:class IMyClass{...virtual void MyFunction(std::shared_ptr<IMyOtherClass> parameter) = 0;}That leaves me with three files for every class: all virtual base interface class, production implementation using all production parameters and mock implementation using all mock parameters. Is this the correct approach?I only found simple examples, where function parameters are primitives, but not classes, which in turn need tests themselves (and may therefore require interfaces).",TD-related,test,"legacy, dependency",3,204,0.058,0.874,0.068,-0.3321
52450819,Black box testing a Node process making external requests with Jest,"I am currently working on a project where we have a backend process running (with codeprocess.env.NODE_ENV = 'test') and then test the backend by running a Jest instance which makes calls to the backend process. The current code base is not unit testable in its current state. There is a lot of technical debt, and we have only started implementing black box tests recently in an effort to help our team move faster.One of the things that we are having trouble testing is whether the backend process makes a proper request, appropriate amount of times, to external source under specific conditions. Additionally, to help us implement new features and make changes with confidence, we would really like a way to peer into the black box internals to at least test if certain blocks of code have been hit.We thought about the following solutions, but are unsure if they are good practices or how to best implement them with Node and Jest:1) Build a socket utility that for the backend that will only run when codeNODE_ENV==='test'. The socket utility will emit events that we can listen for within Jest to confirm the correct actions are occurring.2) Running the backend process through a proxy and somehow configuring Jest to see outbound requests the backend makes. Any advice or tools we could use would be greatly appreciated.",TD-related,test,"automation, coverage",5,224,0.032,0.86,0.108,0.9561
54411069,Testing a C class library that has an external dependency,"I'm working on a C class library that will import a JSON configuration file. It's not a straightforward use case as there are some legacy odds and ends to maneuver around. It's also partly a knowledge journey.I also don't have the time/money/support to do a full blown, SOLID, 100% covered TDD run at this. Technical debt is a thing, but I'll be can kicking for now. With that out of the way..I have two projects in my solution -   ClassLibrary ClassLibrary_Implementer (Console Application)reI put the Json.Net nuget package in the codeClassLibrary and just threw some code in to get started.Then I implemented that class in the codeClassLibrary_Implementer console application, where I get the following errorblock e System.IO.FileNotFoundException: 'Could not load file or assembly 'Newtonsoft.Json, Version=12.0.0.0, Culture=neutral, PublicKeyToken=30ad4fe6b2a6aeed' or one of its dependencies. The system cannot find the file specified.'/block eI want to be able to load this class into a few applications without adding the Json.Net additional dependency. Is there a setting in Visual Studio to make this happen that I missed? I know my approach is not the proper way, but I don't think I'm that far out of bounds. I am rusty, so who knows.",TD-related,test,"mock, management",4,197,0.025,0.943,0.033,0.1322
54643532,How to get test initialize in memory and use in each test,"I'm trying to create Unit Test. I have class User:
public class User
{
public int UsersCount
{
get
{
using (MainContext context = new MainContext())
{
return context.Users.Count();
}
}
}
public Guid Id { get; set; } = Guid.NewGuid();
public string UserName { get; set; }
public string Password { get; set; }
public Contact UserContact { get; set; }
}
My first test is UsersCount_Test test which tests UsersCount property:
[TestMethod]
public void UsersCount_Test()
{
var user = new User();
var context = new MainContext();
int usersCount = context.Users.Count();
context.Users.Add(new User());
context.SaveChanges();
Assert.AreEqual(usersCount + 1, user.UsersCount, $""It should be {usersCount + 1} because we're adding one more user"");
}
If I add new test method in my test class (I'm using separate classes for testing each entity), I need to create new instance of User. That's why I did this:
public class BaseTest<T>
{
public T TestEntity;
public MainContext TestContext = new MainContext();
}
Now each test classes inherits from this class. And also I created test initializer method. Now my test class looks like this :
[TestClass]
public class UserTest : BaseTest<User>
{
[TestMethod]
public void UsersCount()
{
int usersCount = TestContext.Users.Count();
TestContext.Users.Add(new User());
TestContext.SaveChanges();
Assert.AreEqual(usersCount + 1, TestEntity.UsersCount, $""It should be {usersCount + 1} because we're adding one more user"");
}
[TestInitialize]
public void SetTestEntity()
{
TestEntity = new User();
}
}
Now I'm adding new property to User and writing some logic:
string phoneNumber;
public string PhoneNumber { get { return phoneNumber; } set { SetUserContact(phoneNumber, value); phoneNumber = value; } }
void SetUserContact(string oldContact, string newContact)
{
UserContact.ContactsList.Remove(oldContact);
UserContact.ContactsList.Add(newContact);
}
After that I'm creating new test :
[TestMethod]
public void ContactList_Test()
{
var newPhone = ""+8888888888888"";
TestEntity.PhoneNumber = newPhone;
Assert.IsTrue(TestEntity.UserContact.ContactsList.Any(a => a == newPhone), $""It should contains {newPhone}"");
}
Test fails because UserContact of TestEntity is null. I understood that TestEntity should be created by logic. After that I fix test initilizer method:
[TestInitialize]
public void SetTestEntity()
{
TestEntity = new User() { UserContact = new Contact() };
}
Here is Contact model
public class Contact
{
public Guid Id { get; set; } = Guid.NewGuid();
public virtual List<string> ContactsList { get; set; } = new List<string>();
}
My question is how to set TestEntity only one time, is it possible (maybe get it in memory and use it when it calls SetTestEntity method)? Because SetTestentity method creates a new entity in each test and it takes more development time. (For example, If creating an instance of UserContact takes 3 seconds all, test runs more than 3 seconds). Another way, in this case, is to set UserContact in ContactLists test, but I think it's not a good idea. In the future when we will add new logics, I need to fix each test. Please give me any suggestion and/or ideas.",TD-related,test,coding_standards,3,386,0.013,0.944,0.044,0.7384
55671363,Automatic low level testing generation based on high level desired behavioral examples,"Top Level Problem/Our team has inherited a very large and brittle python 2 (and C,C++, few others) codebase that is very difficult and costly to update. Tons of dependencies. Very few tests. Adding behavior improvement and converting to python 3 both have appeared to be monumental tasks. Even making small changes for a new release we've had to revert many times as it's broken something.It's a story of insufficient testing and its major technical debt.Still, the project is so big and helpful, that it seems a no brainer to update it than re-invent everything it does.Sub Problem/How to add a massive amount of missing small tests. How can we automatically generate even simple input/output acceptance unit tests from the high level user acceptance tests?Attempted Solution/There are about 50 large high level behavioral tests that this codebase needs to handle. Unfortunately, it takes days to run them all, not seconds. These exercise all the code we care the most about, but they are just too slow. (Also a nerdy observation, 80% of the same code is exercised in each one). Is there a way to automatically generate the input/output unit tests from automatic stack examination while running these? In other words, I have high level tests, but I would like to automatically create low level unit and integration tests based on the execution of these high level tests.Mirroring the high level tests with unit tests does exactly zero for added code coverage, but what it does do is make the tests far faster and far less brittle. It will allow quick and confident refactoring of the pieces.I'm very familiar with using TDD to mitigate this massive brittle blob issue in the first place as it actually speeds up development in a lot of cases and prevents this issue, but this is a sort of unique beast of a problem to solve as the codebase already exists and works ;).Any automated test tool tips? I googled around a lot, and I found some things that may work for C, but I can't find anything for python to generate pytests/unittest/nose or whatever. I don't care what python test framework it uses (although would prefer pytest). I must be searching the wrong terms as it seems unbelievable a test generation tool doesn't exist for python.",TD-related,test,"automation, complex_testing, coverage, missing_tests",4,381,0.056,0.856,0.089,0.9177
57314768,Adding in assembly info configuration for log4net into .NET Core xunit project,"We are creating an XUnit test project in .NET Core 2.1 for an application that is .NET Framework 4.6.1 so we can test the changes made for features and technical debt cleanup. We've run into a snag with one of our more important unit tests that caused us to add in Log4Net NuGet package into the unit test project. With it added in we get the following error: Message: System.MissingMethodException : Method not found: 'log4net.ILog log4net.LogManager.GetLogger(System.String)'.reWith a bit of research, I found that the error is caused by a lack of configuration for the project missing the XMLConfigurator. Normally, in .NET Framework, you would edit the AssemblyInfo.cs file with the line (according to previous stack overflow answers): [assembly: log4net.Config.XmlConfigurator]reHowever, we don't have an AssemblyInfo.cs file, any app.config file, or json configuration files. In .NET Core, do I need to add in this configuration? Do I add it (and how) into the .csproj file? We don't have a single entry point for the project because it just is xunit tests which is something some people are talking about it. Do I need another configuration file? I can't seem to find a coherent or a complete answer. Thank you.",TD-related,test,debugging,5,197,0.066,0.9,0.035,-0.7308
400479,When will it be impossible to support Visual Basic 6.0 applications?,"In the last 3-5 years I have been renewing an insurance application and a commmercial integration toolkit based on Visual Basic 6.0.According to Microsoft's a href=http://msdn.microsoft.com/en-us/vbasic/ms788708.aspx rel=noreferrerIt just works policy/a the IDE is no longer supported after april 8th 2008.It still works to develop and deploy Visual Basic 6.0 applications.When will it be impossible to support Visual Basic 6.0 applications, or will they live forever like Cobol applications do?Update: Microsoft statement march 2010: The Visual Basic team is committed to It Just Works compatibility for Visual Basic 6.0 applications on Windows Vista, Windows Server 2008 including R2, and Windows 7.Update may 2011:br/a href=http://blogs.msdn.com/b/vbteam/archive/2011/05/20/happy-20th-birthday-visual-basic.aspx rel=noreferrerHappy 20th Birthday Visual Basic!/a",TD-related,versioning,"dependency, framework, outdated",1,108,0.02,0.892,0.088,0.7712
631900,"Branching hell, where is the risk vs productivity tipping point?","My company is floating the idea of extending our version numbers another notch (e.g. from major.minor.servicepack to major.minor.servicepack.customerfix) to allow for customer specific fixes.This strikes me as a bad idea on the surface as my experience is the more branching a product does (and I believe the customer fixes are branches of the code base) the more overhead, the more dilution of effort and ultimately the less productive the development group becomes.I've seen a lot of risk vs productivity discussions but just saying I think this is a bad idea isn't quite sufficient. What literature is there about the real costs of becoming too risk averse and adopting a heavy, customer specific, source code branching, development model?A little clarification. I expect this model would mean the customer has control over what bug fixes go into their own private branch. I think they would rarely upgrade to the general trunk (it may not even exist in this model). I mean why would you if you could control your own private reality bubble?",TD-related,versioning,brenching_hell,2,171,0.078,0.913,0.009,-0.897
670909,Multiple WMD editors (SO forked version) on one page?,"To be clear, I'm referring to the usage of a href=http://github.com/derobins/wmd/tree/master rel=noreferrerstackoverflow's forked WMD/a, emnot/em the a href=http://wmd-editor.com/ rel=noreferreroriginal version from attacklab/a. I'd like to use the forked version, however it seems that the div id's which are used by the script to identify the page elements to WMDify are hardcoded in codewmd.js:66: // A collection of the important regions on the page.// Cached so we don't have to keep traversing the DOM.wmd.PanelCollection = function(){ this.buttonBar = doc.getElementById(wmd-button-bar); this.preview = doc.getElementById(wmd-preview); this.output = doc.getElementById(wmd-output); this.input = doc.getElementById(wmd-input);};reIf I just wanted to use different region names I'd be fine on my ownbut I want to use a variable number of WMD editors on a single page. I'd need a way to tell each instance of WMD about the page regions it should affect, but I don't see any 'hooks' for that.The not-seeing is likely a product of my almost complete lack of js knowledge. The Right Thing To Do trade; is to just learn javascript properly, but I'm in the middle of a project with a deadline. I'd really like to use this version of WMD but I need some clues on how to go about modifying the WMD script, or perhaps simply an example of how to call it in such a fashion that I can speficy which div id's to use.Clues appreciated!",TD-related,versioning,"dependency, framework, outdated, multiple_versions",4,223,0.012,0.91,0.078,0.8782
824367,When to upgrade to a new version of a language or framework?,"When a new version of a framework or language appears (e.g. .NET 3.5, SQL2008), what approach do people take to when to adopt/upgrade?Generally developers will say as soon as possible (they want it on their CV and from a management perspective giving them what they want provides a motivation boost) but commercially there is often little incentive (few clients demand the latest version) and from a cost perspective (retest, training) there is often a disincentive.I'm particularly thinking of on-going systems and projects (such as in a software house) which exist and evolve over years where taking the new projects use the new technology approach doesn't work.Are people driven by specific requirements (the need to use a new feature, a potential or existing client demanding support for it), do they formally assess it (in which case what are the criteria) or do they upgrade as a matter of routine (in which case when - leading edge vs. bleeding edge)?Do people think that not being on the latest version of something should be considered technical debt and managed as such?Or is if it ain't broke don't fix it a valid approach?",TD-related,versioning,"outdated, management",2,189,0.039,0.871,0.09,0.7794
4211158,What might cause a performance drop after migrating a WPF project from 3.5 to 4.0?,"When I compile my application to target version 4.0 of the framework, UI performance goes straight to hell. For instance, opening an Expander that contains a Grid with maybe 6 Label and TextBox controls goes from near-instantaneous to 3-4 seconds, and there's then a visible delay between the time it renders the grid's second column (the editable controls) and the first (their labels).If I drop back to 3.5, everything goes back to the way it was: there's virtually no lag between opening an Expander and seeing its contents, and the labels in the grid render so quickly that you can't see it happen.There are, of course, a million things that could conceivably cause this. I guess what I'm hoping someone can tell me is where I should start looking. I don't especially emneed/em to upgrade to 4.0 right now, so I don't have a huge incentive to dig into profiling this beast, but if I'm accumulating technical debt while I sit here at 3.5 I'd like to know about it.",TD-related,versioning,upgrade_issue,4,170,0.093,0.868,0.039,-0.7284
8606944,Git feature branches and minor code improvements,"We just started using git for our production code, and we are running into a slight issue in our workflow. We need to figure out how to handle general code improvements / technical debt fixes that come up while working on a feature.The workflow we have adopted is to use 'develop' as the main integration branch and develop all features on feature branches off of 'develop'. When a feature is complete, the developer creates a pull request and everyone reviews it to provide comments before it is merged back into develop. This seems to be working very well.The issue we have is that during routine development on a feature, the developer may end up wanting to modify/refactor some common code to improve the system or clean up some technical debt. This change is valuable, but not directly tied to the feature under development.Based on our workflow, it should really be done on a different branch that goes through it's own pull request and code review before getting into develop. If we have them do this though, how can they get the change back over onto their feature branch in the meantime while they wait for the full code review to happen and the code to get merged into develop.The ideas we have are:1) cherry-pick the changes from the 'refactorX' branch into our feature branch. Continue developing and let git (hopefully) figure out when we merge back to develop that it already has the change from the refactor branch.2) Merge the 'refactorX' branch into our feature branch and continue development. (note: the branch off develop for 'refactorX' may have been later in the history of develop, so we think this may have problems)3) Some other smarter option we don't know yet. :)What we are looking for is some best practice guidance on how to handle this part of the workflow. After talking about it more we know that it will come up frequently and we want to find a smooth and efficient way to handle it in our workflow.Any recommendations?",TD-related,versioning,brenching_hell,2,339,0.01,0.921,0.069,0.9612
10629228,Redirecting from a legacy Servlet to Spring 3 and from Spring 3 to a legacy Servlet,"I'm learning Spring by integrating Spring 3 into a legacy Servlet application and gradually converting the legacy app over. A web.xml *-servlet.xml similar to the ones I am using are posted below. Basically things are set up such that retrieving a string like search, Spring will route it to a Controller and the view resolver will convert search into /jsp/search.jspI ran into problems doing a response.sendRedirect(search) from a legacy Servlet and a legacy ServletFilter To Spring. The URL came out correctly, but I got a blank page despite System.out.println() calls indicating that the JSP was reached. No error messages from Spring and the browser only told me something went wrong with the redirect.I fixed that problem by forwarding, instead of redirecting from the legacy Servlets and ServletFilters: <code>",TD-related,versioning,upgrade_issue,2,128,0.123,0.841,0.036,-0.9217
11165034,Downgrading Michael Hartl's Rails application to Rails 2,"I built (hacked) my web app by extending Michael Hartl's Rails 3 tutorial, only to discover that my web hosting service requires Rails 2.3.8. I am a complete newbie to Ruby/Rails, and was wondering how feasible a downgrade from Rails 3.x to Rails 2.x would be.Unfortunately my webhost is not able to upgrade to Rails 3.EditTo be more specific: my application is largely based on the tutorial mentioned above. I am looking to determine what type of effort is involved in downgrading the Rails 3 tutorial application into a Rails 2 application. I will try it out anyway, but due to my inexperience with Ruby / Rails, before I started I just wanted to get an idea of what to expect (i.e., if there will be a lot of syntax changes, or will I have to restructure the file directory, etc.)",TD-related,versioning,upgrade_issue,3,141,0,1,0,0
11261396,How can I make the deprecated functions to work in PHP's latest version?,"How can I make the deprecated functions to work in PHP's latest version? I don't want to change the alternate function of it in each and every page, it's highly impossible in the maintenance project which I have. So please let me know if there is a way to make the deprecated functions to work.",TD-related,versioning,upgrade_issue,4,55,0.023,0.928,0.049,0.3337
13400532,SVN externals alternative in team foundation server 2012,"Currently we use SVN for our source control. Because of the extra features and integration in the development environment we would like to migrate to TFS 2012.We have a lot of portals running that are build in asp.net. Within our portal we use a lot of standard components. Currently all portals use the same code base. This means that whenever we change something in the shared codebase it is (whenever a portal is published) automatically distributed. We are very used to this way of working and we know there is a risk of breaking code in other portals. Though, publishing changes in all other portals would cost way to much time. So to do this we use externals in SVN.I would really like to keep this functionality up and running. So my question is, is there a way to create a external like system in SVN or is there a realy good way that works just as efficient to replace this functionality.",TD-related,versioning,brenching_hell,2,162,0.013,0.882,0.105,0.9274
15068491,How to use a jquery plugin which uses latest version of jquery than being used in application?,"I have a web application which uses jquery version x.x.1. Now we want to use a plugin which uses version x.x.5.Please see below,    <code>Here my plugin is not wporking at all. If I remove the first jquery it works.I tried using jQuery.noConflict(), but no use.Note:- Since this is old application developed by someone else, we dont want to touch their scripts or upgrade the jquery version altogether as it may break some code which we may not be even aware of.The application seems to be using many versions of jquery altogether and its creating a lot of problems and confilcts at so many places.Please help.",TD-related,versioning,multiple_versions,3,105,0.058,0.857,0.085,0.249
15896780,Combining many JS files with Rails Asset Pipeline,"I am making a long-overdue upgrade from Rails 3.0.20 to Rails 3.1.10. (Later I'll upgrade to 3.2, but I want to get the more major changes in 3.1 working with my codebase first. I don't have a test suite, so please bear with me as I overcome quite a bit of technical debt. Thankfully, the app isn't that large or complex.)I've always had separate JS files for the various views in my app. Now, Asset Pipeline wants to combine all of those into one file. Problem is, a lot of my variables and function names collide and generally just cause problems.My assumption is that I need to use some kind of namespacing here, and then initialize the code in a particular namespace on the page that needs it.Is there a standard way to do this? Or, is there a better way overall?One note of clarification: I'm not ready to switch to CoffeeScript yet.",TD-related,versioning,upgrade_issue,3,153,0.068,0.828,0.104,0.7705
19559093,Sonar broken after updating: The plugins 'findbugs' and 'java' must have exactly the same version as they belong to the same group.,"The sonar instance on ubuntu 12.1 is broken since i upgraded to the latest version (via apt-get upgrade). The Web-UI is not accessable, and returns a 503: <code>.<code>What i've tried:Updating the packages in the plugins folder, to the latest from a href=http://docs.codehaus.org/display/SONAR/Java+EcosystemSonar Ecosystem/a no they were all sonar-*-1.4.jar How can i update the findbugs and java plugin without accessing sonar?",TD-related,versioning,upgrade_issue,2,60,0.089,0.911,0,-0.6486
21911063,Using Legacy Outer Join Syntax,"I need to make a change in a legacy SQL System (on the servers, its still on 2008R2 and 2000 Compatibility mode). My local DB is SQL 2012 - so the lowest compat mode I can get to is 2005.Unfortunately there are a bunch of Procs using the Legacy (a href=http://msdn.microsoft.com/en-usbrary/aa213228%28v=sql.80%29.aspx rel=nofollowPre-SQL92/a) join syntax - i.e. code*= and code=*. It's beyond the scope of my current work to fix this (although I have flagged it up the chain as a technical debt). Is there a way to enable this syntax in SQL 2012 for this particular DB?",TD-related,versioning,"upgrade_issue, multiple_versions",3,97,0.032,0.944,0.024,-0.1725
26127900,"TFS Branch for Custom Version, Excluding those Customizations from Merging Back?","I recently inherited an ASP.Net Web Forms project that has no version control and I am trying to move it into TFS. At some point the project was split to make a custom version for a client where the login uses ADFS instead of our database-driven form. After the split some features were added to the main version to manage users; these were not needed in the custom version. Any changes to one version were manually applied to the other if they affected the non-customized parts (although, predictably, this was sometimes forgotten). Each version had a folder on the dev and production servers, so the folder structure is like this: roduction/Generalroduction/Custom/Dev/General/Dev/CustomreAssuming it would be difficult to merge the two versions completely with feature toggles, what is the best approach to managing this?I was thinking I could use diff to pull out what the production versions have in common and make that my MAIN branch. I could then make the two production versions branch from MAIN and have their current state as the first check-in, then do a similar thing for the dev folders, like this: - MAIN | |- General | |- GeneralDev | |- Custom |- CustomDevreHowever, I'm not sure how to manage merging. Is there a way to prevent certain files from merging only between certain branches? If I make a change in CustomDev I want to merge it normally to General, then I want to be able to get that change over to General and GeneralDev without pulling all the other customizations that Custom has...Is there a way to do this well (without having to exclude files every time I merge), or do I just have to treat these as two separate projects and synchronize changes manually?",TD-related,versioning,brenching_hell,3,290,0.035,0.886,0.079,0.8898
27356230,How can I resurrect a branch?,"I have a refactoring/cleanup branch codecleanup where I clean up technical debt. After going through one cycle, I merge this branch back into codemaster.A few weeks later, I have the time to clean up some more and I wanted to resurrect the branch instead of creating a new one. So I pulled codemaster and then moved the local branch pointer for codecleanup to codeHEAD:    git show HEADcommit dd61...   git branch -f cleanup dd61...   git checkout cleanupreAfter this, I could pull and push and the history looked correct. But I had some subtle problems when trying to pull in the latest changes and do a rebase. My usual workflow to rebase the current branch is:    git pull origin master   git rebase masterreBut when I do it with the resurrected branch, then the codegit pull will already start a merge or maybe even a rebase even though I didn't specify code--rebase.My guess is that I should have moved the remote branch pointer as well. I did push codecleanup after the codecheckout above but maybe that wasn't enough?Can someone explain what is going on in my situation and how I can resurrect a shared (= was pushed to codeorigin) branch correctly?",TD-related,versioning,brenching_hell,4,198,0.028,0.891,0.082,0.8559
28110786,How to create a patch system,"I have a question about best practice to make our software patch-able.Some information abour our product/company:olliWe create our software use C/WPFliUse Visual Studio 2013liHave some setup-maker (Advanced installer)liUse TFS for source control.Every time we create a release, we put it into a new branch in the tfs, so that the structure look like this:ulli-- Mainli-- Releasesli---- Version 1.0.0.0li---- Version 2.2.0.0li---- Version 3.3.0.0 (not real version numbers).Now i have the problem, that i don't know how to make our product patch-able, without making a patch for every version. Because if a bug is in version 1.0.0.0 and 2.2.0.0 and i don't want to install the newest version (3.3.0.0), i need to fix both versions (1.x and 2.x).Is there a way to make this more elegant and comfortable for me?Thank you!",TD-related,versioning,brenching_hell,4,129,0.03,0.833,0.137,0.9352
28113104,How to relate change set with a user story or task using TFS 2013 and visual studio 2013,"Hi trying to implement TFS for my team (18 members).I made two branches 1) Main branch 2) Dev branchWe are using Agile.So there is a sprint every week. And on every Thursday i merge changes from Dev to main Branch.Each developer works on different user story. if he completes a task and check in all changes (5 files). change set (e.g 62) is generated. But tester reported a bug while unit testing. Developer fix the error and check in 1 file. it generated a new change set (e.g 63).Problem is when i am merging user story's change to main branch i am confused with which change set to move. (62,63....)what i do is compare whole project. which is headache some times.Can some one suggest better way. Or i am missing something? any blog that can helpThanks",TD-related,versioning,brenching_hell,5,136,0.069,0.903,0.028,-0.6652
30426867,"How to merge a git branch that results in only a single commit (like using --squash), but allowing future merges without conflicts?","I have a branch with many commits in it since creating it and would like to make a single merge commit to move it back to master, usin a single commit. So the only solution I know if is to use git merge --squash branchname. This works well, but if someone adds more commits to branchname and I again merge it into master, I get conflicts from the initial new commits on branchname. How do I prevent merge conflicts, while still only keeping a single commit in master for each merge? I have looked into using git merge --no-ff but that still moves all the commits from branchname into master.",TD-related,versioning,brenching_hell,3,110,0.061,0.774,0.165,0.3678
46508918,How to maintain two or more divergent branches that never merge?,"I'm maintaining a a href=https://github.com/monospice/laravel-redis-sentinel-drivers rel=nofollow noreferrerRedis Sentinel library for Laravel/a in git with two active development branches: 1.x ... o  o  o  o  o  o  o ...    2.x (breaking change)  o  o  o  o  o ...reAs illustrated above, I forked em1.x/em to accomodate breaking changes from a newer version of the framework that this library integrates with, but I find myself codecherry-picking commits or manually copying code between branches that update common functionality in both branches.It seems like I can never merge these branches because they each contain code that is not compatible with the other. What better workflow can I follow to reduce the effort needed to merge common changes between the branches?",TD-related,versioning,"brenching_hell, multiple_versions",4,129,0,0.903,0.097,0.8442
48188786,Releasing parts of a multi-module project,"Assume I have a multi-module project with three modules A, B, C where A depends on B and B depends on C. Assume now I make a change in B. Then I would like to release new versions of B and A. Releasing C would be strange because it did not change nor did any of its dependencies. So B could still depend on the last release version of C. How would I handle this? Or is my logic flawed and I should always release all modules?",TD-related,versioning,brenching_hell,3,87,0.024,0.938,0.038,0.264
50026796,combining two git repositories,"We have some wierd situation with our git repository.The intended workflow was to create our own fork of an open source project with some chnages of our own.The repo was initially created by copying an open source project files without the history and it worked.When we wanted to update the underlying open source repo, instead of merging we again copied the files and used a diff tool to resolve manually. This was and is a pain that we really want to end.We want to finally pay the technical debt and start using git in the intended way. What possible ways can we fix it while retaining our history and finally having the underlying open source's history.Note our project is used as a submodule so we can't create a new repository without serious ramifications.Is this fixable with some secret features of git and lots of cleverness?",TD-related,versioning,"brenching_hell, multiple_versions",5,145,0.047,0.846,0.107,0.7437
56108148,How do I achieve/setup GitFlow in AzureDevOps repos with PR branch policies on master and develop?,"How can I achieve Git Flow on my Azure Repos when I have pull request branch policies on master and develop branch? I'd love to get it working but I don't know the best practice. I currently have gitflow etup on my Azure Git repo but I have PR branch policies on master. How can I finish releases or hotfix branches if the push to master will fail because there is no PR created. Similiarly, if I have PR branch policy in AzureDevOps repo for my develop branch, I cannot ""finish"" my feature using ""git flow feature ...finish"" because the push to develop branch will failI've tried it without PR branch policies on develop (for finishing features) and master (for release merge and /or hotfix merge)I've tried to consult the branch strategy guide for AzureDevOps but it makes no mention of GitFlow https://docs.microsoft.com/en-us/azure/devops/repos/git/git-branching-guidance?view=azure-devops#manage-releasesThe guidance is more directed at creating feature branches from ""master"" for new features and merging back with PR and then for releases it suggests your create release and hotfix branches from master that are never merged back.Expected: be able to finish features and merge back to develop via PR be able to finish releas and hotfix and merge back to master and develop via PR at the same time.Actual: Finishing a feature. release or hotfix fails when attempting to merge to any branches that have PR branch policy on them (master, develop)",TD-related,versioning,coding_standards,5,235,0.093,0.864,0.043,-0.941